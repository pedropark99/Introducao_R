[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introdução à Linguagem R",
    "section": "",
    "text": "Prefácio",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#bem-vindo",
    "href": "index.html#bem-vindo",
    "title": "Introdução à Linguagem R",
    "section": "Bem vindo!",
    "text": "Bem vindo!\n Você está no site do livro “Introdução à Linguagem R: seus fundamentos e sua prática” escrito por Pedro Duarte Faria. Esta obra, tem como objetivo, ensinar os fundamentos da Linguagem R e como eles se aplicam na prática de análises de dados. Alguns temas incluem: estruturas e tipos de dados; coerção e subsetting; importação de dados e operações sobre tabelas; dados relacionais e join’s; geração de gráficos; controles de fluxo, funções e loop’s; datas e fatores; dentre outros.\nAtravés deste site, você pode ler o livro completo gratuitamente. Você também pode comprar uma versão física ou em Ebook deste livro na Amazon. Atualmente, o livro se encontra em sua 5° edição, e está licenciado segundo a Licença Creative Commons - Atribuição - NãoComercial 4.0 Internacional. Você pode visitar a página dessa licença.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#a-história-deste-livro",
    "href": "index.html#a-história-deste-livro",
    "title": "Introdução à Linguagem R",
    "section": "A história deste livro",
    "text": "A história deste livro\nEste livro surgiu inicialmente, como um material de apoio aos pesquisadores e alunos do Curso Introdutório de R, que foi realizado durante o primeiro semestre de 2020, na Fundação João Pinheiro1(FJP-MG).\nO projeto foi idealizado na época, por um conjunto de três pessoas. Dentre elas, estão os autores da primeira edição desta obra: Pedro Duarte Faria e João Pedro Figueira Amorim Parga. Portanto, esse material é resultado dessa experiência de ensino, onde buscamos compartilhar conhecimentos sobre essa linguagem com outras pessoas.\nEu (Pedro) como professor, aluno e economista, sou muito grato por ter compartilhado essas experiências, com meu querido colega João Pedro Figueira Amorim Parga, que me ajudou a montar a primeira edição deste livro. Após a primeira edição desta obra, o livro continuou sendo mantido e desenvolvido por Pedro Duarte. Desde então, o livro já passou por várias revisões, buscando sempre refletir os padrões mais modernos da Linguagem R. O livro já foi inclusive reescrito do zero, passando por uma reformulação completa durante o ano de 2021.\n Pedro Duarte Faria 22/05/2024 Belo Horizonte - MG Brasil",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#sobre-o-autor",
    "href": "index.html#sobre-o-autor",
    "title": "Introdução à Linguagem R",
    "section": "Sobre o autor",
    "text": "Sobre o autor\nPedro Duarte Faria\nPedro Duarte Faria é economista formado pela Universidade Federal de Ouro Preto - UFOP. Atualmente é Data Platform Engineer em Blip, e Associate Developer for Apache Spark 3.0 certificado pela empresa Databricks.\nO autor conta com mais de 5 anos de experiência no mercado de análise de dados, construindo pipelines, relatórios e análises para instituições de pesquisa e algumas das maiores empresas do setor financeiro brasileiro como o Banco BMG, Sodexo e Banco Pan, além de lidar com algumas bases de dados que passam do bilhão de linhas.\nAlém dessas experiências, Pedro já ministrou vários cursos sobre a linguagem R, dentro de centros de pós-graduação (como o PPEA-UFOP2) além de organizações federais e estaduais (como a FJP-MG3). Como pesquisador, tem experiência em especial na área de Economia da Ciência, Tecnologia e Inovação.\nLattes: http://lattes.cnpq.br/0308632529554550\nSite pessoal: https://pedro-faria.netlify.app/\nTwitter: @PedroPark9\nMastodon: @pedropark99@fosstodon.org",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#qual-o-objetivo-deste-livro",
    "href": "index.html#qual-o-objetivo-deste-livro",
    "title": "Introdução à Linguagem R",
    "section": "Qual o objetivo deste livro?",
    "text": "Qual o objetivo deste livro?\nAs origens da linguagem R, remetem a um dos mais importantes laboratórios de pesquisa do mundo, a Bell Labs, localizada nos EUA. Por sua origem, a enorme maioria dos materiais de referência a respeito da linguagem, estão em inglês, incluindo as principais fontes de ajuda da linguagem, como o StackOverflow4, ou as páginas e manuais internos do CRAN R5.\nEntretanto, a comunidade de R no Brasil, tem se expandido constantemente nos últimos anos. Brasileiros tem desenvolvido importantes pacotes para a linguagem, que trazem grande apoio à produção científica do país. Apenas para citar alguns desses excelentes trabalhos, estão (BRAGA; ASSUNCAO; HIDALGO, 2020; MCDONNELL; OLIVEIRA; GIANNOTTI, 2020; PEREIRA et al., 2020; PETRUZALEK, 2016; SIQUEIRA, 2020).\nComo resultado, bons materiais em português, de referência e apoio à linguagem tem surgido. Exemplos são: os materiais curtos montados pelo Curso R6; os trabalhos realizados pelos capítulos brasileiros do grupo R-Ladies7, como os posts do capítulo de Belo Horizonte8, e os encontros desenvolvidos pelo capítulo de São Paulo9; além de alguns materias produzidos pelo Departamento de Estatística da UFPR, como um site de apoio ao seu curso10, ou este produzido por um dos professores do departamento, o Dr. Walmes Marques Zeviani11.\nPorém, mesmo com esse avanço, grande parte desses conteúdos em português geralmente caem em algum desses dois problemas: 1) carecem de profundidade, ou de detalhamento sobre o que está “ocorrendo nos bastidores”. Em outras palavras, esses materiais são muito abstratos, pois tentam abordar muita coisa em um espaço muito curto, sem dar o devido tempo a cada um dos componentes por trás da linguagem; 2) ou são especializados demais. Por exemplo, materiais que ensinam como estimar modelos específicos (ex: regressão linear sobre dados em painel), ou a trabalhar com bases de dados específicas (ex: PNAD contínua). Em outras palavras, esses materiais concedem em geral, uma visão muito restrita sobre a linguagem, e que é de difícil transposição para outros cenários e necessidades práticas.\nEsses problemas emergem do próprio objetivo que esses materiais buscam cumprir. Como exemplo, os materiais escritos pelo Curso-R carregam certa abstração, pois em nenhum momento esses materiais pretendem oferecer uma revisão completa e profunda sobre o tema, mas sim, tutoriais rápidos e úteis, que lhe mostram o básico.\nTendo isso em mente, esta obra em específico, representa uma tentativa de combater esses dois problemas. Ao discutir pacotes largamente utilizados nas mais diversas aplicações, além de fornecer uma visão aprofundada sobre os fundamentos (ou a teoria) da linguagem R. Por isso, o público-alvo deste livro são os brasileiros que desejam obter uma base mais sólida e uma visão mais abrangente da linguagem, de forma que eles possam identificar mais facilmente, as possíveis soluções que o R oferece para vários problemas de seu trabalho.\nComo resultado, este material é até certo ponto, prolixo em muitos assuntos aos quais são comumente tratados como simples e rápidos de se compreender (e.g. Objetos). Ao mesmo tempo, este material certamente busca ser descritivo, e não poupa detalhes em assuntos que são complexos e de difícil compreensão (e.g. Funções e Loops). Para mais, fornecemos ao longo da obra, diversos diagramas e representações visuais, que ajudam o leitor, a formar um modelo mental sobre como a linguagem R funciona. A obra também oferece exercícios ao final de cada capítulo, e suas respostas estão disponíveis na página de publicação do livro.\nVários exemplos são fornecidos em cada tópico. Alguns desses exemplos são reais e retirados diretamente de nosso dia-a-dia com a linguagem. Já uma outra parte desses exemplos, buscam evidenciar ou demonstrar problemas práticos que podem emergir de seu trabalho com a linguagem e, portanto, mostrar quais são as possíveis soluções a serem empregadas. Dessa forma, podemos construir um workflow, ou um modelo mental de trabalho com a linguagem, ao longo de diferentes tópicos importantes para a sua aplicação prática em análise de dados.\nVocê sempre pode encontrar uma versão atualizada desta obra, em sua página de publicação12. O livro foi criado e é até hoje desenvolvido por meio do pacote rmarkdown e do sistema LaTeX. Grande parte do conhecimento exposto aqui, está baseado em diversas referências sobre a linguagem R, em especial os trabalhos de (LONG; TEETOR, 2019; PENG, 2015; WICKHAM, 2015; WICKHAM; GROLEMUND, 2017), assim como a documentação oficial da linguagem R (TEAM, 2020a, 2020b).",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#novidades-desta-quinta-edição",
    "href": "index.html#novidades-desta-quinta-edição",
    "title": "Introdução à Linguagem R",
    "section": "Novidades desta quinta edição",
    "text": "Novidades desta quinta edição\nEsta quinta edição traz algumas melhorias que buscam manter um dos principais objetivos deste livro, que é ser uma referência moderna, introdutória e técnica sobre a Linguagem R.\nPrimeiro, o livro inteiro foi portado para utilizar a engine Quarto. Versões anteriores do livro eram construídas a partir da junção de dos pacotes rmarkdown e bookdown. Porém, a partir desta edição, o livro passa a ser construído utilizando-se da tecnologia mais avançada presente no Quarto.\nSegundo, seguindo uma sugestão feita por um dos leitores, um exemplo de script em R capaz de converter um script SAS de leitura da PNAD Contínua, em específicações de importação ideias para o pacote readr, foi adicionado ao estudo de caso no capítulo 4. Isso garante que os leitores tenham agora um exemplo mínimo de como realizar essa conversão em código.\nTerceiro, houveram vários avanços no pacote dplyr no ano passado, especialmente na área de JOIN’s. Por isso, uma nova seção foi adicionada ao capítulo 6, para descrever joins de desigualdade e os novos tipos de join introduzidos pela função join_by() em versões recentes do pacote dplyr.\nQuarto, o pacote tidyr também evoluiu bastante no ano passado, especialmente na área de dados aninhados e dados em árvores (e.g. JSON, HTML, XML). Por isso, uma nova seção foi adicionada ao capítulo 7, para descrever os métodos disponíveis no pacote tidyr para trabalhar com esses tipos de dados.\nQuinto, os exercícios de cada capítulo foram separados do livro, apenas com o intuito de economizar espaço no livro. Os exercícios de cada capítulo continuam disponíveis gratuitamente para qualquer pessoa, através da página de publicação do livro, que está no endereço abaixo:\nhttps://pedro-faria.netlify.app/publications/book/introducao_linguagem_r/pt/\nSexto, o estudo de caso com os dados da COVID-19 que estava presente no capítulo 7 foi removido. Tal remoção foi em parte motivada pela redução do tamanho do livro, e por uma outra parte, pelo fato desse estudo não entregar tanto valor para o leitor, com alguns exemplos que são um pouco extremos demais para o dia-a-dia do analista de dados.\nSexto, várias melhorias pequenas foram feitas em vários capítulos, incluindo a reformulação de algumas figuras e desenhos.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#onde-encontrar-exercícios-e-respostas-dos-exercícios",
    "href": "index.html#onde-encontrar-exercícios-e-respostas-dos-exercícios",
    "title": "Introdução à Linguagem R",
    "section": "Onde encontrar exercícios e respostas dos exercícios",
    "text": "Onde encontrar exercícios e respostas dos exercícios\nOs exercícios do livro e as suas respostas estão separados do livro. Você pode encontrá-los facilmente (e de forma gratuita) na página de publicação do livro13.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#como-citar-a-obra",
    "href": "index.html#como-citar-a-obra",
    "title": "Introdução à Linguagem R",
    "section": "Como citar a obra",
    "text": "Como citar a obra\nSeguindo as regras da norma ABNT, esta obra poderia ser citada da seguinte maneira:\nFARIA, Pedro Duarte. Introdução à Linguagem R: seus fundamentos e sua prática. 5. ed. Belo Horizonte: [s.n.], 2024. ISBN 978-65-00-57872-0. Disponível em: https://pedro-faria.netlify.app/pt/publication/book/introducao_linguagem_r/.\nSe você preferir, a referêcia em formato BibTex:\n@book{pedro2022,\n  title = {Introdução à Linguagem R},\n  subtitle = {seus fundamentos e sua prática},\n  author = {Pedro Duarte Faria},\n  year = {2024},\n  edition = {5},\n  address = {Belo Horizonte},\n  month = {Junho},\n  isbn = {978-65-00-57872-0},\n  note = {https://pedro-faria.netlify.app/pt/publication/book/introducao_linguagem_r/}\n}\n\n\n\n\nBRAGA, D.; ASSUNCAO, G.; HIDALGO, L. PNADcIBGE: Downloading, Reading and Analysing PNADC Microdata. [s.l.] CRAN R Package, 2020.\n\n\nLONG, J. D.; TEETOR, P. R Cookbook. 2nd. ed. Sebastopol, CA: O’Reilly Media, Inc., 2019.\n\n\nMCDONNELL, R. M.; OLIVEIRA, E.; GIANNOTTI, R. cepR: Busca CEPs Brasileiros. [s.l.] CRAN R Package, 2020.\n\n\nPENG, R. D. R Programming for Data Science. [s.l.] Leanpub, 2015.\n\n\nPEREIRA, R. H. et al. geobr: Loads Shapefiles of Official Spatial Data Sets of Brazil. [s.l.] IPEA - Instituto de Pesquisa Econômica Aplicada; CRAN R Package, 2020.\n\n\nPETRUZALEK, D. read.dbc: Read Data Stored in DBC (Compressed DBF) Files. [s.l.] CRAN R Package, 2016.\n\n\nSIQUEIRA, R. P. sidrar: An Interface to IBGE’s SIDRA API. [s.l.] CRAN R Package, 2020.\n\n\nTEAM, R. C. R Language Definition. Version 4.0.3 ed. [s.l.] R Foundation, 2020a.\n\n\nTEAM, R. C. An Introduction to R: A Programming Environment for Data Analysis and Graphics. Version 4.0.3 ed. [s.l.] R Foundation, 2020b.\n\n\nWICKHAM, H. Advanced R. 2. ed. Boca Raton, Florida: CRC Press, 2015.\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Introdução à Linguagem R",
    "section": "",
    "text": "A Fundação João Pinheiro (fundada em 1969), é uma instituição de pesquisa e ensino vinculada à Secretaria de Estado de Planejamento e Gestão de Minas Gerais, e é responsável por produzir as principais estatísticas econômicas, sociais e demográficas do estado de Minas Gerais.↩︎\nhttps://ppea.ufop.br/↩︎\nhttp://fjp.mg.gov.br/↩︎\nhttps://stackoverflow.com/questions/tagged/r↩︎\nhttps://cran.r-project.org/↩︎\nhttps://www.curso-r.com/material/↩︎\nhttps://rladies.org/↩︎\nhttps://medium.com/rladiesbh↩︎\nhttps://www.meetup.com/pt-BR/rladies-sao-paulo/↩︎\nhttp://cursos.leg.ufpr.br/ecr/↩︎\nhttp://leg.ufpr.br/~walmes/cursoR/data-vis/↩︎\nhttps://pedro-faria.netlify.app/pt/publication/book/introducao_linguagem_r/↩︎\nhttps://pedro-faria.netlify.app/pt/publication/book/introducao_linguagem_r/↩︎",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "Capítulos/01-nocoes-basicas.html",
    "href": "Capítulos/01-nocoes-basicas.html",
    "title": "1  Noções Básicas do R",
    "section": "",
    "text": "1.1 Uma descrição do R",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Noções Básicas do R</span>"
    ]
  },
  {
    "objectID": "Capítulos/01-nocoes-basicas.html#uma-descrição-do-r",
    "href": "Capítulos/01-nocoes-basicas.html#uma-descrição-do-r",
    "title": "1  Noções Básicas do R",
    "section": "",
    "text": "1.1.1 História do R\nA linguagem R nasceu durante a década de 90, inicialmente, como um projeto de pesquisa de Ross Ihaka e Robert Gentleman. Ambos estatísticos e pesquisadores da Universidade de Auckland (IHAKA; GENTLEMAN, 1996). Porém, as origens da linguagem R retornam até a década de 70, com o desenvolvimento da linguagem S, em um dos mais importantes laboratórios de pesquisa do mundo, a Bell Labs (PENG, 2015).\nComo foi descrito por IHAKA; GENTLEMAN (1996), a linguagem R foi desenvolvida com fortes influências das linguagens S e Scheme. A própria sintaxe da linguagem R, se assemelha muito a da linguagem S. Por isso, muitos autores como PENG (2015) e CHAMBERS (2008), caracterizam a linguagem R como um “dialeto da linguagem S”. Segundo IHAKA; GENTLEMAN (1996) a linguagem S representava uma forma concisa de se expressar ideias e operações estatísticas para um computador e, por isso, foi uma fonte de inspiração importante para o R. Em outras palavras, comparado às demais linguagens, a linguagem S oferecia uma sintaxe mais atrativa e confortável para estatísticos executarem as suas ideias, e grande parte dessa sintaxe, foi transportada para o R.\n\n\n1.1.2 O que é o R?\nR é um software estatístico que oferece um ambiente para análise interativa de dados, e que conta com uma poderosa linguagem de programação, e é dessa linguagem que vamos tratar neste livro. Diferente de outras linguagens como C e C++, que são linguagens compiladas, a linguagem R é uma linguagem interpretada. Isso significa, que para trabalharmos no R, vamos estar constantemente escrevendo e enviando comandos para o Console do programa. Esse Console vai avaliar os comandos que enviarmos (segundo as “regras gramaticais” da linguagem R), antes de executá-los.\nPortanto, o console é o coração do R. É a parte mais importante do programa (ADLER, 2010, p. pp.11). Pois é nele que se encontra o interpretador que vai avaliar e executar todos os nossos comandos. O processo de análise de dados adquire um aspecto interativo no R. Ou seja, temos uma sensação de que estamos construindo (interativamente) uma conversa com o console. Você envia um comando para o console; o comando é avaliado pelo console e é executado; o resultado desse comando é retornado pelo console; você olha para o resultado, e se pergunta se este resultado satisfaz os seus desejos; caso não, você faz ajustes em seu comando (ou utiliza um comando completamente diferente), e o envia novamente para o console; e assim, todo o ciclo recomeça.\n\n\n1.1.3 O sistema e universo do R\nO universo do R pode ser divido em duas partes, sendo elas:\n\nQuando você instala o R na sua máquina, ele vem acompanhado por uma coleção de pacotes que compõe a base da linguagem. Esse é o sistema “básico” do R. Esses pacotes são comumente chamados pela comunidade, por base R. Pois o principal pacote deste sistema se chama base.\nTodo o resto, isto é, todos os pacotes externos a este sistema “básico”, são os pacotes desenvolvidos pela comunidade do R. A grande maioria desses pacotes estão disponíveis para você através do Comprehensive R Archive Network (CRAN R), mas alguns outros, estão presentes apenas em outras plataformas, como o GitHub.\n\nTodas as funcionalidades e operações disponíveis no R são executadas através de funções. Essas várias funções existentes são organizadas em “pacotes”. Portanto, um pacote representa uma coleção de funções, datasets, documentações, e outros componentes que te ajudam a desempenhar uma tarefa/operação específica dentro do R.\nO sistema “básico” do R é um conjunto de pacotes que oferecem as funcionalidades básicas da linguagem. Exemplos desses pacotes são base (fornece funções de uso geral) e stats (fornece funções para análises e operações estatísticas). Caso você precise de uma funcionalidade que não está disponível dentro deste conjunto de “pacotes básicos”, é neste momento em que você precisa instalar outros pacotes que estão fora desse sistema “básico”. Vamos dissecar alguns desses pacotes “externos” ao longo deste livro, com especial atenção ao tidyverse1.\nPelo fato do R ser gratuito e open source, várias pessoas estão constantemente desenvolvendo novos pacotes, e efetivamente expandindo cada vez mais o universo da linguagem R. Ou seja, se você quer resolver um problema, é muito provável que alguém já tenha enfrentado esse mesmo problema antes, ou algo próximo, e que tenha desenvolvido um pacote que oferece funções para resolver esse problema. Logo, você pode se aproveitar do trabalho de outras pessoas, que passaram pelas mesmas dificuldades que você, para resolver os seus próprios problemas.\n\n\n1.1.4 RStudio\nRStudio é um Ambiente de Desenvolvimento Integrado (Integrated Development Environment - IDE, em inglês) para o R. Em síntese, esse programa oferece um ambiente com diversas melhorias, atalhos e ferramentas que facilitam o seu trabalho com o R. Por exemplo, o programa oferece menus rápidos para importação e exportação de arquivos, além de diversos atalhos de teclado muito úteis. Sendo, portanto, uma ferramenta muito recomendada para qualquer usuário que venha a trabalhar com a linguagem R (GILLESPIE; LOVELACE, 2017). Para encontrar mais detalhes sobre o programa, você pode consultar o site oficial do RStudio2.\nA partir daqui, vamos focar bastante no uso do R através do RStudio. Portanto, vamos estar constantemente descrevendo atalhos de teclado, opções e telas dentro do RStudio ao longo dos próximos capítulos. Na Figura 1.1 temos um print que mostra os diferentes painéis que existem dentro do RStudio.\n\n\n\n\n\n\n\n\nFigura 1.1: Painéis (ou seções) existentes dentro do RStudio",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Noções Básicas do R</span>"
    ]
  },
  {
    "objectID": "Capítulos/01-nocoes-basicas.html#introdução-ao-r-e-rstudio-noções-básicas",
    "href": "Capítulos/01-nocoes-basicas.html#introdução-ao-r-e-rstudio-noções-básicas",
    "title": "1  Noções Básicas do R",
    "section": "1.2 Introdução ao R e RStudio: noções básicas",
    "text": "1.2 Introdução ao R e RStudio: noções básicas\n\n1.2.1 Executando comandos: Console\nVocê trabalha no R através de sua linguagem de programação. Para realizar qualquer tarefa (e.g. importa os seus dados, remove ou acrescenta colunas, reordena a sua base de dados, constrói gráficos, e estima os seus parâmetros) no R você precisa enviar comandos para o Console. O trabalho do Console (e principalmente do interpretador que está incrustrado dentro dele), é o de traduzir os seus comandos escritos na linguagem R (que nós seres humanos conseguimos entender), para uma linguagem que o seu computador possa entender.\nComo mostrado na Figura 1.1, o Console no RStudio está sempre localizado na parte inferior esquerda de sua tela. Ao olhar para o Console, você pode perceber que em sua parte inferior, nós temos no início da linha um símbolo de “maior que” (&gt;). Esse símbolo, significa que o Console está pronto e esperando por novos comandos a serem executados. Ou seja, você coloca os seus comandos à frente deste símbolo, e em seguida, você aperta Enter para confirmar o envio dos comandos. Assim, os comandos serão avaliados, e o console vai lhe retornar o resultado destes comandos. Existem algumas ocasiões em que o console vai apenas executar os comandos, e não irá lhe mostrar automaticamente o resultado. Isso geralmente ocorre quando você está salvando os resultados desses comandos em um objeto (vamos falar deles mais a frente).\nComo um exemplo clássico, eu posso utilizar o R como uma simples calculadora, ao escrever o comando “1 + 3” no Console (e apertar a tecla Enter), e como não estou salvando o resultado dessa soma em algum objeto, o console me mostra automaticamente o resultado dessa operação.\n\n1 + 3\n\n[1] 4\n\n\nVale destacar, que todo comando que você escrever no Console, deve estar completo para ser avaliado. Dito de outra forma, quando você escreve no Console, algum comando que ainda está incompleto de alguma forma (por exemplo, que ainda está faltando fechar algum par de parênteses, ou está faltando uma vírgula, ou está faltando algum valor a ser fornecido), e você aperta Enter para ele ser avaliado, o símbolo &gt; do Console, será substituído por um +, te indicando que ainda falta algo em sua expressão. Neste caso, o Console ficará esperando até que você escreva o restante do comando, como mostrado na Figura 1.2. Se você se sentir preso nesta situação, não se preocupe! Você pode abortar a operação, e reescrever do início o seu comando, ao apertar a tecla Esc.\n\n\n\n\n\n\n\n\nFigura 1.2: Exemplo de comando incompleto\n\n\n\n\n\n\n\n1.2.2 Comentários\nO R possui diversos caracteres especiais, e que geram efeitos distintos ao serem avaliados. Um desses caracteres, é o hash, ou o “jogo da velha” (#), que no R, representa o início de um comentário. Ou seja, todo e qualquer comando, letra ou expressão escrita após o símbolo # (incluindo o próprio símbolo #), será completamente ignorado pelo Console. Portanto, o símbolo # constitui uma forma útil de incluirmos anotações e comentários em nossos comandos. Por exemplo, você talvez tenha dificuldade de lembrar o que cada função faz, e por isso, você pode utilizar o símbolo # para inserir pequenas descrições e lembretes ao longo de seus comandos, para relembrá-lo o que cada função faz. Veja o exemplo abaixo:\n\n# A função sum() serve para somar um\n# conjunto de números.\nsum(1,2,3,4,5)\n\n[1] 15\n\n\n\n\n1.2.3 Comandos e resultados\nO símbolo de “maior que” (&gt;) no Console, também é uma forma útil de você diferenciar o que é um comando a ser interpretado pelo R, e o que foi retornado pelo R como o resultado desse comando. Ou seja, todo bloco de texto em seu Console, que estiver logo à direita do símbolo &gt;, representa um bloco de comandos a serem avaliados (ou que já foram avaliados) pelo R. Em contrapartida, todo texto que não possuir o símbolo &gt; à sua esquerda, representa o resultado do comando anterior, ou então, uma mensagem de erro referente a esse comando anterior.\nUma outra forma útil de identificar os resultados de seus comandos, é perceber que eles sempre vêm acompanhados por algum índice numérico no início de cada linha. Esse índice pode estar dentro de um par de colchetes (como [1]), ou pode estar livre, como no resultado da função data.frame() apresentado na Figura 1.3. Perceba que esses números são apenas índices, logo, eles não fazem parte do resultado de seus comandos, e são apenas valores que marcam o início de cada linha de seu resultado.\n\n\n\n\n\n\n\n\nFigura 1.3: Comandos e seus respectivos resultados no Console\n\n\n\n\n\n\n\n1.2.4 Histórico de comandos\nO Console possui uma memória dos comandos que você executou anteriormente. Tanto que esses comandos e seus resultados, permanecem visíveis ao navegarmos pelo Console. Porém, quando você estiver dentro do Console, você também pode navegar pelos comandos previamente executados, ao utilizar a seta para cima (\\(\\uparrow\\)) de seu teclado. Através dessa tecla, os comandos executados anteriormente são apresentados na linha de inserção de códigos do próprio Console.\nPorém, você também pode visualizar de forma mais eficiente o seu histórico de comandos, ao acessar a janela History, que fica dentro do painel de Environment no RStudio. Este painel fica na parte superior direita de sua tela, como mostrado na Figura 1.1. Uma outra forma de abrirmos essa janela, está na função history(), que lhe permite determinar até quantos comandos anteriores devem ser exibidos nessa janela.\n\n# Exibir os últimos 10 comandos executados\nhistory(10)\n\nPara mais, você também pode visualizar esse histórico de comandos, por meio de uma pequena janela aberta em seu Console, mostrado na Figura 1.4. Quando estiver no console, você pode acessar essa janela, ao pressionar as teclas Ctrl + \\(\\uparrow\\).\n\n\n\n\n\n\n\n\nFigura 1.4: Histórico de comandos - Console\n\n\n\n\n\n\n\n1.2.5 Operações matemáticas básicas\nO R pode ser utilizado como uma simples calculadora, através de seus operadores aritméticos.\n\n# Simples Adição\n3 + 15\n\n[1] 18\n\n# Multiplicação\n3 * 125\n\n[1] 375\n\n# Potenciação\n3 ^ 4\n\n[1] 81\n\n# Miscelânia de operadores\n((4.505 * 100)/ 5) + 0.015 \n\n[1] 90.115\n\n\nVocê irá rapidamente perceber que esses operadores são extremamente úteis e estão por toda parte, sendo utilizados em diversas outras operações muito mais complexas. Por isso, é importante que você leve um tempo se familiarizando com esses operadores. Temos na Figura 1.5, uma lista dos principais operadores aritméticos, além de alguns comandos no R que exemplificam o seu uso.\n\n\n\n\n\n\n\n\nFigura 1.5: Operadores aritméticos do R",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Noções Básicas do R</span>"
    ]
  },
  {
    "objectID": "Capítulos/01-nocoes-basicas.html#introdução-a-objetos",
    "href": "Capítulos/01-nocoes-basicas.html#introdução-a-objetos",
    "title": "1  Noções Básicas do R",
    "section": "1.3 Introdução a objetos",
    "text": "1.3 Introdução a objetos\nUma das principais características do R, é que ele é uma linguagem orientada a objetos (object oriented)3. Objetos são o método que o R possui para armazenar os valores, funções e resultados que você produz. Como foi posto por ADLER (2010, p. 50), todo comando/código que você escreve no R, busca utilizar, manipular ou modificar de alguma forma, um objeto do R. Logo, quando você estiver trabalhando com seus dados no R, você estará constantemente aplicando operações e transformações sobre os objetos onde seus dados estão guardados, de uma forma interativa e dinâmica.\nPara que um objeto seja criado, o R necessita de uma forma de referenciar aquele objeto, ou em outras palavras, uma forma de reconhecer o objeto ao qual você está requisitando. Esse mecanismo é simplesmente um nome (CHAMBERS, 2008, p. pp.24). Ou seja, todo objeto no R, possui um nome, e será através desse nome, que você será capaz de acessar e usar esse objeto. Portanto, para você salvar todo e qualquer resultado ou valor no R, você precisa obrigatoriamente salvá-lo dentro de um objeto, isto é, dar um nome a esse resultado ou valor que você está gerando.\nNo exemplo abaixo, eu estou guardando a minha idade em um objeto chamado idade_pedro. Dessa forma, quando eu precisar deste número em algum momento de minha análise, eu preciso apenas chamar pelo nome onde guardei este número, ou nos termos do R, pelo nome dei ao objeto onde guardei este número.\n\nidade_pedro &lt;- 22\n\nApós criarmos o objeto de nome idade_pedro, eu posso acessar o valor que foi salvo nele, ao chamar pelo nome do objeto no Console.\n\nidade_pedro\n\n[1] 22\n\n\nSempre que você estiver criando um objeto, ele irá seguir essa estrutura acima. Você possui primeiro o nome do objeto, depois o símbolo de assignment (&lt;-), e por último, o valor (ou o conjunto de valores) que você deseja guardar dentro deste objeto. Não importa o quê o código à direita do símbolo de assignment faz. Assim que você ver essa estrutura em algum comando, você pode ter certeza que esse comando está criando um objeto.\n\n\n\n\n\nEstrutura necessária para criar um objeto\n\n\n\n\nVocê pode sobrepor (ou substituir) o valor guardado em um objeto, ao atribuir um novo valor para este objeto. Neste caso, estaríamos perdendo o valor que salvamos anteriormente neste objeto. Como exemplo, se eu atribuir o texto “Importado” ao objeto idade_pedro. Após este novo comando, se chamarmos pelo nome do objeto novamente, o R irá lhe mostrar o novo texto que acabamos de guardar neste objeto. Portanto, o número 22 que estava anteriormente guardado nele, se perdeu.\n\nidade_pedro &lt;- \"Importado\"\n\nidade_pedro\n\n[1] \"Importado\"\n\n\nCaso você tenha que sobrepor o valor de algum objeto, mas, ao mesmo tempo, você não quer perder o valor que está salvo nele, você deve conectar este valor a um novo objeto. Se um valor não está conectado a um nome, o R vai automaticamente descartar este valor, por isso, precisamos criar uma nova conexão até este valor, ou em outras palavras, precisamos conectá-lo a um novo nome. Dessa forma, podemos tranquilamente sobrepor o valor guardado em idade_pedro, pois agora, o valor 22 está guardado em um outro objeto.\n\nidade_pedro &lt;- 22\n\nnumero_importante &lt;- idade_pedro\n\nidade_pedro &lt;- \"Importado\"\n\n# Ao chamar pelo nome de\n# ambos os objetos, temos dois valores\n# diferentes\n\nidade_pedro\n\n[1] \"Importado\"\n\nnumero_importante\n\n[1] 22\n\n\n\n1.3.1 Como nomear um objeto\nComo foi destacado por WICKHAM; GROLEMUND (2017), existem regras sobre como você pode nomear os seus objetos no R. Segundo TEAM (2020a, p. 4), o nome de um objeto, pode conter qualquer símbolo alfanumérico (qualquer letra ou número), inclusive letras acentuadas. Contudo, o nome do objeto deve obrigatoriamente se iniciar por uma letra, ou por um ponto (.), como por exemplo, os nomes: População; dados.2007; .abc; media_1990.\nSendo assim, um nome não pode começar por um número. Um nome como 1995populacao, não é permitido! Também não é possível criar um nome que se inicie por um ponto (.) caso ele seja seguido por um número. Logo, você não pode criar um objeto com o nome .2media. Mas você pode sim criar um objeto que possua os nomes .m2edia e .media2.\nEm suma, o nome de um objeto pode conter os seguintes tipos de caractere:\n\nLetras.\nNúmeros.\n_ (underline).\n. (ponto).\n\nAlém disso, o nome de um objeto pode se iniciar com:\n\nLetra.\n. (ponto, desde que não seja seguido por um número).\n\nPorém, o nome de qualquer objeto, não deve começar por um:\n\n_ (underline).\nNúmero.\n. (ponto) seguido de um número.\n\nPode ser difícil pensar em um nome para os seus objetos. Mas a melhor alternativa, é sempre dar um nome claro e descritivo aos seus objetos, mesmo que esse nome fique muito extenso. Por exemplo, microdados_pnad_2020 para uma base de dados contendo os microdados da PNAD de 2020; ou vetor_idade, para um vetor que contém as idades das pessoas que foram entrevistadas em uma pesquisa.\n\n\n1.3.2 O R é case-sensitive\nO R é uma linguagem case-sensitive. Isso significa, que ele é capaz de diferenciar a capitalização de sua escrita. Logo, um objeto chamado a, é um objeto completamente diferente de um objeto chamado A. Veja o exemplo abaixo.\n\ncasa &lt;- 10 ^ 2\ncAsa &lt;- 2 + 2\n\ncasa\n\n[1] 100\n\ncAsa\n\n[1] 4\n\n\nComo visto, os objetos casa e cAsa contêm valores diferentes, e, portanto, representam objetos distintos.\n\n\n1.3.3 Como utilizar objetos\nUm objeto é de certa forma, uma referência até um certo conjunto de valores, e você utiliza, ou acessa essa referência, através do nome que você deu a esse objeto. Logo, sempre que você quiser utilizar os valores que estão guardados em algum objeto (seja dentro de alguma função ou em alguma operação específica), basta utilizar o nome que você deu a esse objeto.\nPor exemplo, se eu quero somar um conjunto de valores guardados em um objeto chamado vec_num, eu posso fornecer o nome deste objeto à função sum(), como no exemplo abaixo:\n\nvec_num &lt;- c(2.5, 5.8, 10.1, 25.2, 4.4)\nsum(vec_num)\n\n[1] 48",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Noções Básicas do R</span>"
    ]
  },
  {
    "objectID": "Capítulos/01-nocoes-basicas.html#sec:funcoes",
    "href": "Capítulos/01-nocoes-basicas.html#sec:funcoes",
    "title": "1  Noções Básicas do R",
    "section": "1.4 Funções (noções básicas)",
    "text": "1.4 Funções (noções básicas)\nComo destacado por CHAMBERS (2016), tudo no R são objetos! Inclusive as funções que você utiliza. Toda função no R é utilizada, seguindo o formato abaixo. Primeiro você escreve o nome dessa função, em seguida, você abre um par de parênteses, e dentro desse par de parênteses, você deve fornecer os argumentos (ou input’s) que serão utilizados pela função para gerar o resultado.\n\nnome_da_função(lista_de_argumentos)\n\nOs operadores aritméticos utilizados até aqui (+, -, *, etc.) também são funções para o R, porém, eles representam um tipo especial de função. Pois nós podemos posicionar os seus argumentos, ao redor desses operadores. Por exemplo, na expressão 2 + 3, os argumentos (ou input’s) 2 e 3 são fornecidos ao redor do operador. Por outro lado, nós podemos escrever esses operadores (ou essas funções), da forma “tradicional”, como demonstramos acima. Perceba que pelo fato do nome da função (a função que representa o operador +) se iniciar por um símbolo (e isso não respeita as regras que definimos anteriormente em Seção 1.3.1), para nos referirmos a esse objeto, ou a essa função, nós precisamos contornar o nome dessa função por acentos graves.\n\n# O mesmo que 2 + 3\n`+`(2, 3)\n\n[1] 5\n\n# O mesmo que 12 + 8\n`+`(12, 8)\n\n[1] 20\n\n\nOs argumentos de uma função representam os input’s dessa função. São informações ou dados que você precisa fornecer à função, para que ela possa produzir os resultados que você deseja obter. Portanto, os input’s que você fornece a uma função podem afetar diretamente o resultado que essa função produz para você. Em geral, os argumentos de uma função são fornecidos como uma lista de valores, separados por vírgulas. No exemplo abaixo, eu estou fornecendo dois input’s para a função.\n\nexemplo_função(argumento1 = valor_argumento1, argumento2 = valor_argumento2)\n\nUm argumento pode ser um símbolo, que contém um valor específico (ex.: argumento1 = valor_argumento1). Uma função pode ter vários argumentos diferentes. Mas em muitos casos, você não é obrigado a fornecer um valor (ou um input) explícito para cada argumento. Pois muitos argumentos em certas funções possuem um “valor padrão”. Ou seja, se o usuário dessa função não fornecer um valor explícito para esse argumento, então, a função vai automaticamente usar o valor padrão para esse argumento.\nCaso você não fornecer um valor explícito para um argumento que é obrigatório na função, ou seja, um argumento que precisa necessariamente de um valor explícito, o R vai emitir uma mensagem de erro no formato \"argument ... is missing, with no default\". No exemplo abaixo, eu dou um valor para o argumento x da função besselJ(). Contudo, eu não forneci um valor para o argumento nu, que é obrigatório nessa função. Por isso, o R levantou um erro me avisando que eu preciso também fornecer um valor para este argumento.\n\nbesselJ(x = 1)\n\nError in besselJ(x = 1) : argument \"nu\" is missing, with no default\nPor outro lado, como comentamos, alguns argumentos já possuem um “valor padrão”, e por isso, não precisamos fornecer input’s para esses argumentos explicitamente. Um exemplo disso está na função sum(), que possui um argumento chamado na.rm. Através deste argumento, você pode determinar se os valores NA presentes em um objeto, devem ser ignorados ou não durante o cálculo da soma. Por padrão, esse argumento é configurado para FALSE (falso). Isso significa, que qualquer valor NA que estiver presente no objeto a ser somado, vai alterar o comportamento da soma executada por sum(). Por isso, se quisermos ignorar os valores NA durante o cálculo da soma, nós precisamos definir explicitamente o argumento na.rm para TRUE (verdadeiro), como no exemplo abaixo:\n\nvec &lt;- c(1.2, 2.5, 3, NA_real_, 7.6)\nsum(vec)\n\n[1] NA\n\nsum(vec, na.rm = TRUE)\n\n[1] 14.3\n\n\nVocê talvez tenha percebido que nem sempre eu defino explicitamente o nome do argumento ao fornecer um input a uma função. No exemplo anterior, dentro da função sum(), o input vec foi fornecido de forma livre. Eu não associei esse input de forma explícita a um argumento da função sum(). Nesse caso, o R vai automaticamente associar esse input à um dos argumentos de sum() com base na sua posição dentro da lista de input’s.\nOu seja, o primeiro input fornecido é automaticamente associado ao primeiro argumento da função. Já o segundo input, é associado ao segundo argumento. E assim por diante. Portanto, quando você usa a sintaxe valor_argumento, ao invés de usar a sintaxe nome_argumento = valor_argumento, os valores (ou input’s) que você forneceu vão ser automaticamente associados aos argumentos da função com base na posição que eles estão nesta lista de input’s.\nComo um outro exemplo, veja a função rnorm() abaixo. O primeiro argumento (n) da função, define o número de observações a serem geradas; o segundo (mean), define a média desses valores; e o terceiro (sd), define o desvio padrão que esses valores vão seguir ao serem gerados. Logo, no exemplo abaixo, o input 6 é associado ao argumento n; o input 15 é associado ao argumento mean; e por último, o input 2.5 é associado ao argumento sd.\n\nrnorm(6, 15, 2.5)\n\nSeguindo tudo o que aprendemos até aqui, nós podemos reescrever a expressão acima do modo exposto abaixo. Ou seja, a expressão exposta abaixo é semanticamente igual à expressão acima. Perceba que nesse caso, eu estou explicitamente associando cada input a um determinado argumento. Neste caso, o R não tem o trabalho de calcular a posição dos input’s na lista, e procurar pelo argumento que corresponde àquela posição da lista.\n\nrnorm(n = 6, sd = 2.5, mean = 15)",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Noções Básicas do R</span>"
    ]
  },
  {
    "objectID": "Capítulos/01-nocoes-basicas.html#sec:erros_ajuda",
    "href": "Capítulos/01-nocoes-basicas.html#sec:erros_ajuda",
    "title": "1  Noções Básicas do R",
    "section": "1.5 Erros e ajuda: como e onde obter",
    "text": "1.5 Erros e ajuda: como e onde obter\nA partir do momento em que você começar a aplicar o conhecimento exposto neste livro, você vai rapidamente enfrentar situações adversas. Mensagens de erro, resultados incoerentes, etc. Nestes momentos, muitas perguntas vão surgir. Por isso, é muito importante que você conheça o máximo de recursos possíveis, dos quais você pode consultar e pedir por ajuda (WICKHAM; GROLEMUND, 2017).\nHoje, a comunidade internacional de R, é muito grande, e há diversos locais onde você pode encontrar ajuda, e aprender cada vez mais sobre a linguagem. Nessa seção, vamos explicar como utilizar os guias internos do R e do RStudio, além de algumas técnicas de pesquisa e de perguntas que podem te ajudar a responder as suas dúvidas.\n\n1.5.1 Ajuda Interna do R: help() e ?\nToda função no R, possui uma documentação interna, que contém uma descrição completa (ou quase sempre completa) da função. Essas documentações são muitas vezes úteis, especialmente para descobrirmos os argumentos de uma função, ou para compreendermos que tipo de valores devemos utilizar em um certo argumento, ou então, em ocasiões mais específicas, para adquirirmos um conhecimento mais completo sobre o comportamento de uma função.\nPara acessar essa documentação, você pode anteceder o nome da função com o operador ?, ou então, utilizar a função help() sobre o nome da função de interesse. Como exemplo, através dos comandos abaixo, você pode consultar a documentação interna da função mean().\n\n# Usando `help()`\nhelp(\"mean\")\n# Usando `?`\n?mean\n\nAo executar esse tipo de comando dentro do RStudio, a documentação interna da função será exibida dentro da área de Help do RStudio. Esta área fica dentro do painel de Arquivos (exposto na Figura 1.1) que fica no canto inferior direito de sua tela.\n\n\n1.5.2 Ajuda Externa: referências, documentação oficial e canais úteis\nApesar de útil, a documentação interna de uma função pode ser um pouco limitada, e muitas vezes está escrita em inglês, o que pode dificultar a compreensão do usuário. Por isso, é interessante se aprofundar e conhecer outras referências e materiais externos ao R, produzidas pela comunidade (livros, artigos, blogs, sites de ajuda, cursos online, etc).\nAo longo desse livro, vamos descrever diversas funções que provêm dos pacotes do tidyverse. Por isso, é interessante que você se familiarize com os sites desses pacotes4. Todos esses sites possuem uma página de “Reference”, que contém a documentação de todas as funções do pacote. Uma outra fonte rápida de informação, são as “colas” (ou “cheatsheets”) produzidas pela equipe do RStudio, chamadas de RStudio Cheatsheets5.\nTemos também diversos livros-textos importantes sobre a linguagem, que oferecem diversos conhecimentos extremamente valiosos, como as obras de WICKHAM; GROLEMUND (2017), GILLESPIE; LOVELACE (2017), PENG (2015), GROLEMUND (2014), CHAMBERS (2008), ADLER (2010), além da documentação oficial da linguagem presente em TEAM (2020a) e TEAM (2020b).\nTambém existem diversos cursos e materiais disponíveis, que podem ser boas fontes de informação. Por exemplo, os materiais construídos pela equipe do Curso-R6, além do material produzido pelo professor Walmes Marques Zeviani, intitulado Manipulação e Visualização de Dados7.\nPara mais, temos alguns blogs que fazem boas reflexões e sempre trazem um bom conteúdo sobre a linguagem. Esse é o caso do site R-Bloggers8, que possui uma boa discussão sobre os mais diversos assuntos no R. Um outro exemplo, é o blog do Tidyverse9, que constantemente descreve novos pacotes, novas funções disponíveis e novas aplicações para o R que podem ser muito interessantes para o seu trabalho.\nAlém dessas referências, existem também alguns canais de dúvida muito populares como o Stackoverflow e o RStudio Community. Além disso, muitas dúvidas podem ser solucionadas fazendo uma pesquisa rápida no Google, ou então, perguntando para IAs como o ChatGPT.",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Noções Básicas do R</span>"
    ]
  },
  {
    "objectID": "Capítulos/01-nocoes-basicas.html#sec:scripts",
    "href": "Capítulos/01-nocoes-basicas.html#sec:scripts",
    "title": "1  Noções Básicas do R",
    "section": "1.6 Scripts",
    "text": "1.6 Scripts\nAté o momento, estávamos utilizando diretamente o console para executarmos os nossos comandos. Porém, você provavelmente se sentiu um pouco perdido ao procurar pelos últimos comandos que você executou e, se sentiu um pouco frustrado ao ter que digitar novamente o comando caso queira executá-lo uma segunda vez. Por essa razão, à medida que você trabalha cada vez mais com o R, a necessidade de guardar os seus comandos anteriores em algum lugar, se torna cada vez mais urgente. Para isso, você pode utilizar um script.\nUm script é um simples arquivo de texto, que contém a extensão .R, para indicar que todo o texto contido neste arquivo, representam comandos do R. Portanto, um script contém um conjunto de códigos e comandos do R que podem ser facilmente acessados, editados e executados através das ferramentas e atalhos do RStudio, tornando o seu fluxo de trabalho com o R mais eficiente. Ao utilizar o RStudio, os códigos contidos nos scripts podem ser executados individualmente ou em conjunto.\nPara criar um script no RStudio, você possui duas opções: 1) clicar em File \\(\\rightarrow\\) New File \\(\\rightarrow\\) R Script; ou 2) utilizar o atalho Ctrl + Shift + N. Após criar o script, o quadrante esquerdo do RStudio será dividido verticalmente em dois: a parte superior comporta o editor de script’s e a inferior o Console.\nVocê pode criar títulos que delimitam as áreas, ou as etapas de seu script, e é uma forma muito eficiente de navegar pelo seu script, caso ele seja muito grande. Na Figura 1.6, um exemplo destes títulos está identificado pela seta azul. Também na Figura 1.6, temos uma caixa vermelha, e dentro dela podemos ver uma referência que aponta qual a seção, ou melhor, qual o título da seção no qual o nosso cursor se encontra atualmente. O meu cursor se encontra no momento, na seção “Importando os dados para o R”. Ao clicar sobre esta referência especificada na caixa vermelha, uma nova caixa de seleção irá aparecer contendo cada um dos títulos que foram criados neste script. Ao clicar sobre um destes títulos, eu vou ser redirecionado para o início desta seção no script.\n\n\n\n\n\n\n\n\nFigura 1.6: Títulos e comentários em scripts\n\n\n\n\n\nEsses títulos especiais, são formados pela união entre o caractere de comentário do R (# - hashtag), o texto que você quer inserir neste título, e vários sinais de menos (-) em sequência, formando assim a seguinte estrutura: ### &lt;título desejado&gt; -------. O número de hashtag’s e de sinais de menos que você insere, são arbitrários. Ao invés de escrevê-los a mão, o RStudio oferece um atalho que cria automaticamente esses títulos, através das teclas Ctrl + Shift + R.\nLembre-se que você também pode adicionar pequenas anotações e comentários em seu script com hashtags (#). Nós definimos em seções anteriores, que este é um caractere especial da linguagem, e que qualquer texto que você colocar a frente dele, será ignorado pelo console. Na Figura 1.6, temos um exemplo deste comentário que está marcado por uma seta verde.\n\n1.6.1 Executando comandos de um script\nVocê já sabe que para executarmos qualquer comando do R, precisamos enviar ele diretamente para o console, onde ele será avaliado e executado. Quando utilizamos um script para armazenar os nossos comandos, desejamos uma forma rápida de enviarmos esses comandos do script diretamente para o Console do R. O RStudio oferece um atalho para isso, que é o Ctrl + Enter.\nVeja a Figura 1.7 como exemplo. Se o cursor de seu mouse estiver sobre o retângulo vermelho desenhado no script, ao apertar o atalho Ctrl + Enter, o RStudio enviará todo o bloco de comandos que criam o objeto dados_selecionados, para o console. Agora, se o cursor de seu mouse estivesse sobre o retângulo verde desenhado no script, o RStudio enviaria o bloco de comandos que formam o objeto media_estados.\n\n\n\n\n\n\n\n\nFigura 1.7: Executando comandos de um script\n\n\n\n\n\nApós enviar um bloco de comandos para o console, através deste atalho, o RStudio irá automaticamente mover o cursor de seu mouse para o próximo bloco de comandos. Desta maneira, você pode executar parte por parte de seu script em sequência e, conferir os resultados de cada bloco no console. Além disso, o RStudio também oferece um outro atalho para caso você queira executar todos os comandos de um script de uma vez só. Para isso, você pode apertar as teclas Crtl + Alt + R.\n\n\n1.6.2 Salvando um script\nO grande motivo pelo qual você deve usar scripts em seu workflow com o R, é pela reprodutibilidade que eles oferecem. Ao armazenar os seus comandos em um script você é capaz de reproduzir os seus resultados com maior facilidade. Ou seja, se você quer reproduzir os resultados que você adquiriu ontem com o seu script… basta executar o mesmo script novamente, que você terá o mesmo resultado anterior.\nPara salvar um script que está aberto em seu RStudio, você pode clicar em File \\(\\rightarrow\\) Save As…, e escolher o diretório em que o arquivo será guardado. Você também pode salvar esse script, ao clicar sobre o símbolo de disquete, presente logo abaixo do nome desse script, no canto superior direito. Uma vez definido o nome do script e o local onde ele será guardado, você pode clicar em File \\(\\rightarrow\\) Save, ou utilizar o atalho Ctrl + S para salvar o script corrente a medida em que você for editando-o.\nAlém desses pontos, lembre-se que um script é nada mais do que um arquivo de texto com uma extensão .R e, por isso, ele pode ser aberto normalmente por editores de texto padrão (como o Bloco de Notas do Windows, ou por programas como Notepad ++ e Sublime Text).",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Noções Básicas do R</span>"
    ]
  },
  {
    "objectID": "Capítulos/01-nocoes-basicas.html#sec:pacotes",
    "href": "Capítulos/01-nocoes-basicas.html#sec:pacotes",
    "title": "1  Noções Básicas do R",
    "section": "1.7 Pacotes",
    "text": "1.7 Pacotes\nComo descrevemos anteriormente na seção O sistema e universo do R, o R pode ser divido em duas partes: os pacotes básicos da linguagem; e todos os demais pacotes externos que foram criados e ofertados pela comunidade do R. Um pacote (ou package) corresponde a unidade fundamental de compartilhamento de códigos e funções no R (WICKHAM, 2015). Segundo as palavras de WICKHAM; GROLEMUND (2017), um pacote do R é uma coleção de funções, dados e documentação que estendem as funcionalidades do R.\nExistem milhares e milhares de pacoates disponíveis no CRAN que você pode baixar e usar. Segundo WICKHAM (2015), esta grande variedade de pacotes representa uma das principais razões para o sucesso do R nos anos recentes, e ressalta o seguinte pensamento: é bastante provável que algum usuário já tenha enfrentado o mesmo problema que você, e após solucioná-lo, tenha ofertado um pacote que possa auxiliar você, na busca dessa solução. Logo, você pode obter enormes benefícios ao utilizar o conjunto de funções desenvolvidas por outros usuários para resolver os seus problemas.\n\n1.7.1 Como utilizar um pacote\nComo é descrito por ADLER (2010), para utilizarmos um pacote no R, precisamos “carregá-lo” para a nossa sessão. Porém, para “carregarmos” um pacote para a nossa sessão, esse pacote precisa estar instalado em nosso computador. Logo, em resumo, nós devemos realizar os seguintes passos 10:\n\nInstalar o pacote a partir do servidor do CRAN: install.packages(\"nome_do_pacote\").\nCarregar o pacote em cada sessão no R: library(nome_do_pacote).\n\nVocê precisa executar o primeiro passo (instalar o pacote com a função install.packages()) apenas uma vez. Após instalar o pacote em sua máquina, você precisa carregar esse pacote através da função library() em toda sessão no R que você desejar utilizar as funções desse pacote. Ou seja, toda vez que iniciar o R, você precisa carregar o pacote para ter acesso às suas funções.\nPor exemplo, se você desejasse utilizar as funções disponíveis no pacote ggplot2, que possui um conjunto de funções voltadas para a composição de gráficos, você precisaria dos comandos abaixo. Repare que o nome do pacote é fornecido como string à função install.packages(). Logo, sempre que for instalar um pacote, lembre-se de contornar o nome do pacote por aspas (simples ou duplas).\n\n# Instalar o pacote `ggplot2` em seu computador\ninstall.packages(\"ggplot2\")\n# Carregar o pacote `ggplot2` em sua sessão atual do R\nlibrary(ggplot2)\n\nComo GILLESPIE; LOVELACE (2017) destaca, uma boa prática a ser adotada é carregar todos os pacotes necessários sempre no início de seu script. Dessa forma, você está acoplando a sua sessão, todas as dependências necessárias para aplicar todas as funções dispostas ao longo de seu script.\n\n\n1.7.2 Identificando os pacotes instalados em sua máquina e aqueles que foram carregados para a sua sessão\nUm dos métodos mais diretos de se identificar se um determinado pacote está ou não carregado em sua sessão, consiste em você tentar utilizar uma das funções desse pacote. Se um erro aparecer durante esse processo, indicando que tal função não foi encontrada ou que ela não existe, há grandes chances de que o pacote pelo qual você está preocupado, não se encontra disponível em sua sessão atual.\nPor exemplo, eu posso tentar utilizar a função mutate() do pacote dplyr como eu normalmente faria. Pela mensagem de erro abaixo, sabemos que o R não pôde encontrar a função mutate(), logo, o pacote dplyr provavelmente não foi carregado para a minha sessão até o momento.\n\nmutate()\n\nError in mutate() : não foi possível encontrar a função \"mutate\"\nApesar de rápido, este método é um pouco inseguro. Pois, existe a chance de um dos pacotes que já estão carregados em minha sessão, possuir uma função com o mesmo nome mutate(). Em outras palavras, ao tentar executar a função mutate() em minha sessão, pode ser que o R encontre uma função mutate() diferente da que estou procurando. Por isso, um método mais seguro é necessário.\nA resposta para tal necessidade se encontra na lista de environments conectados à minha sessão atual do R. Cada pacote que você carrega para a sua sessão, é representado por um environment que está acoplado ao seu environment principal. Logo, para descobrirmos se um pacote foi carregado com sucesso para a nossa sessão, podemos consultar se esse pacote está incluso na lista de todos os environments presentes em nossa sessão. Para obtermos uma lista dos environments presentes em nossa sessão, nós podemos executar a função search(), como abaixo:\n\nsearch()\n\n [1] \".GlobalEnv\"        \"package:knitr\"     \"package:stringr\"  \n [4] \"package:stats\"     \"package:graphics\"  \"package:grDevices\"\n [7] \"package:utils\"     \"package:datasets\"  \"package:methods\"  \n[10] \"Autoloads\"         \"package:base\"     \n\n\nOs valores que estiverem na forma package:nome_do_pacote indicam o environment de um pacote que está carregado em sua sessão atual do R. Já o valor denominado .GlobalEnv, representa o global environment, que é o seu environment principal de trabalho, onde todos os seus objetos criados são salvos. Vamos descrever em mais detalhes esses pontos, na seção Noções básicas de environments. Por enquanto, perceba pelo resultado acima, que os pacotes tibble e tidyr estão carregados em minha sessão, pois os seus environments (package:tibble e package:tidyr) estão listados no resultado da função search().\nPor outro lado, você talvez enfrente algum erro ao tentar carregar o pacote de seu interesse. Nesse caso, um bom movimento seria se certificar que esse pacote está instalado em sua máquina. Segundo ADLER (2010), se você precisa identificar todos os pacotes instalados em sua máquina, você pode executar a função library() sem definir nenhum argumento ou pacote em específico.\n\n# Uma nova janela será aberta em seu RStudio\n# contendo uma lista de todos os pacotes instalados\nlibrary()\n\nCaso o pacote que você está tentando carregar não apareça na lista resultante de library(), significa que esse pacote não está instalado em sua máquina. Logo, você precisa instalá-lo com a função install.packages() antes que você possa utilizar as funcionalidades desse pacote em sua sessão do R.\n\n\n1.7.3 Acessando as funções de um pacote sem carregá-lo para sua sessão\nApesar de ser uma prática ideal na maioria das situações, você talvez não queira carregar um pacote específico e, mesmo assim, utilizar uma de suas funções. Tal opção pode gerar uma importante economia de espaço em sua memória RAM, durante a sua análise. Até porque, se você vai utilizar apenas uma única função do pacote, talvez não haja necessidade de carregar o pacote inteiro.\nPara acessarmos uma função de um pacote que não foi carregado ainda em nossa sessão, precisamos chamar primeiro pelo pacote de onde estamos tirando a função, como na estrutura abaixo.\n\n# Acessar uma função de um pacote sem carregá-lo\nnome_do_pacote::nome_da_função()\n\nLogo, se você quisesse acessar a função filter() do pacote dplyr, por exemplo, você precisa primeiro chamar pelo pacote dplyr e, em seguida, posicionar duas vezes dois pontos (:) para acessar uma função ou objeto presente neste pacote. Por último, basta digitar o nome da função de interesse.\n\n# Para acessar a função filter() sem chamar\n# pelo pacote dplyr\ndplyr::filter()\n\n\n\n1.7.4 Atualizando pacotes\nA linguagem R está o tempo todo evoluindo e se aprimorando e, por essa razão, muitos dos pacotes disponíveis hoje, são constantemente atualizados, com o objetivo de implementar novas funcionalidades e/ou aperfeiçoar a eficiência de suas funções. Logo, é uma boa prática que você mantenha os pacotes instalados em seu computador, constantemente atualizados. Para atualizar um pacote, você precisa apenas instalá-lo novamente, através da função install.packages(\"nome_do_pacote\"). Mas o RStudio oferece um atalho útil. Basta acessar a opção Tools \\(\\rightarrow\\) Check for Packages Updates… no menu superior da ferramenta. Através dessa opção, o RStudio irá listar todos os pacotes que possuem versões mais recentes e, portanto, podem ser atualizados. A grande vantagem é que você pode atualizar todos os pacotes presentes nessa lista de uma vez só.\n\n\n\n\nADLER, J. R in a Nutshell. Sebastopol, CA: O’Reilly, 2010.\n\n\nCHAMBERS, J. M. Software for Data Analysis: Programming with R. New York, NY: Springer, 2008.\n\n\nCHAMBERS, J. M. Extending R. Boca Raton, FL: CRC Press, 2016.\n\n\nGILLESPIE, C.; LOVELACE, R. Efficient R Programming. Sebastopol, CA: O’Reilly Media, Inc., 2017.\n\n\nGROLEMUND, G. Hands-On Programming with R. Sebastopol, CA: O’Reilly Media, Inc., 2014.\n\n\nIHAKA, R.; GENTLEMAN, R. R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, v. 5, n. 3, p. 299–314, 1996.\n\n\nLONG, J. D.; TEETOR, P. R Cookbook. 2nd. ed. Sebastopol, CA: O’Reilly Media, Inc., 2019.\n\n\nPENG, R. D. R Programming for Data Science. [s.l.] Leanpub, 2015.\n\n\nTEAM, R. C. R Language Definition. Version 4.0.3 ed. [s.l.] R Foundation, 2020b.\n\n\nTEAM, R. C. An Introduction to R: A Programming Environment for Data Analysis and Graphics. Version 4.0.3 ed. [s.l.] R Foundation, 2020a.\n\n\nWICKHAM, H. R Packages. Sebastopol, CA: O’Reilly Media, Inc., 2015.\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Noções Básicas do R</span>"
    ]
  },
  {
    "objectID": "Capítulos/01-nocoes-basicas.html#footnotes",
    "href": "Capítulos/01-nocoes-basicas.html#footnotes",
    "title": "1  Noções Básicas do R",
    "section": "",
    "text": "https://www.tidyverse.org/↩︎\nhttps://posit.co/products/open-source/rstudio/↩︎\nVárias outras linguagens de programação seguem esse mesmo estilo. Exemplos são: Java, C++ e Python.↩︎\nhttps://www.tidyverse.org/packages/↩︎\nhttps://rstudio.com/resources/cheatsheets/↩︎\nhttp://material.curso-r.com↩︎\nhttp://leg.ufpr.br/~walmes/cursoR/data-vis/↩︎\nhttps://www.r-bloggers.com↩︎\nhttps://www.tidyverse.org/blog/↩︎\nUma parte pequena dos pacotes disponíveis, não se encontram no CRAN, mas sim em outras plataformas como o GitHub. Neste caso, você precisa instalá-los a partir de funções do pacote devtools. Para mais detalhes, consulte o item Installing a Package from GitHub de LONG; TEETOR (2019).↩︎",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Noções Básicas do R</span>"
    ]
  },
  {
    "objectID": "Capítulos/02-fundamentos.html",
    "href": "Capítulos/02-fundamentos.html",
    "title": "2  Fundamentos da Linguagem R",
    "section": "",
    "text": "2.1 Introdução\nNas próximas seções vou abordar os fundamentos da linguagem: os básicos de sua sintaxe, quais são as estruturas e tipos de dados que a linguagem oferece, e como as suas regras de coercion funcionam.\nNa maior parte do tempo, você não vai estar interessado em como o R está estruturando ou interpretando os seus dados. Porém, várias das funções ou ações que você deseja aplicar, exigem que os seus dados estejam estruturados em um formato específica. Logo, ter familiaridade com os fundamentos do R, com as suas estruturas e suas propriedades, e principalmente, poder reconhecê-las, vai te salvar muito tempo. Com esse conhecimento, será mais fácil de você evitar erros, e será mais fácil de identificar e transformar a estrutura de seus dados para qualquer que seja a sua necessidade em um dado momento de sua análise.",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentos da Linguagem R</span>"
    ]
  },
  {
    "objectID": "Capítulos/02-fundamentos.html#mais-detalhes-sobre-objetos",
    "href": "Capítulos/02-fundamentos.html#mais-detalhes-sobre-objetos",
    "title": "2  Fundamentos da Linguagem R",
    "section": "2.2 Mais detalhes sobre objetos",
    "text": "2.2 Mais detalhes sobre objetos\nUma das principais características do R é que ele é uma linguagem orientada a objetos (object oriented). Isto significa, que quando você estiver trabalhando com seus dados no R, você estará constantemente aplicando operações e transformações sobre os objetos onde seus dados estão guardados.\nUm objeto no R é como uma caixa que você utiliza na sua mudança de casa. Você guarda algo dentro dessa caixa, e escreve na lateral um nome (ou um “rótulo”) para essa caixa, para que você se lembre do que está dentro dela. No dia seguinte à mudança, quando você precisar do conteúdo que está guardado naquela caixa, você procura essa caixa pelo nome que você deu a ela.\nNo exemplo abaixo, eu estou criando um objeto. Dou o nome de data_aniversario para este objeto, e estou utilizando o símbolo &lt;- para definir o valor deste objeto. Agora, este objeto guarda a data de aniversário de um amigo importante (20 de maio). O símbolo &lt;- é comumente chamado de assignment, e significa que estamos atribuindo um valor a um objeto (no caso abaixo, data_aniversario). Em outras palavras, os comandos abaixo, podem ser lidos como: eu atribuo ao objeto de nome data_aniversario, o valor de \"20 de maio\". Após isso, sempre que eu chamar por esse nome, o R irá procurar por uma caixa (ou um objeto) que possui o nome de data_aniversario. Quando ele encontrar essa caixa, ele irá me retornar no console o que tem dentro dessa caixa (ou desse objeto).\n\ndata_aniversario &lt;- \"20 de maio\"\n### Quando eu chamo pelo nome deste objeto\n### no console, o R me retorna o que tem dentro dele.\ndata_aniversario\n\n[1] \"20 de maio\"\n\n\nEste conceito de “objeto” é simplesmente uma metáfora, ou uma forma útil de enxergarmos este sistema. Pois para o R, o nome data_aniversario se trata apenas uma conexão até o valor (\"20 de maio\"). Para demonstrarmos essa ideia, vamos utilizar os endereços desses objetos. Isto é, todos os valores contidos nos objetos que você cria em sua sessão do R, vão obrigatoriamente ocupar um espaço, ou um endereço da memória RAM de seu computador. Enquanto este objeto estiver “vivo”, ou seja, enquanto esta conexão entre o nome x e os seus valores permanecer acessível em sua sessão, esses valores vão estar ocupando um endereço específico de sua memória RAM. Para descobrirmos esse endereço, nós podemos utilizar a função ref() do pacote lobstr. Vamos supor por exemplo, que nós criamos um vetor chamado x, que contém três números. Perceba abaixo pelo resultado da função ref(), que ao criar este objeto x, os seus valores foram alocados no endereço 0x1ca169c03d8 da minha memória RAM.\n\nlibrary(lobstr)\nx &lt;- c(6, 7, 8)\nref(x)\n\n## [1:0x1ca169c03d8] &lt;dbl&gt; \nPortanto, um objeto no R, nada mais é do que uma conexão entre um nome e valores que estão guardados em um endereço específico da memória RAM de seu computador. Os únicos momentos em que este endereço muda são: 1) todas as vezes em que você reiniciar a sua sessão no R; 2) ou todas as vezes em que você executar novamente os códigos necessários para criar os seus objetos. Tendo isso em mente, um objeto no R pode ser representado pela Figura 2.1.\n\n\n\n\n\n\n\n\nFigura 2.1: Representação de um objeto\n\n\n\n\n\nPara desenvolvermos essa ideia, pense o que ocorreria, se atribuíssemos os valores do objeto x, a um novo objeto. Segundo essa perspectiva, nós estaríamos apenas conectando o vetor com os valores 6, 7 e 8, a um novo nome, no exemplo abaixo, ao nome y. Nós poderíamos utilizar novamente a função ref() para conferirmos o endereço onde os valores do objeto y, se encontram, e perceba que eles estão no mesmo local que os valores do objeto x.\n\ny &lt;- x\nref(y)\n\n## [1:0x1ca169c03d8] &lt;dbl&gt; \nLogo, se atualizarmos a nossa representação visual, temos o seguinte resultado:\n\n\n\n\n\n\n\n\nFigura 2.2: Conectando mais nomes a um mesmo conjunto de valores\n\n\n\n\n\nEm outras palavras, o R em nenhum momento criou uma cópia do vetor contendo os valores 6, 7 e 8, e alocou essa cópia no objeto y. Ele apenas conectou um novo nome (y) a esse vetor de valores. Por isso, quando você possui um objeto, e atribui um novo valor a este objeto, você está na verdade eliminando a conexão que o nome deste objeto possuía com o valor que estava guardado anteriormente naquele objeto. Ou seja, se você retornar ao vetor x, e definir um novo valor para ele, você estaria eliminando a sua conexão com o vetor que contém os números 6, 7 e 8, e atribuindo essa conexão a um outro conjunto de valores. Por exemplo, caso eu executasse o comando x &lt;- \"Hello World\", o resultado seria uma nova conexão como você pode ver pela Figura 2.3.\n\n\n\n\n\n\n\n\nFigura 2.3: Atribuindo novos valores a seus objetos\n\n\n\n\n\nO R vai automaticamente eliminar qualquer valor que não esteja conectado a um nome (isto é, um objeto em sua sessão). Logo, tendo em mente a Figura 2.3, caso eu atribuísse um novo valor ao objeto y, a última conexão existente até o vetor que contém os números 6, 7 e 8, seria eliminada. Com isso, este vetor não possuiria mais nenhuma conexão até um nome e, por isso, esses valores seriam descartados pelo R. Portanto, se você precisa atribuir um novo valor para um determinado objeto, mas deseja manter o valor que você deu a ele anteriormente vivo de alguma forma, basta que você crie uma nova conexão até esse valor. Em outras palavras, se você quer manter este valor vivo, basta conectá-lo a um novo objeto.\nNo exemplo abaixo, eu crio um objeto (economista_1) contendo o nome de um economista famoso, e em seguida conecto este nome a um novo objeto (economista_anterior). Portanto, o nome de Keynes está agora conectado a dois nomes (isto é, ele está contido em dois objetos diferentes em sua sessão no R). Por último, eu sobreponho o nome de Keynes que guardei no primeiro objeto (economista_1), pelo nome de outro economista famoso. Quando faço isso, estou efetivamente eliminando uma das conexões até o nome de Keynes, e atribuindo essa conexão ao nome de Schumpeter. Porém, como o nome de Keynes ainda possui uma conexão existente (economista_anterior), o nome continua “vivo” e presente em nossa sessão, e se quisermos acessar novamente esse nome, basta chamarmos pelo objeto onde o salvamos.\n\n# Primeiro valor\neconomista_1 &lt;- \"John Maynard Keynes\"\n# Atribuindo o primeiro valor a um novo\n# objeto\neconomista_anterior &lt;- economista_1\n# Sobrepondo o primeiro valor no\n# primeiro objeto com um novo nome\neconomista_1 &lt;- \"Joseph Alois Schumpeter\"\neconomista_1\n\n[1] \"Joseph Alois Schumpeter\"\n\neconomista_anterior\n\n[1] \"John Maynard Keynes\"",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentos da Linguagem R</span>"
    ]
  },
  {
    "objectID": "Capítulos/02-fundamentos.html#como-o-r-organiza-e-interpreta-os-seus-dados",
    "href": "Capítulos/02-fundamentos.html#como-o-r-organiza-e-interpreta-os-seus-dados",
    "title": "2  Fundamentos da Linguagem R",
    "section": "2.3 Como o R organiza e interpreta os seus dados",
    "text": "2.3 Como o R organiza e interpreta os seus dados\nAqui temos duas questões distintas, mas que estão interconectadas. A primeira, se refere a como o R organiza os seus dados. Já a segunda questão, se refere a como o R interpreta os seus dados. A primeira questão fala das diferentes formas que o R possui para estruturar e organizar os seus dados. Essas formas são chamadas de estruturas de dados. A Figura 2.4 apresenta essa questão de forma visual.\nJá a segunda questão, fala dos diferentes tipos de dados que o R pode trabalhar com. Ou seja, todo objeto existente no R é interpretado de uma determinada maneira. É como se o R atribuísse uma cor para cada objeto: “Ah este objeto é vermelho! Opa, este objeto parece ser azul! E esse? Será que é verde? Não, acho que ele é amarelo mesmo”. Para todo objeto existente, o R atribui um tipo de dado específico a ele. Tudo depende do tipo de dado que está armazenado dentro deste objeto. A Figura 2.5 apresenta essa questão de forma visual.\n\n\n\n\n\n\n\n\nFigura 2.4: Estruturas de dados\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 2.5: Tipos de dados\n\n\n\n\n\nTanto a estrutura de dados que está sendo utilizada em um objeto, quanto o tipo de dado atribuído a ele, são partes de extrema importância no R. Pois cada função no R pode esperar como input, um objeto que esteja em um tipo ou estrutura de dados específicos. Além disso, em alguns casos, o R pode aplicar diferentes “versões” de uma mesma função sobre o seu objeto, a depender do tipo de dado associado a ele.\nPortanto, estamos nos perguntando qual o tipo de dado que o R está associando a um certo conjunto de valores, e em muitas ocasiões, podemos nos surpreender com as escolhas da linguagem. Tal surpresa está representada na Figura 2.5. Por exemplo, quando eu vejo o valor \"20/05/2020\", eu rapidamente o associo ele à data 20 de maio de 2020, mas será que o R compreende que este valor se trata de uma data? A resposta curta é, não.\nPelo fato das datas não estarem entre os tipos de dados básicos do R, enquanto não dissermos explicitamente para o R que se tratam de datas, valores como \"20/05/2020\" são tratados inicialmente como simples textos (isto é, valores do tipo character). Isso é um ponto importante, pois várias funções ou ações que queremos executar no R, exigem que os seus dados estejam no tipo adequado. Por isso, você vai enfrentar diversas situações onde o console lhe retorna um erro confuso, e depois de alguns minutos analisando os seus comandos e conferindo a estrutura de seus dados, você se supreende, e descobre que o R estava o tempo todo interpretando os seus números como textos!\nInicialmente, vamos descrever nas próximas seções as estruturas de dados presentes na linguagem. Em seguida, partimos para os tipos de dados básicos do R. Nessas seções, não vamos incluir uma estrutura do R em específico, que é o array. Nós veremos mais a frente, as matrizes (matrix), que no fundo são um caso especial de array. Enquanto matrizes são vetores com duas dimensões (uma dimensão para as linhas e outra para as colunas), os array são vetores com “n” dimensões. Em outras palavras, com um array você pode criar um objeto tridimensional (3 dimensões), ou se quiser ir longe, um objeto com 4, 5, ou infinitas dimensões.",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentos da Linguagem R</span>"
    ]
  },
  {
    "objectID": "Capítulos/02-fundamentos.html#sec:estruturas_dados",
    "href": "Capítulos/02-fundamentos.html#sec:estruturas_dados",
    "title": "2  Fundamentos da Linguagem R",
    "section": "2.4 Estruturas de dados",
    "text": "2.4 Estruturas de dados\n\n2.4.1 Vetores\nOs vetores são a estrutura básica da linguagem R, pois todas as outras estruturas, são construídas a partir desses vetores. Um vetor é simplesmente uma sequência de valores. Valores que podem ser datas, números, textos, índices, ou qualquer outro tipo que você imaginar. Pelo fato de ser uma simples sequência de valores, o vetor é uma estrutura unidimensional. É como se esse vetor fosse composto por apenas uma coluna, que você preenche com quantas linhas você precisar. Ou então, você também pode imaginá-lo como uma corda, que amarra e mantém os seus valores conectados um atrás do outro.\nA forma mais simples de se criar um vetor, é através da função c() (abreviação para combine, ou combinar), em que você fornece os valores que quer incluir neste vetor, separando-os por vírgulas. A outra forma (indireta) de se criar um vetor, é através de funções que retornam por padrão este tipo de estrutura. Um exemplo simples, é a função : que serve para criar sequências numéricas no R, no exemplo abaixo, uso essa função para criar uma sequência de 1 a 10. Outro exemplo, seria a função rep() que serve para repetir um conjunto de valores, por quantas vezes você quiser.\n\nc(48, 24, 12, 6)\n\n[1] 48 24 12  6\n\nc(\"a\", \"b\", \"c\", \"d\")\n\n[1] \"a\" \"b\" \"c\" \"d\"\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nrep(c(\"Ana\", \"Eduardo\"), times = 5)\n\n [1] \"Ana\"     \"Eduardo\" \"Ana\"     \"Eduardo\" \"Ana\"     \"Eduardo\" \"Ana\"    \n [8] \"Eduardo\" \"Ana\"     \"Eduardo\"\n\n\nComo o vetor é uma estrutura unidimensional, eu posso acessar um único valor dentro desse vetor, utilizando apenas um índice. Por exemplo, se eu quero extrair o quarto valor dessa sequência, eu utilizo o número 4, se eu quero o terceiro valor, o número 3, e assim por diante. Para acessar “partes”, ou um único valor de uma estrutura no R, nós utilizamos a função [, e para utilizá-la, basta abrir colchetes após o nome do objeto onde você salvou este vetor, ou após a função que está gerando este vetor.\n\nvetor &lt;- 1:10\nvetor[4]\n\n[1] 4\n\nc(\"a\", \"b\", \"c\")[3]\n\n[1] \"c\"\n\n\nPara acessar mais de um valor dentro deste vetor, você terá que fornecer um novo vetor de índices à função [. Um jeito prático de criar este novo vetor de índices, é criando uma sequência com a função : que vimos anteriormente. Um detalhe, é que o R irá extrair os valores na ordem em que você os dá a [. Logo, se eu dentro de [ incluir o vetor c(2,4,6,1), o R irá lhe retornar um novo vetor, que contém o segundo, quarto, sexto e primeiro item do vetor anterior, respectivamente. Caso você repita algum índice, o R irá repetir o valor dentro do vetor resultante, e não te avisará sobre isso.\n\nvetor &lt;- 1:25\nvetor[1:4]\n\n[1] 1 2 3 4\n\nvetor[8:13]\n\n[1]  8  9 10 11 12 13\n\nvetor[c(2,4,4,1)]\n\n[1] 2 4 4 1\n\n\nOs vetores que estamos criando com essas funções são comumente chamados de vetores atômicos (atomic vector). Esses vetores possuem uma propriedade simples e importante: vetores atômicos possuem apenas um único tipo de dado dentro deles. Você não consegue guardar dentro de um mesmo vetor, valores de dois tipos de dados diferentes (por exemplo, textos e números) sem que alguma transformação ocorra. Caso você tente burlar essa regra, o R irá automaticamente converter os valores para um único tipo de dado, e pode ser que parte desses dados não possam ser convertidos de forma lógica para este único tipo, e acabam sendo “perdidos” neste processo. Falaremos mais sobre esse processo de conversão, quando chegarmos em tipos de dados.\n\n\n2.4.2 Matrizes\nMatrizes nada mais são do que vetores com duas dimensões. Se você possui dados atualmente alocados em um vetor, e deseja organizá-los em colunas e linhas, você pode rapidamente criar uma matriz com este vetor, ao adicionar dimensões a ele, através da função dim(). Você usa a função sobre o vetor desejado à esquerda do símbolo de assignment (&lt;-), e atribui um valor ao resultado dessa função. No caso de matrizes, esse valor será um vetor com dois elementos, o primeiro definindo o número de linhas, e o segundo, o número de colunas.\n\nvetor &lt;- 1:6\ndim(vetor) &lt;- c(3,2)\nvetor\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n\nUma outra forma de criar uma matriz, é através da função matrix(). Você primeiro fornece um vetor à função, e define quantas colunas você deseja em ncol, e quantas linhas em nrow. Um detalhe que fica claro no exemplo abaixo, é que ao criar uma matriz, ela por padrão será preenchida por coluna, e não por linha. Caso você queira que ela seja preenchida por linha, você deve adicionar o valor TRUE, ao argumento byrow na função.\n\n# Para preencher a matriz, por linha, adicione\n# byrow = TRUE à função\nmatrix(1:20, nrow = 5, ncol = 4)\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    6   11   16\n[2,]    2    7   12   17\n[3,]    3    8   13   18\n[4,]    4    9   14   19\n[5,]    5   10   15   20\n\n\nOs vetores são estruturas unidimensionais, e com apenas um índice poderíamos acessar um valor contido nele. Porém, as matrizes possuem duas dimensões, logo, temos que fornecer dois índices à função [ para acessarmos um único elemento dessa matriz. Basta você separar esses dois índices por uma vírgula, onde o primeiro valor corresponde a linha, e o segundo, a coluna desejada. No exemplo abaixo, estou extraindo o elemento que se encontra na terceira linha da quarta coluna.\n\nmatriz &lt;- matrix(1:20, nrow = 5, ncol = 4)\nmatriz[3,4]\n\n[1] 18\n\n\nEu posso também extrair uma parte dessa matriz, ao fornecer mais valores dentro de um vetor, para cada um dos dois índices. No primeiro exemplo abaixo, eu extraio todos os valores da primeira a terceira linha da segunda coluna da matriz. Agora, caso eu queira extrair todos os valores de uma dimensão (todas as linhas, ou todas as colunas), basta que eu deixe em “branco” ao lado de cada índice. No segundo exemplo abaixo, estou extraindo todos os valores da segunda coluna.\n\nmatriz[1:3, 2] # É o mesmo que: matriz[c(1,2,3), 2]\n\n[1] 6 7 8\n\nmatriz[ , 2]\n\n[1]  6  7  8  9 10\n\n\nPelo fato de matrizes serem vetores com duas dimensões, elas herdam a propriedade do vetor, e, portanto: matrizes podem conter dados de apenas um único tipo. Por essa característica, você provavelmente utilizará essa estrutura poucas vezes. De qualquer forma é útil conhecê-la.\n\n\n2.4.3 Listas\nA lista é uma estrutura especial e muito importante do R, pois ela é a exceção da propriedade dos vetores (que podem conter apenas um tipo de dado). Portanto, uma lista é um vetor, onde cada elemento deste vetor pode ser não apenas de um tipo de dado diferente, mas também de tamanho e estrutura diferentes. Dito de outra forma, você pode incluir o que você quiser em cada elemento de uma lista.\nUma lista é criada pela função list(), e para utilizá-la, basta fornecer os valores que deseja inserir em cada elemento desta lista, separados por vírgulas. No exemplo abaixo, estou inserindo no primeiro elemento desta lista a data que vimos anteriormente (“20/05/2020”), no segundo, estou incluindo uma matriz, no terceiro, um vetor com nomes, e no quarto, um data.frame (falaremos sobre eles após essa seção).\n\n# Lista nomeada\n# nome = valor\nlista &lt;- list(\n  data = \"20/05/2020\",\n  matriz = matrix(1:20, ncol = 4, nrow = 5),\n  vetor = c(\"Belo Horizonte\", \"Londrina\", \"Macapá\"),\n  tabela = data.frame(x = 21:30, y = rnorm(10))\n)\n\nlista\n\n$data\n[1] \"20/05/2020\"\n\n$matriz\n     [,1] [,2] [,3] [,4]\n[1,]    1    6   11   16\n[2,]    2    7   12   17\n[3,]    3    8   13   18\n[4,]    4    9   14   19\n[5,]    5   10   15   20\n\n$vetor\n[1] \"Belo Horizonte\" \"Londrina\"       \"Macapá\"        \n\n$tabela\n    x          y\n1  21 -1.6066575\n2  22 -1.6471515\n3  23 -0.8230947\n4  24  0.9044368\n5  25 -1.5193675\n6  26  0.1641503\n7  27  0.7821895\n8  28  0.1951373\n9  29  0.6863949\n10 30  1.0276381\n\n\nPerceba que nós nomeamos cada elemento dessa lista. Isso abre novas possibilidades, pois agora podemos utilizar um sistema diferente da função [ para acessarmos os valores específicos de uma lista, utilizando o operador $. Através deste operador, podemos acessar os elementos dessa lista, através do nome que demos para cada um deles. O problema deste sistema, é que ele lhe permite acessar todos os valores contidos em um elemento de sua lista, mas não lhe permite extrair valores específicos contidos em cada um destes elementos da lista.\n\nlista$matriz\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    6   11   16\n[2,]    2    7   12   17\n[3,]    3    8   13   18\n[4,]    4    9   14   19\n[5,]    5   10   15   20\n\nlista$vetor\n\n[1] \"Belo Horizonte\" \"Londrina\"       \"Macapá\"        \n\n\nVocê não precisa nomear cada um dos elementos dessa lista como fizemos acima. Eu nomeie apenas para dar um exemplo do operador $. Porém, neste caso em que você não atribui um nome a esses elementos, você não pode acessá-los mais pelo operador $, e terá que retornar à funçaõ [ para tal serviço. Em outras palavras, se você deseja criar uma lista, mas não está muito preocupado em nomear cada um dos elementos que vão estar nessa lista, basta separar esses valores por vírgulas como no exemplo abaixo:\n\nlista &lt;- list(\n  c(6, 7, 8),\n  c(\"a\", \"b\", \"c\"),\n  c(T, F, T)\n)\n\nlista\n\n[[1]]\n[1] 6 7 8\n\n[[2]]\n[1] \"a\" \"b\" \"c\"\n\n[[3]]\n[1]  TRUE FALSE  TRUE\n\n\nAntes de prosseguirmos, darei uma nova descrição (dessa vez, uma descrição visual) de uma lista, para que você fixe na sua cabeça o que ela é. Eu espero que eu tenha desejado bem o suficiente, para que você seja capaz de identificar um trem carregando quatro vagões na Figura 2.6. Podemos pensar esse trem como uma lista, e os seus vagões como os elementos dessa lista. Tendo isso em mente, temos na Figura 2.6 uma representação de uma lista com quatro elementos.\nComo disse anteriormente, podemos incluir o que quisermos dentro de cada elemento dessa lista, ou dentro de cada vagão desse trem. Pois cada vagão é capaz de comportar elementos de qualquer dimensão e em qualquer estrutura, e como esses vagões estão separados uns dos outros, esses elementos não precisam compartilhar das mesmas características. Dito de outra forma, eu posso carregar 15 toneladas de ouro no primeiro vagão, 100 Kg de carvão no segundo vagão, e 1 Kg de ferro no terceiro vagão.\n\n\n\n\n\n\n\n\nFigura 2.6: Representação de uma lista\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 2.7: Diferença entre um e dois colchetes em listas\n\n\n\n\n\nPortanto, a lista é uma estrutura que lhe permite transportar todos esses diferentes elementos, em um mesmo objeto no R (ou todos esses diferentes componentes em um mesmo trem). Quando chegarmos em interação, você verá que essa característica torna a lista, uma estrutura extremamente útil.\nAgora como eu posso extrair valores dessa lista através da função [ ? Bem, a lista é a exceção da propriedade dos vetores, mas ela continua sendo um vetor em sua essência, ou uma estrutura unidimensional. Por isso, você pode acessar um item de uma lista com apenas um índice dentro de [.\nPorém, caso você usar apenas um colchete para selecionar o primeiro elemento de sua lista, você percebe que uma pequena descrição (\"[[1]]\"), ou o nome que você deu aquele elemento, aparece em cima dos valores contidos neste elemento da lista. Por isso, se você deseja extrair apenas os valores desse elemento, sem essa descrição, você deve utilizar o índice dentro de dois colchetes.\n\nlista &lt;- list(\n  1:20,\n  \"O ano tem 365 dias\",\n  matrix(1:20, ncol = 4, nrow = 5)\n)\n\nlista[1]\n\n[[1]]\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\nlista[[1]]\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\nlista[[2]]\n\n[1] \"O ano tem 365 dias\"\n\nlista[[3]]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    6   11   16\n[2,]    2    7   12   17\n[3,]    3    8   13   18\n[4,]    4    9   14   19\n[5,]    5   10   15   20\n\n\nIsso ocorre, porque quando você utiliza apenas um colchete para selecionar o primeiro elemento, o R acaba lhe retornando uma nova lista contendo um elemento, e não apenas o que está dentro deste elemento em si. Dizendo em termos da representação visual que utilizamos na Figura 2.6, se eu possuo um trem com quatro vagões, e utilizo um colchete para selecionar o primeiro vagão, o R me retorna um novo trem que contém o primeiro vagão. Mas se eu utilizo dois colchetes, o R me retorna apenas o primeiro vagão, e nada mais.\nMas como eu faço para extrair um valor específico de um elemento de uma lista? Para isso você deve abrir um novo colchete após os colchetes duplos que você criou para selecionar o elemento da lista (como mostrado na Figura 2.7). A partir daí, basta replicar o que vimos anteriormente com os índices. No exemplo abaixo, estou primeiro selecionando o terceiro elemento da nossa lista (que é uma matriz). Em seguida, eu seleciono o item da terceira linha da primeira coluna desta matriz.\n\nlista[[3]][3,1]\n\n[1] 3\n\n\n\n\n2.4.4 Tabelas no R: data.frame\nO data.frame é a principal estrutura utilizada para guardar tabelas e bases de dados no R (esta estrutura é semelhante ao DataFrame no framework pandas do Python). Na grande maioria das vezes que você importar os seus dados para o R, eles serão alocados dentro de um data.frame. Essa estrutura é no fundo, uma lista com algumas propriedades a mais. Por isso, o data.frame herda uma das propriedades da lista: cada uma das colunas da tabela formada por um data.frame, pode conter um tipo de dado diferente das demais colunas deste data.frame.\nEsta é uma das principais características que tornam o data.frame, uma estrutura adequada para guardar a grande maioria das bases de dados. Pois é muito comum, que você possua em sua base, diversas colunas contendo dados de diferentes tipos. Por exemplo, você pode ter uma base que possui uma coluna contendo datas, outras duas contendo valores numéricos, e uma última coluna contendo textos, ou rótulos indicando a qual indicador ou grupo, os valores numéricos da linha se referem. E ao importar uma base como essa para o R, é de seu desejo que o R interprete essas colunas corretamente e mantenha os tipos desses dados intactos.\nOs data.frame’s são criados pela função data.frame(). Você deve preencher essa função com os valores que você deseja alocar em cada coluna separados por vírgulas. Você pode escolher não dar um nome a cada coluna, neste caso a função se ocupará de dar um nome genérico para elas. Caso opte por definir esses nomes, você deve fornecê-los antes dos valores da coluna, seguindo a seguinte estrutura:\n\n# Estrutura Básica:\n# data.frame(\n#   &lt;nome_coluna&gt; = &lt;valor_coluna&gt; \n# )\n\ndata.frame(\n  nomes = rep(c(\"Ana\", \"Eduardo\"), times = 5),\n  numeros = rnorm(10),\n  constante = 25\n)\n\n     nomes    numeros constante\n1      Ana  0.8330798        25\n2  Eduardo -0.3340422        25\n3      Ana -0.0985339        25\n4  Eduardo -2.6462235        25\n5      Ana -0.3456871        25\n6  Eduardo -0.7246778        25\n7      Ana  0.2606361        25\n8  Eduardo  1.4610200        25\n9      Ana -0.2505935        25\n10 Eduardo -0.9257524        25\n\n\nCaso você esteja em dúvida, tudo o que a função rnorm() faz é gerar valores aleatórios seguindo uma distribuição normal. Vemos que no exemplo acima, geramos uma tabela com 3 colunas e 10 linhas, e aqui chego a segunda principal propriedade de um data.frame, que é: todas as colunas de um data.frame devem possuir o mesmo número de linhas. O motivo dessa propriedade é um pouco óbvio, pois se estamos tentando formar uma tabela de dados, é natural pensarmos que ela deve formar um retângulo uniforme.\nIsso significa, que se eu pedisse para a função rep() repetir os valores 6 vezes (ao invés de 5), gerando assim um vetor de 12 elementos (ou 12 linhas), a função data.frame() me retornaria um erro, indicando que o número de linhas criadas pelos diferentes vetores não possuem o mesmo número de linhas.\nCaso não tivéssemos essa propriedade, estaríamos permitindo que alguma dessas colunas deste data.frame, fosse mais longa do que as outras. Neste caso, como você lidaria com as observações “sobressalentes” da tabela ? Você possui um valor na coluna x que não possui um valor correspondente na coluna y, será que você considera o valor da coluna y como vazio ? Não disponível ? Não existente ? Enfim, uma confusão que é desnecessária.\nEssa propriedade nos garante que para cada observação (ou linha) da nossa tabela, deve sempre existir um valor na coluna y correspondente ao valor da coluna x, mesmo que o valor da coluna y seja um valor NA (não disponível), ou algo indicando que não foi possível coletar esse valor no plano físico de nossa atividade.\n\n\n\n\n\nRepresentação de um data.frame a partir de uma lista\n\n\n\n\nAo voltar para o exemplo acima, você pode perceber que na terceira coluna que definimos em data.frame(), demos uma simples constante (25) à função. Como resultado, a função acaba preenchendo toda a coluna por essa constante. Isso ocorre sempre que você fornece um único valor a uma coluna de seu data.frame, seja este valor, uma data, um texto, um número ou qualquer outro tipo que imaginar.\nA partir daqui, é interessante criarmos um modelo visual em nossa cabeça, sobre o que um data.frame representa. Como disse anteriormente, um data.frame, é basicamente uma lista, com algumas propriedades a mais, em especial a propriedade de que todos os seus elementos devem possuir o mesmo número de linhas. Portanto, se você quer imaginar um data.frame em sua mente, você pode imaginar uma lista, onde cada um de seus elementos, representa uma coluna desse data.frame. Em conjunto, essas colunas (ou os elementos dessa lista) formam uma tabela, sendo essa tabela, comumente referida como um data.frame.\nVale destacar um outro comportamento da função data.frame(). Ela transforma por padrão, todos os textos em fatores (factor), ou em outras palavras, valores de uma variável categórica que possui um conjunto limitado de valores possíveis. Vamos aprender mais sobre este tipo de dados nas próximas seções. Inicialmente, isso não tem grandes implicações sobre os seus dados. Eles vão continuar sendo apresentados como textos, e a única grande mudança será sobre a forma como o R irá ordenar esses valores caso você peça isso a ele. Mas é importante saber deste detalhe, pois você vai querer suprimir esse comportamento na maioria das vezes. Para isso, basta adicionar o valor FALSE para o argumento stringsAsFactors.\n\ntabela &lt;- data.frame(\n  cidade = rep(c(\"Belo Horizonte\", \"Londrina\", \"Macapá\"), times = 4),\n  valor = rnorm(12),\n  stringsAsFactors = FALSE\n)\n\n# Estou utilizando a função is.character()\n# para confirmar que data.frame() manteve\n# a coluna de cidades como texto (characters)\nis.character(tabela$cidade)\n\n[1] TRUE\n\n\nNo exemplo acima, você também percebe que eu utilizei dentro da função is.character(), o operador $ para acessar os valores da coluna cidade da nossa tabela. Em data.frame’s você sempre pode utilizar este mecanismo para acessar os valores de uma das colunas de sua tabela, pois data.frame() irá sempre se preocupar em nomear as colunas caso você não o faça. Portanto, mesmo que data.frame() invente um nome completamente esquisito para as suas colunas, elas sempre terão um nome para o qual você pode se referir com $.\nIsso não significa que você deixará de utilizar o sistema [, pois essa função é muito mais flexível do que você imagina. Uma de suas principais e mais poderosas ferramentas, é um sistema que é comumente chamado de logical subsetting. Com ele, podemos usar a função [ para extrair valores de um objeto, de acordo com o resultado de testes lógicos. Em diversas funções de pacotes que você utilizar, se você visitar o código fonte dessas funções, você irá encontrar este sistema sendo utilizado em algum momento, sendo portanto, uma ferramenta extremamente útil dentro do R.\nEm resumo, se você quer extrair todos os valores de uma coluna de seu data.frame, você pode utilizar o sistema $, ou o mesmo sistema que utilizamos em matrizes, ao deixar o índice das linhas em “branco” dentro de [. Se você quer extrair partes específicas de sua tabela, você terá que usar [ da mesma forma que o utilizamos em matrizes. Como as colunas de um data.frame são nomeados, você pode também extrair uma coluna inteira, ao colocar o nome dessa coluna entre aspas dentro dos colchetes. Todos os sistemas utilizados abaixo, nos retorna todos os valores da coluna cidade.\n\ntabela$cidade\n\ntabela[, 1]\n\ntabela[[\"cidade\"]]\n\nVocê deve ter percebido acima que utilizei novamente os dois colchetes, ao me referir dentro deles pelo nome da coluna desejada. Este sistema funciona exatamente da mesma forma que ele funciona em listas. Se eu utilizar um colchete, o R me retorna um data.frame contendo uma única coluna (neste caso, a coluna cidade), se eu uso dois colchetes, o R me retorna um vetor contendo apenas os valores dessa coluna.\nAgora, voltando um pouco em nossa descrição, quando eu disse que um data.frame são listas, pois herdava muitas de suas propriedades, eu acabei omitindo uma dessas propriedades para evitar confusões. Você deve ter percebido pelos exemplos anteriores, que cada elemento de um data.frame é uma coluna de sua tabela. Você talvez tenha percebido também que todos esses elementos nos exemplos anteriores, eram vetores. Isso é uma característica marcante de um data.frame, pois na maioria das vezes em que você ver um, ele estará servindo apenas como um laço, que amarra e mantém diferentes vetores unidos em uma mesma estrutura, vetores esses que juntos formam uma tabela.\nVocê deve estar pensando: “Mas é claro que cada coluna é um vetor! Não faria sentido se eu incluísse matrizes ou outras tabelas em uma coluna de uma tabela! Um vetor é a estrutura que faz mais sentido para essas colunas!”. Bom, eu creio que agora é uma boa hora para “explodir” a sua cabeça!…ou pelo menos metaforicamente falando. A outra propriedade que data.frame’s herdam de listas, é que cada um de seus elementos também não precisam ser da mesma estrutura. \nEssa propriedade significa que eu posso incluir sim, uma matriz, ou um outro data.frame, como uma nova coluna de um data.frame que está salvo em algum objeto. Lembre-se que a principal diferença entre um data.frame e uma lista, é que os elementos de um data.frame precisam obrigatoriamente ter o mesmo número de linhas. No exemplo abaixo, eu estou criando inicialmente um data.frame com 10 linhas e 2 colunas, logo, se eu quiser incluir uma nova tabela como uma nova coluna desse data.frame, essa nova tabela (ou novo data.frame) deve possuir 10 linhas (mas esse novo data.frame pode ter quantas colunas você desejar).\nVocê pode facilmente adicionar uma nova coluna a um data.frame, utilizando o operador $. Você escreve primeiro o nome do objeto onde o seu data.frame está contido, abre o cifrão ($), e em seguida, coloca um nome de uma coluna que não existe em seu data.frame até aquele momento. Se não há alguma coluna neste data.frame que possui este nome, o R irá adicionar esta coluna a ele, e para você preencher essa coluna com algum valor, basta utilizar o símbolo de assignment (&lt;-), como se você estivesse salvando algum valor em um novo objeto. Após criar essa nova coluna, eu chamo por ela, para que o R me mostre o que tem nessa coluna, e como esperávamos, ele me retorna o novo data.frame que criamos.\n\ntabela &lt;- data.frame(\n  cidade = rep(c(\"Belo Horizonte\", \"Londrina\"), times = 5),\n  valor = rnorm(10)\n)\n\ntabela$novo_dataframe &lt;- data.frame(\n  x = rep(\"Ana\", times = 10),\n  y = rep(\"Eduardo\", times = 10),\n  z = 25\n)\n\ntabela$novo_dataframe\n\n     x       y  z\n1  Ana Eduardo 25\n2  Ana Eduardo 25\n3  Ana Eduardo 25\n4  Ana Eduardo 25\n5  Ana Eduardo 25\n6  Ana Eduardo 25\n7  Ana Eduardo 25\n8  Ana Eduardo 25\n9  Ana Eduardo 25\n10 Ana Eduardo 25\n\n\nNa Figura 2.8, estou utilizando a função str() sobre o objeto tabela. Essa função nos retorna no console, uma descrição da estrutura de um objeto. No retângulo vermelho, temos a estrutura geral do objeto, vemos que o objeto tabela é um data.frame com dez linhas e três colunas. Os nomes de suas três colunas estão especificadas no retângulo verde. A direita do nome da terceira coluna (chamada novo_dataframe), podemos ver uma descrição de sua estrutura marcada por um retângulo azul. Vemos neste retângulo azul, portanto, a estrutura desta terceira coluna, e podemos confirmar que se trata também de um data.frame com 10 linhas e 3 colunas, e no retângulo roxo, podemos ver o nome das três colunas (no caso abaixo, colunas x, y e z) contidas neste segundo data.frame. Os falantes de língua inglesa costumam se referir a esta situação onde inserimos uma nova estrutura dentro de uma mesma estrutura, como uma nested structure, ou uma estrutura “aninhada”. Logo, o exemplo que estou dando, se trata de um nested data.frame. Pois estamos inserindo um data.frame, dentro de um outro data.frame.\n\n\n\n\n\n\n\n\nFigura 2.8: Estrutura de um data.frame aninhado\n\n\n\n\n\nSe você chamar pelo nome tabela no console, para ver o que tem dentro deste objeto, o console irá lhe mostrar um data.frame com 10 linhas e 5 colunas. Pois ele lhe apresenta tanto as 2 colunas definidas como vetores em tabela, quanto as 3 colunas definidas em tabela$novo_dataframe, tudo em uma mesma tabela. Entretanto, como vimos através da função str(), o R está considerando este objeto como um data.frame com 10 linhas e 3 colunas, onde a terceira coluna contém um novo data.frame de 10 linhas e com outras 3 colunas, e não como um único data.frame com 10 linhas e 5 colunas.\nTendo essas considerações em mente, você pode sim incluir dados que estão em qualquer uma das estruturas anteriormente mencionadas, dentro de uma coluna (ou elemento) de um data.frame. Essa propriedade é mais citada nos manuais originais da linguagem (veja TEAM, 2020a, 2020b), enquanto é muito pouco mencionada, ou pouco explicada em detalhes em outros livros-texto sobre a linguagem. Pois é uma propriedade que faz pouco sentido, considerando-se as principais aplicações de um data.frame. Porém, com essa propriedade, você pode pensar facilmente em uma outra estrutura que é muito mais útil e muito mais poderosa, para ser incluída em uma nova coluna de seu data.frame. Essa estrutura, é uma lista!\nPense um pouco sobre isso. Uma lista é um vetor em sua essência, e por isso, pode facilmente formar uma nova coluna desse data.frame. A vantagem de se incluir uma lista, é que agora em cada célula (ou em cada linha) dessa nova coluna, eu posso guardar um dado de um tipo, tamanho e estrutura diferentes. Se fossemos utilizar a representação visual da seção anterior, é como se a coluna de seu data.frame tenha se transformado em um trem, e agora cada célula, ou cada linha dessa coluna, tenha se tornado um vagão deste trem. Com essa realidade, você pode por exemplo, facilmente aplicar um modelo de regressão sobre 1.000 bases de dados diferentes, e ainda guardar os resultados em cada linha de uma nova coluna, tudo isso com apenas um comando! Dessa forma, você terá em uma coluna de seu data.frame contendo uma lista, lista essa que está mantendo todos esses 1.000 data.frame’s diferentes juntos.\nSe você consegue entender a língua inglesa, mesmo que sutilmente, eu altamente recomendo que assista a palestra de Hadley Wickham, entitulada “Managing many models with R”, que está disponível no YouTube1. Nesta palestra, ele dá um exemplo prático de como você pode implementar essa ideia, ao aplicar um modelo de regressão sobre várias bases diferentes, utilizando essa propriedade em um data.frame.\n\n\n2.4.5 tibble’s como uma alternativa moderna aos data.frame’s\nUm tibble nada mais é do que uma “versão moderna” de um data.frame. Essa estrutura de dado é originária do pacote tibble, logo, se você deseja utilizá-la em algum de seus dados, você terá que chamar obrigatoriamente por esse pacote com o comando library()2. Lembre-se que o pacote deve estar instalado em sua máquina, para que você seja capaz de chamar por ele com o comando library().\nPortanto, essa estrutura foi criada com o intuito de melhorar alguns comportamentos do data.frame, que eram adequados para a sua época, mas que hoje, são desnecessários e que podem gerar um pouco de dor de cabeça. Tais estruturas podem ser criadas do zero, através da função tibble(), que funciona da mesma maneira que data.frame(). Você dá o nome para cada coluna, e após um igual (=) você define o que irá preencher cada uma dessas colunas.\n\nlibrary(tibble)\n\ntab_tibble &lt;- tibble(\n  Datas = seq.Date(as.Date(\"2020-12-01\"), as.Date(\"2020-12-10\"), by = 1),\n  Usuario = sample(c(\"Ana\", \"Eduardo\"), size = 10, replace = T),\n  Valor = sample(c(2000, 3000, 4000, 5000), size = 10, replace = T)\n)\n\ntab_tibble\n\n# A tibble: 10 × 3\n  Datas      Usuario Valor\n  &lt;date&gt;     &lt;chr&gt;   &lt;dbl&gt;\n1 2020-12-01 Eduardo  4000\n2 2020-12-02 Ana      4000\n3 2020-12-03 Ana      4000\n4 2020-12-04 Eduardo  3000\n5 2020-12-05 Ana      2000\n# ℹ 5 more rows\n\n\nPor outro lado, se você já possui um data.frame e deseja convertê-lo para um tibble, você precisa apenas aplicar a função as_tibble() sobre ele.\n\ntabela &lt;- as_tibble(tabela)\n\nA primeira melhoria dessas estruturas, se encontra no método de print(), ou em outras palavras, na forma como o R lhe mostra a sua tabela no console. Quando chamamos por um objeto que é um data.frame, o console acaba lhe retornando muito mais linhas do que o necessário (ele pode retornar até 1000 linhas), além de todas as colunas da tabela. Se o seu data.frame possui várias colunas, você pode se sentir frustrado com esse comportamento, pois se alguma coluna de sua tabela não couber ao lado das colunas anteriores, o console acaba quebrando o resultado em várias “linhas”, algo que pode tornar a leitura confusa com certa facilidade.\nAs origens do R são antigas (&gt; 50 anos), e aparentemente esse não era um comportamento muito ruim na época, talvez porque as dimensões das tabelas dessa época eram muito limitadas. Porém, com as capacidades de processamento atuais, essa atitude é desnecessária ou indesejada em quase todas as situações. Veja no exemplo abaixo, onde eu pego a base flights (que possui 19 variáveis diferentes), e transformo-a em um data.frame com a função as.data.frame(). Para que o resultado não consuma muito espaço deste material, eu ainda limito o resultado às 5 primeiras linhas da tabela com head(). Perceba que a tabela foi dividida em 3 linhas diferentes de output.\n\nlibrary(nycflights13)\n\nas.data.frame(flights) %&gt;% \n  head(n = 5)\n\n  year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n1 2013     1   1      517            515         2      830            819\n2 2013     1   1      533            529         4      850            830\n3 2013     1   1      542            540         2      923            850\n4 2013     1   1      544            545        -1     1004           1022\n5 2013     1   1      554            600        -6      812            837\n  arr_delay carrier flight tailnum origin dest air_time distance hour minute\n1        11      UA   1545  N14228    EWR  IAH      227     1400    5     15\n2        20      UA   1714  N24211    LGA  IAH      227     1416    5     29\n3        33      AA   1141  N619AA    JFK  MIA      160     1089    5     40\n4       -18      B6    725  N804JB    JFK  BQN      183     1576    5     45\n5       -25      DL    461  N668DN    LGA  ATL      116      762    6      0\n            time_hour\n1 2013-01-01 05:00:00\n2 2013-01-01 05:00:00\n3 2013-01-01 05:00:00\n4 2013-01-01 05:00:00\n5 2013-01-01 06:00:00\n\n\nQuando as suas tabelas são tibble’s, o console lhe retorna por padrão, apenas as 10 primeiras linhas da tabela (caso a tabela seja muito pequena, ele pode lhe retornar todas as linhas), o que já é o suficiente para vermos a sua estrutura. Além disso, caso as próximas colunas não caibam em uma mesma “linha”, ou ao lado das colunas anteriores, o tibble acaba omitindo essas colunas para não sobrecarregar o seu console de resultados. Lembre-se que você sempre pode ver toda a tabela, em uma janela separada através da função View().\n\nView(flights)\n\nVeja o exemplo abaixo, onde eu chamo novamente pela base flights. O primeiro detalhe que você percebe, é a dimensão da tabela (algo que não é informado, quando chamamos por um data.frame) no canto superior esquerdo da tabela (336.776 linhas e 19 colunas). O segundo detalhe, é que o tipo de dado contido em cada coluna, está descrito logo abaixo do nome da coluna, de acordo com a abreviação deste tipo. Por exemplo, nas três primeiras colunas estão contidos números inteiros (integer’s - int), enquanto na sexta coluna (dep_delay) temos números decimais (double’s - dbl).\nMesmo que em um tibble, você fique sem a possibilidade de visualizar todas as outras colunas da tabela, que não cabem na mesma linha junto com as colunas anteriores, um tibble sempre lhe retorna logo abaixo da tabela, uma lista contendo o nome de todas as colunas restantes, além do tipo de dado contido em cada coluna, através das mesmas abreviações que vimos nas colunas anteriores.\n\nflights\n\n# A tibble: 336,776 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n# ℹ 336,771 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n\nAlém desses pontos, tibble’s vão sempre criar destaques, ou ênfases em certos dados no console, algo que os data.frame’s não fazem em nenhum momento. Por exemplo, tibble’s vão sempre marcar de vermelho, qualquer número que seja negativo, uma funcionalidade que é bem familiar aos usuários de Excel que utilizam formatação condicional. Um outro detalhe, é que essa estrutura também marca as casas dos milhares com um pequeno sublinhado, o que facilita muito a leitura de números muito grandes.\nPara mais, um comportamento muito comum de um data.frame, é converter os seus dados em textos, para fatores (factor). Este não é um comportamento de todo ruim, e nem sempre ele ocorre. Porém o principal valor dos fatores no R, está no uso de dummies em regressões e análises estatísticas, além da maneira como a ordenação de seus valores é executada. Estas características são importantes, mas também são irrelevantes para uma gama muito grande de situações. Em outras palavras, este é um comportamento desnecessário na maioria de nossas análises.\nPor isso, uma outra característica que os tibble’s carregam, é que eles nunca transformam os seus dados para um outro tipo. Isso é um ponto muito importante! As funções com as quais nós trabalhamos no R, geralmente funcionam melhor com (ou são especializadas em) uma estrutura ou tipo de dado específico, e quando nós estruturamos as nossas análises sobre essas funções, nós desejamos evitar mudanças não autorizadas sobre os tipos e estruturas utilizados.\nOu seja, é sempre melhor evitar transformações implícitas de seus dados. Pois essas operações podem muito bem, levantar erros dos quais você não compreende, até que você (depois de muito tempo analisando os resultados) perceba que os seus dados foram convertidos para algo incompatível com o que você deseja realizar.\nDessa forma, em um tibble os seus dados em texto são interpretados como textos (character), a menos que você peça explicitamente ao R que interprete esses dados de uma outra forma. Veja o exemplo abaixo, onde utilizo a função str() para ver um resumo da estrutura de cada tabela. Podemos ver abaixo, que a coluna text na tabela tib contém dados do tipo character (chr), enquanto essa mesma coluna na tabela df, possui dados do tipo factor.\n\ntib &lt;- tibble(\n  x = rnorm(10),\n  text = sample(c(\"Ana\", \"Eduardo\"), size = 10, replace = T)\n)\n\ndf &lt;- data.frame(\n  x = rnorm(10),\n  text = sample(c(\"Ana\", \"Eduardo\"), size = 10, replace = T)\n)\n\nstr(tib)\n\ntibble [10 x 2] (S3: tbl_df/tbl/data.frame)\n $ x   : num [1:10] 0.172 0.315 0.119 -0.155 -0.165 ...\n $ text: chr [1:10] \"Eduardo\" \"Ana\" \"Eduardo\" \"Eduardo\" ...\n\nstr(df)\n\n'data.frame':   10 obs. of  2 variables:\n $ x   : num  0.0639 -0.4522 0.7528 -1.3353 1.454 ...\n $ text: Factor w/ 2 levels \"Ana\",\"Eduardo\": 2 2 2 1 2 2 1 1 2 1\nUma última característica de um tibble, é que ele lhe permite criar colunas com nomes que não respeitam as regras usuais do R. Por exemplo, não é permitido criar variáveis que possuam um nome que se inicia por um número, ou então, que possuam algum tipo de espaço ao longo dele. Mas dentro de um tibble, você não possui tais restrições. No exemplo abaixo, eu tento ultrapassar essa regra na função data.frame(), e ela acaba preenchendo o espaço no nome, com um ponto (.), e também coloca uma letra qualquer antes do número da coluna “10_janeiro”, enquanto em um tibble, isso não ocorre. Entretanto, mesmo que você possua essa liberdade em um tibble, ao se referir a essas colunas que não se encaixam nas regras do R, você terá de contornar o nome dessas colunas, com acentos graves (`).\n\ndata_frame &lt;- data.frame(\n    \"Nome coluna\" = rnorm(10),\n    \"10_janeiro\" = rnorm(10)\n  )\n\ntibble &lt;- tibble(\n    \"Nome coluna\" = rnorm(10),\n    \"10_janeiro\" = rnorm(10)\n  )\n\nhead(data_frame, 10)\n\n   Nome.coluna X10_janeiro\n1  -0.45764736   0.9913638\n2  -2.10647428  -0.7395212\n3  -0.21903112   0.5121502\n4  -0.01960892  -0.4120472\n5  -0.26020194   1.3513892\n6  -0.28121829   0.4525027\n7  -0.00375185  -1.2101422\n8  -1.21804846   0.7554987\n9   0.38031145   0.3100944\n10  0.57720568   0.6967177\n\ntibble\n\n# A tibble: 10 × 2\n  `Nome coluna` `10_janeiro`\n          &lt;dbl&gt;        &lt;dbl&gt;\n1       -0.0723     -0.00880\n2       -0.512       0.181  \n3       -0.861       0.174  \n4       -1.97       -0.304  \n5        0.186       0.451  \n# ℹ 5 more rows\n\ntibble$`10_janeiro`\n\n [1] -0.008795092  0.180859057  0.174439957 -0.303780672  0.451265078\n [6] -0.637147039  0.411965845  2.153059407 -0.346874251  0.941143979\n\n\nPortanto, os tibble’s foram criados com o intuito de manter as funcionalidades importantes de um data.frame, e ao mesmo tempo, eliminar comportamentos que hoje são desnecessários ou ineficientes. O tibble é uma estrutura preguiçosa. Pois ele nunca converte implicitamente os seus dados para algum outro tipo, ele não altera o nome de suas colunas, e ele também não sobrecarrega o seu console com linhas e linhas de resultados, lhe mostrando apenas o necessário.",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentos da Linguagem R</span>"
    ]
  },
  {
    "objectID": "Capítulos/02-fundamentos.html#sec:fundamentos_tipos_dados",
    "href": "Capítulos/02-fundamentos.html#sec:fundamentos_tipos_dados",
    "title": "2  Fundamentos da Linguagem R",
    "section": "2.5 Tipos de dados",
    "text": "2.5 Tipos de dados\nComo foi destacado anteriormente, além das estruturas de dados, o R possui os tipos de dados. Tipos esses que dizem respeito a forma como o R está interpretando os seus dados, em um dado momento. Os cinco tipos de dados básicos da linguagem são:\n\ncharacter: valores de texto ou caracteres.\ndouble: valores númericos inclusos no conjunto dos números reais.\ninteger: valores númericos inclusos no conjunto de números inteiros, ou basicamente, números sem casas decimais.\nlogical: valores TRUE (verdadeiro) e FALSE (falso), resultantes de testes lógicos.\ncomplex: valores em números complexos.\n\nVários outros tipos de dados mais complexos, como datas (Date) e fatores (factor), são construídos a partir desses 5 tipos básicos da linguagem. O único tipo básico que não irei abordar nas próximas seções, será o tipo complex, pois é um tipo muito específico e extremamente raro na linguagem.\nVale destacar que, diferentes autores denominam essa propriedade de formas diferentes, ou, tendem a misturá-la em outros conceitos. Como exemplo, PENG (2015) denomina os “tipos de dados” como “classes atômicas de objetos” (ou, “atomic classes of objects”), enquanto WICKHAM; GROLEMUND (2017), costuma se referir a essa propriedade como “tipos de vetores” (ou, “vector types”). Independente da forma como os autores denominam essa propriedade, a lógica permanece a mesma.\nO termo utilizado por WICKHAM; GROLEMUND (2017) é o mais apropriado para essa situação. Não apenas porque ele representa melhor a forma como esses conceitos são apresentados nos manuais internos da linguagem (veja TEAM, 2020a, 2020b), mas também, porque o termo utilizado por PENG (2015) mistura dois conceitos importantes que são diferentes entre si: a classe e o tipo de um objeto.\nO tipo do objeto, (isto é, o que estou chamando aqui de tipo de dado - character, double, etc.), determina a representação interna do objeto. Ou seja, como esse objeto é armazenado internamente na memória de seu computador. Já a classe é um atributo do objeto, que determina quais são os métodos de funções a serem aplicados sobre este objeto (CHAMBERS, 2016, pp. 45). Por isso eu evito a denominação utilizada por PENG (2015), dado que ela pode ter um sentido dúbio dependendo da situação.\n\n2.5.1 Textos e caracteres (character)\nArtigos, livros, línguas, documentos, dicionários, jornais, páginas da web, são várias as possíveis fontes de texto. Certos campos da ciência conseguem extrair diversas análises e conhecimentos importantes desses tipos de fonte. Ou seja dados em texto são extremamente importantes e comuns nos mais diversos tipos de análises (a inteligencia artificial, ChatGPT, webscrapping, etc., são provas disso).\nVariáveis do tipo texto são geralmente denominadas de variáveis categóricas. Pois em geral, elas buscam classificar os seus dados em certas categorias e grupos. Para além dessas variáveis, também é comum utilizarmos textos para definir rótulos e títulos de gráficos, ou ainda, para definir certos argumentos de funções.\nPara armazenar, interpretar e transformar esse tipo de dado, o R nos oferece o tipo character. Valores do tipo character também são conhecidos pelo termo string (ou string of characters). Todo valor em texto no R (isto é, todo dado do tipo character), deve ser fornecido entre aspas (simples - ', ou duplas - \"), sendo essa uma convenção utilizada em quase todas as linguagens de programação existentes, e no R não é diferente. Esta convenção se torna ainda mais importante no R, pois ela também serve para diferenciar valores em texto de nomes de objetos.\nEm outras palavras, quando queremos acessar os valores que estão dentro de um objeto, nós simplesmente escrevemos o nome deste objeto. Entretanto, quando estamos fornecendo um simples texto ao R, é muito comum que nos esqueçamos de contornar esse texto com aspas. Como resultado, o R acaba interpretando esse valor como o nome de um objeto e, por isso, começa a procurar por um objeto que possua um nome igual a este texto que você digitou. Caso o R não encontre um objeto com um nome equivalente a esse texto, ele vai lhe retornar um erro indicando que ele não foi capaz de encontrar um objeto com este nome em sua sessão.\nPara mais, caso este texto que você digitou, possua algum espaço, o R vai lhe retornar um erro um pouco diferente, dizendo que o símbolo que você inseriu no console, é inesperado ou inválido. De qualquer forma, o problema desse erro é o mesmo, você provavelmente se esqueceu de contornar o texto por aspas.\n\nO_ano_tem_365_dias\n## Erro: objeto 'O_ano_tem_365_dias' não encontrado\nO ano tem 365 dias\n## Erro: unexpected symbol in \"O ano\"\n\"O ano tem 365 dias\"\n## [1] \"O ano tem 365 dias\"\n\nVale destacar que, um par de aspas, delimita um único valor do tipo character. Portanto, para criar um vetor contendo vários valores do tipo character, você tem que contornar cada um desses valores por aspas. Caso você contorne todos os diferentes valores por um único par de aspas, você vai criar um vetor do tipo character que contém 1 único elemento. Tal problemática está demonstrada abaixo.\n\nvec &lt;- c(\"a, b, c, d\")\nlength(vec)\n\n[1] 1\n\nvec2 &lt;- c(\"a\", \"b\", \"c\", \"d\")\nlength(vec2)\n\n[1] 4\n\n\n\n\n2.5.2 Números reais (double)\nEm quase todos os momentos que você estiver trabalhando com dados numéricos, esses dados vão estar sendo interpretados pelo tipo double. Pois este tipo básico abarca todo o conjunto dos números reais. E como o conjunto de números inteiros (integer) está incluso no conjunto dos números reais, quando você insere um número inteiro, ou um número sem casas decimais no console, ele será interpretado inicialmente pelo R como um número real (double).\nDito de outra forma, ao inserirmos apenas o número 10 no console, o R vai interpretar este 10 como um double, e não como integer, independente do fato desse número aparecer no console sem casas decimais. Pense como se este 10, fosse na verdade para o R algo como 10,00000000000… No exemplo abaixo, eu utilizo a função is.integer() para perguntar ao R, se ele está interpretando este valor como um integer, e como esperávamos a função nos retorna um FALSE, indicando que não se trata de um número inteiro.\n\n# O R está basicamente interpretando\n# este 10 como 10.00000000, mesmo\n# que ele te mostre\n10\n\n[1] 10\n\nis.double(10)\n\n[1] TRUE\n\nis.integer(10)\n\n[1] FALSE\n\n\nVale destacar, que o R é uma linguagem centralizada nos padrões americanos, e que, portanto, utiliza o ponto para definir casas decimais, ao invés da vírgula que nós brasileiros utilizamos. Por esse motivo, para criar um vetor de números decimais, você deve utilizar um ponto para delimitar as casas decimais de seus valores. As vírgulas servem apenas para separar os diferentes valores deste vetor.\n\nc(1.24, 2.25, 3.62381, 7.05)\n\n[1] 1.24000 2.25000 3.62381 7.05000\n\n\n\n\n2.5.3 Números inteiros (integer)\nO tipo integer abarca o conjunto dos números inteiros, ou basicamente todos os números sem casas decimais. Você utilizará muito este tipo, quando estiver utilizando sequências numéricas, seja para extrair partes de um objeto com a função [, ou gerando um índice para as linhas de sua tabela. Como vimos na seção anterior, caso você insira um número sem casas decimais no console, o R vai interpretar inicialmente este número como um double.\nAssim sendo, você tem três formas de se criar um integer no R. A primeira é inserindo um L maiúsculo após o número que você está criando. A segunda, é transformando o seu vetor do tipo double para o tipo integer, através da função as.integer(). A terceira, seria através de funções que lhe retornam por padrão este tipo de dado, sendo o principal exemplo, a função : que lhe retorna, por padrão, uma sequência de integer’s. Podemos confirmar se os números criados são de fato integer’s, usando a função is.integer().\n\nc(1L, 2L, 3L, 10L)\n\n[1]  1  2  3 10\n\nas.integer(c(1, 2, 10.2561, 1.55))\n\n[1]  1  2 10  1\n\nis.integer(1:10)\n\n[1] TRUE\n\n\n\n\n2.5.4 O tipo numérico (numeric)\nEm alguns momentos você pode se deparar com o tipo numeric. Ele nada mais é do que um “apelido” para os tipos integer e double. Dito de outra forma, os tipos integer e double são conjuntamente conhecidos como o tipo numeric (WICKHAM, 2015).\nEntretanto, mesmo que numeric seja um sinônimo para os tipos integer e double, o R não costuma empregar esse nome numeric de forma uniforme. Na maioria das ocasiões em que o tipo numeric aparece, o R está na verdade, se referindo especificamente ao tipo double. De qualquer forma, apenas entenda que se um conjunto de dados está associado ao tipo double ou ao tipo integer, ele também está diretamente associado ao tipo numeric.\n\nis.numeric(1L)\n\n[1] TRUE\n\nis.numeric(1.25)\n\n[1] TRUE\n\n\n\n\n2.5.5 Valores lógicos (logical)\nNo R, valores lógicos são interpretados pelo tipo de dado logical e, como você já deve ter percebido, este tipo abrange apenas dois valores possíveis, que são verdadeiro - TRUE, e falso - FALSE. Valores lógicos também são muito conhecidos em diversas linguagens de programação pelo termo boolean. Você irá utilizar muito este tipo de dado para filtrar linhas de seu data.frame, para preencher uma coluna de rótulos, ou para identificar valores “não disponíveis” e outliers em sua base de dados.\nTemos dois métodos de se obter esse tipo de valor no R. A primeira, é escrevê-los na mão, podendo também se referir apenas a primeira letra maiúscula de cada um, ao invés de escrever toda a palavra.\n\nvetor_logico &lt;- c(T, F, T, TRUE, FALSE)\nvetor_logico\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n\n\nA segunda e principal forma, é através de testes lógicos. No exemplo abaixo, eu estou criando um vetor com 5 elementos, e em seguida, peço ao R que me diga se cada elemento deste vetor é maior do que 5. Vemos que apenas o terceiro e o quarto elemento deste vetor, são maiores do que 5.\n\nvetor &lt;- c(0.5, 2.45, 5.6, 7.2, 1.3)\nvetor &gt; 5\n\n[1] FALSE FALSE  TRUE  TRUE FALSE\n\n\nO que acabamos de fazer acima, se trata de um teste lógico, pois estamos testando uma hipótese (maior do que 5) sobre cada um dos elementos deste vetor. Como resultado, o R lhe retorna um vetor com o mesmo comprimento do primeiro, porém agora, este vetor está preenchido com TRUE’s e FALSE’s, lhe indicando quais dos elementos do primeiro vetor se encaixam na hipótese que você definiu.\nEste vetor contendo apenas valores lógicos, não é tão útil em sua singularidade. Porém, ao utilizarmos ele sobre à função [, podemos utilizar o sistema que mencionei anteriormente, chamado de logical subsetting, que é uma forma extremamente útil de extrairmos partes de um objeto. A ideia, é extrairmos qualquer elemento deste objeto que possua um valor TRUE correspondente em um teste lógico específico que podemos definir. Consequentemente, poderíamos utilizar o teste anterior que criamos, para extrair todos os elementos do vetor, que são maiores do que 5, desta forma:\n\nvetor[vetor &gt; 5]\n\n[1] 5.6 7.2\n\n\nPara criar um teste lógico, você precisa utilizar algum operador lógico (como os operadores &gt; e ==), ou então, alguma função que aplique este tipo de teste e lhe retorne um valor lógico como resultado (por exemplo, a função is.integer()).",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentos da Linguagem R</span>"
    ]
  },
  {
    "objectID": "Capítulos/02-fundamentos.html#sec:funcoes_str_is",
    "href": "Capítulos/02-fundamentos.html#sec:funcoes_str_is",
    "title": "2  Fundamentos da Linguagem R",
    "section": "2.6 Identificando tipos e estruturas com a função str() e as funções is.*()",
    "text": "2.6 Identificando tipos e estruturas com a função str() e as funções is.*()\nNa linguagem Python, a função str() serve para convertermos um objeto para o tipo string. Porém, na linguagem R, essa mesma função str() exerce um papel completamente diferente. No R, o nome str representa na realidade uma abreviação para structure (ou “estrutura”). Por isso, a função str() nos fornece uma pequena descrição da estrutura de um objeto específico.\nComo um primeiro exemplo, quando aplicamos a função str() sobre a tabela diamonds do pacote ggplot2, o R nos retorna uma descrição contendo: a estrutura na qual esse objeto se encontra (tibble); as dimensões dessa tabela (53,940 x 10); as classes associadas a esse objeto (S3: tbl_df/tbl/data.frame); os nomes das colunas dessa tabela ($ carat, $ cut, $ color, etc); além de uma abreviação que indica o tipo de dado associado a cada uma dessas colunas (num para numeric, int para integer, etc.).\n\nlibrary(ggplot2)\nstr(diamonds)\n\ntibble [53,940 × 10] (S3: tbl_df/tbl/data.frame)\n $ carat  : num [1:53940] 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ...\n $ cut    : Ord.factor w/ 5 levels \"Fair\"&lt;\"Good\"&lt;..: 5 4 2 4 2 3 3 3 1 3 ...\n $ color  : Ord.factor w/ 7 levels \"D\"&lt;\"E\"&lt;\"F\"&lt;\"G\"&lt;..: 2 2 2 6 7 7 6 5 2 5 ...\n $ clarity: Ord.factor w/ 8 levels \"I1\"&lt;\"SI2\"&lt;\"SI1\"&lt;..: 2 3 5 4 2 6 7 3 4 5 ...\n $ depth  : num [1:53940] 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ...\n $ table  : num [1:53940] 55 61 65 58 58 57 57 55 61 61 ...\n $ price  : int [1:53940] 326 326 327 334 335 336 336 337 337 338 ...\n $ x      : num [1:53940] 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ...\n $ y      : num [1:53940] 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ...\n $ z      : num [1:53940] 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ...\n\n\nComo um segundo exemplo, ao aplicarmos a função str() sobre uma lista, a descrição resultante me confirma que o objeto se trata de uma lista de 5 elementos (List of 5). Devido à abreviação chr presente nos elementos produto_vendido e data_de_registro, nós também identificamos que os valores armazenados nesses elementos da lista estão associados ao tipo character.\n\nregistro_venda &lt;- list(\n  produto_vendido = \"Leite Mua 1L\",\n  unidades_vendidas = 5,\n  preco_por_unidade = 3.45,\n  valor_venda = 5 * 3.45,\n  data_de_registro = \"2021-08-22\"\n)\n\nstr(registro_venda)\n\nList of 5\n $ produto_vendido  : chr \"Leite Mua 1L\"\n $ unidades_vendidas: num 5\n $ preco_por_unidade: num 3.45\n $ valor_venda      : num 17.2\n $ data_de_registro : chr \"2021-08-22\"\n\n\nComo um terceiro exemplo, quando aplicamos a função str() sobre um vetor, podemos identificar o tipo de dado associado àquele vetor além de suas dimensões. Pela demonstração abaixo, sabemos através da abreviação int que o vetor sequencia contém dados do tipo integer, e que este vetor possui 100 elementos ([1:100]).\n\nsequencia &lt;- 1:100\nstr(sequencia)\n\n int [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n\n\nPortanto, a função str() é a forma mais prática e visual de se identificar as características principais de um objeto no R. Entretanto, futuramente você vai enfrentar situações onde você deve construir um programa (isto é, um script) que executa determinadas ações a depender da estrutura de um objeto ou dos tipos de dados associados a ele. Ou seja, haverá momentos em que você precisa inserir dentro de seu programa, testes que realizam essas verificações de forma automática. O primeiro passo para a construção desses testes são as funções is.*().\nEm geral, toda função is.*() retorna um único valor do tipo logical, informando se o objeto em questão pertence ou não ao tipo ou estrutura definido no nome dessa função. O tipo ou estrutura para a qual você está testando é definido no próprio nome da função. Por exemplo, se eu utilizo a função is.character(x), eu estou querendo testar se o objeto x está associado ao tipo character. Como demonstrado abaixo, a função is.character() me retorna um valor TRUE para o objeto nome, entretanto, o mesmo não ocorre para o objeto idade.\n\nnome &lt;- \"Pedro Faria\"\nidade &lt;- 23\nis.character(nome)\n\n[1] TRUE\n\nis.character(idade)\n\n[1] FALSE\n\n\nEm resumo, se você deseja testar se um objeto possui uma certa propriedade, procure por uma função cujo nome comece por \"is.\" seguido pelo nome dessa estrutura ou tipo no qual você está interessado. Como uma lista inicial, as funções para os tipos de dados são:\n\nis.integer().\nis.character().\nis.numeric().\nis.double().\nis.logical().\nis.atomic().\nis.complex().\n\nJá para o caso das estruturas de dados, estamos nos referindo às seguintes funções:\n\nis.vector().\nis.list().\nis.data.frame().\nis.matrix().\nis.array().\ntibble::is_tibble()\n\nUma outra forma (mais informal) de se identificar o tipo de dado associado a um objeto (ou a uma parte desse objeto) é através da função typeof(). Ao aplicar essa função sobre um objeto específico (ou sobre uma parte desse objeto), a função nos retorna o nome do tipo de dado associado a este objeto.\n\nvec &lt;- c(1L, 2L, 3L)\ntypeof(vec)\n\n[1] \"integer\"\n\n\n\n2.6.1 Tome muito cuidado com is.vector() e is.numeric()\nA função is.vector() testa se um objeto é um vetor atômico. Porém, o principal problema dessa função é que ela baseia o seu teste na ausência de atributos, ao invés de se preocupar se o objeto se encaixa ou não na descrição de um vetor. Você pode encontrar mais detalhes sobre isso ao ler atentamente a documentação interna da função, com o comando ?is.vector. Mas em resumo, a função is.vector() testa se o objeto em questão, é um vetor que não possui atributos (exceto o atributo names).\nVamos descrever o que são atributos mais a frente, mas devido a essa especificação, a função is.vector() retorna FALSE para diversos tipos de vetores “não-atômicos”, como os tipos factor, Date, POSIXct e POSIXlt (vamos descrever esses tipos em capítulos posteriores), pois todos eles possuem um atributo chamado class. Para mais, saiba que is.vector() retorna TRUE para listas, pois como descrevemos na seção Listas, listas são no fundo, vetores. Além disso, listas geralmente contém no máximo um atributo names (o qual é permitido por is.vector()). Para demonstrar os resultados gerados por cada função que vou apresentar nessa seção, estou criando abaixo alguns objetos de teste, além de uma função que será responsável por aplicar a função sobre cada um desses objetos.\n\nm &lt;- matrix(1)\na &lt;- array(1, dim = c(1,1,1))\nl &lt;- list(1)\nd &lt;- data.frame(1)\nv1 &lt;- as.Date(\"2021-01-01\")\nv2 &lt;- factor(\"a\")\nvec &lt;- double(1)\n\naplicar_teste &lt;- function(x){\n  objs &lt;- list(m, a, l, d, v1, v2, vec, NULL)\n  r &lt;- purrr::map_lgl(objs, x)\n  names(r) &lt;- c(\n    \"matrix\", \"array\", \"list\",\n    \"data.frame\", \"Date\", \n    \"factor\", \"double\", \n    \"NULL\"\n  )\n  return(r)\n}\n\nPerceba pelo resultado abaixo, que a função is.vector() nos retorna TRUE para uma lista (list), mas nos retorna FALSE para diversos vetores associados a tipos “não-atômicos” da linguagem, como os tipos Date e factor.\n\naplicar_teste(is.vector)\n\n    matrix      array       list data.frame       Date     factor     double \n     FALSE      FALSE       TRUE      FALSE      FALSE      FALSE       TRUE \n      NULL \n     FALSE \n\n\nDevido a essas características, caso você deseje testar se um objeto x é um vetor atômico de forma mais restrita (isto é, que retorna FALSE para listas e FALSE para tipos de dados “não-atômicos” como Date e factor), você pode utilizar o teste lógico is.vector(x) & !is.list(x). Como demonstrado abaixo, esse teste retorna TRUE para vec, mas FALSE para l e para v1.\n\nis.vector(l) & !is.list(l) # lista\n\n[1] FALSE\n\nis.vector(v1) & !is.list(v1) # Vetor do tipo Date\n\n[1] FALSE\n\nis.vector(vec) & !is.list(vec) # Vetor do tipo double\n\n[1] TRUE\n\n\nDentro dos pacotes básicos do R nós temos a função is.atomic(), mas o pacote purrr nos oferece uma função “irmã” chamada de is_atomic() . A única diferença entre essas duas funções, é que is_atomic() retorna FALSE para um valor NULL, enquanto is.atomic() retorna TRUE. Para além desse detalhe, você pode reparar abaixo, que ambas as funções retornam um valor TRUE para matrizes (matrix) e arrays (array).\n\nlibrary(purrr)\n\n\naplicar_teste(is_atomic)\n\n    matrix      array       list data.frame       Date     factor     double \n      TRUE       TRUE      FALSE      FALSE       TRUE       TRUE       TRUE \n      NULL \n     FALSE \n\naplicar_teste(is.atomic)\n\n    matrix      array       list data.frame       Date     factor     double \n      TRUE       TRUE      FALSE      FALSE       TRUE       TRUE       TRUE \n      NULL \n     FALSE \n\n\nCom esses detalhes em mente, se você deseja adotar um conceito levemente mais abrangente de vetor, de forma a testar se um objeto é um vetor e incluir os diversos tipos “não-atômicos” como Date e factor, você pode utilizar a função is_atomic() do pacote purrr. Mas também é necessário contornar o comportamento de is_atomic() para matrizes e arrays, ao aplicar o teste lógico is_atomic(x) & is.null(dim(x)).\n\nlibrary(purrr)\n\n\nis_atomic(m) & is.null(dim(m)) # Matriz\n\n[1] FALSE\n\nis_atomic(a) & is.null(dim(a)) # Array\n\n[1] FALSE\n\nis_atomic(v1) & is.null(dim(v1)) # Vetor do tipo Date\n\n[1] TRUE\n\nis_atomic(vec) & is.null(dim(vec)) # Vetor do tipo double\n\n[1] TRUE\n\n\nPara além de is_atomic(), o pacote purrr também nos oferece a função is_vector(). Ao invés de se preocupar com os atributos que um objeto carrega, a função is_vector() verifica se o objeto x é armazenado (na camada mais profunda da linguagem) a partir de um vetor. Entretanto, como os vetores atômicos são a unidade fundamental das demais estruturas de dados presentes na linguagem, este conceito de vetor adotado por is_vector() é bastante abrangente, de modo que a função nos retorna TRUE para todas as estruturas e tipos de dados, como está demonstrado abaixo. Portanto, de certa forma, is_vector() busca identificar se um dado objeto é construído a partir de um vetor, mas não necessariamente se ele é um vetor per se.\n\naplicar_teste(is_vector)\n\n    matrix      array       list data.frame       Date     factor     double \n      TRUE       TRUE       TRUE       TRUE       TRUE       TRUE       TRUE \n      NULL \n     FALSE \n\n\nPor último, como o tipo numeric é um sinônimo para os tipos integer e double, ao aplicar a função is.numeric() sobre um objeto, você está na verdade testando se esse objeto específico está associado ao tipo double ou ao tipo integer. Se você precisa que esse objeto esteja associado a apenas um desses dois tipos, utilize a função correspondente a esse tipo (is.integer() ou is.double()) ao invés de is.numeric().",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentos da Linguagem R</span>"
    ]
  },
  {
    "objectID": "Capítulos/02-fundamentos.html#sec:coercion_R_fundamentos",
    "href": "Capítulos/02-fundamentos.html#sec:coercion_R_fundamentos",
    "title": "2  Fundamentos da Linguagem R",
    "section": "2.7 Coerção no R",
    "text": "2.7 Coerção no R\nQuando discuti sobre vetores e sua principal propriedade (vetores podem manter apenas um tipo de dado dentro dele), eu mencionei que caso você tentasse burlar essa regra, o R automaticamente converteria todos os valores para um único tipo de dado. Este processo é usualmente chamado por coercion, ou coerção, e iremos explicar como ele funciona nesta seção.\nEm resumo, coerção é o processo em que o R converte automaticamente e, implicitamente, valores de um tipo de dado para um outro tipo. Esse processo é bem semelhante ao processo de coerção que ocorre na linguagem JavaScript, sendo a soma entre um número e um string, o exemplo mais clássico de coerção em JavaScript. Reproduzindo esse exemplo abaixo, nós estamos somando um valor numérico a um texto. Ao perceber essa diferença entre os tipos de dados, o JavaScript converte automaticamente o valor 10 para o tipo string, antes de executar a soma. Logo, ao realizar essa conversão, o JavaScript transforma uma soma entre um número e um string, em uma soma entre dois strings e, como resultado, o JavaScript apenas concatena os dois números um do lado do outro, como demonstrado abaixo:\n\n// Em JavaScript:\nvar x = 10 + \"20\"\nprint(x)\n\n\n1020\n\ntypeof(x)\n\n\"string\"\nApesar da semelhança, processos de coerção no R, ocorrem geralmente quando estamos lidando com vetores de alguma maneira, especialmente quando estamos alterando partes de um vetor específico, ou também, quando estamos calculando um vetor a partir de uma função, e essa função nos retorna mais de 1 tipo de dado em seus resultados. Provavelmente, o exemplo mais clássico de coerção no R, está na concatenação entre um número e um texto. Perceba abaixo, que independente do vetor vec possuir valores do tipo integer (1L e 2L), todo o vetor foi automaticamente convertido para o tipo character.\n\nvec &lt;- c(1L, 2L, \"Texto\")\ntypeof(vec)\n\n[1] \"character\"\n\n\nUm outro exemplo bem comum de coerção no R, é quando inserimos valores de um tipo “y” em um vetor que contém valores de um tipo “x”. Repare abaixo que, inicialmente, o vetor a possuía 3 elementos que pertenciam ao tipo integer. Porém, ao inserirmos um texto como quarto elemento desse vetor, todos os elementos desse vetor foram automaticamente convertidos para o tipo character:\n\na &lt;- c(1L, 2L, 3L)\ntypeof(a)\n\n[1] \"integer\"\n\na[4] &lt;- \"Texto\"\nprint(a)\n\n[1] \"1\"     \"2\"     \"3\"     \"Texto\"\n\ntypeof(a)\n\n[1] \"character\"\n\n\nOs exemplos acima são ilustrativos, pois na prática, você geralmente não provoca um processo de coerção de forma proposital. Na grande maioria das vezes, você será surpreendido por tal evento. Um exemplo bastante comum no dia-a-dia de coerção ocorre durante a importação de bases de dados mal formatadas. Isso significa que, um processo de coerção pode representar, em muitos momentos, um sinal vermelho para você, lhe indicando que há algo mal formatado na sua base de dados, ou que, você não está incluindo alguma configuração importante no comando de importação da base, ou ainda, que algum de seus comandos no R está gerando um bug, ou um resultado que os demais comandos de seu script não são capazes de lidar com.\nPor outro lado, uma situação em que é extremamente útil nos aproveitarmos dessa coerção, é quando queremos somar um vetor lógico. Pois ao convertermos um vetor logical para um vetor integer, os valores TRUE são automaticamente convertidos para 1, enquanto valores FALSE são convertidos para 0. Com isso, você pode aplicar a função sum() sobre um teste lógico para descobrir, por exemplo, quantos elementos de um vetor são maiores do que 5. Para mais, ao calcularmos a média desse vetor lógico, com a função mean(), estamos na verdade calculando a proporção de TRUE’s neste vetor.\n\nvec &lt;- c(1.2, 3.6, 7.8, 1.9, 5.2, 9.6)\nsum(vec &gt; 5)\n\n[1] 3\n\nmean(vec &gt; 5)\n\n[1] 0.5\n\n\nUm processo de coerção ocorre apenas sobre vetores atômicos. Porém, lembre-se que todas as outras estruturas são construídas a partir desses vetores, ou todas as outras estruturas podem conter esses vetores dentro delas. Por isso, uma coluna de seu data.frame, ou toda uma matriz, podem sofrer uma coerção, independentemente de você ter ou não requisitado por tal transformação.\n\n2.7.1 A árvore de coerção\nQuando o processo de coerção ocorre, o R segue uma regra bem simples para escolher o tipo de dado para o qual os seus valores serão convertidos. Em resumo, o R irá sempre transformar os seus dados para o tipo de dado mais flexível, seguindo uma espécie de árvore ou hierarquia, a qual está referenciada na Figura 2.9. Você pode ver que o tipo character, está no topo da árvore e, portanto, é o tipo mais flexível de todos, enquanto o logical que está na base, é o tipo mais restrito de todos.\nIsso significa, que se você criar um vetor com valores integer e logical, todos esses valores serão convertidos para integer’s. Por outro lado, se for um vetor com valores integer e character, esses valores serão convertidos para character’s. E assim por diante. Ou seja, você é capaz de prever para qual tipo esse vetor será convertido, ao olhar para os dois tipos que estão sendo misturados neste vetor, e identificar qual deles é tipo de dado mais flexível.\n\n\n\n\n\n\n\n\nFigura 2.9: Árvore de coerção\n\n\n\n\n\n\n\n2.7.2 Coerções explícitas com as funções as.*()\nNa seção Identificando tipos e estruturas com a função str() e as funções is.*(), mostramos as funções is.*() que servem para identificarmos se um objeto pertence ou não a uma estrutura ou um tipo de dado específicos. Para além dessas funções, o R também nos oferece as funções as.*().\nEm suma, as funções as.*() servem para convertermos explicitamente os valores de um objeto para um tipo de dado específico. Ou seja, você aplica uma dessas funções quando você deseja provocar explicitamente um processo de coerção sobre um objeto. Como exemplo, se eu tenho um vetor contendo valores do tipo double, e desejo transformá-los em valores do tipo character, eu preciso apenas fornecer este vetor à função as.character(). Veja o exemplo abaixo:\n\nvetor &lt;- c(0, 1, 0.5, -2, 20)\nas.character(vetor)\n\n[1] \"0\"   \"1\"   \"0.5\" \"-2\"  \"20\" \n\n\nDa mesma forma como ocorre com as funções is.*(), o nome da função as.*() que você está utilizando, determina o tipo de dado com o qual essa função trabalha. Logo, a função as.logical() busca converter um objeto para o tipo logical, enquanto a função as.integer(), converte um objeto para o tipo integer, e assim por diante. Abaixo temos uma lista dessas funções.\n\nas.character().\nas.double().\nas.integer().\nas.logical().\nas.numeric().\n\nApesar de serem funções extremamente úteis, o R não é capaz de fazer mágica. Quando uma função as.*() encontra algum elemento que ela não consegue converter (de alguma forma lógica) para o tipo especificado, a função acaba inserindo um valor NA (valor não disponível) no lugar deste elemento. Por exemplo, se eu possuo o objeto D abaixo, e tento convertê-lo para o tipo double, apenas o terceiro elemento deste objeto é de fato convertido, pois o R não sabe como converter os outros dois elementos para o tipo double.\n\nD &lt;- c(\"R$2,45\", \"Texto\", \"8.90\")\nas.double(D)\n\nWarning: NAs introduced by coercion\n\n\n[1]  NA  NA 8.9\n\n\nComo um outro exemplo, ao utilizarmos a função as.logical() sobre um objeto x, se esse objeto x se encontra no tipo double ou integer, todos os valores que forem iguais a 0, serão convertidos para FALSE, enquanto todos os demais valores (diferentes de 0) serão convertidos para TRUE. Contudo, se o objeto x se encontra no tipo character, apenas textos explícitos dos valores lógicos (FALSE e TRUE), podem ser convertidos. Perceba pelo exemplo abaixo, que o R consegue converter apenas os elementos 1, 5 e 6 do vetor.\n\nvetor &lt;- c(\"TRUE\", \"a\", \"b\", \"c\", \"F\", \"T\")\n\nas.logical(vetor)\n\n[1]  TRUE    NA    NA    NA FALSE  TRUE\n\n\n\n\n2.7.3 Também podemos converter estruturas de dados com as funções as.*()\nApesar do processo de coerção ocorrer (de forma automática e implícita) apenas sobre os tipos de dados associados a um objeto, nós também temos a capacidade de provocar um “processo de coerção” sobre a estrutura de dado empregada por um objeto, com as funções as.*(). Ou seja, da mesma forma que temos uma função as.*() para cada tipo de dado, nós também temos uma função as.*() para cada estrutura de dado do R. Como uma lista inicial, temos as seguintes funções:\n\nas.vector().\nas.list().\nas.matrix().\nas.array().\nas.data.frame().\ntibble::as_tibble().\n\nAlgumas conversões são bem diretas, e simples de se compreender. Por exemplo, uma lista (list) pode ser facilmente convertida para um data.frame, pois como descrevemos na seção Tabelas no R: data.frame, um data.frame é no fundo, uma lista nomeada com elementos de mesmo comprimento. Tal conversão é demonstrada no exemplo abaixo.\n\nlista &lt;- list(\n  produtoid = c(1335, 1335, 1242, 1198),\n  preco = c(2.4, 2.4, 5.6, 1.9),\n  unidades = c(200, 100, 430, 90)\n)\n\ndata_frame &lt;- as.data.frame(lista)\ndata_frame\n\n  produtoid preco unidades\n1      1335   2.4      200\n2      1335   2.4      100\n3      1242   5.6      430\n4      1198   1.9       90\n\n\nPor outro lado, algumas conversões podem ser estranhas. Por exemplo, ao convertermos uma matriz para uma lista, cada elemento dessa matriz é transformada em um elemento dessa nova lista. Esse mesmo processo ocorre se convertermos um vetor em uma lista. Lembre-se que, uma matriz é no fundo, um vetor com duas dimensões. Logo, ao requisitarmos a conversão de uma matriz para uma lista, é como se essa matriz fosse convertida primeiro para um vetor e, a partir desse vetor, fosse convertida para uma lista.\n\nm &lt;- matrix(1:4, nrow = 2, ncol = 2)\nm\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nas.list(m)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3\n\n[[4]]\n[1] 4",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentos da Linguagem R</span>"
    ]
  },
  {
    "objectID": "Capítulos/02-fundamentos.html#um-estudo-de-caso-importando-os-dados-da-pintec-ibge-para-o-r",
    "href": "Capítulos/02-fundamentos.html#um-estudo-de-caso-importando-os-dados-da-pintec-ibge-para-o-r",
    "title": "2  Fundamentos da Linguagem R",
    "section": "2.8 Um estudo de caso: importando os dados da PINTEC-IBGE para o R",
    "text": "2.8 Um estudo de caso: importando os dados da PINTEC-IBGE para o R\nComo um exemplo prático de coerção, durante um determinado dia eu (Pedro) estava analisando os dados da PINTEC-IBGE (Pesquisa de Inovação), mais especificamente, a tabela 1 da pesquisa referente à edição de 2000. Com os comandos abaixo, você pode baixar o arquivo dessa tabela em Excel para um diretório temporário de seu computador e importá-la para dentro de seu R, de modo que você possa acompanhar os próximos comandos que vou mostrar.\n\nlibrary(readxl)\ngithub &lt;- \"https://github.com/pedropark99/\"\npasta &lt;- \"Curso-R/raw/master/Dados/\"\narquivo &lt;- \"tab01_2000.xls\"\n\nurl &lt;- paste0(github, pasta, arquivo)\n\ndir &lt;- tempdir()\ncaminho &lt;- paste(dir, arquivo, sep = \"\\\\\")\n\ndownload.file(url, destfile = caminho, mode = \"wb\")\n\ntab1 &lt;- readxl::read_excel(\n  caminho, \n  range = \"A9:R57\",\n  col_names = paste0(\"X\", 1:18)\n)\n\nNeste dia, eu estava tentado calcular uma simples soma das colunas X5 e X6, porém, o R estava me retornando o erro abaixo, me indicando que alguma dessas colunas estava associada a um tipo de dado não-numérico.\n\ntab1$X6 + tab1$X5\n\nError in tab1$X6 + tab1$X5 : non-numeric argument to binary operator\nEste é um erro inesperado, pois quando abrimos o arquivo Excel da tabela, podemos observar que praticamente todas as colunas da tabela (incluindo as colunas X6 e X5) são claramente colunas numéricas e, portanto, deveriam estar sendo interpretadas por tipos numéricos. Ao analisarmos mais de perto a estrutura do objeto tab1 com a função str(), podemos perceber que diversas colunas da tabela (incluindo a coluna X6) estão sendo interpretadas pelo tipo character, ao invés do tipo double.\n\nstr(tab1)\n\ntibble [49 x 18] (S3: tbl_df/tbl/data.frame)\n $ X1 : chr [1:49] \"Total\" \"Indústrias extrativas\" ...\n $ X2 : num [1:49] 72005 1729 70277 10253 9491 ...\n $ X3 : num [1:49] 22698 297 22401 3024 2773 ...\n $ X4 : num [1:49] 12658.5 92.5 12566 1683.5 1559 ...\n $ X5 : num [1:49] 10355.5 68.1 10287.3 1553.2 1439.4 ...\n $ X6 : chr [1:49] \"2974.6496207720083\" \"27.740643394384399\" ...\n $ X7 : num [1:49] 18160 285 17874 2558 2320 ...\n $ X8 : num [1:49] 16753 254 16499 2331 2099 ...\n $ X9 : num [1:49] 2000 36 1964 327 318 ...\n $ X10: num [1:49] 8120.3 80.7 8039.6 1216.7 1105.9 ...\n $ X11: num [1:49] 8944 146 8798 1325 1221 ...\n $ X12: chr [1:49] \"3427.0471614397024\" \"25.137011567518176\" ...\n $ X13: chr [1:49] \"2996.0692977925214\" \"91.851470771912076\" ...\n $ X14: num [1:49] 2520.6 28.6 2492 355.6 322.8 ...\n $ X15: chr [1:49] \"4276.5049681355704\" \"62.304616808180924\" ...\n $ X16: chr [1:49] \"2264.1329981437439\" \"6.021725515719007\" ...\n $ X17: chr [1:49] \"1175.6811947066112\" \"51.283169365446376\" ...\n $ X18: chr [1:49] \"836.69077528521564\" \"4.99972192701554\" ...\nPodemos confirmar esse cenário, ao aplicarmos a função is.character() sobre a coluna X6, como demonstrado abaixo:\n\nis.character(tab1$X6)\n\n[1] TRUE\nPortanto, identificamos a origem do erro: a coluna X6 está sendo interpretada pelo tipo character e, consequentemente, não pode ser somada diretamente a uma coluna do tipo numeric. Poderíamos utilizar a função as.numeric() sobre a coluna X6 e somar o resultado à coluna X5 para contornarmos esse problema. Todavia, seria útil identificarmos o porquê dessa coluna estar sendo interpretada desde o início como uma coluna de texto.\nSe no arquivo original tab01_2000.xls, essas colunas estão configuradas como colunas numéricas, o mesmo deveria ocorrer dentro do R. Porque o R decidiu aplicar o tipo character sobre essas colunas? Podemos encontrar a resposta para essa pergunta ao olharmos mais atentamente para o intervalo da linha 15 à linha 24 dessa coluna X6. Abaixo, estou justamente selecionando esse intervalo de linhas da coluna. Perceba que na sexta linha do resultado, temos um símbolo de menos (-).\n\ntab1[15:24, \"X6\"]\n\n### A tibble: 10 x 1\n##    X6                \n##    &lt;chr&gt;             \n##  1 47.766222201789986\n##  2 53.292711161353139\n##  3 0                 \n##  4 1.222975124981859 \n##  5 0                 \n##  6 -                 \n##  7 1.222975124981859 \n##  8 452.69478203700271\n##  9 384.49410807956616\n## 10 68.200673957436564\nPense sobre “como o R deveria interpretar esse sinal de menos?”. Considerando apenas as 10 primeiras linhas da coluna X6, o R claramente optaria por um tipo de dado numérico para interpretar essa coluna. Contudo, ao se deparar com esse sinal de menos, como o R converteria esse símbolo para um número? A resposta é: ele simplesmente não sabe como realizar essa conversão! Logo, como o R não sabe como converter esse sinal de menos para um número, ele optou por interpretar esse símbolo pelo tipo de dado mais flexível de todos. Isto é, o tipo characater. Ao interpretar esse símbolo pelo tipo character, o R percebeu que teria de converter toda a coluna X6 para o tipo character para manter esses dados juntos em uma mesma coluna.\nConcluindo, este é um exemplo onde uma formatação ruim da base de dados, pode levar a coerções implícitas e inesperadas no R. Como um exercício, você pode abrir o arquivo tab01_2000.xls no Excel, e eliminar manualmente esse símbolo de menos da coluna X6, e tentar importar novamente o arquivo para o R. Ao fazer isso, você vai perceber que o tipo double será empregado sobre a coluna X6, ao invés do tipo character, pois justamente o R não enfrentou o entrave de encontrar um símbolo ou um texto, em uma coluna que é claramente numérica.",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentos da Linguagem R</span>"
    ]
  },
  {
    "objectID": "Capítulos/02-fundamentos.html#subsetting",
    "href": "Capítulos/02-fundamentos.html#subsetting",
    "title": "2  Fundamentos da Linguagem R",
    "section": "2.9 Subsetting",
    "text": "2.9 Subsetting\nAs operações de subsetting, são extremamente importantes no R, e você irá utilizá-las com grande frequência ao longo de seu trabalho. Ao longo das seções de Estruturas de Dados, eu dei exemplos sobre como utilizar o subsetting com cada tipo de estrutura. Tendo isso em mente, essa seção busca explicitar (ou formalizar) algumas características importantes dessas operações. Como o próprio nome dá a entender, as operações de subsetting servem para extrairmos ou modificarmos subsets (partes) de seus objetos (TEAM, 2020a). Como vimos anteriormente, essas operações são realizadas pelas funções [ e [[.\nPara utilizar a função [, você precisa abrir um par de colchetes ([ ]) após o nome do objeto (ou função) com o qual está trabalhando. Já para a função [[, você necessita abrir dois pares de colchetes ([[ ]]) após o nome (ou função) com o qual você está trabalhando. Também já vimos ao longo das seções de Estruturas de Dados, que para extrairmos partes de estruturas unidimensionais como vetores e listas, precisamos de apenas um índice, ou de um único conjunto de índices. Mas para extrairmos partes de estruturas bidimensionais, como matrizes e data.frame’s, precisamos de dois índices, ou de dois conjuntos de índices.\nAlém disso, lembre-se que como definimos anteriormente, as listas são estruturas especiais, pois podem conter diversas outras estruturas em seus elementos. Portanto, apesar das listas serem estruturas unidimensionais, elas podem conter outras estruturas bidimensionais dentro delas. Por isso, caso você esteja interessado em extrair partes de uma estrutura bidimensional, que está dentro de algum elemento de uma lista, por exemplo, você irá precisar de uma combinação entre um único índice (para acessar o elemento da lista) e outros dois conjuntos de índices (para acessar uma parte específica da estrutura bidimensional).\n\n2.9.1 Principais diferenças entre as funções [ e [[:\n\nA função [ é capaz de trabalhar com todas as dimensões disponíveis de um objeto. Quais serão essas dimensões disponíveis depende da estrutura em que o objeto se encontra. Por outro lado, a função [[ pode trabalhar apenas com uma dessas dimensões disponíveis.\nA função [ nos permite extrair um conjunto de elementos (ou seções) de um objeto (Ex: da 1° a 100° linha de um data.frame; os elementos 4, 5 e 8 de um vetor; do 3° ao 6° elemento de uma lista). Já a função [[ nos permite extrair uma única parte, ou um único elemento de um objeto (Ex: o 5° elemento de uma lista; a 2° coluna de um data.frame; o 10° elemento de um vetor).\nA função [ geralmente lhe retorna um resultado na mesma estrutura de seu objeto original. Em outras palavras, se você utilizar a função [ sobre uma lista, ela irá lhe retornar uma lista como resultado. Já a função [[, geralmente lhe retorna um resultado em uma estrutura diferente. Dito de outra forma, se você utilizar a função [[ sobre um data.frame, por exemplo, ela geralmente vai lhe retornar um vetor como resultado.\n\n\n\n2.9.2 Dimensões disponíveis em subsetting\nA estrutura em que um objeto se encontra, define as dimensões que estão disponíveis para as funções [ e [[ . Logo, se você está trabalhando com um data.frame, por exemplo, você possui duas dimensões (linhas e colunas) com as quais você pode trabalhar com a função [. Mas se você está trabalhando com uma estrutura unidimensional, como um vetor atômico, você terá apenas uma única dimensão (os elementos desse vetor) para trabalhar em ambas às funções de subsetting ([ e [[).\nUma das diferenças básicas entre as funções [ e [[, se encontra no número de dimensões com as quais elas podem trabalhar. A função [, seria uma forma mais “geral” de subsetting, pois ela pode trabalhar com todas as dimensões disponíveis segundo a estrutura que um objeto se encontra. Já a função [[, representa uma forma mais restritiva de subsetting, pois ela trabalha em geral com apenas uma única dimensão de seu objeto (independentemente de qual seja a sua estrutura).\nPortanto, se temos uma estrutura bidimensional como um data.frame, a função [ pode trabalhar com as suas duas dimensões (linhas e colunas). Porém, a função [[ pode trabalhar apenas com uma dessas dimensões, sendo no caso de data.frame’s, a dimensão das colunas. Agora, quando estamos trabalhando com uma estrutura unidimensional, como nós possuímos apenas uma dimensão (elementos) disponível, não há diferença entre as funções [ e [[ no sentido estabelecido anteriormente. De qualquer maneira, a função [ continuará sendo a forma mais geral e flexível de subsetting para objetos unidimensionais. Pois a função [ lhe permite selecionar um conjunto, ou uma sequência de elementos de uma estrutura unidimensional, enquanto que com a função [[, você poderá selecionar apenas um único elemento dessa estrutura. Um resumo das dimensões disponíveis em cada estrutura, se encontra na Figura 2.10.\n\n\n\n\n\n\n\n\nFigura 2.10: Resumo das dimensões disponíveis em cada estrutura\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 2.11: Notação matemática das dimensões disponíveis em cada estrutura\n\n\n\n\n\nNós também podemos ver essas diferenças entre as dimensões disponíveis em cada estrutura e para cada função de subsetting, sob uma perspectiva mais matemática, ao formar uma notação matemática de cada estrutura, incluindo subscritos que representem as suas respectivas dimensões. Essa visão está exposta na Figura 2.11. Por exemplo, pegando um data.frame chamado \\(DF\\), com \\(i\\) linhas e \\(j\\) colunas (\\(DF_{i,j}\\)), temos que o comando DF[2,4] busca extrair o valor (ou valores) localizados na 2° linha da 4° coluna da tabela. Por outro lado, considerando-se uma lista chamada \\(L\\), contendo \\(e\\) elementos (\\(L_e\\)), o comando L[[4]], traz como resultado, o 4° elemento dessa lista.\n\n\n2.9.3 Tipos de índices\nOs índices que você fornece às funções [ e [[, podem ser de três tipos: 1) índices de texto - character; 2) índices numéricos - integer; 3) índices lógicos - logical. Logo abaixo, temos um exemplo do uso de índices numéricos sobre um vetor qualquer. Lembre-se que no caso de vetores, nós podemos utilizar um único índice para extrairmos um único valor do objeto em questão, e nós utilizamos dois ou mais índices, para extrairmos um conjunto de valores deste mesmo vetor.\n\nvec &lt;- c(2.2, 1.3, 4.5, 3.7, 5.2)\n\nvec[4]\n\n[1] 3.7\n\nvec[1:4]\n\n[1] 2.2 1.3 4.5 3.7\n\nvec[c(3,5,1)]\n\n[1] 4.5 5.2 2.2\n\n\nPara utilizar um índice de texto (character), o objeto sobre o qual você está trabalhando, deve ser uma estrutura nomeada. Todas as estruturas (vetor, lista, matriz e data.frame) permitem o uso de nomes, que você pode acessar e definir através de funções como colnames(), row.names() e names(). Sendo que algumas estruturas, mais especificamente os data.frame’s, vão sempre nomear automaticamente os seus elementos. Ou seja, você sempre poderá utilizar um índice de texto em um data.frame, para selecionar alguma de suas colunas. Pois mesmo que você se esqueça de nomear alguma coluna, ao criar o seu data.frame, a função que cria essa estrutura irá automaticamente criar um nome qualquer para cada coluna não nomeada.\n\ndf &lt;- data.frame(\n  id = LETTERS[1:10],\n  nome = \"Ana\",\n  valor = rnorm(10),\n  \"Belo Horizonte\"\n)\n\ndf\n\n   id nome       valor X.Belo.Horizonte.\n1   A  Ana -0.57044920    Belo Horizonte\n2   B  Ana -0.43696847    Belo Horizonte\n3   C  Ana -0.83420574    Belo Horizonte\n4   D  Ana  0.14276180    Belo Horizonte\n5   E  Ana  1.23892217    Belo Horizonte\n6   F  Ana  0.44776337    Belo Horizonte\n7   G  Ana  0.34634654    Belo Horizonte\n8   H  Ana -0.72019757    Belo Horizonte\n9   I  Ana -1.60427016    Belo Horizonte\n10  J  Ana  0.06544987    Belo Horizonte\n\ncolnames(df)[4] &lt;- \"cidade\"\n\ndf[[\"cidade\"]]\n\n [1] \"Belo Horizonte\" \"Belo Horizonte\" \"Belo Horizonte\" \"Belo Horizonte\"\n [5] \"Belo Horizonte\" \"Belo Horizonte\" \"Belo Horizonte\" \"Belo Horizonte\"\n [9] \"Belo Horizonte\" \"Belo Horizonte\"\n\ndf[c(\"id\", \"valor\")]\n\n   id       valor\n1   A -0.57044920\n2   B -0.43696847\n3   C -0.83420574\n4   D  0.14276180\n5   E  1.23892217\n6   F  0.44776337\n7   G  0.34634654\n8   H -0.72019757\n9   I -1.60427016\n10  J  0.06544987\n\ndf[[\"valor\"]]\n\n [1] -0.57044920 -0.43696847 -0.83420574  0.14276180  1.23892217  0.44776337\n [7]  0.34634654 -0.72019757 -1.60427016  0.06544987\n\ndf[[\"nome\"]]\n\n [1] \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\"\n\n\nEm outras estruturas como um vetor, nomes não são atribuídos automaticamente a cada um de seus elementos, e por isso, você deve nomear os elementos deste vetor, para que você seja capaz de utilizar um índice de texto nele. Para isso, basta igualar esses elementos a um valor em texto (valor entre aspas) que representa esse nome, como no exemplo abaixo:\n\nvec &lt;- c(\"a\" = 1, \"b\" = 2, \"c\" = 3, \"d\" = 4)\n\nvec[\"c\"]\n\nc \n3 \n\nvec[c(\"a\", \"c\", \"b\")]\n\na c b \n1 3 2 \n\nvec[[\"b\"]]\n\n[1] 2\n\n\nPor último, os índices lógicos (TRUE ou FALSE) são extremamente úteis em diversas aplicações, especialmente quando desejamos realizar um subsetting mais “complexo”. Porém, pelo fato de que a função [[ nos permite extrair apenas uma única parte de um objeto, os índices lógicos são de certa forma inúteis com essa função. Portanto, sempre que utilizar índices do tipo lógico para selecionar os seus dados, você muito provavelmente quer utilizá-los com a função [. Por padrão, as funções [ e [[, vão extrair todas as partes de um objeto, que possuírem um valor TRUE correspondente.\nPortanto, no exemplo abaixo, caso eu utilize o vetor lógico vlog, para selecionar valores do vetor vec, a função [ irá selecionar o 2°, 3° e 5° valor do vetor vec. Pois são essas as posições no vetor vlog que contém TRUE’s. Porém, a principal forma de gerarmos esses vetores lógicos a serem utilizados na função [, é através de testes lógicos. Por exemplo, podemos testar quais valores do vetor vec, são maiores do que 3, através do operador lógico &gt; (maior que).\n\nvec &lt;- c(2.2, 1.5, 3.4, 6.7, 8.9)\n\nvlog &lt;- c(FALSE, TRUE, TRUE, FALSE, TRUE)\n\nvec[vlog]\n\n[1] 1.5 3.4 8.9\n\nvec[vec &gt; 3]\n\n[1] 3.4 6.7 8.9\n\n\nO R possui vários operadores lógicos diferentes, e o operador &gt; é apenas um deles. Um outro operador muito conhecido, é o de negação \"!\". Este operador é utilizado, quando você deseja inverter um teste lógico, ou de certa forma, inverter o comportamento da função [ quando fornecemos índices lógicos. O que o operador ! faz na verdade, é inverter os valores de um vetor lógico. Logo, se eu aplicar este operador ao vetor vlog, esse será o resultado:\n\n!vlog\n\n[1]  TRUE FALSE FALSE  TRUE FALSE\n\n\nPortanto, os valores que antes eram TRUE, passam a ser FALSE, e vice-versa. Por isso, ao utilizarmos o operador ! sobre um teste lógico qualquer, nós invertemos o teste em questão. Pois o operador ! inverte os valores do vetor lógico resultante desse teste. Com isso, se eu utilizar esse operador sobre o teste anterior, onde testamos quais valores do vetor vec são maiores do que 3, nós estaremos efetivamente testando a hipótese contrária, de que esses valores são menores ou iguais a 3. Vale ressaltar, que esse operador deve ser posicionado antes do objeto que você deseja inverter, ou antes do teste lógico a ser realizado.\n\nvec[!vec &gt; 3]\n\n[1] 2.2 1.5\n\n\nUm uso muito comum deste operador, é em conjunto com a função is.na(). Essa função, aplica um teste lógico sobre cada valor de um vetor, testando a hipótese de que esse valor se trata de um valor não-disponível (NA). Por isso, caso o valor em questão, seja de fato um valor não-disponível, a função is.na() irá retornar um TRUE correspondente, caso contrário, a função vai lhe retornar um FALSE. Logo, caso eu utilize a função is.na() dentro da função [, estaremos selecionando todos os valores não-disponíveis de um vetor. Porém, é muito mais comum que as pessoas queiram fazer justamente o contrário, que é eliminar esses valores não-disponíveis de seus dados. Por essa razão, é muito comum que se utilize o operador ! em conjunto com a função is.na(), pois dessa forma, estaremos selecionando justamente os valores que se encaixam na hipótese contrária a testada por is.na().\n\nvec &lt;- c(2.2, 1.3, NA_real_, NA_real_, 2.5)\n\nvec\n\n[1] 2.2 1.3  NA  NA 2.5\n\nvec[is.na(vec)]\n\n[1] NA NA\n\nvec[!is.na(vec)]\n\n[1] 2.2 1.3 2.5\n\n\nVamos pensar no caso de um data.frame. Como definimos anteriormente, temos duas dimensões com as quais podemos trabalhar na função [, com este tipo de estrutura. Podemos por exemplo, utilizar o operador ! e a função is.na() sobre a dimensão das linhas desse data.frame. Dessa forma, podemos eliminar todas as linhas dessa tabela, que possuam algum valor não-disponível em uma coluna. Veja o exemplo abaixo, em que uma tabela chamada df, contém três valores não-disponíveis na coluna valor.\n\ndf &lt;- data.frame(\n  id = LETTERS[1:8],\n  valor = c(1.2, 2.5, NA_real_, 5.5, NA_real_, NA_real_, 3.5, 1.3),\n  nome = sample(c(\"Ana\", \"Luiza\", \"João\"), size = 8, replace = TRUE)\n)\n\ndf\n\n  id valor  nome\n1  A   1.2 Luiza\n2  B   2.5  João\n3  C    NA  João\n4  D   5.5 Luiza\n5  E    NA Luiza\n6  F    NA Luiza\n7  G   3.5  João\n8  H   1.3 Luiza\n\nnao_e_NA &lt;- !(is.na(df$valor))\n\ndf[nao_e_NA, ]\n\n  id valor  nome\n1  A   1.2 Luiza\n2  B   2.5  João\n4  D   5.5 Luiza\n7  G   3.5  João\n8  H   1.3 Luiza\n\n\n\n\n2.9.4 O operador $ e a estrutura do resultado\nVocê provavelmente se lembra do operador $, que se trata de um atalho à função [[. Porém, você talvez tenha percebido também, que utilizamos o operador $ apenas em estruturas nomeadas. Logo, apesar de o operador $ ser um “irmão” da função [[, ele não herda todas as características dessa função. Por exemplo, nós não podemos utilizar índices numéricos ou lógicos com este operador, para selecionarmos alguma parte de um objeto. Isto significa, que o operador $ se trata de uma versão ainda mais restrita de subsetting, em relação à função [[. As únicas estruturas nomeadas com as quais este operador funciona, são listas e data.frame’s. Em outras palavras, mesmo que você nomeie os elementos de um vetor atômico, você não poderá utilizar o operador $ para selecionar um desses elementos.\n\nvec &lt;- c(\"a\" = 2.5, \"b\" = 4.3, \"c\" = 1.2)\n\nvec$a\n\n\nError in vec$a : $ operator is invalid for atomic vectors\n\nDentre as características da função [[ herdadas pelo operador $, está o fato de que este operador pode trabalhar apenas com uma dimensão de um objeto. Em listas, podemos utilizar o operador $ para selecionarmos algum dos elementos nomeados dessa lista. Já em data.frame’s, o operador $ pode ser utilizado para selecionarmos uma das colunas desse data.frame3.\nUm outro ponto a ser discutido, é que tanto o operador $, quanto a função [[, geram um resultado em uma estrutura diferente da estrutura do objeto original. Ou seja, quando realizamos um subsetting por meio desses operadores, o resultado geralmente possui uma estrutura com menos componentes do que a estrutura do objeto original, de onde estamos retirando esta parte. Dito de outra forma, se utilizarmos o operador $, ou a função [[ para selecionarmos a coluna valor do data.frame df abaixo, o resultado de ambas as funções, serão um vetor atômico contendo os valores dessa coluna, e não um data.frame contendo apenas a coluna valor.\nLogo, o uso da função [[ (ou do operador $) sobre data.frame’s, vão lhe trazer a coluna (ou o elemento) em si do data.frame, e não um novo data.frame contendo essa coluna. Podemos confirmar isso, com o uso da função str(), que nos traz um resumo da estrutura de um objeto. Perceba nos exemplos abaixo, que em ambos os casos, o resultado da função str() está nos dizendo que o objeto resultante do uso de $ ou de [[, se trata de um vetor atômico contendo dados do tipo numérico (num).\n\ndf &lt;- data.frame(\n  id = LETTERS[1:10],\n  valor = rnorm(10),\n  nome = sample(c(\"Ana\", \"Luiza\", \"João\"), size = 10, replace = TRUE)\n)\n\nstr(df$valor)\n\n num [1:10] 0.289 0.688 -0.7 -0.375 0.161 ...\n\nstr(df[[\"valor\"]])\n\n num [1:10] 0.289 0.688 -0.7 -0.375 0.161 ...\n\n\nEssa característica é definida em detalhes no capítulo 4 de WICKHAM (2015). Sendo exatamente esta característica, que eu estava querendo destacar na Figura 2.7, quando estávamos descrevendo as listas. Se você utilizar a função [ para selecionar um elemento de uma lista, o resultado será uma nova lista contendo esse elemento. Mas se você utilizar a função [[ para fazer este trabalho, o resultado será apenas o elemento em si.\nVocê pode entender essa característica como uma “simplificação do resultado”, como se as funções [[ e $ gerassem um resultado em uma estrutura mais simples do que a do objeto original. Porém, eu creio que essa é uma forma equivocada de se enxergar esse sistema, pois estruturas não são usualmente comparadas em níveis de complexidade, mas sim por suas propriedades e características.\nPor isso, uma forma mais útil e fiel de se enxergar essa característica, é através da representação apresentada pela Figura 2.7, onde através da função [[, podemos selecionar o elemento em si, e não uma nova estrutura contendo este elemento. Além disso, uma outra forma útil de enxergarmos essa característica no resultado das funções [[ e $, é como uma forma de eliminarmos componentes da estrutura do objeto original. Em outras palavras, podemos enxergar o operador $ ou a função [[, como uma forma de gerarmos um resultado com menos componentes do que a estrutura do objeto original.\nPor exemplo, se temos um data.frame chamado df, onde temos duas colunas simples (que são vetores atômicos), e em seguida, adicionamos duas novas colunas, uma contendo uma lista, e outra contendo um outro data.frame de duas colunas (y e z), nós temos uma estrutura razoavelmente complexa. Se utilizarmos a função str(), para nos fornecer um resumo da estrutura de df, vemos que esse objeto tem pelo menos três componentes: 1) os vetores representados pelas colunas x e nome; 2) os cinco elementos da lista alocada na coluna lista; 3) e as duas colunas contidas no data.frame da coluna outro_df.\n\ndf &lt;- data.frame(\n  x = rnorm(5),\n  nome = \"Ana\"\n)\n\ndf$lista &lt;- list(1, 2, 3, 4, 5)\ndf$outro_df &lt;- data.frame(y = rnorm(5), z = rnorm(5))\n\nstr(df)\n\n'data.frame':   5 obs. of  4 variables:\n $ x       : num  -0.639 -1.679 2.442 -1.303 1.331\n $ nome    : chr  \"Ana\" \"Ana\" \"Ana\" \"Ana\" ...\n $ lista   :List of 5\n  ..$ : num 1\n  ..$ : num 2\n  ..$ : num 3\n  ..$ : num 4\n  ..$ : num 5\n $ outro_df:'data.frame':   5 obs. of  2 variables:\n  ..$ y: num  -0.0881 -1.1691 1.647 -0.7244 1.0107\n  ..$ z: num  0.00698 -0.3366 -1.51617 0.7101 0.89831\n\n\nCaso eu utilize as funções [[ e $ para selecionarmos alguma das colunas de df, podemos aplicar novamente a função str() sobre o resultado, para compreendermos sua estrutura. Veja pelo exemplo abaixo, que o resultado da função str() nos descreve uma estrutura com menos componentes do que a estrutura original. Com isso, eu quero destacar que a estrutura desse resultado não necessariamente será menos “complexa” do que a original, mas sim que essa estrutura terá menos componentes. Portanto, pelo menos um dos componentes da estrutura original, será eliminado com o uso de [[ ou de $.\n\nstr(df[[\"lista\"]])\n\nList of 5\n $ : num 1\n $ : num 2\n $ : num 3\n $ : num 4\n $ : num 5\n\nstr(df[[\"outro_df\"]])\n\n'data.frame':   5 obs. of  2 variables:\n $ y: num  -0.0881 -1.1691 1.647 -0.7244 1.0107\n $ z: num  0.00698 -0.3366 -1.51617 0.7101 0.89831\n\nstr(df$outro_df)\n\n'data.frame':   5 obs. of  2 variables:\n $ y: num  -0.0881 -1.1691 1.647 -0.7244 1.0107\n $ z: num  0.00698 -0.3366 -1.51617 0.7101 0.89831",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentos da Linguagem R</span>"
    ]
  },
  {
    "objectID": "Capítulos/02-fundamentos.html#valores-especiais-do-r",
    "href": "Capítulos/02-fundamentos.html#valores-especiais-do-r",
    "title": "2  Fundamentos da Linguagem R",
    "section": "2.10 Valores especiais do R",
    "text": "2.10 Valores especiais do R\nNa linguagem R, possuímos alguns valores especiais, que não apenas são tratados de maneira diferente em relação a outros valores, mas que também efetivamente alteram o comportamento de algumas operações importantes na linguagem. Por exemplo, se você tentar dividir qualquer número por zero no console, ao invés do R lhe retornar um erro, lhe indicando que essa divisão é indefinida, o console vai lhe retornar o valor Inf, que se refere a infinito (ou infinite).\nPor outro lado, de forma ainda mais estranha, se você tentar dividir zero por ele mesmo, o console vai lhe retornar o valor NaN, que significa “not a number”, ou em outras palavras, que o valor resultante da divisão não é um número.\nAssim como várias outras linguagens de programação, o R também possui um valor “nulo”, ou, em outras palavras, um valor que representa o “vazio” ou o “nada”. Este valor é o NULL. Você encontra esse valor, sempre que a função ou expressão que você executou não possui um valor de retorno definido.\nEsses são alguns exemplos de valores especiais que você pode adquirir. Porém, o valor especial mais comum, é o valor NA, que significa not avaliable, ou “não-disponível”. Este valor geralmente é resultado de uma dessas duas situações: 1) ao importar a sua base de dados para o R, a linguagem vai preencher automaticamente todas as células em sua base que estiverem vazias, com um valor NA; 2) quando você executa (ou causa de maneira indireta) um processo de coerção, no qual o R não consegue realizar. Ou seja, se o R não souber como converter um valor específico, para o tipo de dado ao qual você requisitou, ele vai lhe retornar um valor NA correspondente àquele valor.\nPortanto, a primeira situação ocorre durante o processo de importação de dados, em todas as ocasiões em que você possuir alguma observação vazia na base de dados que você está importando. Logo, se em uma planilha do Excel, por exemplo, você possuir alguma célula vazia em sua tabela, ao importar essa planilha para o R, essas células vazias serão preenchidas com valores NA no R. Lembre-se que um valor NA indica uma observação não-disponível, o que significa que o valor correspondente aquela observação não pôde ser observado, ou não pôde ser registrado no momento de coleta dos dados.\nJá a segunda situação, ocorre sempre quando o R não sabe como realizar o processo de coerção, pelo qual requisitamos, de uma forma lógica. Por exemplo, isso ocorre ao tentarmos converter valores de texto para números com as.double(). Pois o R não sabe como, ou não sabe qual a maneira mais adequada de se converter esses valores em texto para números. Por isso, a linguagem vai lhe retornar como resultado, valores NA.\n\n2.10.1 Os impactos desses valores especiais\nPor que estamos falando desses valores especiais? Porque eles alteram o comportamento de certas operações importantes do R e, com isso, podem deixar você desorientado! Por exemplo, se você tentar calcular a soma de uma coluna (de um data.frame) que contém um valor NA, o resultado dessa operação será um valor NA. Da mesma forma, se a coluna possuir um valor NaN, o resultado dessa soma será um valor NaN. Para que isso ocorra, o valor especial pode estar em qualquer linha que seja, basta que ele ocorra uma única vez, que a sua soma não vai funcionar.\n\nsum(c(1, 2, 3, NA, 4))\n\n[1] NA\n\nsum(c(1, 2, 3, NaN, 4))\n\n[1] NaN\n\n\nIsso não significa que esses valores especiais serão uma dor de cabeça para você, pois cada um deles tem o seu propósito, e eles o cumprem muito bem. Mas é importante que você saiba do quão especiais eles são, e dos efeitos que eles causam em certas operações no R. Com isso, se em alguma situação uma função lhe retornar um valor NA, quando ela deveria lhe retornar algum valor definido, ou se essa função se comportar de maneira inesperada, você pode desconfiar que algum valor especial presente em seus dados, possa ser a fonte de sua surpresa.\nEm geral, todas as funções que são afetadas por esses valores especiais, como as funções sum() e mean(), possuem um argumento na.rm, que define se a função deve ignorar esses valores especiais em seus cálculos. Portanto, caso uma coluna de seu data.frame possua esses valores especiais, e você precisa ignorá-los durante o cálculo de uma soma, lembre-se de configurar este argumento para verdadeiro (TRUE).\n\nsum(c(1, 2, 3, NA, 4), na.rm = TRUE)\n\n[1] 10\n\n\nUm outro tipo de operação importante que é afetada por esses valores especiais, são os testes lógicos. Como exemplo, vamos criar um teste lógico sobre os dados apresentados pela tabela compras. Nós temos nessa tabela, o nome da composição química dos principais remédios que estão em falta nos estoques de três grandes hospitais. Os três remédios presentes nessa tabela, são remédios bem comuns, como o valor AA que se refere à composição química da Aspirina (Ácido Acetilsalicílico).\n\ncompras &lt;- structure(list(ano = c(2019, 2019, 2019, 2019, 2019, 2019, 2019, \n2019, 2019, 2019), mes = c(2L, 4L, 5L, 6L, 8L, 8L, 10L, 10L, \n10L, 12L), hospital1 = c(\"AA\", NA, \"dexametasona\", \"AA\", NA, \n\"doxiciclina\", NA, \"AA\", \"doxiciclina\", NA), hospital2 = c(\"AA\", \n\"doxiciclina\", \"dexametasona\", \"dexametasona\", \"AA\", NA, \"dexametasona\", \n\"AA\", \"dexametasona\", \"AA\"), hospital3 = c(\"AA\", \"AA\", \"dexametasona\", \nNA, \"dexametasona\", \"doxiciclina\", \"dexametasona\", NA, NA, \"AA\"\n)), row.names = 1:10, class = \"data.frame\")\n\n\ncompras\n\n    ano mes    hospital1    hospital2    hospital3\n1  2019   2           AA           AA           AA\n2  2019   4         &lt;NA&gt;  doxiciclina           AA\n3  2019   5 dexametasona dexametasona dexametasona\n4  2019   6           AA dexametasona         &lt;NA&gt;\n5  2019   8         &lt;NA&gt;           AA dexametasona\n6  2019   8  doxiciclina         &lt;NA&gt;  doxiciclina\n7  2019  10         &lt;NA&gt; dexametasona dexametasona\n8  2019  10           AA           AA         &lt;NA&gt;\n9  2019  10  doxiciclina dexametasona         &lt;NA&gt;\n10 2019  12         &lt;NA&gt;           AA           AA\n\n\nPor exemplo, se nós quiséssemos identificar todas as linhas na tabela compras, em que a composição química da Aspirina (valor AA) aparece em pelo menos um dos hospitais (ou dito de outra forma, em pelo menos uma das colunas), poderíamos aplicar um teste lógico sobre a tabela compras. O teste lógico abaixo, serve para esse propósito, mas se olharmos para o resultado desse teste, podemos identificar que algo está errado.\n\nteste &lt;- compras$hospital1 == \"AA\" |\n  compras$hospital2 == \"AA\" |\n  compras$hospital3 == \"AA\" \n\nteste\n\n [1]  TRUE  TRUE FALSE  TRUE  TRUE    NA    NA  TRUE    NA  TRUE\n\n\nPerceba acima, que o teste lógico detectou com sucesso todas as linhas da tabela compras, que possuem um valor AA em pelo menos uma de suas colunas. Mais especificamente, as linhas de posição 1°, 2°, 4°, 5°, 8° e 10°. Porém, podemos também identificar, que para as linhas de posição 6°, 7° e 9° na tabela, o teste lógico teste nos retornou valores NA. Ou seja, ao invés do teste lógico nos retornar um valor FALSE, para as linhas que não possuem um valor AA ao longo de suas colunas, ele acaba nos retornando um valor NA, pelo simples fato de que temos um valor NA em pelo menos uma das colunas. Isso se torna um grande problema, a partir do momento em que desejamos filtrar a nossa tabela compras, ao fornecer o nosso vetor teste, à função de subsetting.\n\ncompras[teste, ]\n\n      ano mes hospital1    hospital2    hospital3\n1    2019   2        AA           AA           AA\n2    2019   4      &lt;NA&gt;  doxiciclina           AA\n4    2019   6        AA dexametasona         &lt;NA&gt;\n5    2019   8      &lt;NA&gt;           AA dexametasona\nNA     NA  NA      &lt;NA&gt;         &lt;NA&gt;         &lt;NA&gt;\nNA.1   NA  NA      &lt;NA&gt;         &lt;NA&gt;         &lt;NA&gt;\n8    2019  10        AA           AA         &lt;NA&gt;\nNA.2   NA  NA      &lt;NA&gt;         &lt;NA&gt;         &lt;NA&gt;\n10   2019  12      &lt;NA&gt;           AA           AA\n\n\nPortanto, o problema gerado pelos valores NA presentes no resultado do teste lógico, é que eles geram indiretamente um novo problema a ser resolvido. O objetivo principal está em identificar as linhas da tabela compras, que possuem um valor AA, em pelo menos uma de suas colunas, e filtrá-las da tabela. Porém, ao fornecermos esse vetor teste à função de subsetting, a função [ acaba adicionando uma nova linha ao resultado, para cada valor NA presente no vetor teste. Logo, o resultado que era para ter 6 linhas, acaba tendo 9. Com isso, teríamos um novo trabalho de eliminar essas novas linhas de NA’s, para chegarmos às linhas que queremos filtrar da nossa tabela compras.\n\n\n2.10.2 Valores especiais também estão associados a algum tipo de dado\nVale destacar que, assim como qualquer outro valor no R, os valores especiais do R também estão associados a algum dos 5 tipos básicos de dados apresentados na seção Tipos de dados. Como exemplo, os valores Inf, -Inf e NaN são valores associados ao tipo double.\n\ntypeof(Inf)\n\n[1] \"double\"\n\ntypeof(-Inf)\n\n[1] \"double\"\n\ntypeof(NaN)\n\n[1] \"double\"\n\n\nPor outro lado, o valor NA é por padrão, um valor do tipo logical. Porém, diferentemente de Inf, -Inf e NaN, o valor NA possui diferentes “versões” para cada um dos 5 tipos de dados. Essas versões são NA_character_, NA_real_, NA_complex_ e NA_integer_. Temos também outras “versões” referentes a tipos de dados mais complexos, como NA_POSIXct_ e NA_Date_ que se referem aos tipos POSIXct e Date, os quais vamos descrever no capítulo Introdução à variáveis de tempo com lubridate.\n\ntypeof(NA)\n\n[1] \"logical\"\n\ntypeof(NA_character_)\n\n[1] \"character\"\n\ntypeof(NA_real_)\n\n[1] \"double\"\n\n\nPortanto, valores como Inf, -Inf e NaN estão presentes apenas no tipo double, enquanto o valor NA possui uma “versão” para cada tipo de dado no R. Tanto que, se tentarmos converter um valor como NaN para algum outro tipo, como o tipo logical, ele será automaticamente convertido para um valor NA do tipo logical, como demonstrado abaixo.\n\nas.logical(NaN)\n\n[1] NA\n\n\n\n\n2.10.3 Como identificar valores especiais\nPor serem valores especiais, o R nos oferece um conjunto de funções para cada um desses valores especiais, as quais estão listadas abaixo:\n\nis.na().\nis.finite().\nis.infinite().\nis.nan()\n\nA função is.finite() busca identificar se um valor numérico é finito, o que significa basicamente, um valor do tipo numeric diferente de Inf, -Inf, NaN e de NA. Perceba abaixo que, quando digo que a função is.finite() busca testar valores numéricos, estou querendo dizer que essa função é irrelevante para testar valores do tipo character, dado que ela nos retorna FALSE para qualquer valor textual. Repare também que essa função nos retorna TRUE para dados do tipo logical, dado que, no fundo, valores do tipo logical são armazenados através de 1’s e 0’s do tipo integer.\n\nlibrary(purrr)\nobjs &lt;- list(Inf, NaN, NA, \"texto\", 1.25, 1L, TRUE)\nr &lt;- map_lgl(objs, is.finite)\nnames(r) &lt;- c(\n  \"Inf\", \"NaN\", \"NA\",\n  \"character\", \"double\",\n  \"integer\", \"logical\"\n)\n\nprint(r)\n\n      Inf       NaN        NA character    double   integer   logical \n    FALSE     FALSE     FALSE     FALSE      TRUE      TRUE      TRUE \n\n\nAo descobrir o valor NA, você talvez tenha pensado que você seria capaz de identificar esse valor especial por um simples teste de igualdade. Entretanto, como descrevemos na seção Os impactos desses valores especiais, valores especiais alteram o comportamento de testes lógicos tradicionais, de modo que, um teste de igualdade como x == NA vai sempre resultar em um novo valor NA.\n\nx &lt;- NA\nx == NA\n\n[1] NA\n\n\nPortanto, a forma adequada de se testar se um determinado objeto no R contém um valor NA, é aplicar a função is.na() sobre o objeto em questão. Caso o seu objetivo seja justamente o contrário (isto é, testar se o objeto não contém um valor NA), você precisa apenas inverter o teste lógico ao adicionar o operador ! sobre a função.\n\nis.na(x)\n\n[1] TRUE\n\n# Fazendo o teste inverso:\n!is.na(x)\n\n[1] FALSE\n\n\nJá as funções is.infinite() e is.nan() funcionam exatamente da mesma forma, com a diferença que, essas funções testam se o objeto contém valores infinitos (Inf e -Inf) e valores NaN, respectivamente.\n\nis.infinite(Inf)\n\n[1] TRUE\n\nis.nan(NaN)\n\n[1] TRUE\n\n\n\n\n\n\nCHAMBERS, J. M. Extending R. Boca Raton, FL: CRC Press, 2016.\n\n\nPENG, R. D. R Programming for Data Science. [s.l.] Leanpub, 2015.\n\n\nTEAM, R. C. R Language Definition. Version 4.0.3 ed. [s.l.] R Foundation, 2020a.\n\n\nTEAM, R. C. An Introduction to R: A Programming Environment for Data Analysis and Graphics. Version 4.0.3 ed. [s.l.] R Foundation, 2020b.\n\n\nWICKHAM, H. Advanced R. 2. ed. Boca Raton, Florida: CRC Press, 2015.\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentos da Linguagem R</span>"
    ]
  },
  {
    "objectID": "Capítulos/02-fundamentos.html#footnotes",
    "href": "Capítulos/02-fundamentos.html#footnotes",
    "title": "2  Fundamentos da Linguagem R",
    "section": "",
    "text": "https://www.youtube.com/watch?v=rz3_FDVt9eg↩︎\nCaso tenha alguma dificuldade em chamar pelo pacote, volte a seção Pacotes para descobrir o passo que você se esqueceu de cumprir.↩︎\nLembre-se que no fundo, data.frame’s são listas, com a propriedade de que todos os elementos dessa lista, devem possuir o mesmo número de linhas. Portanto, se cada coluna desse data.frame representa um elemento da lista que forma esse data.frame, ao utilizarmos o operador $, também estaríamos selecionando um “elemento”, que se traduz em uma coluna do data.frame.↩︎",
    "crumbs": [
      "Introduzindo a Linguagem R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentos da Linguagem R</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-tidyverse.html",
    "href": "Capítulos/03-tidyverse.html",
    "title": "3  Introduzindo o universo do tidyverse",
    "section": "",
    "text": "3.1 Os diferentes pacotes do tidyverse\nA lista abaixo contém os pacotes que formam o core do tidyverse. Para cada pacote, temos uma breve descrição de sua especialidade. Não se preocupe em entender exatamente o que eles fazem, pois isso ficará mais claro a medida em que você caminhar por este livro.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduzindo o universo do `tidyverse`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-tidyverse.html#os-diferentes-pacotes-do-tidyverse",
    "href": "Capítulos/03-tidyverse.html#os-diferentes-pacotes-do-tidyverse",
    "title": "3  Introduzindo o universo do tidyverse",
    "section": "",
    "text": "ggplot2: visualização de dados, ou produção de gráficos.\ndplyr: verbos para manipulação de tabelas.\nreadr: importação e exportação de dados em arquivos de texto.\ntibble: data.frame’s modernos.\nstringr: manipulação de texto (character).\nforcats: trabalhando com fatores (factor).\ntidyr: formatar e limpar os seus dados.\npurrr: repita você mesmo com functional programming.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduzindo o universo do `tidyverse`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-tidyverse.html#acessando-o-tidyverse",
    "href": "Capítulos/03-tidyverse.html#acessando-o-tidyverse",
    "title": "3  Introduzindo o universo do tidyverse",
    "section": "3.2 Acessando o tidyverse",
    "text": "3.2 Acessando o tidyverse\nO tidyverse nada mais é do que um conjunto de pacotes dentro dele aglomerados em um único pacote. Portanto, para ter acesso a esses vários pacotes que estendem as funcionalidades do R, basta instalar o tidyverse na sua máquina, com a função install.packages(). Assim, sempre que você quiser usar um desses pacotes em sua sessão do R, basta carregar o tidyverse para sua sessão com a função library().\n\n# Primeiro, instale o tidyverse:\ninstall.packages(\"tidyverse\")\n# Em seguida, importe ele para sua sessão:\nlibrary(tidyverse)\n\n\n\n\n\nWICKHAM, H. et al. Welcome to the Tidyverse. Journal of Open Source Software, v. 4, n. 43, p. 1686, 2019.\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduzindo o universo do `tidyverse`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html",
    "href": "Capítulos/03-importacao.html",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "",
    "text": "4.1 Introdução e pré-requisitos\nPara analisar os seus dados no R, você precisa primeiro importar esses dados para dentro do R. Neste capítulo, vamos aprender como utilizar as funções dos pacotes readr, readxl e haven, para ler e importar dados presentes em arquivos de texto (plain text files - .txt ou .csv), em planilhas do Excel (.xlsx) e em arquivos produzidos por programas estatísticos como o Stata (.dta), SPSS (.sav; .zsav e .por) e SAS (.sas).\nPara que você tenha acesso as funções e possa acompanhar os exemplos desse capítulo você precisa chamar pelos pacotes readr, readxl e haven, através do comando library(). O pacote readr especificamente, está incluso dentro do tidyverse e, por isso, você também pode chamar por ele.\nlibrary(tidyverse)\n\nlibrary(readr)\nlibrary(readxl)\nlibrary(haven)",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#fontes-de-dados",
    "href": "Capítulos/03-importacao.html#fontes-de-dados",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "4.2 Fontes de dados",
    "text": "4.2 Fontes de dados\nOs seus dados podem vir de vários tipos de fontes diferentes. Para citar alguns tipos bastante comuns de fontes de dados, temos:\n\nArquivos estáticos salvo no disco rígido de seu computador (e.g. CSV, Excel, etc.).\nAPIs (Application Programming Interface);\nBancos de dados (e.g. MySQL, Cassandra, MongoDB, PostgreSQL, etc.);\nArquivos fornecidos por um servidor (e.g. um página HTML);\n\nCada um desses tipos de fontes exigem técnicas ou métodos de importação diferentes entre si. Por exemplo, para importarmos dados de bancos de dados, nós precisamos criar uma conexão com o banco de dados, geralmente através de um driver ODBC (Open DataBase Connectivity). Como um outro exemplo, para coletarmos dados de uma API, nós geralmente precisamos enviar requisições HTTP para essa API.\nEu não espero que você entenda o que esses termos significam (ODBC? HTTP? …). O que eu realmente quero que você entenda aqui, é que você vai, em geral, utilizar pacotes e funções diferentes do R para importar os seus dados, a depender de onde, ou do tipo de fonte da qual você está extraindo esses dados. Por exemplo, para importar os seus dados de um banco de dados através do R, você geralmente vai utilizar as funções dos pacotes DBI e odbc. Por outro lado, para importar dados de uma API você geralmente vai utilizar as funções do pacote httr2.\nPara mais, você vai perceber que os pacotes e funções utilizados dentro de um mesmo tipo de fonte, também podem variar. Por exemplo, ao longo desse capítulo, vamos mostrar métodos para se importar dados de arquivos estáticos salvos em seu computador. Porém, você vai perceber que os pacotes e funções utilizados são diferentes para cada tipo de arquivo estatíco. Ou seja, a função utilizada para importar uma planilha do Excel é diferente da função utilizada para importar um arquivos CSV, e assim por diante.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#arquivos-estáticos",
    "href": "Capítulos/03-importacao.html#arquivos-estáticos",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "4.3 Arquivos estáticos",
    "text": "4.3 Arquivos estáticos\nArquivos estatícos são um método prático de se transportar dados entre computadores. Uma situação comum que mostra essa praticidade é: “o seu colega de trabalho precisa dos dados daquela planilha que só você tem no seu computador. Para isso, você pode salvar essa planilha, em um arquivo .xlsx, e enviar um email para esse colega com esse arquivo .xlsx em anexo. A partir daí, o seu colega pode baixar esse arquivo para o computador dele”.\nPortanto, arquivos estatícos são os arquivos que você normalmente salva em seu computador. Todo arquivo estatíco possui uma extensão que define o tipo do arquivo estatíco que ele é. Por exemplo, planilhas do Excel são salvas em arquivos com extensão .xlsx ou .xls. Já arquivos CSV são arquivos com extensão .csv, e arquivos de texto padrão possuem extensão .txt.\nUm detalhe característico desse tipo de fonte de dado, é que sempre que você for importar os dados de um arquivo estático para o R, você terá que coletar obrigatoriamente o endereço no disco rígido no qual esse arquivo está salvo atualmente. Vamos descrever em breve como coletar esses endereços. Mais especificamente na seção Definindo endereços do disco rígido no R.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#diretório-de-trabalho",
    "href": "Capítulos/03-importacao.html#diretório-de-trabalho",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "4.4 Diretório de trabalho",
    "text": "4.4 Diretório de trabalho\nA Linguagem R possui uma forte noção de diretórios de trabalho (WICKHAM; GROLEMUND, 2017, pp. 113). O diretório de trabalho (ou working directory) é a pasta de seu computador onde o R está atualmente enraizado, ou, em outras palavras, é a pasta para a qual o R está olhando atualmente.\n\n\n\n\n\n\n\n\nFigura 4.1: Diretório de trabalho - Console RStudio\n\n\n\n\n\nPortanto, sempre que você estiver no R, ele vai estar necessariamente trabalhando com alguma pasta específica de seu computador. Será nessa pasta que o R vai inicialmente procurar pelos arquivos que você demanda, e também será nessa pasta que o R vai inicialmente salvar todos os arquivos que você pedir a ele que salve.\nNo RStudio, você pode identificar o seu diretório de trabalho atual na parte esquerda e superior do console, logo abaixo do nome de sua guia (Console), como mostrado na Figura 4.1. Repare abaixo, que no momento em que a foto presente na Figura 4.1 foi tirada, eu estava trabalhando com uma pasta de meu computador chamada Curso-R, que por sua vez, se encontrava dentro de uma pasta chamada Projeto curso R.\nAlém disso, você também pode descobrir o seu diretório de trabalho atual ao executar a função getwd() no console:\n\ngetwd()\n\n## [1] \"C:/Users/Pedro/Documents/Projeto curso R/Curso-R\"\n\n4.4.1 Um exemplo\nVamos supor que o meu diretório de trabalho atual seja a pasta Curso-R, a qual está dentro da pasta Projeto curso R. Se eu pedir por algum arquivo chamado frase.txt, o R vai procurar por esse arquivo dentro dessa pasta Curso-R:\n\nreadLines(\"frase.txt\")\n\n## [1] \"Aristóteles foi um filósofo da Grécia Antiga\"\nIsso tem duas implicações muito importantes:\n\no arquivo frase.txt deve estar dentro dessa pasta Curso-R, caso contrário o R não poderá encontrar esse arquivo;\ntemos uma maneira muito simples e poderosa de acessarmos qualquer arquivo que esteja presente na pasta Curso-R, pois precisamos apenas do nome desse arquivo, como no exemplo acima;\n\nUm ponto muito importante é que a extensão do arquivo (que traduz o tipo do arquivo estático) também faz parte do nome do arquivo. No exemplo acima, o arquivo se chama frase e possui a extensão .txt, logo, o nome do arquivo a ser fornecido ao R é frase.txt.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#sec:enderecos_disco_rigido",
    "href": "Capítulos/03-importacao.html#sec:enderecos_disco_rigido",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "4.5 Definindo endereços do disco rígido no R",
    "text": "4.5 Definindo endereços do disco rígido no R\nPortanto, o mecanismo de diretórios de trabalho apenas define onde o R vai olhar primeiro pelos arquivos que você pede. Entretanto, isso não te impede de acessar arquivos que se encontram em outros locais do seu computador. Porém, para acessar qualquer arquivo que esteja em uma pasta diferente do seu diretório de trabalho atual, você precisa obrigatoriamente fornecer o endereço completo até esse arquivo para o R.\n\n4.5.1 Cuidados ao definir endereços\nAlguns cuidados no R são necessários ao definir um endereço até um arquivo. Primeiro, endereços de seu disco rígido devem sempre ser fornecidos como textos (strings). Por isso, lembre-se de contornar o seu endereço com aspas duplas ou simples no R. Segundo, o Windows utiliza por padrão a barra inclinada à esquerda (\\) para separar cada diretório presente no caminho até um certo arquivo. Todavia, a barra inclinada à esquerda possui um significado especial para o R.\nAbordando especificamente o segundo ponto, você tem duas alternativas para contornar as particularidades das barras inclinadas utilizadas nos endereços de seus arquivos: 1) utilizar o estilo dos sistemas Mac e Linux, que utilizam a barra inclinada à direita (/) para separar os diretórios; 2) ou contornar o comportamento especial de uma barra inclinada à esquerda, com duas barras inclinadas à esquerda (\\\\). Ou seja, é como se essas duas barras \\\\ significassem apenas uma barra \\ para o R. Eu particularmente prefiro utilizar o estilo dos sistemas Mac e Linux para resolver esse problema, pois ele incorre em um trabalho menor de digitação.\nPor exemplo, eu tenho um arquivo chamado livros.txt localizado dentro da pasta Lista de compras, que por sua vez, se encontra dentro da minha pasta de Documentos do Windows. Segundo o padrão do Windows, o endereço até esse arquivo seria: \"C:\\Users\\Pedro\\Documents\\Lista de compras\\livros.txt\". Porém, levando-se em conta os pontos que acabamos de abordar, nós poderíamos escrever esse endereço dos dois modos expostos abaixo:\n\nlivros &lt;- read_csv(\"C:\\\\Users\\\\Pedro\\\\Documents\\\\Lista de compras\\\\livros.txt\")\nlivros &lt;- read_csv(\"C:/Users/Pedro/Documents/Lista de compras/livros.txt\")\nlivros\n\n\n\n# A tibble: 4 × 3\n  Titulo                               Autor                          Preco\n  &lt;chr&gt;                                &lt;chr&gt;                          &lt;dbl&gt;\n1 O Hobbit                             J. R. R. Tolkien                40.7\n2 Matemática para Economistas          Carl P. Simon e Lawrence Blume 140. \n3 Microeconomia: uma Abordagem Moderna Hal R. Varian                  141. \n4 A Luneta Âmbar                       Philip Pullman                  42.9\n\n\n\n\n4.5.2 Endereços relativos e absolutos\nExistem dois tipos de endereços do disco rígido que você pode fornecer ao R, endereços relativos e endereços absolutos. Endereços absolutos, são endereços que começam pelo disco rígido e vão até o nome do arquivo. Esse tipo de endereço é chamado de absoluto, porque ele aponta para um endereço único e absoluto de seu computador. Ou seja, não existe nenhum outro local de seu computador com este endereço.\nUm exemplo de endereço absoluto é o endereço do arquivo livros.txt que fornecemos no exemplo da seção anterior (C:/Users/Pedro/Documents/Lista de compras/livros.txt). Este é um endereço absoluto pois ele começa pelo disco rígido C:/ e vai até o nome do arquivo livros.txt específico que desejamos ler.\nPara coletarmos o endereço absoluto de um arquivo no Windows, podemos clicar com o botão direito do mouse sobre o arquivo de interesse, e selecionar a opção Propriedades. Uma caixa vai abrir em sua tela, contendo diversas informações sobre o arquivo em questão. Logo a sua frente, temos a seção chamada Local na parte inicial dessa caixa, onde podemos encontrar o endereço absoluto até a pasta onde o seu arquivo de interesse está localizado.\nDe outro modo, endereços relativos são endereços “relativos” a um ponto inicial. Esse ponto inicial é sempre o seu diretório de trabalho atual. Ou seja, todo endereço relativo sempre começa pelo seu diretório de trabalho atual. O comando readLines(\"frase.txt\") que mostramos em uma seção anterior é um exemplo de uso de um endereço relativo. Pois nós fornecemos diretamente o nome do arquivo, logo, o R pesquisa por esse arquivo no diretório de trabalho atual.\nTendo isso em mente, sempre que você for construir um endereço relativo, identifique primeiro qual o seu diretório de trabalho atual, e, a partir desse diretório, pense em qual é o caminho restante para chegar ao arquivo que você deseja importar.\nVamos utilizar como exemplo, o conjunto de arquivos mostrados na Figura 4.2 que se encontram dentro de uma pasta chamada Dados. Perceba que essa pasta Dados está dentro de uma pasta Curso-R, que por sua vez está dentro de uma pasta Projeto curso R:\n\n\n\n\n\n\n\n\nFigura 4.2: Exemplo de arquivos\n\n\n\n\n\nVamos supor que o nosso diretório de trabalho atual fosse, por exemplo, a pasta Projeto curso R. Nesse caso, poderíamos fornecer um endereço relativo para qualquer um desses arquivos presentes na pasta Dados. Pois a pasta Dados se encontra dentro da pasta Projeto curso R. Em outras palavras, a pasta Dados é uma subpasta da pasta Projeto curso R.\nLembre-se, um endereço relativo possui como ponto inicial, o seu diretório de trabalho atual. Por isso, você sempre pode utilizar um endereço relativo para acessar qualquer arquivo que esteja dentro de seu diretório de trabalho, ou dentro de alguma de suas subpastas. No caso dos arquivos da pasta Dados, nós poderíamos fornecer o endereço \"Curso-R/Dados/\" para chegarmos a pasta Dados. Em seguida, precisaríamos apenas acrescentar o nome do arquivo de nosso desejo. Por exemplo, para ler o arquivo de nome covid.csv, o endereço resultante seria \"Curso-R/Dados/covid.csv\".\n\n\n4.5.3 Wildcards em endereços do disco rígido\nAo fornecer endereços do disco rígido, você tem a opção de utilizar um wildcard. Temos dois wildcards comumente utilizados em endereços do disco rígido, que são o ponto final (.) e dois pontos finais (..). Ou seja, esses dois textos específicos possuem significados especiais em endereços do disco rígido, e podem ser utilizados em qualquer sistema operacional que você esteja (Mac, Windows, Linux, etc.).\nO ponto final representa um apelido para o seu diretório de trabalho atual. Isso significa que, os endereços relativos \"./Curso-R/Dados/convid.csv\" e \"Curso-R/Dados/convid.csv\" são equivalentes. Já os dois pontos, se referem ao diretório anterior ao diretório atual. Por exemplo, o endereço \"Curso-R/..\" é equivalente ao endereço \".\", isto é, ao diretório de trabalho atual.\nOu seja, o endereço \"Curso-R/..\" se refere à pasta anterior à pasta Curso-R. Como um outro exemplo, o endereço \"src/writexml/../xml.cpp\" se refere ao arquivo xml.cpp que está dentro da pasta anterior à pasta writexml, que nesse exemplo é a pasta src. Portanto, este endereço é equivalente à \"src/xml.cpp\".\nVale destacar que você pode empilhar um wildcard múltiplas vezes. Dessa forma, você consegue “subir” vários steps na árvore genealógica de pastas de seu computador, ou, em outras palavras, você consegue “andar várias pastas para trás”. Por exemplo, o endereço \"../../../planilha_importante.xlsx\" se refere à um arquivo chamado planilha_importante.xlsx que está a três pastas anteriores ao seu diretório de trabalho atual.\n\n\n4.5.4 Qual tipo de endereço utilizar?\nSegundo WICKHAM; GROLEMUND (2017), é recomendável que você evite endereços absolutos, especialmente se você trabalha em conjunto com outras pessoas em um mesmo projeto. Pois é muito provável que os computadores de seus parceiros de trabalho não possuem exatamente a mesma estrutura de diretórios que o seu computador.\nPor isso, o ideal é que você sempre organize todos os arquivos referentes a um certo projeto ou a uma certa análise, dentro de uma pasta específica de seu computador. Dessa forma, você pode tornar essa pasta específica o seu diretório de trabalho no R, e a partir daí, fornecer endereços relativos até cada arquivo.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#plataforma-de-projetos-do-rstudio",
    "href": "Capítulos/03-importacao.html#plataforma-de-projetos-do-rstudio",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "4.6 Plataforma de Projetos do RStudio",
    "text": "4.6 Plataforma de Projetos do RStudio\nNo R, você pode configurar o seu diretório de trabalho atual, através da função setwd(). Basta fornecer o endereço absoluto até a pasta com a qual você deseja trabalhar. Veja o exemplo abaixo, em que eu escolho a pasta de Documentos do Windows como o meu diretório de trabalho:\n\nsetwd(\"C:/Users/Pedro/Documents\")\n\nPorém, esse não é um método recomendado de se configurar o seu diretório de trabalho, especialmente porque nós precisamos realizar essa configuração toda vez em que acessamos o R, sendo algo contraproducente. Por isso, WICKHAM; GROLEMUND (2017) caracterizam a plataforma de Projetos do RStudio, como uma forma mais adequada e eficiente de realizarmos essa configuração.\n\n\n\n\n\n\n\n\nFigura 4.3: Plataforma de Projetos do RStudio\n\n\n\n\n\nAo criar um projeto no RStudio, você está apenas criando um arquivo com o nome desse projeto e que possui uma extensão .Rproj. Esse arquivo .Rproj funciona como um link até a pasta onde você o guardou. Dessa forma, ao acessarmos esse projeto no RStudio, o seu console já vai estar trabalhando com a pasta onde o arquivo .Rproj foi salvo. Em termos técnicos, toda vez que você acessar esse projeto, o RStudio vai automaticamente configurar essa pasta como o seu diretório de trabalho atual do R.\nPara criarmos um projeto no RStudio, você pode acessar um pequeno menu localizado na parte superior e direita de sua tela, mostrado na Figura 4.3. Ao selecionar a opção New Project..., o seu RStudio vai abrir uma aba. Nessa aba, você vai selecionar como deseja criar o novo arquivo .Rproj. Caso você já tenha organizado todos os arquivos de seu projeto uma pasta específica, você pode selecionar a opção Existing Directory para salvar o arquivo .Rproj em uma pasta já existente. Por outro lado, caso você esteja iniciando o seu projeto do zero, você pode selecionar a opção New Directory para criar um novo diretório em seu computador, onde você vai guardar todos os arquivos referentes ao seu projeto.\nAo selecionar uma dessas opções, o RStudio também vai lhe questionar sobre o tipo desse projeto, ou dito de outra maneira, qual o tipo de produto que você busca gerar com esse projeto. Ou seja, se você está planejando construir um novo pacote para o R, é interessante que você selecione a segunda opção (R Package). Pois assim, o próprio RStudio vai automaticamente criar para você, os principais arquivos que um pacote do R precisa ter. Em geral, você vai selecionar a primeira opção (New Project) para criar um projeto padrão.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#importando-arquivos-de-texto-com-readr",
    "href": "Capítulos/03-importacao.html#importando-arquivos-de-texto-com-readr",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "4.7 Importando arquivos de texto com readr",
    "text": "4.7 Importando arquivos de texto com readr\nArquivos de texto, também conhecidos como plain text files, ou flat files, estão entre os formatos de arquivo mais utilizados em todo o mundo para transportar e armazenar dados. Por isso é muito importante que você conheça esses arquivos e saiba reconhecê-los.\nUm arquivo de texto, normalmente assume a extensão .txt, e contém apenas cadeias de textos ou cadeias de valores numéricos que são organizados em linhas. Apesar de simples, os dados armazenados podem ser organizados de diferentes formas em cada linha do arquivo. Por essa razão, um arquivo de texto pode assumir diferentes extensões que identificam o tipo de arquivo de texto ao qual ele pertence.\nEm outras palavras, nós possuímos diferentes tipos de arquivos de texto, e a diferença básica entre eles, está na forma como os valores são organizados em cada linha do arquivo. Um dos tipos de arquivo de texto mais famosos é o arquivo CSV (comma separated file), que utiliza vírgulas (ou pontos e vírgulas como é o caso brasileiro) para separar os valores de diferentes colunas em cada linha do arquivo. Por isso, não basta que você identifique se o seu arquivo de interesse é um arquivo de texto, pois você também precisa identificar o tipo de arquivo de texto no qual ele se encaixa.\nPara importarmos os dados presentes nesses arquivos, vamos utilizar as funções do pacote readr, que oferece um conjunto de funções especializadas em arquivos de texto. Logo abaixo, temos uma lista que associa os respectivos tipos de arquivos de texto a cada uma das funções desse pacote.\n\nread_delim(): essa é uma função geral, que é capaz de ler qualquer tipo de arquivo de texto em que os valores estão delimitados por algum caractere especial.\nread_csv2(): lê arquivos CSV (comma separated file) que seguem o padrão adotado pelo Brasil e por alguns países europeus. Isto é, arquivos .txt ou .csv onde os valores são separados por ponto e vírgula (;).\nread_csv(): lê arquivos CSV (comma separated file) que seguem o padrão americano. Isto é, arquivos .txt ou .csv onde os valores são separados por vírgula (,).\nread_tsv(): lê arquivos TSV (tab separated values). Arquivos .txt ou .tsv onde os valores são separados por tabulação (\\t).\nread_fwf(): lê arquivos FWF (fixed width file). Arquivos .txt ou .fwf onde cada coluna do arquivo possui uma largura fixa de valores.\n\nRepare que o nome de todas as funções acima segue o padrão read_*(), onde a palavra presente no ponto * corresponde a extensão que identifica o tipo de arquivo no qual a função é especializada. Nós sempre iniciamos qualquer uma das funções acima, pelo endereço até o arquivo que desejamos ler. Como exemplo inicial, eu possuo um arquivo CSV chamado Censo_2010.csv, que se encontra dentro da pasta 6 - Importacao.\n\nlibrary(readr)\nCenso_2010 &lt;- read_csv2(\"Parte 1/6 - Importacao/Censo_2010.csv\")\n\n## ‐‐ Column specification ‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐\n## cols(\n## `Região metropolitana` = col_character(),\n## `População residente` = col_double(),\n## `População em área urbana` = col_double(),\n## `População em área não urbanizada` = col_double(),\n## `População em área isolada` = col_double(),\n## `Área rural` = col_double(),\n## `Aglomerado urbano` = col_double(),\n## Povoado = col_double(),\n## Núcleo = col_double(),\n## `Outros aglomerados` = col_double(),\n## `Código unidade` = col_double()\n## )\n\nPerceba no resultado acima que, a função read_csv2() nos reporta a lista de colunas que ela encontrou no arquivo (Column specification), e também, o tipo de dado que foi associado para cada uma delas. Por exemplo, a coluna Região metropolitana que foi encontrada no arquivo CSV, foi automaticamente associado com o tipo de dado character.\nEste relatório é muito útil, pois você pode rapidamente identificar se alguma coluna de seu arquivo CSV não foi importada por algum motivo, ou ainda, se o tipo de dado que foi associado a essa coluna está incorreto. Por se tratar de uma variável categórica, o tipo character é, a princípio, um tipo de dado adequado para a variável Região metropolitana.\nAgora, a partir daqui, eu não vou evitar mostrar esse relatório. Apenas com o objetivo de ser mais breve, e evitar ser muito repetitivo ao longo do livro. Mas lembre-se que, por padrão, sempre que utilizar as funções do pacote readr, elas vão produzir esse relatório automaticamente para você.\nAlém de tudo isso, perceba também no exemplo acima, que eu salvo o resultado da função read_csv2() em um objeto chamado Censo_2010. Isso é muito importante! Lembre-se sempre de salvar o resultado das funções read_*() em algum objeto. Pois tudo que a função read_csv2() faz é ler o arquivo Censo_2010.csv e encaixar o seu conteúdo em uma tabela (ou um data.frame) do R. Ou seja, em nenhum momento, a função read_csv2() se preocupa em salvar os dados que ela coletou do arquivo Censo_2010.csv, em algum lugar que podemos acessar futuramente.\nÉ por esse motivo, que eu salvo a tabela gerada pela função read_csv2() em um novo objeto do R chamado Censo_2010. Pois dessa forma, eu posso acessar novamente os dados que coletamos do arquivo Censo_2010.csv, através deste objeto Censo_2010.\n\nCenso_2010\n\n# A tibble: 2,013 × 11\n  `Região metropolitana` `População residente` `População em área urbana`\n  &lt;chr&gt;                                  &lt;dbl&gt;                      &lt;dbl&gt;\n1 Manaus  AM                           2106322                    1972885\n2 Homens                               1036676                     964041\n3 Mulheres                             1069646                    1008844\n4 Careiro da Várzea                      23930                       1000\n5 Homens                                 12688                        481\n# ℹ 2,008 more rows\n# ℹ 8 more variables: `População em área não urbanizada` &lt;dbl&gt;, …\n\n\nMesmo que o arquivo Censo_2010.csv seja claramente um arquivo CSV, nós precisamos identificar qual o padrão que ele está adotando. Nos EUA, um arquivo CSV utiliza vírgulas (,) para separar os valores de cada coluna. Porém, pelo fato de nós, brasileiros, usarmos a vírgula para delimitar casas decimais em números reais, nós empregamos o padrão de um arquivo CSV adotado por alguns países europeus, que utilizam o ponto e vírgula (;) como separador.\nLogo abaixo, temos as linhas iniciais do arquivo Censo_2010.csv e, podemos rapidamente identificar que esse arquivo utiliza o padrão europeu, pois os valores estão separados por ponto e vírgula (;). Por essa razão que eu utilizo a função read_csv2(), e não a função read_csv() para ler o arquivo.\nManaus  AM;2106322;1972885;3011;;108160;;22266;;;30\nHomens;1036676;964041;2018;;59024;;11593;;;30\nMulheres;1069646;1008844;993;;49136;;10673;;;30\nCareiro da Várzea;23930;1000;;;21089;;1841;;;1301159\nHomens;12688;481;;;11281;;926;;;1301159\nMulheres;11242;519;;;9808;;915;;;1301159\nApesar de ser esse o padrão adotado por nós brasileiros, você enfrentará ocasiões em que o seu arquivo de texto possui separadores diferentes do esperado. Por exemplo, talvez os seus dados sejam separados por cifrões ($).\n\nt &lt;- \"Ano$Código$Dia$Valor\n2020$P.A22$01$4230.45\n2020$B.34$02$1250.28\n2020$S.T4$03$3510.90\"\n\nEm casos como esse, você será obrigado a definir explicitamente o separador utilizado no arquivo. Para isso, você pode utilizar a função read_delim(), que possui o argumento delim, onde podemos determinar o caractere que delimita as colunas no arquivo.\n\nread_delim(t, delim = \"$\")\n\n# A tibble: 3 × 4\n    Ano Código Dia   Valor\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n1  2020 P.A22  01    4230.\n2  2020 B.34   02    1250.\n3  2020 S.T4   03    3511.\n\n\nComo um outro exemplo, arquivos TSV são simplificadamente um arquivo CSV que utiliza um caractere especial de tabulação como separador, representado pelos caracteres \\t. Ou seja, nós podemos recriar a função read_tsv() através da função read_delim(), ao configurarmos o argumento delim, como no exemplo abaixo.\n\nt &lt;- \"Ano\\tCódigo\\tDia\\tValor\n2020\\tP.A22\\t01\\t4.230,45\n2020\\tB.34\\t02\\t1.250,28\n2020\\tS.T4\\t03\\t3.510,90\"\n\nread_delim(t, delim = \"\\t\")\n\n# A tibble: 3 × 4\n    Ano Código Dia   Valor\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n1  2020 P.A22  01     4.23\n2  2020 B.34   02     1.25\n3  2020 S.T4   03     3.51\n\n\n\n4.7.1 Definindo os tipos de dados em cada coluna\nAs funções read_*() vão sempre, por padrão, ler as 1000 primeiras linhas de seu arquivo, e com base nelas, a função vai tentar adivinhar qual o tipo de dado contido em cada coluna. Após esse processo, em que a função read_*() escolhe um tipo de dado para cada coluna, a função lê as linhas restantes do arquivo, se baseando nesses tipos de dados identificados por ela. No relatório produzido pela função com as especificação de cada coluna (Column specification), podemos ver justamente qual foi o “chute” da função, ou qual o tipo de dado que a função utilizou para ler os dados de cada coluna.\nVeja no exemplo abaixo, que a função read_csv() interpretou que as colunas Título e Autor continham dados em texto e, por isso, utilizou colunas do tipo character (col_character()) para ler e armazenar esses dados. Por outro lado, a função percebeu que a coluna Preço continha dados numéricos e, por essa razão, preferiu utilizar uma coluna do tipo double (col_double()) para alocar esses dados na tabela.\n\nlivros &lt;- read_csv(\"C:/Users/Pedro/Documents/Lista de compras/livros.txt\")\n\n-- Column specification -----------------------\ncols(\n  Título = col_character(),\n  Autor = col_character(),\n  Preço = col_double()\n)\nIsso é uma característica importante e útil das funções read_*(), pois podemos contar na maioria das vezes com essa detecção automática da função. Porém, quanto maior for o tamanho de seu arquivo, mais frágil se torna esse sistema. Pois essas 1000 primeiras linhas começam a representar uma parte cada vez menor do arquivo e, portanto, as suas chances de demonstrarem fielmente os tipos de dados presentes em todo arquivo, ficam cada vez menores.\nPor isso, é provável que em algum momento, você terá de contornar esse comportamento padrão, e definir explicitamente os tipos de dados que você deseja utilizar para ler cada coluna de seu arquivo. Este controle é feito por meio do argumento col_types de qualquer função read_*(). Para construirmos essa definição, nós utilizamos a função cols() e suas variantes col_*(). Dentro da função cols(), precisamos igualar o nome da coluna presente no arquivo de texto à função col_*() que corresponde ao tipo de dado que desejamos utilizar nessa coluna.\nNo exemplo abaixo, ao igualar as colunas year, month e day à função col_integer(), eu estou definindo que essas colunas devem ser interpretadas como colunas do tipo integer. Ao mesmo tempo, ao igualar as colunas carrier e tailnum à função col_character(), eu estou requisitando que essas colunas sejam lidas como colunas do tipo character.\nPara mais, a função cols() nos oferece um atalho útil chamado .default. Mediante esse atalho, podemos nos referir a todas as colunas do arquivo de uma vez só. Por isso, no exemplo abaixo, ao igualar esse atalho à função col_double(), eu estou dizendo à função cols(), que qualquer outra coluna do arquivo que não tenha sido definida explicitamente na função cols(), deve ser interpretada como uma coluna do tipo double. Por este motivo, as colunas dep_time e dep_delay (e várias outras), que não foram configuradas explicitamente na função cols(), acabaram sendo interpretadas como colunas do tipo double.\n\ntipos_col &lt;- cols(\n  .default = col_double(),\n  year = col_integer(),\n  month = col_integer(),\n  day = col_integer(),\n  carrier = col_character(),\n  tailnum = col_character(),\n  origin = col_character(),\n  dest = col_character(),\n  time_hour = col_datetime(format = \"\")\n)\n\nflights &lt;- read_csv2(\n  \"flights.csv\",\n  col_types = tipos_col\n)\n\nflights\n\n\n\n# A tibble: 336,776 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n# ℹ 336,771 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;dbl&gt;, …\n\n\n\n\n4.7.2 Compreendendo o argumento locale\nO argumento locale está presente em todas as funções read_*(), e é responsável por definir as especificações do arquivo de texto que mudam de país para país. No Brasil, por exemplo, datas são definidas no formato “Dia/Mês/Ano”, enquanto nos EUA, datas se encontram no formato “Ano-Mês-Dia”. Além disso, no Brasil, utilizamos vírgulas para separar a parte decimal de um número, enquanto nos EUA, essa separação é definida por um ponto final. Uma diferença ainda mais importante, se encontra no sistema de encoding adotado, que varia de maneira muito violenta ao longo dos países.\nO R é uma linguagem centrada nos padrões americanos. Por isso, sempre que você estiver tentando ler algum arquivo de texto que não se encaixa de alguma forma neste padrão, você terá que ajustar o locale da função read_*() que você está utilizando. Algumas funções já preveem e adotam essas diferenças. Um exemplo disso, é a função read_csv2(), que é na verdade um atalho para o padrão de arquivo CSV adotado por nós brasileiros, e por alguns países europeus.\nComo exemplo inicial, vamos tentar ler o arquivo pib_per_capita.csv, que novamente se encontra dentro da pasta 6 - Importacao. Dessa vez, vamos utilizar a função geral do pacote, a read_delim(). Lembre-se que nessa função, você deve sempre indicar qual o caractere separador do arquivo, através do argumento delim.\n\npib &lt;- read_delim(\"Parte 1/6 - Importacao/pib_per_capita.csv\", delim = \";\")\npib\n\n## # A tibble: 853 x 7\n##  IBGE2   IBGE `Munic\\xedpio`        `Popula\\xe7\\xe3o`   Ano PIB\n##  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n## 1   10 310010 \"Abadia dos Dourados\"              6972  2017 33.389.769,00\n## 2   20 310020 \"Abaet\\xe9\"                       23223  2017 96.201.158,00\n## 3   30 310030 \"Abre Campo\"                      13465  2017 29.149.429,00\n## 4   40 310040 \"Acaiaca\"                          3994  2017 2.521.892,00\n## 5   50 310050 \"A\\xe7ucena\"                       9575  2017 15.250.077,00\n## # ... with 848 more rows, and 1 more variable: PIB per capita &lt;chr&gt;\nPerceba que algo deu errado acima durante a importação deste arquivo. Pois as colunas PIB e PIB per capita foram importadas como colunas de texto (character), sendo que elas são claramente colunas numéricas. Em momentos como esse, é interessante que você consulte as primeiras linhas do arquivo, para compreender melhor a sua estrutura e identificar o que deu errado.\nPor isso, temos logo abaixo, as três primeiras linhas do arquivo pib_per_capita.csv. Perceba que os dois últimos valores em cada linha, representam os dados das colunas PIB e PIB per capita. Ao olharmos, por exemplo, para o número 33.389.769,00 nós podemos identificar qual o problema que está ocorrendo em nossa importação.\n10;310010;Abadia dos Dourados;6972;2017;33.389.769,00;4.789,12\n20;310020;Abaeté;23223;2017;96.201.158,00;4.142,49\n30;310030;Abre Campo;13465;2017;29.149.429,00;2.164,83\nO motivo para tal conflito, se encontra justamente no uso do ponto final como separador de milhares, e da vírgula para marcar a parte decimal dos números dispostos nas colunas PIB e PIB_per_capita. Ou seja, como não informamos nada sobre as particularidades do arquivo, a função read_delim() está imaginando que o arquivo pib_per_capita.csv se encontra no padrão americano. Por isso, para que esse problema seja corrigido, nós precisamos avisar a função read_delim(), sobre essas particularidades de nosso arquivo.\nPara fornecer tais informações, utilizamos a função locale(), como no exemplo abaixo. No nosso caso, precisamos ajustar o caractere responsável por separar os milhares, e o caractere que separa a parte decimal dos nossos números, que correspondem aos argumentos grouping_mark e decimal_mark da função locale(), respectivamente. Perceba no exemplo abaixo, que após provermos essas informações à função read_delim() através da função locale(), as colunas PIB e PIB per capita foram corretamente interpretadas como colunas numéricas (double).\n\npib &lt;- read_delim(\n  \"Parte 1/6 - Importacao/pib_per_capita.csv\",\n  delim = \";\",\n  locale = locale(decimal_mark = \",\", grouping_mark = \".\")\n)\n\npib\n\n## # A tibble: 853 x 7\n##  IBGE2   IBGE `Munic\\xedpio`        `Popula\\xe7\\xe3o`   Ano      PIB\n##  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                             &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n## 1   10 310010 \"Abadia dos Dourados\"              6972  2017 33389769\n## 2   20 310020 \"Abaet\\xe9\"                       23223  2017 96201158\n## 3   30 310030 \"Abre Campo\"                      13465  2017 29149429\n## 4   40 310040 \"Acaiaca\"                          3994  2017  2521892\n## 5   50 310050 \"A\\xe7ucena\"                       9575  2017 15250077\n## # ... with 848 more rows, and 1 more variable: PIB per capita &lt;dbl&gt;\nApesar de resolvermos o problema gerado anteriormente nas colunas PIB e PIB per capita, ainda há algo que precisamos corrigir nessa importação. O problema remanescente, se encontra em colunas textuais e no título de algumas colunas. Perceba que alguns desses textos (especialmente em letras acentuadas) estão esquisitos. Por exemplo, a coluna que deveria se chamar Município está denominada como Munic\\xedpio.\nEsse é um típico problema de encoding, onde a função read_delim() imagina que o arquivo pib_per_capita.csv se encontra em um sistema de encoding específico, quando na verdade, ele se encontra em um outro sistema. Ou seja, tudo o que precisamos fazer, é informar qual o sistema correto de leitura do arquivo à função read_delim(). Por padrão, todas as funções do pacote readr vão pressupor que os seus arquivos se encontram no sistema UTF-8 de encoding. Porém, a enorme maioria dos computadores brasileiros utilizam um outro sistema, chamado de ISO-8859-1, que também é conhecido pelo termo “Latin1”.\nNas funções do pacote readr, nós podemos definir o encoding de leitura do arquivo, através do argumento encoding presente na função locale(). Nesse argumento, você pode fornecer tanto o nome oficial do sistema (ISO-8859-1) quanto o seu apelido (Latin1). Repare no exemplo abaixo, que ao definirmos o encoding correto de leitura, os problemas em elementos textuais foram resolvidos. Para ter uma melhor compreensão desse problema, por favor, leia a seção Encoding de caracteres.\n\npib &lt;- read_delim(\n  \"Parte 1/6 - Importacao/pib_per_capita.csv\",\n  delim = \";\",\n  locale = locale(\n    decimal_mark = \",\",\n    grouping_mark = \".\",\n    encoding = \"Latin1\"\n  )\n)\n\n\npib\n\n# A tibble: 853 × 7\n  IBGE2   IBGE Município           População   Ano      PIB `PIB per capita`\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;\n1    10 310010 Abadia dos Dourados      6972  2017 33389769            4789.\n2    20 310020 Abaeté                  23223  2017 96201158            4142.\n3    30 310030 Abre Campo              13465  2017 29149429            2165.\n4    40 310040 Acaiaca                  3994  2017  2521892             631.\n5    50 310050 Açucena                  9575  2017 15250077            1593.\n# ℹ 848 more rows\n\n\n\n\n4.7.3 Sobre o erro nchar(x, \"width\") : invalid multibyte string\nO exemplo do arquivo pib_per_capita.csv da seção anterior, é bastante útil, pois o arquivo possui três características distintas que não se encaixam no padrão americano de um CSV: 1) o arquivo é delimitado por pontos e vírgulas (;); 2) o arquivo utiliza pontos para separar os milhares, e vírgulas para separar a parte decimal de números; 3) o arquivo utiliza o encoding ISO-8859-1 ao invés do sistema UTF-8.\nPorém, em versões mais recentes do R e do pacote readr, o encoding do arquivo passou a ser uma configuração ainda mais importante durante o processo de importação. Como destacamos anteriormente, todas as funções read_*() do pacote readr, vão sempre ler os seus arquivos com o pressuposto de que eles utilizam o sistema UTF-8 de encoding.\nEm versões passadas, caso você tentasse ler um arquivo que estivesse em um encoding diferente do UTF-8, as funções read_*() leriam o arquivo normalmente. Devido à diferença entre o encoding do arquivo e o encoding utilizado pela função read_*(), certas palavras como \"Município\" seriam trocadas por \"Munic\\xedpio\". Ou seja, os comandos mostrados na seção anterior mostram como esse processo funcionava antigamente.\nContudo, em versões mais atuais do pacote readr, os comandos apresentados na seção anterior costumam resultar no erro nchar(x, \"width\") : invalid multibyte string. Tal erro, ocorre justamente pela diferença de encodings. Portanto, enquanto em versões mais antigas, as funções read_*() costumavam ser mais permissivas, hoje, nas versões mais atuais, essas funções costumam reclamar com maior facilidade caso o arquivo em questão não esteja utilizando o encoding UTF-8.\nSendo assim, mesmo que os códigos apresentados na seção anterior sejam um retrato do passado, eles ainda assim são bastante úteis para demonstrar como certas configurações de seu arquivo podem afetar o seu processo de importação para dentro do R.\nDe qualquer forma, caso você enfrente o erro nchar(x, \"width\") : invalid multibyte string ao utilizar uma das funções read_*(), tente definir o encoding correto do arquivo que você está tentando ler, com a função locale(). Por exemplo, o arquivo pib_per_capita.csv utiliza o sistema ISO-8859-1, logo, o comando para importar esse arquivo nos dias atuais seria:\n\n### Funciona em todas as versões:\npib &lt;- read_delim(\n  \"Parte 1/6 - Importacao/pib_per_capita.csv\",\n  delim = \";\",\n  locale = locale(\n    decimal_mark = \",\",\n    grouping_mark = \".\",\n    encoding = \"ISO-8859-1\"\n  )\n)\n\n\n\n4.7.4 Outras configurações envolvendo linhas e colunas\nNessa seção, vamos utilizar como exemplo base, o arquivo CSV que forma o objeto t abaixo. Perceba que esse arquivo utiliza pontos e vírgulas como separador, e que ele não possui cabeçalho aparente. Ou seja, aparentemente os nomes das colunas não estão definidos no arquivo.\n\nt &lt;- \"2020;P.A22;01;4230.45\n2020;B.34;02;1250.28\n2020;S.T4;03;3510.90\n2020;B.35;04;1200.25\n2020;F.J4;05;1542.20\n2020;A.12;06;9854.09\n2020;B.Q2;07;7654.10\n2020;G.T4;08;4328.36\n2020;E.7A;09;2310.25\"\n\nPor padrão, as funções read_*() utilizam a primeira linha do arquivo para construir o nome de cada coluna presente.\n\nread_delim(t, delim = \";\")\n\n# A tibble: 8 × 4\n  `2020` P.A22 `01`  `4230.45`\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n1   2020 B.34  02        1250.\n2   2020 S.T4  03        3511.\n3   2020 B.35  04        1200.\n4   2020 F.J4  05        1542.\n5   2020 A.12  06        9854.\n# ℹ 3 more rows\n\n\nMas se você deseja evitar esse comportamento, você pode configurar o argumento col_names para FALSE. Dessa forma, a função read_*() vai gerar nomes genéricos para cada coluna, como no exemplo abaixo:\n\nread_delim(t, delim = \";\", col_names = FALSE)\n\n# A tibble: 9 × 4\n     X1 X2    X3       X4\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1  2020 P.A22 01    4230.\n2  2020 B.34  02    1250.\n3  2020 S.T4  03    3511.\n4  2020 B.35  04    1200.\n5  2020 F.J4  05    1542.\n# ℹ 4 more rows\n\n\nUma outra alternativa é fornecer um vetor ao argumento col_names, contendo os nomes de cada coluna na ordem em que elas aparecem no arquivo, como no exemplo abaixo.\n\ncol &lt;- c(\"Ano\", \"Código\", \"Dia\", \"Valor\")\n\nread_delim(t, delim = \";\", col_names = col)\n\n# A tibble: 9 × 4\n    Ano Código Dia   Valor\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n1  2020 P.A22  01    4230.\n2  2020 B.34   02    1250.\n3  2020 S.T4   03    3511.\n4  2020 B.35   04    1200.\n5  2020 F.J4   05    1542.\n# ℹ 4 more rows\n\n\nAlém disso, as funções read_*() nos permite determinar o número máximo de linhas que desejamos ler de um arquivo, através do argumento n_max. Logo, mesmo que um arquivo de texto qualquer possua 500 mil linhas, nós podemos ler apenas as 10 primeiras linhas desse arquivo, ao configurarmos esse argumento. No exemplo abaixo, eu estou lendo apenas as 5 primeiras linhas do arquivo t.\n\nread_delim(t, delim = \";\", n_max = 5, col_names = col)\n\n# A tibble: 5 × 4\n    Ano Código Dia   Valor\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n1  2020 P.A22  01    4230.\n2  2020 B.34   02    1250.\n3  2020 S.T4   03    3511.\n4  2020 B.35   04    1200.\n5  2020 F.J4   05    1542.\n\n\nPara mais, também podemos indiretamente definir a linha pela qual a função deve iniciar a leitura, por meio do argumento skip. Nesse argumento, você vai determinar quantas linhas do início do arquivo devem ser desconsideradas pela função. Portanto, no exemplo abaixo, eu estou ignorando as 2 primeiras linhas do arquivo t.\n\nread_delim(t, delim = \";\", skip = 2, col_names = col)\n\n# A tibble: 7 × 4\n    Ano Código Dia   Valor\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n1  2020 S.T4   03    3511.\n2  2020 B.35   04    1200.\n3  2020 F.J4   05    1542.\n4  2020 A.12   06    9854.\n5  2020 B.Q2   07    7654.\n# ℹ 2 more rows",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#sec:estudo_pnad_continua",
    "href": "Capítulos/03-importacao.html#sec:estudo_pnad_continua",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "4.8 Um estudo de caso: lendo os microdados da PNAD Contínua com read_fwf()",
    "text": "4.8 Um estudo de caso: lendo os microdados da PNAD Contínua com read_fwf()\nA PNAD Contínua é uma pesquisa amostral, e vem sendo realizada desde janeiro de 2012 pelo Instituto Brasileiro de Geografia e Estatística (IBGE, 2019). Os principais indicadores periódicos do mercado de trabalho são extraídos dessa pesquisa, e por isso, ela representa uma das principais fontes de informação econômica e demográfica do país. Nessa seção, vamos utilizar as funções do pacote readr para importarmos os microdados da divulgação trimestral dessa pesquisa para o R.\nVocê pode encontrar os microdados da PNAD Contínua Trimestral, na página oficial da pesquisa1. Para que você possa acompanhar os comandos mostrados nessa seção, lembre-se de chamar pelo pacote readr, ou pelo tidyverse (que contém o pacote readr), através do comando library().\n\nlibrary(readr)\nlibrary(tidyverse)\n\n\n4.8.1 Conhecendo a estrutura dos microdados\nComo um exemplo inicial, eu fui até a página oficial da pesquisa2, e baixei os microdados do primeiro trimestre de 2020. O arquivo veio compactado (.zip), e por isso, eu o descompactei para que tivéssemos acesso ao arquivo bruto que contém os microdados, mostrado na Figura 4.4.\n\n\n\n\n\n\n\n\nFigura 4.4: Arquivo contendo os microdados da PNAD Contínua - 1° Trimestre de 2020\n\n\n\n\n\nComo podemos ver pela Figura 4.4, o arquivo é um simples arquivo de texto (extensão .txt), e todas as funções de importação do pacote readr são capazes de ler este tipo de arquivo. Porém, ainda temos que identificar como os valores estão organizados dentro desse documento de texto. Será que os valores de cada coluna são separados por vírgulas (.csv)? por ponto e vírgula (.csv)? por tabulação (.tsv)?\nPara respondermos a essas questões, podemos dar uma olhada nas 5 primeiras linhas do arquivo. Para isso, vou usar a função read_lines() do pacote readr. Em resumo, essa função simplesmente lê as linhas do arquivo, da forma como elas estão, e encaixa este conteúdo dentro de um vetor do tipo character. Lembre-se que as funções do pacote readr geralmente possuem um argumento n_max, onde podemos configurar o número máximo de linhas a serem lidas do arquivo.\nAgora, a primeira coisa que podemos abstrair do resultado abaixo, é que o arquivo de texto parece uma muralha de números, e aparentemente não se encaixa em nenhuma das hipóteses anteriores.\n\nread_lines(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n  n_max = 5\n)\n\n## [1] \"202011111  11000001611100110107511000098.75663631000139.734222300005349~\"\n## [2] \"202011111  11000001611100110107511000098.75663631000139.734222300005349~\"\n## [3] \"202011111  11000001611100110107511000098.75663631000139.734222300005349~\"\n## [4] \"202011111  11000001611100110107511000098.75663631000139.734222300005349~\"\n## [5] \"202011111  11000001611100110307511000098.75663631000139.734222300005349~\"\n## [6] \"202011111  11000001611100110307511000098.75663631000139.734222300005349~\"\nEsse é um exemplo de arquivo chamado de fixed width file (.fwf), ou “arquivo de largura fixa”. Provavelmente, o principal motivo pelo qual o IBGE decidiu adotar esse formato de arquivo na divulgação de seus dados, está no fato de que arquivos desse tipo são muito mais rápidos de se ler, do que um arquivo CSV tradicional. Pois os valores de cada coluna em um arquivo fixed width file, se encontram sempre nos mesmos lugares ao longo de todo o arquivo. Em contrapartida, esse tipo de arquivo, torna a sua vida mais difícil, pois você precisa especificar a largura, ou o número de caracteres presentes em cada coluna, para a função que será responsável por ler esse arquivo.\nOu seja, nesse tipo arquivo, não há qualquer tipo de valor ou especificação responsável por delimitar as colunas da base de dados. O arquivo simplesmente contém todos os valores, um do lado do outro. Será sua tarefa, dizer ao programa (no nosso caso, o R) quantos caracteres estão presentes em cada coluna, ou em outras palavras, definir em quais caracteres estão as “quebras” de colunas.\nIsso significa que você irá precisar de um dicionário desses dados, contendo as especificações de cada coluna dessa base de dados. No caso da PNAD Contínua, são oferecidos: 1) o dicionário das variáveis (geralmente em uma planilha do Excel, com extensão .xls), que contém uma descrição completa de cada variável (ou coluna) presente na base; 2) e o arquivo de texto input, que contém as especificações para a importação da base.\nEsses arquivos geralmente estão disponíveis através de um ZIP (Dicionario_input.zip) que fica na seção de “Documentação” na página oficial da pesquisa3. Logo abaixo, na Figura 4.5, temos uma foto desses arquivos em meu computador.\n\n\n\n\n\n\n\n\nFigura 4.5: Arquivos input e dicionário da PNAD Contínua\n\n\n\n\n\nEntretanto, para surpresa de muitos, o arquivo de texto input (que geralmente assume o nome de input_PNADC_trimestral.txt), é na verdade, um script de importação utilizado pelo programa estatístico SAS4. O SAS é um programa estatístico pago, parecido com o seu concorrente SPSS5. Ambos os programas são mais populares no mercado americano. Logo, se você estivesse trabalhando com o programa SAS, você já teria um script pronto para importar os microdados da PNAD Contínua. Como não é o nosso caso, temos que extrair, a partir desse script de SAS, as especificações de cada coluna.\n\n\n4.8.2 Extraindo especificações de um script SAS\nComo veremos mais a frente, extrair as especificações desse script é uma tarefa simples, e existem hoje, diversas ferramentas que podemos utilizar para rapidamente extrairmos essas informações do script, sem a necessidade de um trabalho manual. Porém, antes de partirmos para a prática, precisamos primeiro, compreender a estrutura do script de SAS, presente nesse arquivo input (input_PNADC_trimestral). Na Figura 4.6, temos um resumo que descreve essa estrutura.\nO script, ou mais especificamente, os comandos que definem a importação dos dados, se inicia pelo termo input, logo, estamos interessados em todas as configurações feitas após esse termo. As especificações de cada coluna, são compostas por 3 itens principais: 1) a posição inicial dessa coluna (ou a posição do caractere que inicia essa coluna); 2) o nome dessa coluna; e 3) a largura dessa coluna, ou em outras palavras, a quantidade de caracteres presentes em cada linha dessa coluna. Para o nosso objetivo, precisamos extrair os dois últimos componentes (o nome e a largura da coluna), além de definirmos se essa coluna é numérica ou textual, que é determinado pela presença ou não de um cifrão ($) ao lado da largura da coluna, no script.\n\n\n\n\n\n\n\n\nFigura 4.6: Resumo da estrutura de um script de importação do SAS\n\n\n\n\n\nNa minha visão, a melhor forma de importarmos essas especificações para dentro do R, seria transformar esse script inicial de SAS que temos, em um arquivo CSV. Poderíamos fazer essa transformação de diferentes formas. Por exemplo, você poderia usar qualquer programa que oferece uma ferramenta de Find/Replace para remover os caracteres que não te interessam nesse arquivo, e deixar apenas aqueles que te interessam. Uma outra alternativa, seria usar o próprio R em conjunto com um pouco de REGEX (para mais detalhes sobre REGEX, veja o capítulo Manipulação e transformação de strings com stringr).\nO código abaixo é um exemplo do que você poderia fazer para importar e transformar esse arquivo input de modo a extrair as específicações das colunas.\n\nlibrary(tidyverse)\ninput_file &lt;- read_file(\"input.txt\")\ninput_file &lt;- unlist(str_split(input_file, \"\\n\"))\ninput_pos &lt;- str_which(input_file, \"input\")\ncolumns &lt;- input_file[(input_pos + 1L):length(input_file)]\ncolumns &lt;- separate_wider_delim(\n  tibble(specs = columns),\n  cols = \"specs\",\n  names = c(\"start_pos\", \"name\", \"width\"),\n  delim = \" \"\n)\n\ncolumns &lt;- columns %&gt;% \n  mutate(\n    is_character = str_detect(width, \"[$]\"),\n    width = parse_number(width),\n    start_pos = parse_number(start_pos)\n  )\n\nAlém disso, a título de comparação, você pode importar diretamente essas especificações para dentro do R, ao construir um arquivo CSV com essas especificações. Como exemplo, com o código abaixo você pode baixar um CSV com tais especificações:\n\nlibrary(readr)\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo &lt;- \"input_PNADC.txt\"\ninput &lt;- read_csv(\n  paste0(github, pasta, arquivo),\n  col_names = c(\"name\", \"width\", \"is_numeric\")\n)\n\nEnfim, após extrair as especificações de cada coluna do arquivo input, eu tenho como resultado, o objeto columns. Veja pelo resultado abaixo, que eu defini 3 colunas na tabela armazenada neste objeto. A coluna name possui os nomes da colunas, na ordem em que elas aparecem no script do arquivo input, e portanto, nos microdados. A coluna width possui o número de caracteres presentes em cada uma dessas colunas. Já a coluna is_character, possui um valor lógico, indicando se os dados contidos nessa coluna, devem ser interpretados como texto (TRUE), ou como números (FALSE).\n\ncolumns &lt;- read_csv(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/widths.txt\", \n  col_names = c(\"name\", \"width\", \"is_character\")\n)\ncolumns \n\n## # A tibble: 217 x 3\n##    variavel  width char \n##    &lt;chr&gt;     &lt;dbl&gt; &lt;lgl&gt;\n##  1 Ano           4 TRUE \n##  2 Trimestre     1 TRUE \n##  3 UF            2 TRUE \n##  4 Capital       2 TRUE \n##  5 RM_RIDE       2 TRUE \n## # ... with 212 more rows\n\n\n4.8.3 Importando os microdados da PNAD Contínua\nAgora que possuímos as especificações necessárias de cada coluna, podemos começar o processo de importação dos microdados da PNAD Contínua. Como esses microdados estão estruturados em um arquivo de texto do tipo fixed width file (.fwf), podemos utilizar a função read_fwf() para ler este arquivo. Pois como o próprio nome dessa função dá a entender, ela é especializada nesse tipo de arquivo.\nO primeiro argumento (file) dessa função, é o caminho até o arquivo a ser importado. Já o segundo argumento (col_positions), será o local onde vamos fornecer as especificações de cada coluna. Entretanto, nós precisamos utilizar uma função como a fwf_widths(), para definirmos essas especificações no argumento col_positions. Na função fwf_widths() temos apenas dois argumentos, que são widths e col_names. Basta fornecermos ao argumento widths, as larguras de cada coluna, e ao argumento col_names, os nomes de cada coluna, como no exemplo abaixo.\n\npnad_continua &lt;- read_fwf(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n  col_positions = fwf_widths(columns$width, col_names = columns$name)\n)\n\n## Warning: 156486 parsing failures.\n## row  col               expected actual   file\n## 1670 V40431  1/0/T/F/TRUE/FALSE 2        'C:/Users/Pedro/Downloads/PNADC~'\n## 2194 V4057   1/0/T/F/TRUE/FALSE 2        'C:/Users/Pedro/Downloads/PNADC_~'\n## 2194 V405811 1/0/T/F/TRUE/FALSE 3        'C:/Users/Pedro/Downloads/PNADC~'\n## 2194 V405812 1/0/T/F/TRUE/FALSE 00001200 'C:/Users/Pedro/Downloads/PNADC~'\n## 2194 V405912 1/0/T/F/TRUE/FALSE 00000000 'C:/Users/Pedro/Downloads/PNADC~'\n## .... ....... .................. ........ .........................\n## See problems(...) for more details.\nComo podemos ver acima, pela mensagem de parsing failures, obtivemos alguns problemas durante a importação. Isso ocorre, pois a função read_fwf() está tendo que adivinhar sozinha, quais são os tipos de dados contidos em cada coluna dos microdados. Lembre-se que por padrão, se não fornecemos uma descrição dos tipos de dados de cada coluna a qualquer função do pacote readr, essas funções vão automaticamente ler as 1000 primeiras linhas de cada coluna, e se basear nesses 1000 valores para determinar o tipo de dado incluso em cada coluna do arquivo.\nEsse sistema automático, apesar de útil, se torna frágil a medida em que o tamanho da nossa base cresce. Pois essas 1000 linhas vão representar uma parte cada vez menor da base, e, portanto, podem não ser suficientes para determinar com precisão o tipo de dado contido em cada coluna. No nosso exemplo, a base da PNAD possui 487 mil linhas, logo, essas 1000 linhas representam apenas 0,2% da base. Se a função não está sendo capaz de adivinhar corretamente, os tipos de dados de cada coluna, nós precisamos dizer a ela exatamente quais são esses tipos. Para isso, vamos utilizar os dados contidos na coluna is_character da nossa tabela columns.\nAs funções de importação do pacote readr, possuem o argumento col_types, onde podemos definir os tipos de cada coluna. Essa definição pode ser fornecida, utilizando-se a função cols(). Porém, para o nosso caso, creio que será mais prático, utilizarmos um método alternativo que o argumento col_types disponibiliza. Esse método alternativo, consiste em fornecermos um vetor de letras, contendo a primeira letra de cada tipo. Essas letras devem estar na ordem em que as colunas aparecem em seus dados. Logo, se eu fornecer o vetor \"ccdlcdd\", a função irá interpretar a primeira e a segunda coluna como dados do tipo character, enquanto a terceira e a quarta coluna serão interpretadas como dados dos tipos double e logical, respectivamente.\nPrimeiro, precisamos construir esse vetor de letras, que indicam o tipo de cada coluna. Com os dados da nossa tabela columns, nós já sabemos que todo valor TRUE na coluna char, indica uma coluna de texto, e, portanto, essa coluna deve ser interpretada como uma coluna do tipo character. Já os valores FALSE indicam uma coluna numérica, e por isso, essa coluna deve ser interpretada como uma coluna do tipo double. Com isso, podemos utilizar a função ifelse(), para construírmos um vetor inicial de letras, baseado nos valores da coluna char. Em seguida, podemos juntar todas essas letras em um string só, com a função paste().\n\ntipos &lt;- ifelse(columns$is_character == TRUE, \"c\", \"d\")\ntipos &lt;- paste(tipos, collapse = \"\")\ntipos\n\n[1] \"ccccccccccccdddcdccccccdcccccccccccccccccccccccccccccccccccccccccccc\ncccccccccccccccccccccccccccdccdcccccdccdddcdddccccccccccccdccdcccccdccddd\nccccdccdccccccdcddcccccccccccccdddcccccdcccccccccccccccccccddcddccdddddcc\"\nAgora com o vetor tipos, podemos fornecê-lo ao argumento col_types e realizar novamente o processo de importação, com os tipos das colunas sendo corretamente interpretados. Porém, repare que mesmo definindo os tipos das colunas, obtivemos novamente erros durante o processo de importação. Dessa vez, foram mais de 2 milhões de erros. Isso não significa necessariamente que o nosso processo de importação esteja incorretamente especificado. Porém, nós deveríamos pelo menos compreender o porquê esses erros ocorrem.\n\npnad_continua &lt;- read_fwf(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n  col_positions = fwf_widths(columns$width, col_names = columns$name), \n  col_types = tipos\n)\n\n## Warning: 2032039 parsing failures.\n## row    col expected actual                                              file\n##   1 VD4032 a double      . 'C:/Users/Pedro/Downloads/PNADC_012020/PNADC_01~'\n##   1 VD4033 a double      . 'C:/Users/Pedro/Downloads/PNADC_012020/PNADC_01~'\n##   1 VD4034 a double      . 'C:/Users/Pedro/Downloads/PNADC_012020/PNADC_01~'\n##   2 VD4031 a double      . 'C:/Users/Pedro/Downloads/PNADC_012020/PNADC_01~'\n##   2 VD4032 a double      . 'C:/Users/Pedro/Downloads/PNADC_012020/PNADC_01~'\n## ... ...... ........ ...... ................................................\n## See problems(...) for more details.\n\n\n4.8.4 Analisando erros de importação\nNós podemos obter através da função problems(), uma tabela contendo todos os erros que ocorreram durante esse processo de importação. Precisamos apenas fornecer a essa função, os comandos que geraram esses problemas, como no exemplo abaixo.\n\nproblemas &lt;- problems(\n  read_fwf(\n    \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n    col_positions = fwf_widths(columns$width, col_names = columns$name), \n    col_types = tipos\n  )\n)\n\nproblemas\n\n## # A tibble: 2,032,039 x 5\n##      row col    expected   actual file\n##    &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;        \n##  1     1 VD4032 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  2     1 VD4033 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  3     1 VD4034 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  4     2 VD4031 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  5     2 VD4032 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n## # ... with 2,032,034 more rows\nPelo que podemos ver da coluna actual, parece que os erros estão ocorrendo, pela presença de um ponto final (“.”), nos locais em que deveriam estar números (double). Podemos utilizar a função unique() sobre a coluna actual para identificarmos se há algum outro problema que precisamos analisar. Pelo resultado abaixo, percebemos que todos os mais de 2 milhões de erros gerados, estão sendo causados por essa presença de pontos finais na base. Também podemos utilizar a função unique() sobre a coluna col, para descobrirmos em quais colunas esse erro ocorre. Vemos abaixo, que esses erros estão concentrados em cinco das últimas colunas de toda a base (obs. a última coluna da base é VD4037).\n\nunique(problemas$actual)\n\n## [1] \".\"\n\nunique(problemas$col)\n\n## [1] \"VD4032\" \"VD4033\" \"VD4034\" \"VD4031\" \"VD4035\"\nSeria uma boa ideia, olharmos mais de perto como essas colunas aparecem no arquivo de microdaddos. Para determinarmos a parte do arquivo que diz respeito a essas colunas, precisamos descobrir o intervalo de caracteres que cobrem essas colunas, através dos dados da tabela columns. Para isso, vamos precisar descobrir o número total de caracteres em cada linha (ou em outras palavras, a largura total da base), ao somarmos a largura de todas as colunas na tabela columns. Ao longo do caminho, teremos que subtrair uma faixa desse total, para descobrirmos o caractere que inicia o intervalo de colunas que estamos interessados.\n\n(total_caracteres &lt;- sum(columns$width))\n\n[1] 464\n\n\nEm seguida, podemos aplicar a função tail() sobre a tabela columns, para extrairmos as últimas linhas dessa tabela, e verificarmos as especificações das colunas que cobrem essa faixa. Pois nós sabemos que as variáveis que geraram problemas na importação, estão entre as últimas colunas dos microdados, logo, as especificações dessas colunas vão se encontrar nas últimas linhas da tabela columns. Vemos abaixo, que as duas últimas colunas da base (VD4036 e VD4037), das quais não estamos interessados, possuem juntas, 2 caracteres de largura. Portanto, o intervalo que cobre as colunas que geraram os problemas na importação (VD4031-VD4035), termina no 462° caractere, como vemos abaixo. Pelo resultado de tail(), vemos que as colunas das quais estamos interessados (VD4031-VD4035), somam 15 caracteres de largura. Tendo isso em mente, o intervalo que cobre essas colunas, se inicia no 448° caractere.\n\ntail(columns, 7)\n\n# A tibble: 7 × 3\n  name   width is_character\n  &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt;       \n1 VD4031     3 FALSE       \n2 VD4032     3 FALSE       \n3 VD4033     3 FALSE       \n4 VD4034     3 FALSE       \n5 VD4035     3 FALSE       \n# ℹ 2 more rows\n\n(fim_intervalo &lt;- total_caracteres - 2)\n\n[1] 462\n\n(inicio_intervalo &lt;- fim_intervalo - 15 + 1)\n\n[1] 448\n\n\nPortanto, nós temos agora a posição dos caracteres que iniciam e terminam o intervalo de caracteres que dizem respeito as colunas que estamos interessados. Porém, ainda precisamos calcular os caracteres de início e de fim de cada uma das cinco colunas (VD4031-VD4035), que cobrem esse intervalor. Para esse trabalho, podemos aplicar um pouco de aritmética simples, como a aplicada pelo código abaixo.\n\n(inicio &lt;- (0:4 * 3) + inicio_intervalo)\n\n[1] 448 451 454 457 460\n\n(fim &lt;- (1:5 * 3) + inicio_intervalo - 1)\n\n[1] 450 453 456 459 462\n\n\nAgora que nós temos as posições dos caracteres que iniciam e que terminam cada uma das cinco colunas, podemos importar apenas essas cinco colunas ao R. Para isso, podemos usar novamente a função read_fwf(), aliada à função fwf_positions(). Ou seja, utilizamos anteriormente a função fwf_widths() para determinarmos as especificações de todas as colunas da base. Porém, como nós queremos importar apenas uma parte dessa base, vamos utilizar a função fwf_positions() para determinarmos as especificações dessas colunas desejadas.\nNa função fwf_positions(), temos três argumentos principais: 1) start, um vetor contendo as posições dos caracteres que iniciam cada coluna; 2) end, um vetor contendo as posições dos caracteres que terminam cada coluna; 3) col_names, um vetor contendo os nomes dessas colunas selecionadas. Tendo esses argumentos em mente, podemos importar as cinco colunas da seguinte maneira:\n\ncolunas &lt;- c(\"VD4031\",\"VD4032\",\"VD4033\",\"VD4034\",\"VD4035\")\nconferir &lt;- read_fwf(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n  col_positions = fwf_positions(\n    start = inicio,\n    end = fim,\n    col_names = colunas\n  )\n)\n\nLogo abaixo, temos o resultado do intervalo que selecionamos do arquivo, em que podemos ver o grupo de pontos finais que estão causando o problema. Agora, temos que identificar o motivo desses pontos estarem aí. Se nós retornarmos às especificações dessas colunas apresentadas na tabela columns, nós sabemos que essas colunas são colunas numéricas. Será que esses pontos estão aí, para marcar as casas decimais dos números dessa coluna?\nTalvez não seja esse o caso. Pois se esses pontos estivessem de fato, marcando as casas decimais, porque eles não aparecem na primeira linha das colunas VD4031 e VD4035? Isto é, por que o valor 040 que aparece nessas colunas, não se apresenta como 0.40, ou 04.0, ou 40.0 na tabela conferir? Lembre-se que esses valores da tabela conferir são apresentados exatamente da forma como eles estam escritos no arquivo dos microdados. Pois todas as colunas estão sendo interpretadas como character.\n\nconferir\n\n## # A tibble: 487,937 x 5\n##    VD4031 VD4032 VD4033 VD4034 VD4035\n##    &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; \n##  1 040    .      .      .      040   \n##  2 .      .      .      .      .     \n##  3 .      .      .      .      .     \n##  4 .      .      .      .      .     \n##  5 .      .      .      .      .     \n## # ... with 487,932 more rows\nPela visão que temos até o momento, parece que as colunas VD4032, VD4033 e VD4034, estão vazias, no sentido de que elas estão preenchidas apenas por pontos finais, em toda a sua extensão. Talvez seja o momento de verificarmos essa hipótese. Podemos fazer isso, novamente por meio da função unique(). Pelos resultados abaixo, as colunas VD4032, VD4033 e VD4034 estão de fato vazias. Com isso, temos a seguinte questão: por que uma coluna numérica está preenchida com pontos? Se esses pontos não estão marcando as casas decimais em cada linha, é mais provável que esses pontos estejam ali simplesmente para marcar um valor vazio, ou uma observação que não pôde ser mensurada.\n\nunique(conferir$VD4032)\n\n## [1] \".\"\n\nunique(conferir$VD4033)\n\n## [1] \".\"\n\nunique(conferir$VD4034)\n\n## [1] \".\"\nEm resumo, nós sabemos pelas especificações das colunas presentes no arquivo input, que as colunas VD4032, VD4033 e VD4034 devem ser interpretadas como colunas numéricas. Ao que tudo indica, esses pontos não possuem o propósito de delimitar as casas decimais. Seria apropriado encontrarmos alguma documentação que nos pudesse guiar sobre esses questionamentos. Porém, até onde pesquisei, não há qualquer menção a esses pontos ao longo da documentação do IBGE sobre esses microdados. Com as informações que possuímos, só podemos inferir que esses valores estão servindo para marcar valores não-disponíveis (em outras palavras, estão cumprindo o papel de um valor NA) nessas colunas.\nTendo essas considerações em mente, todos esses pontos presentes nessas colunas, devido ao erro que eles incorrem durante o processo de importação, serão convertidos para valores NA ao importarmos a base, e, portanto, vão representar observações não-disponíveis na base. Ou seja, se a função read_fwf() não consegue interpretar corretamente um valor, ele acaba sendo convertido para um valor NA.\n\npnad_continua &lt;- read_fwf(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n  col_positions = fwf_widths(columns$width, col_names = columns$name), \n  col_types = tipos\n)",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#exportando-os-seus-dados-com-o-pacote-readr",
    "href": "Capítulos/03-importacao.html#exportando-os-seus-dados-com-o-pacote-readr",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "4.9 Exportando os seus dados com o pacote readr",
    "text": "4.9 Exportando os seus dados com o pacote readr\nPara além de importar os seus dados para dentro do R, haverá um momento em que você vai precisar exportar os seus resultados para fora do R, de modo que você possa enviá-los para os seus colegas de trabalho ou para utilizá-los em outros programas. Em um momento como esse, você deseja escrever um arquivo estático em seu computador, contendo esses resultados. O pacote readr oferece funções que permitem a escrita de um conjunto de arquivos de texto. Logo abaixo, temos uma lista relacionando os tipos de arquivos de texto às respectivas funções do pacote:\n\nwrite_csv2(): constrói um arquivo CSV, segundo o padrão adotado por alguns países europeus; utilizando pontos e vírgulas (;) como separador.\nwrite_csv(): constrói um arquivo CSV, segundo o padrão americano; utilizando vírgulas (,) como separador.\nwrite_tsv(): constrói um arquivo TSV.\nwrite_delim(): função geral onde você pode definir o caractere a ser utilizado como separador no arquivo de texto construído.\n\nUm fator muito importante sobre o pacote readr em geral, é que todas as suas funções utilizam o encoding UTF-8 o tempo todo. Logo, ao utilizar essas funções para exportar os seus dados, lembre-se sempre que os arquivos construídos por essas funções vão estar utilizando o encoding UTF-8. Isso significa que ao utilizar esses arquivos em outros programas como o Excel, você precisa informar ao programa para utilizar o encoding UTF-8 ao ler o arquivo.\nPara além disso, você não terá nenhum outro problema com esses arquivos. Porém, caso você se sinta incomodado com esse comportamento, você pode utilizar as variantes dessas funções presentes nos pacotes básicos do R (write.csv2(), write.csv(), write.table()). Pois essas funções variantes vão escrever o arquivo definido, de acordo com o encoding padrão de seu sistema.\nO primeiro argumento (x) dessas funções, se trata do nome do objeto em sua sessão que contém os dados que você deseja exportar. Já no segundo argumento (file) dessas funções, você deve definir o nome do novo arquivo estático que será construído. Por exemplo, se eu possuo uma tabela chamada transf, e desejo salvá-la em um arquivo chamado transf.csv, eu preciso executar o seguinte comando:\n\nwrite_csv2(transf, file = \"transf.csv\")\n\nApós executar os comandos acima, você irá encontrar na pasta que representa o seu diretório de trabalho atual no R, um novo arquivo chamado transf.csv que contém os seus dados. Vale destacar, que você pode salvar esse novo arquivo em diferentes áreas de seu computador. Basta que você forneça um endereço (absoluto ou relativo) até a pasta desejada, em conjunto com o nome do novo arquivo. Como exemplo, eu posso salvar a tabela Censo_2010 dentro da minha área de trabalho da seguinte forma:\n\nwrite_csv2(Censo_2010, file = \"C:/Users/Pedro/Desktop/Censo_2010.csv\")",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#sec:read_excel",
    "href": "Capítulos/03-importacao.html#sec:read_excel",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "4.10 Importando planilhas do Excel com readxl",
    "text": "4.10 Importando planilhas do Excel com readxl\nO Excel continua sendo um dos programas mais populares no mundo e, por essa razão, muitas pessoas ainda o utilizam para analisar dados e gerar gráficos. Tendo isso em vista, nessa seção, vamos aprender como podemos importar para o R, dados que se encontram em planilhas do Excel (.xlsx), através da função read_excel() que pertence ao pacote readxl.\nVale destacar que, nessa seção, vamos mostrar apenas como ler (ou importar) os dados armazenados em planilhas de Excel no R. Porém, em um capítulo posterior, mais especificamente na seção Um estudo de caso: exportando múltiplas planilhas de Excel, vamos mostrar quais são os pacotes e funções do R disponíveis hoje para escrever (ou exportar os seus dados para) uma planilha de Excel.\nO principal argumento da função read_excel() corresponde novamente ao endereço até o arquivo que você deseja ler, ou apenas o seu nome caso esse arquivo se encontre em seu diretório de trabalho atual.\n\nlibrary(readxl)\ncodigos &lt;- read_excel(\"codigos.xlsx\")\n\n\ncodigos\n\n# A tibble: 853 × 4\n   IBGE1 IBGE2   SEF Municípios         \n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;              \n1 310010    10     1 ABADIA DOS DOURADOS\n2 310020    20     2 ABAETÉ             \n3 310030    30     3 ABRE CAMPO         \n4 310040    40     4 ACAIACA            \n5 310050    50     5 AÇUCENA            \n# ℹ 848 more rows\n\n\n\n4.10.1 Delimitando a parte de seu arquivo .xlsx\nUm único arquivo .xlsx pode conter várias planilhas, ou várias abas (sheet’s) diferentes. Por padrão, a função read_excel() sempre lê a primeira planilha de seu arquivo .xlsx. Porém, você pode ler diferentes planilhas de seu arquivo por meio do argumento sheet. Somos capazes de selecionar a planilha desejada de acordo com a sua ordem (1, 2, 3, …), ou de acordo com o nome dado à aba que a contém.\n\n## Lê a terceira planilha do arquivo\nread_excel(\"datasets.xlsx\", sheet = 3)\n\n\n\n# A tibble: 71 × 2\n  weight feed     \n   &lt;dbl&gt; &lt;chr&gt;    \n1    179 horsebean\n2    160 horsebean\n3    136 horsebean\n4    227 horsebean\n5    217 horsebean\n# ℹ 66 more rows\n\n\n\n## Lê a planilha presente na aba denominada mtcars\nread_excel(\"datasets.xlsx\", sheet = \"mtcars\")\n\n\n\n# A tibble: 32 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  21       6   160   110  3.9   2.62  16.5     0     1     4     4\n2  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n4  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1\n5  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2\n# ℹ 27 more rows\n\n\nAlém dessas configurações, conseguimos delimitar o intervalo de células a serem lidas pela função, através do argumento range. Podemos fornecer esse intervalo em dois estilos diferentes. Nós podemos utilizar o sistema tradicional do Excel (CL:CL), como no exemplo abaixo, em que estamos lendo da célula A1 à célula C150 através da notação A1:C150.\n\nread_excel(\"datasets.xlsx\", range = \"A1:C150\")\n\n\n\n# A tibble: 149 × 3\n  Sepal.Length Sepal.Width Petal.Length\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1          5.1         3.5          1.4\n2          4.9         3            1.4\n3          4.7         3.2          1.3\n4          4.6         3.1          1.5\n5          5           3.6          1.4\n# ℹ 144 more rows\n\n\nUma outra possibilidade é utilizarmos as funções cell_cols() e cell_rows() que limitam o intervalo para apenas uma das dimensões da planilha. Ou seja, nós empregamos a função cell_cols(), quando desejamos ler todas as linhas, e, apenas algumas colunas da planilha. Enquanto com a função cell_rows(), desejamos ler todas as colunas da tabela, porém, queremos extrair apenas uma parte das linhas.\nAs colunas de uma planilha do Excel, são identificadas por uma letra ou por um conjunto de letras (ex: A; E; F; BC). Por isso, ao utilizar a função cell_cols() você pode delimitar as colunas a serem lidas de duas formas: 1) utilizando a notação do Excel (C:C), com as letras que representam as colunas desejadas; 2) ou através de um vetor numérico que representa a ordem das colunas, e contém o intervalo desejado.\n\n## Da coluna A até a coluna C\nread_excel(\"datasets.xlsx\", range = cell_cols(\"A:C\"))\n## Da 1° até a 3° coluna\nread_excel(\"datasets.xlsx\", range = cell_cols(1:3))\n\nPor outro lado, para delimitarmos o intervalo de linhas em cell_rows() precisamos apenas fornecer um vetor de dois elementos, contendo os limites superior e inferior do intervalo, ou então, uma sequência que cobre esses limites.\n\n## Da 1° até a 140° linha\nread_excel(\"datasets.xlsx\", range = cell_rows(1:140))\n## Da 10° até a 400° linha\nread_excel(\"datasets.xlsx\", range = cell_rows(c(10, 400)))\n\nO argumento range é tão flexível que nós podemos utilizá-lo para executar o trabalho do argumento sheet. Isto é, além do intervalo de células, nós também podemos selecionar a aba do arquivo .xlsx a ser lida pela função, através do argumento range. No Excel, quando você está utilizando em sua planilha, algum valor que é proveniente de uma outra planilha do mesmo arquivo .xlsx, o Excel cria uma referência até esse valor. Essa referência possui o nome da planilha em conjunto com a referência da célula onde o valor se encontra, separados por um ponto de exclamação (!). Logo, se eu quisesse ler da célula A1 até a célula C150, da planilha denominada mtcars, do arquivo datasets.xlsx, eu precisaria criar a seguinte referência no argumento range:\n\nread_excel(\"datasets.xlsx\", range = \"mtcars!A1:C150\") \n\n\n\n# A tibble: 149 × 3\n    mpg   cyl  disp\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  21       6   160\n2  21       6   160\n3  22.8     4   108\n4  21.4     6   258\n5  18.7     8   360\n# ℹ 144 more rows\n\n\nApesar de sua flexibilidade, o argumento range pressupõe que você conheça exatamente as células que compõe os limites de sua tabela, ou então, que você pelo menos tenha uma boa compreensão de onde eles se encontram. Por isso, você também possui na função read_excel() os argumentos skip e n_max, que funcionam exatamente da mesma forma empregada pelas funções do pacote readr. Logo, esses argumentos representam uma alternativa menos flexível, mas, talvez sejam mais ideais para as suas necessidades, especialmente se você deseja apenas pular algumas linhas de metadados que se encontram no início de sua planilha.\n\nread_excel(\"datasets.xlsx\", sheet = 2, n_max = 50, skip = 10, col_names = FALSE) \n\n## # A tibble: 23 x 11\n##     ...1  ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 ...10 ...11\n##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n##  1  19.2     6 168.    123  3.92  3.44  18.3     1     0     4     4\n##  2  17.8     6 168.    123  3.92  3.44  18.9     1     0     4     4\n##  3  16.4     8 276.    180  3.07  4.07  17.4     0     0     3     3\n##  4  17.3     8 276.    180  3.07  3.73  17.6     0     0     3     3\n##  5  15.2     8 276.    180  3.07  3.78  18       0     0     3     3\n##  6  10.4     8 472     205  2.93  5.25  18.0     0     0     3     4\n##  7  10.4     8 460     215  3     5.42  17.8     0     0     3     4\n##  8  14.7     8 440     230  3.23  5.34  17.4     0     0     3     4\n##  9  32.4     4  78.7    66  4.08  2.2   19.5     1     1     4     1\n## 10  30.4     4  75.7    52  4.93  1.62  18.5     1     1     4     2\n## # ... with 13 more rows\n\n\n4.10.2 Definindo os tipos de dados contidos em cada coluna\nPor padrão, a função read_excel() vai automaticamente decifrar os tipos de dados contidos em cada coluna. Porém, diferentemente das funções do pacote readr, que constroem essa suposição com base nos dados em si do arquivo, a função read_excel() adivinha os dados contidos em cada coluna, com base nos tipos associados a cada célula da planilha. Ou seja, se as células de uma coluna estão associadas ao tipo Texto, essa coluna será transformada no R em uma coluna do tipo character.\nPelo fato do Excel tratar cada célula de forma individual, você possui uma liberdade muito grande no programa. Por exemplo, você pode misturar dados de diferentes tipos em uma mesma coluna, ou em uma mesma linha de uma planilha do Excel. Porém, essa liberdade tem o seu preço. Um programa que trata as suas células dessa maneira, gera uma estrutura inconsistente em seus dados. Esse fato é importante, pois você tem um trabalho muito maior ao replicar cálculos em sua tabela. Com uma estrutura inconsistente, você precisa pensar não apenas em quais tipos estão associados a cada coluna de sua tabela, mas também, em quais tipos estão associados a cada célula de cada coluna. As chances de erros serem gerados durante o processo, são bem maiores.\nPortanto, o sistema que a função read_excel() adota, está de acordo com essa característica. Pois se diversas células em uma mesma coluna possuírem tipos diferentes associados a elas, a função será capaz de reconhecer essa inconsistência, e agir adequadamente. Nós sabemos que o R leva muito a sério a consistência de seus dados, especialmente se tratando de vetores com suas regras de coerção e, por isso, tal liberdade presente em programas como o Excel, representam um desafio para a importação de dados provenientes dessa plataforma.\nNo R, há duas maneiras principais de lidarmos com essa possível inconsistência de uma planilha do Excel. Uma está no uso do tipo character, pois esse é o tipo de dado mais flexível de todos e, portanto, consegue guardar qualquer outro tipo de dado. Outra está na adoção de listas para qualquer coluna que apresente essa inconstância.\nPortanto, em toda coluna que possui dados de diferentes tipos em suas células, a função read_excel() vai geralmente transformar essa coluna, em uma coluna do tipo character. Veja no exemplo abaixo, mais especificamente, na coluna value que contém ao menos três tipos de dados diferentes.\n\nread_excel(readxl_example(\"clippy.xlsx\"))\n\n# A tibble: 4 × 2\n  name                 value    \n  &lt;chr&gt;                &lt;chr&gt;    \n1 Name                 Clippy   \n2 Species              paperclip\n3 Approx date of death 39083    \n4 Weight in grams      0.9      \n\n\nComo destacamos, uma outra alternativa, seria transformarmos essa coluna em uma lista. Dessa forma, nós podemos incluir qualquer tipo de dado em cada elemento dessa lista (ou em cada “célula” dessa coluna). Porém, teremos que pedir explicitamente a função read_excel() que realize esse tipo de transformação, através do argumento col_types.\nPortanto, em todas as ocasiões que você precisar evitar que a função read_excel() decifre os tipos os tipos de cada coluna, você pode definir de forma explícita esses tipos no argumento col_types. Você precisa apenas fornecer um vetor a esse argumento, contendo rótulos que representam os tipos de cada coluna na ordem em que elas aparecem na planilha. Os rótulos possíveis nesse argumento são : \"skip\", \"guess\", \"logical\", \"numeric\", \"date\", \"text\" e \"list\".\n\nread_excel(readxl_example(\"clippy.xlsx\"), col_types = c(\"text\", \"list\"))\n\n# A tibble: 4 × 2\n  name                 value     \n  &lt;chr&gt;                &lt;list&gt;    \n1 Name                 &lt;chr [1]&gt; \n2 Species              &lt;chr [1]&gt; \n3 Approx date of death &lt;dttm [1]&gt;\n4 Weight in grams      &lt;dbl [1]&gt;",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#importando-arquivos-do-spss-stata-e-sas-com-o-pacote-haven",
    "href": "Capítulos/03-importacao.html#importando-arquivos-do-spss-stata-e-sas-com-o-pacote-haven",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "4.11 Importando arquivos do SPSS, Stata e SAS com o pacote haven",
    "text": "4.11 Importando arquivos do SPSS, Stata e SAS com o pacote haven\nApesar de serem programas mais populares em mercados específicos, especialmente o mercado americano, algumas pessoas no Brasil ainda utilizam programas como o Stata para produzirem as suas pesquisas. Por isso, nessa seção, vamos utilizar as funções do pacote haven, com o objetivo de importarmos dados que estejam presentes em arquivos produzidos por um desses três programas: SPSS (.sav, .zsav, .por), Stata (.dta) e SAS (.sas7bdat, .sas7bcat). Logo abaixo, temos uma lista relacionando as funções do pacote com os respectivos formatos de arquivo.\n\nread_dta() - Stata (.dta).\nread_spss() - SPSS (.sav, .zsav, .por).\nread_sas() - SAS (.sas7bdat, .sas7bcat).\n\nAssim como as funções de importações vistas até o momento, o primeiro argumento das três funções acima, se trata do endereço ou do nome do arquivo (caso ele se encontre em seu diretório de trabalho atual) que você deseja ler.\n\nread_spss(\"survey.sav\")\n\nread_sas(\"survey.sas7bdat\")\n\nread_dta(\"pnad_2015.dta\")\n\n\n4.11.1 Tratando variáveis rotuladas\nOs programas SPSS, SAS e Stata permitem, e muitas vezes utilizam, um sistema de rótulos sobre seus valores. O uso desses rótulos é especialmente comum em colunas que representam variáveis qualitativas (cor, sexo, faixa etária, etc.). Nessas colunas, os dados são representados por valores numéricos, porém, esses valores são rotulados com um valor textual que corresponde a faixa, ou a categoria a qual aquele valor numérico corresponde.\nComo exemplo, veja a tabela abaixo, ou mais especificamente, as colunas sex, marital e child. Perceba que essas três colunas, estão sendo tratadas como colunas do tipo double + labelled (dbl + lbl). Ou seja, os dados presentes nessas colunas, são dados numéricos (double). Porém, certos rótulos (labelled) estão associados a cada um desses valores. Por exemplo, todo valor igual a 1 na coluna child, indica que a pessoa entrevistada naquela linha é responsável por alguma criança (YES), enquanto todo valor igual a 2, representa uma pessoa que não possui uma criança sobre a sua tutela (NO).\n\npesquisa &lt;- read_spss(\"survey.sav\")\n\npesquisa\n\n\n\n# A tibble: 439 × 9\n     id sex           age marital       child   educ    source  smoke   smokenum\n  &lt;dbl&gt; &lt;dbl+lbl&gt;   &lt;dbl&gt; &lt;dbl+lbl&gt;     &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+l&gt;    &lt;dbl&gt;\n1   415 2 [FEMALES]    24 4 [MARRIED F… 1 [YES] 5 [COM… 7 [LIF… 2 [NO]        NA\n2     9 1 [MALES]      39 3 [LIVING WI… 1 [YES] 5 [COM… 1 [WOR… 1 [YES]        2\n3   425 2 [FEMALES]    48 4 [MARRIED F… 1 [YES] 2 [SOM… 4 [CHI… 2 [NO]        NA\n4   307 1 [MALES]      41 5 [REMARRIED] 1 [YES] 2 [SOM… 1 [WOR… 2 [NO]         0\n5   440 1 [MALES]      23 1 [SINGLE]    2 [NO]  5 [COM… 1 [WOR… 2 [NO]         0\n# ℹ 434 more rows\n\n\nToda coluna que estiver rotulada no arquivo, será importada dessa maneira para o R, criando um tipo misto. Porém, após a importação dos dados, o ideal é que você sempre transforme essas colunas “mistas” para o tipo factor, pois esse tipo de dado apresenta um suporte muito melhor ao longo da linguagem R. Tal transformação pode ser facilmente gerada através da função as_factor(), que provêm do pacote forcats.\n\nlibrary(forcats)\n\npesquisa &lt;- as_factor(pesquisa)\n\npesquisa\n\n# A tibble: 439 × 9\n     id sex       age marital             child educ       source smoke smokenum\n  &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;fct&gt;               &lt;fct&gt; &lt;fct&gt;      &lt;fct&gt;  &lt;fct&gt;    &lt;dbl&gt;\n1   415 FEMALES    24 MARRIED FIRST TIME  YES   COMPLETED… LIFE … NO          NA\n2     9 MALES      39 LIVING WITH PARTNER YES   COMPLETED… WORK   YES          2\n3   425 FEMALES    48 MARRIED FIRST TIME  YES   SOME SECO… CHILD… NO          NA\n4   307 MALES      41 REMARRIED           YES   SOME SECO… WORK   NO           0\n5   440 MALES      23 SINGLE              NO    COMPLETED… WORK   NO           0\n# ℹ 434 more rows\n\n\n\n\n4.11.2 Delimitando partes do arquivo\nTodas as três funções do pacote haven possuem os argumentos skip e n_max, que novamente, funcionam da mesma forma que é empregado pelas funções do pacote readr. Portanto, o argumento skip e n_max definem o número de linhas a serem ignoradas no início do arquivo, e o número máximo de linhas do arquivo a serem lidas, respectivamente.\n\nread_spss(\"survey.sav\", skip = 5)\n\n\n\n# A tibble: 434 × 9\n     id sex           age marital      child   educ    source   smoke   smokenum\n  &lt;dbl&gt; &lt;dbl+lbl&gt;   &lt;dbl&gt; &lt;dbl+lbl&gt;    &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt;    &lt;dbl&gt;\n1   484 2 [FEMALES]    31 4 [MARRIED … 1 [YES] 5 [COM…  7 [LIF… 2 [NO]        NA\n2   341 2 [FEMALES]    30 6 [SEPARATE… 2 [NO]  4 [SOM…  8 [MON… 2 [NO]         0\n3   300 1 [MALES]      23 2 [STEADY R… 2 [NO]  5 [COM…  1 [WOR… 1 [YES]      100\n4    61 2 [FEMALES]    18 2 [STEADY R… 2 [NO]  2 [SOM…  2 [SPO… 1 [YES]       40\n5    24 1 [MALES]      23 1 [SINGLE]   2 [NO]  6 [POS… NA       2 [NO]         0\n# ℹ 429 more rows\n\n\n\nread_spss(\"survey.sav\", n_max = 10)\n\n\n\n# A tibble: 10 × 9\n     id sex           age marital       child   educ    source  smoke   smokenum\n  &lt;dbl&gt; &lt;dbl+lbl&gt;   &lt;dbl&gt; &lt;dbl+lbl&gt;     &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+l&gt;    &lt;dbl&gt;\n1   415 2 [FEMALES]    24 4 [MARRIED F… 1 [YES] 5 [COM… 7 [LIF… 2 [NO]        NA\n2     9 1 [MALES]      39 3 [LIVING WI… 1 [YES] 5 [COM… 1 [WOR… 1 [YES]        2\n3   425 2 [FEMALES]    48 4 [MARRIED F… 1 [YES] 2 [SOM… 4 [CHI… 2 [NO]        NA\n4   307 1 [MALES]      41 5 [REMARRIED] 1 [YES] 2 [SOM… 1 [WOR… 2 [NO]         0\n5   440 1 [MALES]      23 1 [SINGLE]    2 [NO]  5 [COM… 1 [WOR… 2 [NO]         0\n# ℹ 5 more rows\n\n\nAlém dessas opções, as funções também oferecem o argumento col_select, pelo qual você pode definir quais colunas do arquivo devem ser importadas. Esse recurso é particularmente interessante quando você possui um arquivo muito grande, como os microdados da PNAD contínua, e você deseja utilizar apenas algumas colunas, ou apenas algumas variáveis da pesquisa. Para selecionar colunas no argumento col_select, você pode fornecer um vetor contendo os nomes das colunas desejadas, porém, uma outra alternativa mais útil é utilizar um vetor de índices que representam a ordem das colunas desejadas.\n\nread_spss(\"survey_complete.sav\", col_select = 45:52)\n\n\n\n# A tibble: 439 × 8\n  lifsat3 lifsat4 lifsat5  pss1  pss2  pss3  pss4  pss5\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1       5       4       3     3     3     4     3     4\n2       5       7       5     2     2     3     5     4\n3       7       6       6     1     2     2     4     4\n4       7       7       6     4     3     5     5     4\n5       4       3       3     2     2     3     2     3\n# ℹ 434 more rows\n\n\n\nread_dta(\"pnad_2015.dta\", col_select = c(\"uf\", \"v0102\", \"v0103\", \"cor\", \"sexo\"))\n\n\n\n# A tibble: 164,204 × 5\n     uf    v0102 v0103 cor        sexo         \n  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;    \n1    31 31001718    14 8 [parda]  1 [masculino]\n2    15 15003760     1 8 [parda]  1 [masculino]\n3    35 35002425     8 2 [branca] 1 [masculino]\n4    43 43000126    15 4 [preta]  0 [feminino] \n5    33 33001812    18 8 [parda]  1 [masculino]\n# ℹ 164,199 more rows",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#sec:encoding",
    "href": "Capítulos/03-importacao.html#sec:encoding",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "4.12 Encoding de caracteres",
    "text": "4.12 Encoding de caracteres\nQuando nós estamos trabalhando com dados em um computador, estamos lidando com registros digitalizados de informação, e esses registros quase sempre contêm letras e palavras, ou simplesmente, variáveis textuais (strings ou caracteres). Dados geográficos, por exemplo, usualmente vem acompanhado de certas informações textuais, como partes de um endereço (cidade, região, rua, etc.), que dão suporte à identificação e localização de certa informação. Como um outro exemplo, dados de uma pesquisa amostral comumente possuem variáveis qualitativas que funcionam como rótulos, e que categorizam cada pessoa entrevistada em um certo grupo (homem ou mulher; branco, pardo, preto, amarelo ou indígena; etc.).\nEm uma escala microscópica, as informações presentes em um computador são armazenadas como bytes de informação, que por sua vez são formados por bits de informação, que nada mais são do que combinações específicas de 0’s e 1’s. Com esse fato, eu quero destacar que os nossos computadores não são capazes de guardar diretamente letras, palavras e outros valores textuais. Na verdade, o que os nossos computadores são capazes de guardar, são os códigos binários que em conjunto formam os bytes de informação que representam cada uma das letras, ou cada um dos caracteres que formam a sua palavra, o seu parágrafo ou o seu capítulo. Como exemplo, o nome “Belo Horizonte”, é representado em meu computador através da seguinte sequência de bytes:\n\ncharToRaw(\"Belo Horizonte\")\n\n [1] 42 65 6c 6f 20 48 6f 72 69 7a 6f 6e 74 65\n\n\nCada um dos bytes acima, representam uma letra, e para que o seu computador seja capaz de relacionar cada um desses bytes às respectivas letras que eles representam, ele utiliza um sistema que nós chamamos de encoding. É possível que o sistema operacional de seu computador utilize um sistema de encoding diferente do meu. Com isso, os bytes que representam o nome “Belo Horizonte” em seu computador, podem ser diferentes dos bytes acima.\n\n4.12.1 Um pouco sobre fontes, encoding e tipografia\nPara apresentar visualmente em sua tela, uma palavra ou um texto, o seu computador precisa relacionar caracteres (characters) com os seus respectivos glyphs (HARALAMBOUS, 2007). Uma fonte que se encontra em seu computador, representa um conjunto de glyphs. Um glyph é uma imagem ou um desenho de cada letra que está definida dentro dessa fonte. Quando você está, por exemplo, escrevendo um novo documento no Word, e você aperta a tecla “A”, um caractere (que corresponde a letra A) é enviado para o seu computador. Após o seu computador descobrir o glyph da fonte que você está utilizando, que corresponde ao caractere A, o Word vai desenhar a palavra A em seu documento, através do glyph que corresponde a esse caractere (HARALAMBOUS, 2007).\nOu seja, quando as letras A e A aparecem em sua tela, elas representam o mesmo caractere, mas utilizam diferentes glyphs para serem desenhadas na tela de seu computador, pois ambos os caracteres utilizam fontes diferentes. Por um outro ângulo, nós podemos escrever uma frase de mesmo significado em diferentes línguas, porém, muito provavelmente vamos utilizar diferentes caracteres em cada língua. Por exemplo, ao escrevermos “Olá”, “Hello”, “Bonjour” ou “你好”, estamos dizendo a mesma coisa, porém, estamos utilizando caracteres ou letras bem diferentes para tal ato.\nPortanto, quando importamos os nossos dados para dentro do R, qualquer informação ou variável textual que esteja presente nesses dados, são guardadas em nosso computador como bytes de informação; e o sistema que o nosso computador utiliza, para traduzir esses bytes de informação, em caracteres, que futuramente serão renderizados em nossa tela, através dos glyphs que os representa, é chamado de encoding (HARALAMBOUS, 2007).\nOs primeiros sistemas de encoding eram capazes de representar apenas as letras de línguas anglo-saxônicas. Porém, a medida em que os chineses precisavam escrever um relatório em sua língua, ou a partir do momento em que o povo nórdico precisava representar em seus computadores os diferentes acentos presentes em seu alfabeto, diversos outros sistemas de encoding foram sendo desenvolvidos ao longo do tempo. Por isso, nós temos hoje uma miscelânia muito grande de sistemas em uso no mundo. Sendo essa confusão, a principal motivação por trás do desenvolvimento do sistema Unicode, que busca universalizar todos esses sistemas em um só (HARALAMBOUS, 2007).\n\n\n4.12.2 Problemas que emergem do encoding\nPor que esse assunto é importante dentro da leitura e escrita de arquivos? Porque diferentes arquivos podem utilizar diferentes sistemas de encoding, e se quisermos trabalhar corretamente com os dados textuais presentes nesses arquivos, nós devemos interpretá-los através do sistema de encoding correto.\nQuando você lê um arquivo de acordo com um sistema de encoding diferente do sistema que o arquivo de fato utiliza, uma troca de caracteres (ou de letras) ocorre. Com isso, os textos presentes em seu arquivo, ou no nosso caso, em nossos dados, podem ficar bem estapafúrdios. Devido a essa troca de caracteres, há grandes chances de que uma simples pesquisa por algum caractere específico, fique prejudicada.\nComo exemplo, eu possuo abaixo um vetor t contendo algumas palavras. Ao utilizar a função grep() para pesquisar por qualquer palavra que contenha a letra “Á”. Como resultado, a função nos retorna o número 1, indicando que o primeiro elemento do vetor (a palavra “Árabe”) possui essa letra.\n\nt &lt;- c(\"Árabe\", \"Francês\" ,\"Japonês\", \"Chinês\")\n\ngrep(\"Á\", x = t)\n\n[1] 1\n\n\nAgora, se eu pedir ao R, que interprete o vetor t segundo um encoding diferente, perceba que a função grep() não é mais capaz de encontrar uma palavra que contenha a letra “Á”.\n\nEncoding(t) &lt;- \"UTF-8\"\n\nt\n\n[1] \"Árabe\"   \"Francês\" \"Japonês\" \"Chinês\" \n\ngrep(\"Á\", x = t)\n\n[1] 1\n\n\nNa hipótese de você abrir um arquivo e estar utilizando o encoding incorreto, desde de que você não salve esse arquivo, você não vai corrompê-lo. Em resumo, se algum caractere de seu texto não estiver da forma como você esperava, não salve o seu arquivo! Antes, você precisa ajustar o encoding de leitura do arquivo, até o momento em que a leitura dos textos presentes em seu arquivo esteja correta.\nApenas para que esse problema fique claro, vamos pegar como exemplo, o arquivo livros.txt, que utiliza o sistema de encoding UTF-8.\n\nlivros &lt;- read_csv(\"livros.txt\")\n\nlivros\n\n# A tibble: 4 x 3\n  Titulo                             Autor                       Preco\n  &lt;chr&gt;                              &lt;chr&gt;                       &lt;dbl&gt;\n1 O Hobbit                           J. R. R. Tolkien             40.7\n2 Matemática para Economistas        Carl P. Simon e Lawrence B~ 140. \n3 Microeconomia: uma Abordagem Mode~ Hal R. Varian               141. \n4 A Luneta Âmbar                     Philip Pullman               42.9\nAgora, veja abaixo o que acontece se utilizarmos o encoding errado na leitura do arquivo. Alguns sistemas de encoding são relativamente próximos e, por isso, menos trocas tendem a ocorrer em seus textos quando utilizamos o encoding errado. Porém, alguns sistemas são muito divergentes e, portanto, os seus textos podem ficar bem bizarros. Perceba abaixo, que ao utilizarmos o encoding Latin1, apenas as letras acentuadas foram trocadas.\n\nlivros &lt;- read_csv(\"livros.txt\", locale = locale(encoding = \"Latin1\"))\n\nlivros\n\n# A tibble: 4 x 3\n  Titulo                              Autor                      Preco\n  &lt;chr&gt;                               &lt;chr&gt;                      &lt;dbl&gt;\n1 \"O Hobbit\"                          J. R. R. Tolkien            40.7\n2 \"MatemÃ¡tica para Economistas\"      Carl P. Simon e Lawrence ~ 140. \n3 \"Microeconomia: uma Abordagem Mode~ Hal R. Varian              141. \n4 \"A Luneta Ã\\u0082mbar\"              Philip Pullman              42.9\nPortanto, tudo o que precisamos fazer aqui, é voltar para o encoding correto de leitura, ao ajustar o valor utilizado no argumento encoding de locale(), como vimos na seção Compreendendo o argumento locale. Em geral, no Brasil se utiliza o sistema ISO-8859-1, ou simplesmente Latin1. Já as funções do pacote readr utilizam por padrão, o sistema UTF-8, por isso, você terá de ajustar o encoding de leitura com certa frequência.\n\n\n4.12.3 A função guess_encoding() como um possível guia\nNem sempre temos a sorte de sabermos o encoding utilizado por um certo arquivo. Por isso, o pacote readr oferece a função guess_encoding(), que pode descobrir o encoding utilizado por certo arquivo.\nComo foi destacado por (WICKHAM; GROLEMUND, 2017, pp. 133), essa função funciona melhor quando você possui uma quantidade grande de texto no qual ela pode se basear. Além disso, ela não é certeira 100% do tempo, porém, ela lhe oferece um início razoável caso você esteja perdido.\nPara utilizar essa função, você deve fornecer o caminho até o arquivo que você deseja investigar. Repare no exemplo abaixo, que a função nos deu 61% de chance do arquivo Cod_IBGE.txt estar utilizando o encoding ISO-8859-1, que é de fato o encoding utilizado pelo arquivo.\n\nguess_encoding(\"./../Dados/Cod_IBGE.txt\")\n\n# A tibble: 2 × 2\n  encoding   confidence\n  &lt;chr&gt;           &lt;dbl&gt;\n1 ISO-8859-1       0.61\n2 ISO-8859-2       0.33\n\n\n\n\nHARALAMBOUS, Y. Fonts & Encodings. Sebastopol, CA: O’Reilly Media, Inc., 2007.\n\n\nIBGE. Pesquisa Nacional por Amostra de Domicílios Contínua: Notas Técnicas. Rio de Janeiro: Instituto Brasileiro de Geografia e Estatística, 2019.\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/03-importacao.html#footnotes",
    "href": "Capítulos/03-importacao.html#footnotes",
    "title": "4  Importando e exportando dados com readr, readxl e haven",
    "section": "",
    "text": "https://www.ibge.gov.br/estatisticas/sociais/trabalho/9171-pesquisa-nacional-por-amostra-de-domicilios-continua-mensal.html?=&t=microdados↩︎\nhttps://www.ibge.gov.br/estatisticas/sociais/trabalho/9171-pesquisa-nacional-por-amostra-de-domicilios-continua-mensal.html?=&t=microdados↩︎\nhttps://www.ibge.gov.br/estatisticas/sociais/trabalho/9171-pesquisa-nacional-por-amostra-de-domicilios-continua-mensal.html?=&t=microdados↩︎\nhttps://www.sas.com/en_us/home.html↩︎\nhttps://www.ibm.com/products/spss-statistics↩︎",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Importando e exportando dados com `readr`, `readxl` e `haven`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html",
    "href": "Capítulos/04-transformacao.html",
    "title": "5  Transformando dados com dplyr",
    "section": "",
    "text": "5.1 Introdução e pré-requisitos\nSão raras as ocasiões em que os seus dados já se encontram no formato exato que você precisa para realizar as suas análises, ou para gerar os gráficos que você deseja (WICKHAM; GROLEMUND, 2017). Por essa razão, você irá passar uma parte considerável de seu tempo calculando novas variáveis e aplicando transformações sobre os seus dados. Pelo fato de seus dados estarem, na maioria das situações, alocados em um data.frame, ou em um tibble, você precisa de ferramentas que sejam eficientes com tais estruturas (PENG, 2015). Esse é o objetivo do pacote dplyr com o qual vamos trabalhar neste capítulo.\nPara que você tenha acesso as funções e possa acompanhar os exemplos desse capítulo, você precisa chamar pelo pacote dplyr. Porém, vamos utilizar algumas bases de dados que estão disponíveis através de outros pacotes presentes no tidyverse. Por isso, é preferível que você chame pelo tidyverse por meio do comando library().\nlibrary(tidyverse)\nlibrary(dplyr)",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#panorama-e-padrões-do-pacote-dplyr",
    "href": "Capítulos/04-transformacao.html#panorama-e-padrões-do-pacote-dplyr",
    "title": "5  Transformando dados com dplyr",
    "section": "5.2 Panorama e padrões do pacote dplyr",
    "text": "5.2 Panorama e padrões do pacote dplyr\nSegundo a página oficial1, o pacote dplyr oferece um conjunto de “verbos” (i.e. funções) para as operações mais comumente aplicadas em tabelas. Ou seja, as funções desse pacote em geral aceitam um data.frame como input, e retornam um novo data.frame como output. Dito de forma menos técnica, você fornece uma tabela para essas funções, e elas lhe retornam como resultado uma nova tabela.\nSe você possui alguma experiência com relational database management systems (RDBMS), você vai acabar percebendo ao longo deste capítulo, que o pacote dplyr é profundamente inspirado nos verbos da linguagem SQL. Por esse motivo, muitos usuários tendem a chamar as funções do pacote dplyr de “verbos”. Logo abaixo, temos uma lista das principais funções oferecidas pelo pacote, além de uma descrição rápida da ação realizada por cada um desses verbos.\n\nselect(): busca selecionar ou extrair colunas de seu data.frame.\nfilter(): busca filtrar linhas de seu data.frame.\narrange(): busca ordenar (ou organizar) as linhas de seu data.frame.\nmutate(): busca adicionar ou calcular novas colunas em seu data.frame.\nsummarise(): busca sintetizar múltiplos valores de seu data.frame em um único valor.\ngroup_by(): permite que as operações sejam executadas dentro de cada “grupo” de seu data.frame; em outras palavras, a função busca definir os grupos existentes em seu data.frame, e deixar essa definição explícita e disponível para os outros verbos, de modo que eles possam respeitar esses grupos em suas operações.\n\nDentre os verbos acima, o group_by() é definitivamente o mais difícil de se explicar de uma maneira clara e, ao mesmo tempo, resumida. De qualquer maneira, vamos discutir ele por extenso na seção Agrupando dados com group_by() e gerando estatísticas sumárias com summarise(). Além disso, também vamos abordar nesse capítulo, o uso do operador pipe (%&gt;%) que provêm do pacote magrittr, e que hoje, faz parte da identidade do pacote dplyr, e do tidyverse como um todo.\nPENG (2015) destacou algumas características compartilhadas pelas funções do pacote dplyr:\n\nPossuem como primeiro argumento (.data), o data.frame no qual você deseja aplicar a função que você está utilizando.\nOs argumentos subsequentes buscam descrever como e onde aplicar a função sobre o data.frame definido no primeiro argumento.\nGeram um novo data.frame como resultado.\nComo você definiu o data.frame a ser utilizando no primeiro argumento da função, você pode se referir às colunas desse data.frame apenas pelo seus nomes. Ou seja, dentro das funções do pacote dplyr, você não precisa mais do operador $ para acessar as colunas do data.frame utilizado.\n\nNo momento, essas características podem parecer confusas. Porém, você irá rapidamente reconhecê-las ao longo deste capítulo.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#operador-pipe-do-pacote-magrittr",
    "href": "Capítulos/04-transformacao.html#operador-pipe-do-pacote-magrittr",
    "title": "5  Transformando dados com dplyr",
    "section": "5.3 Operador pipe do pacote magrittr (%>%)",
    "text": "5.3 Operador pipe do pacote magrittr (%&gt;%)\nHoje, o operador pipe (%&gt;%) faz parte da identidade dos pacotes que compõe o tidyverse. Por esse motivo, você vai encontrar esse operador em praticamente todos os script que utilizam algum desses pacotes. Grande parte dessa identidade foi construída nos últimos anos, em especial, com a obra de WICKHAM; GROLEMUND (2017) que se tornou um importante livro-texto da linguagem R como um todo.\nO operador pipe provêm do pacote magrittr, e o seu único objetivo é tornar o seu código mais claro e compreensível. Ou seja, o pipe em nada altera o resultado ou as configurações de seus comandos, ele apenas os organiza em uma estrutura mais limpa e arranjada. Apesar de sua origem ser o pacote magrittr, o pipe é carregado automaticamente quando chamamos pelo tidyverse, através do comando library(). Com isso, temos duas opções para termos acesso a esse operador: chamar diretamente pelo pacote magrittr, ou chamar pelo tidyverse.\n\n## Com um desses comandos você\n## pode utilizar o operador %&gt;% \nlibrary(tidyverse)\n## Ou\nlibrary(magrittr)\n\nATALHO: No RStudio, você pode escrever um pipe usando o atalho Ctrl + Shift + M.\nOrganizar o seu código é algo de extrema importância, e o pipe te ajuda a cumprir essa missão. Além disso, a estrutura em “cadeia” construída pelo pipe gera uma grande economia em seu tempo de trabalho, pois você não precisa mais se preocupar em salvar o resultado de vários passos intermediários em algum objeto.\nDessa maneira, você pode focar uma parte maior de seu tempo nas ações e transformações que você deseja aplicar, e no resultado que você deseja atingir. Para mais, essa estrutura também vai salvar muito de seu tempo, nos momentos em que você retornar ao seu trabalho no dia seguinte. Pois o seu código fica mais claro e fácil de se ler nessa estrutura. Com isso, você pode recuperar com maior rapidez a compreensão do ponto em que você parou no dia anterior.\nIsso é muito importante, pois você nunca está trabalhando sozinho! Você sempre está, no mínimo, trabalhando com o seu futuro eu (WICKHAM; GROLEMUND, 2017). Por isso, qualquer quantidade de tempo que você emprega para tornar os seus comandos mais legíveis e eficientes, você estará automaticamente economizando o seu tempo no dia seguinte, quando você terá de retornar a esses comandos, e prosseguir com o seu trabalho.\nPara mais, os seus possíveis colegas de trabalho, ou outras pessoas que estiverem envolvidas no desenvolvimento de seu script, vão compreender de maneira mais eficiente as transformações que você está aplicando e, portanto, vão ser capazes de contribuir com o seu trabalho de maneira mais rápida.\n\n5.3.1 O que o pipe faz ?\nEm qualquer análise, temos em geral diversas etapas ou transformações a serem executadas, e em sua maioria, essas etapas assumem uma ordem específica. Quando realizamos essas etapas no R, nós comumente salvamos os resultados de cada passo em novos objetos, e utilizamos esses objetos “intermediários” em cada operação adicional para chegarmos ao resultado final que desejamos. Perceba no exemplo abaixo, o trabalho que temos ao salvarmos os resultados de cada passo em um objeto, e utilizarmos esse objeto na próxima transformação.\n\ndados &lt;- mpg\nagrupamento &lt;- group_by(.data = dados, class)\nbase_ordenada &lt;- arrange(.data = agrupamento, hwy)\nbase_completa &lt;- mutate(\n  .data = base_ordenada,\n  media = mean(hwy),\n  desvio = hwy - media\n)\n\nAqui se encontra uma vantagem muito importante do operador pipe, pois ele elimina essa necessidade de objetos “intermediários”, ao “carregar” os resultados ao longo de diversas funções. Em outras palavras, esse operador funciona como uma ponte (ou uma “conexão”) entre cada etapa, ou entre cada função aplicada. Dito de uma maneira mais específica, quando conectamos duas funções por um pipe, o operador carrega o resultado da primeira função, e o insere como o primeiro argumento da segunda função. Com isso, eu posso reescrever os comandos anteriores da seguinte forma:\n\nmpg %&gt;% \n  group_by(class) %&gt;% \n  arrange(hwy) %&gt;% \n  mutate(\n    media = mean(hwy),\n    desvio = hwy - media\n  )\n\nAlém das vantagens destacadas até o momento, ao evitar o uso de objetos “intermediários”, o pipe acaba evitando que você use desnecessariamente a memória de seu computador. Pois cada objeto criado no R, precisa ocupar um espaço de sua memória RAM para permanecer “vivo” e disponível em sua sessão. Como estamos evitando criar novos objetos “intermediários”, estamos utilizando menos memória para realizar exatamente as mesmas etapas e gerar os mesmos resultados.\nApenas para que o uso do pipe fique claro, se eu possuo as funções x(), y() e z(), e desejo calcular a expressão z(y(x(10), times = 1), n = 20, replace = TRUE), nós podemos reescrever essa expressão do modo exposto abaixo. Dessa maneira, o pipe vai pegar o resultado de x(10), e inseri-lo como o primeiro argumento da função y(); depois de calcular o resultado da função y(), o próximo pipe vai passá-lo para o primeiro argumento da função z(); e como a função z() é a última função da cadeia, o console vai lhe mostrar o resultado final desse processo.\n\n## Expressão original\nz(y(x(10), times = 1), n = 20, replace = TRUE)\n## Com o uso do pipe %&gt;% \nx(10) %&gt;% \n  y(times = 1) %&gt;% \n  z(n = 20, replace = TRUE)\n\n\n\n5.3.2 O que o pipe não é capaz de fazer ?\nO pipe não é capaz de trabalhar perfeitamente com qualquer função, e a principal característica que você precisa observar para identificar se essa afirmação é verdadeira ou falsa para uma dada função, é o seu primeiro argumento.\nComo o pipe insere o resultado da expressão anterior no primeiro argumento da próxima função, esse primeiro argumento precisa corresponder ao argumento no qual você deseja utilizar esse resultado. Na maior parte do tempo, desejamos utilizar esse resultado como os dados sobre os quais vamos aplicar a nossa próxima função.\nEste é um dos principais motivos pelos quais praticamente todas as funções de todos os pacotes que compõe o tidyverse, trabalham perfeitamente bem com o operador pipe. Pois todas essas funções possuem como primeiro argumento, algo parecido com .data, data ou x, que busca definir o objeto sobre o qual vamos aplicar a função.\nPorém, caso o argumento a ser utilizado, esteja em uma posição diferente (se trata do segundo, terceiro ou quarto argumento da função), você pode utilizar um ponto final (.) para alterar a posição em que o resultado das etapas anteriores será introduzido. Basta posicionar o ponto final no argumento em que você deseja inserir esse resultado.\nUm clássico exemplo que se encaixa nessa hipótese, é a função lm(), que é a principal função empregada no cálculo de uma regressão linear no R. Nessa função, o primeiro argumento corresponde a fórmula a ser utilizada na regressão; já os dados a serem usados na regressão, são delimitados no segundo argumento da função (data). Veja no exemplo abaixo, que eu utilizo um ponto final sobre o argumento data, para dizer ao pipe que ele deve inserir o resultado anterior especificamente nesse argumento.\n\nmpg %&gt;% \n  lm(hwy ~ cyl, data = .)\n\n\nCall:\nlm(formula = hwy ~ cyl, data = .)\n\nCoefficients:\n(Intercept)          cyl  \n     40.019       -2.815  \n\n\n\n\n5.3.3 Duas dicas rápidas sobre o pipe\nO pipe cria uma espécie de efeito em cadeia, e muitas vezes nos preocupamos demais com as etapas dessa cadeia, e nos esquecemos de definir o local em que o resultado dessa cadeia deve ocupar. Portanto, lembre-se que para salvar o resultado final da cadeia formada pelos seus pipe’s, você necessita salvar esse resultado em algum objeto. Para isso, você deve posicionar o nome do objeto, e o símbolo de assignment (&lt;-), logo no início dessa cadeia, como no exemplo abaixo.\n\nresultado &lt;- mpg %&gt;% \n  group_by(class) %&gt;% \n  arrange(hwy) %&gt;% \n  mutate(\n    consumo_medio = mean(hwy),\n    desvio_consumo = hwy - consumo_medio\n  ) %&gt;%\n  select(\n    manufacturer, model, class,\n    consumo_medio, desvio_consumo\n  )\n\nresultado\n\n# A tibble: 234 × 5\n# Groups:   class [7]\n  manufacturer model               class  consumo_medio desvio_consumo\n  &lt;chr&gt;        &lt;chr&gt;               &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1 dodge        dakota pickup 4wd   pickup          16.9          -4.88\n2 dodge        durango 4wd         suv             18.1          -6.13\n3 dodge        ram 1500 pickup 4wd pickup          16.9          -4.88\n4 dodge        ram 1500 pickup 4wd pickup          16.9          -4.88\n5 jeep         grand cherokee 4wd  suv             18.1          -6.13\n# ℹ 229 more rows\n\n\nUma outra dica, seria não formar cadeias muito longas. Se você precisa aplicar várias transformações em sequência sobre o mesmo objeto, tente dividir essas várias transformações em vários “blocos” de pipe’s. Como um guia, o ideal é que uma cadeia de pipe’s nunca passe de 10 etapas. Caso você precise aplicar mais do que 10 etapas, é melhor que você salve o resultado da 10° etapa em um objeto, e inicie uma nova cadeia de pipe’s a partir deste objeto.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#operador-pipe-nativo-do-r",
    "href": "Capítulos/04-transformacao.html#operador-pipe-nativo-do-r",
    "title": "5  Transformando dados com dplyr",
    "section": "5.4 Operador pipe nativo do R (|>)",
    "text": "5.4 Operador pipe nativo do R (|&gt;)\nDepois do grande sucesso do operador pipe criado pelo pacote magrittr (%&gt;%), a equipe que mantém a linguagem R decidiu desenvolver um operador pipe nativo para a linguagem. Tal operador possui o formato |&gt;, e foi oficialmente introduzido na versão 4.1 do R.\nEm resumo, o operador |&gt; possui a exata mesma funcionalidade do operador %&gt;%. Ou seja, ele pega o resultado da função a esquerda, e, o transfere para o primeiro argumento da função a direita. Logo, poderíamos tranquilamente reescrever o exemplo anterior, ao substituir o operador %&gt;% por |&gt;, produzindo assim, o mesmo resultado:\n\nresultado &lt;- mpg |&gt;\n  group_by(class) |&gt;\n  arrange(hwy) |&gt; \n  mutate(\n    consumo_medio = mean(hwy),\n    desvio_consumo = hwy - consumo_medio\n  ) |&gt;\n  select(\n    manufacturer, model, class,\n    consumo_medio, desvio_consumo\n  )\n\nresultado\n\n# A tibble: 234 × 5\n# Groups:   class [7]\n  manufacturer model               class  consumo_medio desvio_consumo\n  &lt;chr&gt;        &lt;chr&gt;               &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1 dodge        dakota pickup 4wd   pickup          16.9          -4.88\n2 dodge        durango 4wd         suv             18.1          -6.13\n3 dodge        ram 1500 pickup 4wd pickup          16.9          -4.88\n4 dodge        ram 1500 pickup 4wd pickup          16.9          -4.88\n5 jeep         grand cherokee 4wd  suv             18.1          -6.13\n# ℹ 229 more rows\n\n\nContudo, apesar de realizar o mesmo trabalho, o operador |&gt; possui três características importantes:\n\nPrimeiro, esse operador é nativo. Ou seja, ele vem “de fábrica”, junto com o R. Logo, você não precisa chamar por nenhum pacote extra para utilizá-lo;\nSegundo, enquanto o operador %&gt;% executa cada uma das etapas de forma sequencial, o operador |&gt; utiliza uma transformação sintática (syntax transformation) para agrupar todas as etapas em uma única chamada;\nTerceiro, enquanto o operador %&gt;% utiliza um ponto final para alterar a posição em que o resultado será inserido, o operador |&gt; utiliza um underline (_) para realizar esse serviço;\n\nQuanto à segunda característica supracitada, o operador |&gt; sempre realiza uma transformação sintática sobre a sua cadeia de operações, antes de executá-la. Em outras palavras, ele reescreve os comandos em sua cadeia, com o objetivo de agrupar todas as operações em um único comando. Você pode ver o resultado desse processo, ao revelar a expressão gerada por uma cadeia qualquer, com a função quote():\n\nquote({\n  mpg |&gt;\n  group_by(class) |&gt;\n  arrange(hwy) |&gt; \n  mutate(\n    consumo_medio = mean(hwy),\n    desvio_consumo = hwy - consumo_medio\n  ) |&gt;\n  select(\n    manufacturer, model, class,\n    consumo_medio, desvio_consumo\n  )\n})\n\n## {\n##     select(mutate(arrange(group_by(mpg, class), hwy),\n##        consumo_medio = mean(hwy), \n##        desvio_consumo = hwy - consumo_medio),\n##        manufacturer, model, class,\n##        consumo_medio, desvio_consumo)\n## }\nPortanto, o operador |&gt; agrupa todas as suas operações em um único comando, e, em seguida, executa esse comando único para adquirir o resultado final de sua cadeia. Em contrapartida, o operador %&gt;% executa cada uma das etapas de sua cadeia de forma separada.\nQuanto à terceira característica supracitada, para alterarmos a posição em que o resultado da expressão anterior é inserido, precisamos utilizar um underline ao invés de um ponto final (como ocorre com %&gt;%). Vale destacar que este underline é permitido apenas em argumentos nomeados. Em outras palavras, a expressão x |&gt; y(10, _) não é permitida, enquanto a expressão x |&gt; y(10, z = _) é.\nTendo isso em mente, para reproduzirmos o exemplo anterior dado com a função lm(), teríamos:\n\nmpg |&gt; \n  lm(hwy ~ cyl, data = _) \n\n\nCall:\nlm(formula = hwy ~ cyl, data = mpg)\n\nCoefficients:\n(Intercept)          cyl  \n     40.019       -2.815  \n\n\n\n5.4.1 Utilizando o operador pipe nativo no RStudio\nEm versões mais recentes do RStudio, você pode utilizar o pipe nativo do R através do atalho Crtl + Shift + M. Basta acessar a janela de configurações globais, através de Tools \\(\\rightarrow\\) Global Options..., depois, ir na seção de Code, e, marcar a caixa “Use native pipe operator |&gt;”, como demonstrado na Figura 5.1 abaixo:\n\n\n\n\n\n\n\n\nFigura 5.1: RStudio - opção para utilizar o pipe nativo do R",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#selecionando-colunas-com-select",
    "href": "Capítulos/04-transformacao.html#selecionando-colunas-com-select",
    "title": "5  Transformando dados com dplyr",
    "section": "5.5 Selecionando colunas com select()",
    "text": "5.5 Selecionando colunas com select()\nComo definimos anteriormente, a função select() busca selecionar colunas de seu data.frame. Você já possui uma boa ideia de como realizar essa ação através da função de subsetting ([). Porém, nós podemos usufruir da flexibilidade oferecida pela função select(), que lhe permite realizar essa mesma operação de diversas maneiras intuitivas.\nNo geral, temos ao menos 5 métodos diferentes que podemos utilizar na função select():\n\nsimplesmente listar o nome das colunas que desejamos;\nfornecer um vetor externo, contendo os nomes das colunas a serem extraídas;\nselecionar um conjunto de colunas com base em seu tipo (integer, double, character, logical);\nselecionar um conjunto de colunas com base em padrões que aparecem nos nomes dessas colunas (nome começa por y, ou termina em z, ou contém x);\nselecionar um conjunto de colunas com base em seus índices numéricos (1° coluna, 2° coluna, 3° coluna, etc.).\n\nComo exemplo inicial, vamos utilizar a tabela billboard, que apresenta a posição de diversas músicas na lista Billboard Top 100, ao longo do ano 2000. Se você chamou com sucesso pelo tidyverse, você tem acesso a essa tabela. Perceba que a posição de cada música descrita na tabela, é apresentada de forma semanal, onde cada semana possui a sua coluna própria. Por essa razão, temos uma quantidade exorbitante de colunas na tabela.\n\nbillboard\n\n# A tibble: 317 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby… 2000-02-26      87    82    72    77    87    94    99    NA\n2 2Ge+her     The … 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n3 3 Doors Do… Kryp… 2000-04-08      81    70    68    67    66    57    54    53\n4 3 Doors Do… Loser 2000-10-21      76    76    72    69    67    65    55    59\n5 504 Boyz    Wobb… 2000-04-15      57    34    25    17    17    31    36    49\n# ℹ 312 more rows\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;, …\n\n\nO método 5 citado acima é um dos métodos mais práticos e eficientes de se utilizar a função select(). Por exemplo, se desejássemos extrair todas as colunas entre a 1° e 4° colunas da tabela, poderíamos fornecer um vetor à função, contendo uma sequência de 1 a 4, que representa os índices das colunas que desejamos, como no exemplo abaixo.\n\nbillboard_sel &lt;- select(billboard, 1:4)\nbillboard_sel\n\n# A tibble: 317 × 4\n  artist       track                   date.entered   wk1\n  &lt;chr&gt;        &lt;chr&gt;                   &lt;date&gt;       &lt;dbl&gt;\n1 2 Pac        Baby Don't Cry (Keep... 2000-02-26      87\n2 2Ge+her      The Hardest Part Of ... 2000-09-02      91\n3 3 Doors Down Kryptonite              2000-04-08      81\n4 3 Doors Down Loser                   2000-10-21      76\n5 504 Boyz     Wobble Wobble           2000-04-15      57\n# ℹ 312 more rows\n\n\nAgora, e se você precisasse selecionar todas as colunas que representam as semanas? Nesse caso, o método 5 ainda seria uma boa alternativa, pois você precisaria apenas fornecer uma sequência que represente a posição dessas colunas na tabela (de 4 a 79 para ser mais preciso).\nPorém, todas essas colunas possuem um padrão em seus nomes. Elas se iniciam pelos caracteres \"wk\", acrescidos de um número que representa o índice da semana que essa coluna corresponde. Portanto, em todas as ocasiões que houver algum padrão presente nos nomes das colunas que você deseja selecionar, o método 4 que citamos configura-se como uma ótima solução. Nesse método, devemos utilizar as funções de suporte starts_with(), ends_with(), matches().\nComo os seus próprios nomes dão a entender, as funções starts_with() e ends_with() vão selecionar qualquer coluna de sua tabela que comece (start) ou termine (end) por uma determinada cadeia de caracteres, respectivamente. Como exemplo, eu posso selecionar todas as colunas que apresentam as posições semanais na tabela billboard, ao encontrar todas as colunas que começam pelas letras \"wk\", com a função starts_with().\n\nbillboard_sel &lt;- select(billboard, starts_with(\"wk\"))\nbillboard_sel\n\n# A tibble: 317 × 76\n    wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  wk12  wk13\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    87    82    72    77    87    94    99    NA    NA    NA    NA    NA    NA\n2    91    87    92    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n3    81    70    68    67    66    57    54    53    51    51    51    51    47\n4    76    76    72    69    67    65    55    59    62    61    61    59    61\n5    57    34    25    17    17    31    36    49    53    57    64    70    75\n# ℹ 312 more rows\n# ℹ 63 more variables: wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, …\n\n\nJá a função matches() se trata de um caso muito mais flexível das funções starts_with() e ends_with(), pois ela lhe permite selecionar qualquer coluna cujo o nome se encaixa em uma dada expressão regular. Expressões regulares são uma poderosa ferramenta para processamento de texto, a qual vamos discutir no capítulo Manipulação e transformação de strings com stringr, especialmente na seção Expressões regulares (ou regex) com str_detect().\n\n## Seleciona todas as semanas que são\n## maiores do que 9 e menores do que 100.\n## Ou seja, toda semana com dois dígitos\nbillboard %&gt;% \n  select(matches(\"wk[0-9]{2}\")) %&gt;% print(n = 5)\n\n# A tibble: 317 × 67\n   wk10  wk11  wk12  wk13  wk14  wk15  wk16  wk17  wk18  wk19  wk20  wk21  wk22\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n2    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n3    51    51    51    47    44    38    28    22    18    18    14    12     7\n4    61    61    59    61    66    72    76    75    67    73    70    NA    NA\n5    57    64    70    75    76    78    85    92    96    NA    NA    NA    NA\n# ℹ 312 more rows\n# ℹ 54 more variables: wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;, wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, …\n\n## Seleciona todas as colunas cujo nome\n## possua um ponto final antecedido por\n## 4 letras\nbillboard %&gt;% \n  select(matches(\"[a-z]{4}[.]\")) %&gt;% print(n = 5)\n\n# A tibble: 317 × 1\n  date.entered\n  &lt;date&gt;      \n1 2000-02-26  \n2 2000-09-02  \n3 2000-04-08  \n4 2000-10-21  \n5 2000-04-15  \n# ℹ 312 more rows\n\n\nEssas são maneiras eficientes de selecionarmos um grande conjunto de colunas, porém, muitas vezes as nossas necessidades são pequenas e, portanto, não exigem mecanismos tão poderosos.\nNessas situações, o método 1 se torna útil pois ele consiste em simplesmente listarmos o nome das colunas desejadas. Como exemplo, eu posso selecionar as colunas artist, track e wk5 da tabela billboard pelo comando abaixo.\n\nbillboard %&gt;% select(artist, track, wk5)\n\n# A tibble: 317 × 3\n  artist       track                     wk5\n  &lt;chr&gt;        &lt;chr&gt;                   &lt;dbl&gt;\n1 2 Pac        Baby Don't Cry (Keep...    87\n2 2Ge+her      The Hardest Part Of ...    NA\n3 3 Doors Down Kryptonite                 66\n4 3 Doors Down Loser                      67\n5 504 Boyz     Wobble Wobble              17\n# ℹ 312 more rows\n\n\nVale destacar que a ordem dos índices utilizados importa para a função select(). Logo, se no exemplo acima, eu listasse as colunas na ordem track, wk5 e artist, o novo data.frame resultante de select(), iria conter essas colunas precisamente nessa ordem.\nO mesmo efeito seria produzido, caso eu utilizasse novamente o método 5, e fornecesse o vetor c(3, 2, 4) à função. Dessa forma, select() iria me retornar um novo data.frame contendo 3 colunas, que correspondem a 3°, 2° e 4° colunas da tabela billboard, exatamente nessa ordem.\nPor outro lado, não há uma maneira de variarmos a ordem dos resultados gerados nos métodos 3 e 4, especificamente. Por isso, caso você utilize um desses dois métodos, as colunas selecionadas serão apresentadas no novo data.frame, precisamente na ordem em que eles aparecem no data.frame inicial.\nVisto esses pontos, ao invés de selecionar colunas, você também pode utilizar o método 1 para rapidamente eliminar algumas colunas de seu data.frame, ao posicionar um sinal negativo (-) antes do nome da coluna que você deseja retirar. Por exemplo, eu posso selecionar todas as colunas da tabela mpg, exceto as colunas hwy e manufacturer por meio do seguinte comando:\n\nmpg %&gt;% select(-hwy, -manufacturer)\n\n# A tibble: 234 × 9\n  model displ  year   cyl trans      drv     cty fl    class  \n  &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;  \n1 a4      1.8  1999     4 auto(l5)   f        18 p     compact\n2 a4      1.8  1999     4 manual(m5) f        21 p     compact\n3 a4      2    2008     4 manual(m6) f        20 p     compact\n4 a4      2    2008     4 auto(av)   f        21 p     compact\n5 a4      2.8  1999     6 auto(l5)   f        16 p     compact\n# ℹ 229 more rows\n\n\nEm contrapartida, o método 3 busca selecionar um conjunto de colunas com base em seu tipo de dado, através da função where() e das funções de teste lógico is.*() (is.double, is.character, is.integer, …). Como exemplo, nós podemos selecionar todas as colunas da tabela billboard que contém dados textuais, através do comando abaixo. Portanto, para utilizar esse método você precisa apenas se referir a função is.*() que corresponde ao tipo de dado no qual você está interessado, dentro da função where().\n\nbillboard %&gt;% select(where(is.character))\n\n# A tibble: 317 × 2\n  artist       track                  \n  &lt;chr&gt;        &lt;chr&gt;                  \n1 2 Pac        Baby Don't Cry (Keep...\n2 2Ge+her      The Hardest Part Of ...\n3 3 Doors Down Kryptonite             \n4 3 Doors Down Loser                  \n5 504 Boyz     Wobble Wobble          \n# ℹ 312 more rows\n\n\nCom isso, você possui não apenas uma boa variedade de métodos disponíveis na função select(), mas você também é capaz de misturá-los livremente dentro da função. Ou seja, se for de meu desejo, eu posso utilizar os métodos 2, 4 e 5 ao mesmo tempo, como no exemplo abaixo. Tratando especificamente do método 2, eu preciso fornecer dentro da função all_of(), um vetor contendo os nomes das colunas desejadas.\nComo exemplo, eu posso novamente extrair as colunas artist, track e wk5 através desse método. O método 2, em particular, se torna um método interessante quando ainda não conhecemos o conjunto de colunas a serem extraídas. Talvez você precise aplicar previamente diversos testes sobre o seu data.frame, para identificar essas colunas. Logo, um vetor contendo os nomes das colunas desejadas seria o resultado ideal para tais testes.\n\nvec &lt;- c(\"artist\", \"track\", \"wk5\")\nbillboard %&gt;% select(\n  all_of(vec),  ## Método 2\n  3:5,  ## Método 5\n  matches(\"wk[0-9]{2}\")  ## Método 4\n)\n\n# A tibble: 317 × 73\n  artist      track   wk5 date.entered   wk1   wk2  wk10  wk11  wk12  wk13  wk14\n  &lt;chr&gt;       &lt;chr&gt; &lt;dbl&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby…    87 2000-02-26      87    82    NA    NA    NA    NA    NA\n2 2Ge+her     The …    NA 2000-09-02      91    87    NA    NA    NA    NA    NA\n3 3 Doors Do… Kryp…    66 2000-04-08      81    70    51    51    51    47    44\n4 3 Doors Do… Loser    67 2000-10-21      76    76    61    61    59    61    66\n5 504 Boyz    Wobb…    17 2000-04-15      57    34    57    64    70    75    76\n# ℹ 312 more rows\n# ℹ 62 more variables: wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;, …",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#filtrando-linhas-com-filter",
    "href": "Capítulos/04-transformacao.html#filtrando-linhas-com-filter",
    "title": "5  Transformando dados com dplyr",
    "section": "5.6 Filtrando linhas com filter()",
    "text": "5.6 Filtrando linhas com filter()\nVocê também já possui conhecimento para realizar essa operação através da função de subsetting ([). Porém, novamente o pacote dplyr nos oferece uma alternativa mais intuitiva. A função filter() busca filtrar linhas de uma tabela de acordo com uma condição lógica de nossa escolha. Ou seja, os operadores lógicos são primordiais para essa função. Por isso, temos na Figura 5.2, um resumo de cada um deles.\n\n\n\n\n\n\n\n\nFigura 5.2: Lista de operadores lógicos\n\n\n\n\n\nPortanto, ao utilizar a função filter() você deve construir uma condição lógica que seja capaz de identificar as linhas que você deseja filtrar. Como exemplo inicial, nós podemos retornar à tabela mpg, que contém dados de consumo de diversos modelos de carro. Por exemplo, nós podemos filtrar todas as linhas que dizem respeito a modelos da Toyota, através do comando abaixo. Como um paralelo, temos mais abaixo a mesma operação segundo a função de subsetting.\n\nmpg %&gt;% filter(manufacturer == \"toyota\")\n\n# A tibble: 34 × 11\n  manufacturer model       displ  year   cyl trans drv     cty   hwy fl    class\n  &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n1 toyota       4runner 4wd   2.7  1999     4 manu… 4        15    20 r     suv  \n2 toyota       4runner 4wd   2.7  1999     4 auto… 4        16    20 r     suv  \n3 toyota       4runner 4wd   3.4  1999     6 auto… 4        15    19 r     suv  \n4 toyota       4runner 4wd   3.4  1999     6 manu… 4        15    17 r     suv  \n5 toyota       4runner 4wd   4    2008     6 auto… 4        16    20 r     suv  \n# ℹ 29 more rows\n\n\n\n## A mesma operação por subsetting:\nclog &lt;- mpg$manufacturer == \"toyota\"\nmpg[clog, ]\n\nMúltiplas condições lógicas podem ser construídas dentro da função filter(). Por exemplo, podemos ser um pouco mais específicos e selecionarmos apenas os modelos da Toyota que possuem um motor de 4 cilindradas com o comando abaixo. Repare abaixo, que ao acrescentarmos novas condições na função filter(), elas acabam se tornando dependentes. Ou seja, ambas as condições devem ser atendidas ao mesmo tempo em cada linha retornada pela função filter().\n\nmpg %&gt;% filter(manufacturer == \"toyota\", cyl == 4)\n\n# A tibble: 18 × 11\n  manufacturer model       displ  year   cyl trans drv     cty   hwy fl    class\n  &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n1 toyota       4runner 4wd   2.7  1999     4 manu… 4        15    20 r     suv  \n2 toyota       4runner 4wd   2.7  1999     4 auto… 4        16    20 r     suv  \n3 toyota       camry         2.2  1999     4 manu… f        21    29 r     mids…\n4 toyota       camry         2.2  1999     4 auto… f        21    27 r     mids…\n5 toyota       camry         2.4  2008     4 manu… f        21    31 r     mids…\n# ℹ 13 more rows\n\n\n\n## A mesma operação por subsetting:\nclog &lt;- mpg$manufacturer == \"toyota\" & mpg$cyl == 4\nmpg[clog, ]\n\nNós tradicionalmente estabelecemos relações de dependência entre condições lógicas, por meio do operador &. Mas a função filter() busca ser prática e, por isso, ela automaticamente realiza esse trabalho por nós. Porém, isso implica que se as suas condições forem independentes, ajustes precisam ser feitos, através do operador |.\nVisto esse ponto, você pode estar interessado em filtrar a sua tabela, de acordo com um conjunto de valores. Por exemplo, ao invés de selecionar apenas os modelos pertencentes à Toyota, podemos selecionar um conjunto maior de marcas. Em ocasiões como essa, o operador %in% se torna útil, pois você está pesquisando se o valor presente em cada linha de sua tabela, pertence ou não a um dado conjunto de valores.\n\nmarcas &lt;- c(\"volkswagen\", \"audi\", \"toyota\", \"honda\")\nmpg %&gt;% \n  filter(manufacturer %in% marcas)\n\n# A tibble: 88 × 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; \n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa…\n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa…\n3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa…\n4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa…\n5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compa…\n# ℹ 83 more rows\n\n\n\n## A mesma operação por subsetting:\nmarcas &lt;- c(\"volkswagen\", \"audi\", \"toyota\", \"honda\")\nclog &lt;- mpg$manufacturer %in% marcas\nmpg[clog, ]\n\n\n5.6.1 Cuidados com o operador de igualdade\nQuando você estiver filtrando as linhas de sua tabela de acordo com uma condição de igualdade, é importante que você tome alguns cuidados, especialmente se valores textuais estiverem envolvidos nessa condição. O primeiro ponto a ser abordado é o uso do operador ==, que para além de igualdade, ele busca encontrar valores exatamente iguais.\nO “exatamente” é importante aqui, pois certos valores numéricos podem ser aparentemente idênticos aos nossos olhos, mas ainda assim, diferentes segundo a visão de ==. Isso ocorre especialmente com valores numéricos do tipo double. Pois os nossos computadores utilizam precisão aritmética finita para guardar esse tipo de valor (WICKHAM; GROLEMUND, 2017, p. 47). Isso significa que os nossos computadores guardam apenas as casas decimais significantes de um valor double, e a perda de casas decimais que ocorre nesse processo, pode ser a fonte de alguma diferença em operações aritméticas. Por exemplo, se testarmos a igualdade entre \\((\\sqrt{2})^2 = 2\\), o R vai nos indicar alguma diferença existente entre esses dois valores.\n\n(sqrt(2)^2) == 2\n\n[1] FALSE\n\n\nPor essa razão, quando você estiver testando a igualdade entre valores do tipo double, é interessante que você utilize a função near() ao invés do operador ==. Por padrão, a função near() possui uma tolerância próxima de \\(1,49 \\times 10^{-8}\\), mas você pode ajustar esse valor pelo argumento tol da função.\n\nnear(sqrt(2)^2, 2)\n\n[1] TRUE\n\n\nPara mais, você também deve estar atento ao uso do operador ==, quando estiver testando a igualdade entre palavras, ou valores textuais. Pois uma palavra pode ser escrita de múltiplas maneiras sem que ela perca o seu sentido, e a mínima diferença presente nos caracteres utilizados pode torná-las valores completamente diferentes aos olhos do operador ==. Logo, os valores \"Isabela\" e \"isabela\" são diferentes na visão de ==, mesmo que na prática, esses valores muito provavelmente se referem ao mesmo indivíduo.\n\n\"Isabela\" == \"isabela\"\n\n[1] FALSE\n\n\nSe você possui em sua coluna, uma variedade maior de valores textuais, que são diferentes, mas que dizem respeito ao mesmo indivíduo (por exemplo, você possui seis variedades de “Isabela”: Isabela; ISABELA; IsAbElA; Ísabela; ísabela; i\\@abela), você muito provavelmente necessita de uma expressão regular. Para acessar esse mecanismo e utilizá-lo dentro da função filter(), você precisa de uma função que utilize essa funcionalidade para pesquisar os textos que se encaixam em sua expressão, e que retorne como resultado, um vetor de valores lógicos que indicam as linhas de sua tabela em que esses textos ocorrem. Sendo os principais indivíduos dessa categoria, a função grepl(), e a função str_detect() que pertence ao pacote stringr.\nPor outro lado, pode ser que você não precise ir tão longe, caso as diferenças presentes em seus textos se apresentem na forma de capitalização das letras (maiúsculo ou minúsculo). Por exemplo, suponha que a sua variedade de “Isabela” fosse: Isabela; ISABELA; IsAbElA e isabela. Para tornar esses valores iguais, você precisaria apenas de um método de pesquisa que seja capaz de ignorar a capitalização das letras. Para isso, você pode utilizar a função grepl() que possui o argumento ignore.case, no qual você pode pedir a função que ignore essas diferenças na capitalização, como no exemplo abaixo.\n\nset.seed(2)\ndf &lt;- data.frame(\n  usuario = c(\"Ana\", \"Isabela\", \"isabela\", \"Julia\"),\n  id = 1:4,\n  valor = round(rnorm(4), 2)\n)\n\ndf %&gt;% \n  filter(grepl(\"Isabela\", usuario, ignore.case = TRUE))\n\n  usuario id valor\n1 Isabela  2  0.18\n2 isabela  3  1.59\n\n\n\n\n5.6.2 Estabelecendo intervalos com a função between()\nPara estabelecermos uma condição de intervalo no R, precisamos de duas condições lógicas que definam os limites deste intervalo. Em seguida, nós devemos tornar essas duas condições dependentes. Por exemplo, se desejássemos filtrar todas as linhas de mpg que possuem um valor na coluna hwy entre 18 e 24, precisaríamos do seguinte teste lógico:\n\nmpg %&gt;% \n  filter(hwy &gt;= 18, hwy &lt;= 24)\n## A mesma operação por subsetting:\nclog &lt;- mpg$hwy &gt;= 18 & mpg$hwy &lt;= 24\nmpg[clog, ]\n\nPorém, de uma maneira mais prática, podemos utilizar a função between() que consiste em um atalho para essa metodologia. A função possui três argumentos: 1) x, a coluna ou o vetor sobre o qual você deseja aplicar o teste de intervalo; 2) left, o limite “inferior” (ou “esquerdo”) do intervalo; 3) right, o limite “superior” (ou “direito”) do intervalo. Logo, se fôssemos traduzir o teste de intervalo anterior para a função between(), faríamos da seguinte maneira:\n\nmpg %&gt;% \n  filter(between(hwy, 18, 24))\n\n# A tibble: 63 × 11\n  manufacturer model       displ  year   cyl trans drv     cty   hwy fl    class\n  &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n1 audi         a6 quattro    2.8  1999     6 auto… 4        15    24 p     mids…\n2 audi         a6 quattro    4.2  2008     8 auto… 4        16    23 p     mids…\n3 chevrolet    c1500 subu…   5.3  2008     8 auto… r        14    20 r     suv  \n4 chevrolet    c1500 subu…   5.3  2008     8 auto… r        14    20 r     suv  \n5 chevrolet    corvette      5.7  1999     8 auto… r        15    23 p     2sea…\n# ℹ 58 more rows\n\n\n\n\n5.6.3 Ataque terrorista\nVamos dar um pouco de contexto para as nossas operações. Nessa seção, vamos utilizar os dados disponíveis na tabela transf, que podem ser importados para o seu R através dos comandos abaixo. A tabela transf contém informações sobre diversas transferências bancárias realizadas por uma instituição bancária. Algumas informações presentes nessa tabela incluem: a data e o horário da transferência (Data); O username do usuário do banco responsável por realizar a transferência (Usuario); o país de destino da transferência (Pais); um código de identificação da transferência (TransferID); e o valor transferido (Valor).\n\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo &lt;- \"transf_reform.csv\"\ntransf &lt;- read_csv2(paste0(github, pasta, arquivo))\ntransf\n\n# A tibble: 20,006 × 6\n  Data                Usuario  Valor TransferID Pais     Descricao\n  &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;lgl&gt;    \n1 2018-12-06 22:19:19 Eduardo   599.  116241629 Alemanha NA       \n2 2018-12-06 22:10:34 Júlio    4611.  115586504 Alemanha NA       \n3 2018-12-06 21:59:50 Nathália 4418.  115079280 Alemanha NA       \n4 2018-12-06 21:54:13 Júlio    2740.  114972398 Alemanha NA       \n5 2018-12-06 21:41:27 Ana      1408.  116262934 Alemanha NA       \n# ℹ 20,001 more rows\n\n\nVamos supor que no dia 24 de dezembro de 2018, tenha ocorrido um ataque terrorista na cidade de Berlim (Alemanha). Suponha também, que você faz parte do setor de compliance da instituição financeira responsável pelas transferências descritas na tabela transf. Em geral, um dos principais papéis de um setor de compliance é garantir que a sua instituição não esteja contribuindo com práticas ilícitas (dentre elas está o terrorismo).\nSegundo o relatório da polícia, há fortes indícios de que a munição utilizada no ato, foi comprada durante os dias 20 e 23. Além disso, a polícia também destacou que levando em conta a quantidade utilizada no ataque, somente a munição empregada custou em média mais de $15.000.\nLogo, o seu papel seria se certificar de que a instituição a qual você pertence, não realizou alguma transferência que se encaixa nessas características. Pois caso tal transferência exista, vocês teriam de abrir uma investigação em conjunto com a polícia, para apurar as fontes e os destinatários dos recursos dessa transferência.\nPortanto, estamos procurando por uma transferência na tabela transf de valor acima de $15.000, que possua a Alemanha como país de destino, e que tenha ocorrido durante os dias 20 e 23 de dezembro de 2018. Perceba que todas essas condições, ou características da transferência devem ser atendidas ao mesmo tempo. Ou seja, essas condições lógicas são dependentes uma da outra.\nLembre-se que quando temos diversas condições lógicas dependentes, nós podemos separá-las por vírgulas na função filter(). Por outro lado, fora do uso da função filter(), nós estabelecemos uma relação de dependência entre várias condições lógicas por meio do operador &, e será esse o método tradicional utilizado nessa seção. Logo, quando temos diversas condições no R que devem ser atendidas ao mesmo tempo, nós devemos conectar cada uma dessas condições pelo operador &, como no exemplo abaixo.\n\ntransf %&gt;% \n  filter(\n    Valor &gt; 15000 & Pais == \"Alemanha\" &\n    between(as.Date(Data), as.Date(\"2018-12-20\"), as.Date(\"2018-12-23\"))\n  )\n\n# A tibble: 132 × 6\n  Data                Usuario      Valor TransferID Pais     Descricao\n  &lt;dttm&gt;              &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;lgl&gt;    \n1 2018-12-22 20:00:56 Armando     18521.  114513684 Alemanha NA       \n2 2018-12-21 18:46:59 Júlio Cesar 16226.  116279014 Alemanha NA       \n3 2018-12-21 17:41:48 Nathália    17583.  115748273 Alemanha NA       \n4 2018-12-23 09:46:23 Júlio       15396.  115272184 Alemanha NA       \n5 2018-12-21 06:38:20 Júlio Cesar 17555.  114983226 Alemanha NA       \n# ℹ 127 more rows\n\n\n\n## A mesma operação por subsetting:\nclog &lt;- transf$Valor &gt; 15000 & transf$Pais == \"Alemanha\" &\n  between(as.Date(transf$Data), as.Date(\"2018-12-20\"), as.Date(\"2018-12-23\"))\ntransf[clog, ]\n\nNo total, 132 linhas foram retornadas pela função, e você teria de conferir cada uma dessas transferências. Um baita trabalho! Porém, vamos supor que em um minuto de reflexão sobre as regras do banco, você se lembre que o remetente da transferência não é obrigado a apresentar uma prova de fundos ou um comprovante de endereço, caso a transferência possua um valor menor do que $200. Em casos como esse, o remetente precisa apresentar apenas a identidade (que ele pode ter falsificado).\n\ntransf %&gt;%\n  filter(\n    Valor &lt;= 200 & Pais == \"Alemanha\" &\n    between(as.Date(Data), as.Date(\"2018-12-20\"), as.Date(\"2018-12-23\"))\n  )\n\n# A tibble: 5 × 6\n  Data                Usuario Valor TransferID Pais     Descricao\n  &lt;dttm&gt;              &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;lgl&gt;    \n1 2018-12-20 00:31:17 Júlio     193  115555598 Alemanha NA       \n2 2018-12-22 06:30:01 Sandra    100  116400001 Alemanha NA       \n3 2018-12-22 06:35:00 Sandra    200  116400002 Alemanha NA       \n4 2018-12-22 06:42:12 Eduardo   200  116400005 Alemanha NA       \n5 2018-12-22 06:55:54 Eduardo   150  116400009 Alemanha NA       \n\n\nIsso é interessante, pois conseguimos reduzir os nossos resultados para apenas 5 transferências. Ao conferirmos as informações da primeira transferência, os recursos estão limpos. Porém, as próximas 4 transferências levantam algumas suspeitas. Pois elas foram realizadas por clientes diferentes, mas com poucos minutos de diferença. Ao conversar com os agentes Sandra e Eduardo, que autorizaram essas transferências, você descobre que todos os diferentes clientes apresentaram documentos de identidade franceses. Será que esses clientes estavam testando as regras da instituição para com identidades desse país?\nAo procurar por todas as transferências em que identidades francesas foram apresentadas, e que foram realizadas entre os dias 20 e 23 de dezembro de 2018, e que possuíam a Alemanha como país de destino, você chega a uma estranha transferência de $20.000 efetuada poucos minutos depois das 4 transferências que encontramos anteriormente. Durante a análise das informações dessa transferência, você percebe diversas falhas presentes na prova de fundos que sustentou a decisão de autorização dessa operação. Há uma grande possibilidade de que os chefes e agentes de sua instituição que autorizaram essa operação, estejam em maus lençóis.\n\ntransf %&gt;%\n  inner_join(\n    identidade,\n    by = \"TransferID\"\n  ) %&gt;%\n  filter(\n    Pais == \"Alemanha\" & Identi_Nacion == \"França\" &\n    between(as.Date(Data), as.Date(\"2018-12-20\"), as.Date(\"2018-12-23\"))\n  )\n\n# A tibble: 5 × 7\n  Data                Usuario Valor TransferID Pais     Descricao Identi_Nacion\n  &lt;dttm&gt;              &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;lgl&gt;     &lt;chr&gt;        \n1 2018-12-22 06:30:01 Sandra    100  116400001 Alemanha NA        França       \n2 2018-12-22 06:35:00 Sandra    200  116400002 Alemanha NA        França       \n3 2018-12-22 06:42:12 Eduardo   200  116400005 Alemanha NA        França       \n4 2018-12-22 06:55:54 Eduardo   150  116400009 Alemanha NA        França       \n5 2018-12-22 06:59:07 Eduardo 20000  116400010 Alemanha NA        França       \n\n\n\n\n5.6.4 Condições dependentes (&) ou independentes (|) ?\nNa seção anterior, as condições lógicas que guiavam o nosso filtro eram dependentes entre si. Em outras palavras, as condições deveriam ser todas atendidas ao mesmo tempo. Por essa razão, nós conectamos as condições lógicas com o operador &. Porém, em algumas ocasiões as suas condições serão independentes e, por isso, devemos utilizar um outro operador para conectá-las, que é a barra vertical (|).\nPor exemplo, se eu quiser encontrar todas as transferências na tabela transf que ocorreram no dia 13 de novembro de 2018, ou que possuem um valor menor que $500, ou que foram autorizadas pelo agente Eduardo, eu devo construir o comando abaixo. Logo, toda linha da tabela transf que atenda pelo menos uma das condições que estabelecemos, é filtrada pela função filter().\n\ntransf %&gt;% \n  filter(\n    as.Date(Data) == as.Date(\"2018-11-13\") | Valor &lt; 500 |\n    Usuario == \"Eduardo\"\n  )\n\n# A tibble: 5,581 × 6\n  Data                Usuario      Valor TransferID Pais     Descricao\n  &lt;dttm&gt;              &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;lgl&gt;    \n1 2018-12-06 22:19:19 Eduardo       599.  116241629 Alemanha NA       \n2 2018-12-06 20:54:32 Eduardo      5665.  114830203 Alemanha NA       \n3 2018-12-06 19:07:50 Eduardo      9561.  115917812 Alemanha NA       \n4 2018-12-06 18:09:15 Júlio Cesar   388.  114894102 Alemanha NA       \n5 2018-12-06 16:59:38 Eduardo     11759.  115580064 Alemanha NA       \n# ℹ 5,576 more rows\n\n\n\n## A mesma operação por subsetting:\nclog &lt;- as.Date(transf$Data) == as.Date(\"2018-11-13\") | \n  transf$Valor &lt; 500 | transf$Usuario == \"Eduardo\"\ntransf[clog, ]",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#ordenando-linhas-com-arrange",
    "href": "Capítulos/04-transformacao.html#ordenando-linhas-com-arrange",
    "title": "5  Transformando dados com dplyr",
    "section": "5.7 Ordenando linhas com arrange()",
    "text": "5.7 Ordenando linhas com arrange()\nAlgumas operações que realizamos dependem diretamente da forma como as linhas de nossa tabela estão ordenadas. Em outros momentos, desejamos ordenar a nossa tabela, para rapidamente identificarmos as observações que possuem os 10 maiores valores de alguma variável ao longo da base. Ou seja, a ordenação de linhas é uma operação muito comum, e o pacote dplyr oferece a função arrange() para tal ação.\nO uso da função arrange() é bem simples. Tudo o que você precisa fazer é listar as colunas pelas quais você deseja ordenar a base. Caso a coluna seja numérica, arrange() vai seguir uma ordenação numérica. Mas se essa coluna for do tipo character, arrange() vai utilizar uma ordenação alfabética para organizar os valores da coluna. Por outro lado, na hipótese dessa coluna ser do tipo factor, arrange() vai seguir a ordem presente nos “níveis” (levels) desse factor, aos quais você pode acessar pela função levels().\n\nmpg %&gt;% arrange(displ)\n\n# A tibble: 234 × 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; \n1 honda        civic   1.6  1999     4 manual(m5) f        28    33 r     subco…\n2 honda        civic   1.6  1999     4 auto(l4)   f        24    32 r     subco…\n3 honda        civic   1.6  1999     4 manual(m5) f        25    32 r     subco…\n4 honda        civic   1.6  1999     4 manual(m5) f        23    29 p     subco…\n5 honda        civic   1.6  1999     4 auto(l4)   f        24    32 r     subco…\n# ℹ 229 more rows\n\n\nVocê pode recorrer a várias colunas para ordenar a sua base. Nessa situação, a função arrange() vai ordenar as colunas na ordem em que você as definiu na função. Ou seja, no exemplo abaixo, a função arrange() primeiro ordena a base de acordo com a coluna displ, em seguida, segundo a coluna hwy, e por último, a coluna trans.\n\nmpg %&gt;% arrange(displ, hwy, trans)\n\n# A tibble: 234 × 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; \n1 honda        civic   1.6  1999     4 manual(m5) f        23    29 p     subco…\n2 honda        civic   1.6  1999     4 auto(l4)   f        24    32 r     subco…\n3 honda        civic   1.6  1999     4 auto(l4)   f        24    32 r     subco…\n4 honda        civic   1.6  1999     4 manual(m5) f        25    32 r     subco…\n5 honda        civic   1.6  1999     4 manual(m5) f        28    33 r     subco…\n# ℹ 229 more rows\n\n\nPor padrão, a função arrange() utiliza uma ordenação em um sentido crescente (do menor para o maior valor; do primeiro para o último valor), qualquer que seja o tipo de dado contido na coluna que você forneceu a função. Caso você deseja utilizar uma ordenação em um sentido decrescente (do maior para o menor valor; do último para o primeiro valor) em uma dada coluna, você deve encapsular o nome dessa coluna na função desc(). No exemplo abaixo, arrange() primeiro ordena a coluna manufacturer em uma forma decrescente e, em seguida, ordena a coluna hwy de acordo com uma ordem crescente.\n\nmpg %&gt;% arrange(desc(manufacturer), hwy)\n\n# A tibble: 234 × 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; \n1 volkswagen   jetta   2.8  1999     6 auto(l4)   f        16    23 r     compa…\n2 volkswagen   gti     2.8  1999     6 manual(m5) f        17    24 r     compa…\n3 volkswagen   jetta   2.8  1999     6 manual(m5) f        17    24 r     compa…\n4 volkswagen   gti     2    1999     4 auto(l4)   f        19    26 r     compa…\n5 volkswagen   jetta   2    1999     4 auto(l4)   f        19    26 r     compa…\n# ℹ 229 more rows\n\n\nComo estamos basicamente definindo colunas na função arrange(), é natural que você anseie pelos diversos métodos de seleção que aprendemos em select(). Por isso, em versões mais recentes do pacote dplyr tivemos a introdução da função across(), pela qual você tem novamente acesso a todos esses métodos que vimos em select().\n\n## Ordenar a base segundo as três primeiras colunas\nmpg %&gt;% arrange(across(1:3))\n## Ordenar a base segundo o conjunto de colunas\n## que possuem um nome que se inicia\n## pelos caracteres \"dis\"\nmpg %&gt;% arrange(across(starts_with(\"dis\")))\n\nVale destacar que a função arrange(), por padrão, não respeita os grupos de sua tabela e, portanto, considera toda a sua tabela no momento em que a ordenação ocorre. Ainda veremos em mais detalhes nas próximas seções, a função group_by(), pela qual você pode definir os grupos presentes em sua tabela. Portanto, pode ser de seu desejo que a ordenação executada por arrange() ocorra dentro de cada um dos grupos que você delimitou através da função group_by(). Para isso, você precisa configurar o argumento .by_group para TRUE.\n\nmpg %&gt;% \n  group_by(manufacturer) %&gt;% \n  arrange(hwy, .by_group = TRUE)\n\n# A tibble: 234 × 11\n# Groups:   manufacturer [15]\n  manufacturer model      displ  year   cyl trans  drv     cty   hwy fl    class\n  &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n1 audi         a6 quattro   4.2  2008     8 auto(… 4        16    23 p     mids…\n2 audi         a6 quattro   2.8  1999     6 auto(… 4        15    24 p     mids…\n3 audi         a4 quattro   1.8  1999     4 auto(… 4        16    25 p     comp…\n4 audi         a4 quattro   2.8  1999     6 auto(… 4        15    25 p     comp…\n5 audi         a4 quattro   2.8  1999     6 manua… 4        17    25 p     comp…\n# ℹ 229 more rows",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#sec:mutate_dplyr",
    "href": "Capítulos/04-transformacao.html#sec:mutate_dplyr",
    "title": "5  Transformando dados com dplyr",
    "section": "5.8 Adicionando variáveis à sua tabela com mutate()",
    "text": "5.8 Adicionando variáveis à sua tabela com mutate()\nJá aprendemos muitas coisas sobre como trabalhar com as colunas que já existem em nossa tabela. Mas e se precisamos de adicionar novas colunas a essa tabela? Se precisamos calcular novas variáveis para essa tabela? Como podemos fazer isso? Para isso, o pacote dplyr disponibiliza a função mutate().\nEssa função funciona da mesma forma que o método with_columns() do framework polars, e também, ao método withColumns() do Apache Spark. Em resumo, você fornece uma lista de expressões a essa função. Cada expressão é responsável por criar uma nova coluna separada em sua tabela.\nComo um exemplo inicial, vamos voltar a tabela transf que introduzimos na seção Ataque terrorista. A coluna Data contém a data e o horário em que cada operação foi registrada no sistema do banco. Entretanto, o horário pode se tornar irrelevante para certos passos e, por essa razão, pode ser interessante conter uma nova coluna que contém apenas a data de cada transferência. Com esse objetivo em mente, podemos extrair a data da coluna Data através da função as.Date(), e empregar a função mutate() para armazenarmos o resultado desse procedimento em uma nova coluna chamada Sem_hora, como mostrado abaixo:\n\ntransf %&gt;% \n  select(-Pais, -Descricao) %&gt;% \n  mutate(\n    Sem_hora = as.Date(Data)\n  )\n\n# A tibble: 20,006 × 5\n  Data                Usuario  Valor TransferID Sem_hora  \n  &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;date&gt;    \n1 2018-12-06 22:19:19 Eduardo   599.  116241629 2018-12-06\n2 2018-12-06 22:10:34 Júlio    4611.  115586504 2018-12-06\n3 2018-12-06 21:59:50 Nathália 4418.  115079280 2018-12-06\n4 2018-12-06 21:54:13 Júlio    2740.  114972398 2018-12-06\n5 2018-12-06 21:41:27 Ana      1408.  116262934 2018-12-06\n# ℹ 20,001 more rows\n\n\nPortanto, sempre que você recorrer à função mutate(), você deve compor essa estrutura de &lt;nome_coluna&gt; = &lt;expressao&gt; em cada coluna adicionada. Ou seja, como flexibilidade e eficiência são valores que as funções do pacote dplyr carregam, você tem a capacidade de criar múltiplas colunas em um único mutate(). Porém, como um aviso, é ideal que você não crie mais de 7 colunas ao mesmo tempo, pois há uma probabilidade de você enfrentar problemas de memória e mensagens de erro bastante nebulosas.\n\n## Estrutura básica de um mutate():\n&lt;sua_tabela&gt; %&gt;% \n  mutate(\n    nome_coluna1 = expressao1,\n    nome_coluna2 = expressao2,\n    nome_coluna3 = expressao3,\n    ...\n  )\n\nUm outro ponto muito importante, é que em um mesmo mutate(), você também pode empregar uma nova coluna que você acabou de criar, no cálculo de uma outra coluna a ser produzida em sequência. Por exemplo, eu posso guardar o desvio de Valor em relação à sua média, na coluna Desvio, e logo em seguida, utilizar os valores desta nova coluna para produzir uma outra coluna chamada Valor_norm, como exposto abaixo.\n\ntransf %&gt;% \n  select(-Pais, -Descricao) %&gt;%\n  mutate(\n    Desvio = Valor - mean(Valor),\n    Valor_norm = Desvio / sd(Valor)\n  )\n\n# A tibble: 20,006 × 6\n  Data                Usuario  Valor TransferID Desvio Valor_norm\n  &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 2018-12-06 22:19:19 Eduardo   599.  116241629 -2920.     -0.772\n2 2018-12-06 22:10:34 Júlio    4611.  115586504  1093.      0.289\n3 2018-12-06 21:59:50 Nathália 4418.  115079280   900.      0.238\n4 2018-12-06 21:54:13 Júlio    2740.  114972398  -778.     -0.206\n5 2018-12-06 21:41:27 Ana      1408.  116262934 -2110.     -0.558\n# ℹ 20,001 more rows\n\n\nCom isso, a parte fundamental de um mutate() é construirmos a expressão que produzirá os valores a serem alocados na nova coluna que estamos criando. Logo abaixo, consta uma lista de várias funções que você pode utilizar para formar a expressão que você deseja. Essa é uma lista parcial, logo, há diversas outras funções que você pode utilizar para calcular os valores dos quais você necessita.\n\nSomatórios: soma total de uma coluna - sum(); somatório por linha, ao longo de algumas colunas - operador +; somatório por linha, ao longo de várias colunas - rowSums().\nOperações cumulativas: somatório acumulado de uma coluna - cumsum(); média acumulada de uma coluna - cummean(); mínimo acumulado de uma coluna - cummin(); máximo acumulado de uma coluna - cummax().\nMedidas de posição: média de uma coluna - mean(); mediana de uma coluna - median(); média por linha, ao longo de várias colunas - rowMeans(); média móvel - roll_mean()2.\nMedidas de dispersão: desvio padrão de uma coluna - sd(); variância de uma coluna - var(); intervalo interquartil - IQR(); desvio absoluto da mediana - mad().\nOperadores aritméticos: soma (+); subtração (-); divisão (/); multiplicação (*); potência, ou elevar um número a x (^); restante da divisão (%%); apenas o número inteiro resultante da divisão (%/%); logaritmo - log().\nOperadores lógicos: aplique um teste lógico em cada linha, e preencha essa linha com x caso o teste resulte em TRUE, ou preencha com y caso o teste resulte em FALSE - if_else(); quando você quer aplicar uma operação parecida com if_else(), mas que há vários casos possíveis, um exemplo típico seria criar uma coluna de faixas etárias - case_when(); você também pode utilizar normalmente todos os operadores que vimos na seção de filter(), para criar um teste lógico sobre cada linha - &lt;, &lt;=, &gt;, &gt;=, ==, !=, !, &, |.\nFunções para discretizar variáveis contínuas: calcula intervalos de forma a encaixar o mesmo número de observações em cada intervalo (comumente chamados de quantis) - cut_number(); calcula intervalos com o mesmo alcance - cut_interval(); calcula intervalos de largura definida no argumento width - cut_width().\nFunções de defasagem e liderança: quando você precisa em algum cálculo naquela linha, utilizar o valor da linha anterior - lag(); ou ao invés do valor da linha anterior, você precisa do valor da linha posterior - lead().\n\nPorém, é necessário ter cautela. Como a função mutate() busca trabalhar com data.frame’s, é de suma importância, que você esteja sempre consciente das propriedades que essa estrutura carrega. Em especial, a propriedade de que as suas colunas devem possuir o mesmo número de elementos. Portanto, se o seu data.frame possui exatamente 10 mil linhas, você precisa se certificar de que cada expressão utilizada na função mutate(), vai gerar 10 mil elementos como resultado.\nNa hipótese de que alguma dessas expressões produzam, por exemplo, 9.999 elementos, um erro será acionado, pois esses 9,999 mil elementos não podem ser guardados em um data.frame que possui 10 mil linhas. Logo, a função mutate() lhe provê flexibilidade e eficiência, mas ela não é capaz de quebrar regras fundamentais da linguagem R.\nUm exemplo prático disso é encontrado quando tentamos calcular uma média móvel de alguma série temporal, ou de algum valor diário utilizando a função mutate(), como no exemplo abaixo. O erro ocorre devido a própria natureza do cálculo de uma média móvel, que gera uma “perda” de observações, e como consequência, um número menor de observações é gerado dentro do resultado. Perceba abaixo, que ao aplicarmos uma janela de cálculo de 5 observações, a função roll_mean() foi capaz de produzir 996 valores, consequentemente, perdemos 4 observações no processo.\n\nlibrary(RcppRoll)\nset.seed(1)\ndf &lt;- tibble(\n  dia = 1:1000,\n  valor = rnorm(1000)\n)\ndf %&gt;% \n  mutate(\n    media_movel = roll_mean(df$valor, n = 5)\n  )\n\nError in `mutate()`:\nℹ In argument: `media_movel = roll_mean(df$valor, n = 5)`.\nCaused by error:\n! `media_movel` must be size 1000 or 1, not 996.\nCompreendendo essa característica do cálculo de uma média móvel, a função roll_mean() oferece o argumento fill, no qual podemos pedir à função que complete as observações restantes com zeros, como no exemplo abaixo. Dessa forma, a função volta a produzir 1000 observações em seu resultado e, consequentemente, nenhum erro é acionado.\n\ndf %&gt;% \n  mutate(\n    media_movel = roll_mean(valor, n = 5, fill = 0, align = \"right\")\n  )\n\n# A tibble: 1,000 × 3\n    dia  valor media_movel\n  &lt;int&gt;  &lt;dbl&gt;       &lt;dbl&gt;\n1     1 -0.626       0    \n2     2  0.184       0    \n3     3 -0.836       0    \n4     4  1.60        0    \n5     5  0.330       0.129\n# ℹ 995 more rows\n\n\nDesse modo, estamos discutindo as possibilidades existentes de sua expressão fornecida à mutate(), produzir múltiplos valores. Todavia, diversas funções extremamente úteis, e que utilizamos com bastante frequência nessas expressões, resultam apenas em um único valor. Grandes exemplos são as funções mean() e sum(), que calculam a média e a soma de uma coluna, respectivamente.\nEm todas as ocasiões em que a sua expressão na função mutate() gerar um único valor, qualquer que ele seja, a função mutate() irá automaticamente replicar esse mesmo valor ao longo de toda a coluna que você acaba de criar. Vemos uma demonstração disso, ao criarmos abaixo, as colunas soma, prop e um_numero. Com essa ideia em mente, se temos diversos valores numéricos em uma dada coluna, nós podemos eficientemente calcular uma proporção desses valores em relação ao total de sua coluna, com o uso da função sum(), como no exemplo abaixo. Da mesma forma, nós podemos rapidamente normalizar uma coluna numérica segundo a fórmula de uma estatística Z, por meio das funções sd() e mean().\n\ndf &lt;- tibble(\n  id = 1:5,\n  x = c(2.5, 1.5, 3.2, 5.1, 2.2),\n  y = c(1, 2, 3, 4, 5)\n)\n\ndf &lt;- df %&gt;% \n  mutate(\n    soma = sum(x),\n    prop = y * 100 / sum(y),\n    um_numero = 25,\n    norm = (x - mean(x)) / sd(x)\n  )\n\ndf\n\n# A tibble: 5 × 7\n     id     x     y  soma  prop um_numero   norm\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1     1   2.5     1  14.5  6.67        25 -0.291\n2     2   1.5     2  14.5 13.3         25 -1.02 \n3     3   3.2     3  14.5 20           25  0.219\n4     4   5.1     4  14.5 26.7         25  1.60 \n5     5   2.2     5  14.5 33.3         25 -0.510",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#sec:group_by_summarise",
    "href": "Capítulos/04-transformacao.html#sec:group_by_summarise",
    "title": "5  Transformando dados com dplyr",
    "section": "5.9 Agrupando dados com group_by() e gerando estatísticas sumárias com summarise()",
    "text": "5.9 Agrupando dados com group_by() e gerando estatísticas sumárias com summarise()\nEm diversas áreas é muito comum encontramos variáveis qualitativas nas bases de dados. Variáveis desse tipo, usualmente definem grupos ou estratos de uma amostra, população ou medida, como faixas etárias ou faixas de valor salarial. Se você está analisando, por exemplo, dados epidemiológicos, você em geral deseja examinar se uma dada doença está ocorrendo com maior ou menor intensidade em um determinado grupo de sua população.\nOu seja, será que fatores como a cor de pele, a idade, o gênero, a orientação sexual ou a localidade de um indivíduo são capazes de afetar as suas chances de ser infectado por essa doença? De outra maneira, será que essas variáveis qualitativas são capazes de gerar, por exemplo, diferenças no salário deste indivíduo? Da mesma forma, quando analisamos a performance de determinadas firmas, desejamos saber se a localidade, o setor, o tamanho, o investimento e a receita total, além do número de funcionários dessa firma são capazes de prover alguma vantagem em relação aos seus concorrentes.\nPara esse tipo de estudo, o pacote dplyr nos oferece a função group_by() que fundamentalmente altera o comportamento de funções como mutate() e summarise(), e nos permite calcular estatísticas e aplicarmos operações dentro de cada grupo presente em nossos dados. Ou seja, você geralmente usa group_by() em conjunto com outras funções do pacote. Como um exemplo inicial, vamos utilizar a tabela minas_pop, que contém dados de população e PIB (Produto Interno Bruto) dos 853 municípios do estado de Minas Gerais.\n\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo &lt;- \"populacao.csv\"\nminas_pop &lt;- read_csv2(paste0(github, pasta, arquivo))\nminas_pop\n\n# A tibble: 853 × 7\n  IBGE2   IBGE Munic               Populacao   Ano      PIB Intermediaria\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;        \n1    10 310010 Abadia dos Dourados      6972  2017 33389769 Uberlândia   \n2    20 310020 Abaeté                  23223  2017 96201158 Divinópolis  \n3    30 310030 Abre Campo              13465  2017 29149429 Juíz de Fora \n4    40 310040 Acaiaca                  3994  2017  2521892 Juíz de Fora \n5    50 310050 Açucena                  9575  2017 15250077 Ipatinga     \n# ℹ 848 more rows\n\n\nComo demonstramos na seção anterior, a função sum() calcula a soma total de uma coluna. Logo, se aplicássemos a função sum() sobre a coluna Populacao, teríamos a população total do estado de Minas Gerais. Porém, e se desejássemos calcular a população total de cada uma das regiões intermediárias (presentes na coluna Intermediaria) que compõe o estado de Minas Gerais?\nPara isso, nós podemos utilizar a função group_by() para determinar onde em nossa tabela se encontram os grupos de nossos dados. No nosso caso, esses grupos estão na coluna Intermediaria. Dessa forma, após utilizarmos o group_by(), perceba abaixo que os totais calculados pela função sum(), e que estão apresentados na coluna Pop_total, variam ao longo da tabela de acordo com o valor presente na coluna Intermediaria. Logo, temos agora a população total de cada região intermediária na coluna Pop_total. Da mesma maneira, ao invés de possuírmos uma proporção baseada na população do estado, as proporções de cada município expostas na coluna Prop_pop_mun possuem como denominador, a população total da região intermediária a qual o município pertence.\n\nminas_pop %&gt;% \n  select(-Ano, -PIB) %&gt;% \n  group_by(Intermediaria) %&gt;% \n  mutate(\n    Pop_total = sum(Populacao),\n    Prop_pop_mun = Populacao * 100 / Pop_total\n  )\n\n# A tibble: 853 × 7\n# Groups:   Intermediaria [13]\n  IBGE2   IBGE Munic              Populacao Intermediaria Pop_total Prop_pop_mun\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;        &lt;dbl&gt;\n1    10 310010 Abadia dos Dourad…      6972 Uberlândia      1161513        0.600\n2    20 310020 Abaeté                 23223 Divinópolis     1300658        1.79 \n3    30 310030 Abre Campo             13465 Juíz de Fora    2334530        0.577\n4    40 310040 Acaiaca                 3994 Juíz de Fora    2334530        0.171\n5    50 310050 Açucena                 9575 Ipatinga        1022384        0.937\n# ℹ 848 more rows\n\n\nPara verificarmos se os grupos em uma dada tabela estão definidos, podemos observar se a descrição Groups se encontra logo abaixo às dimensões da tabela (tibble: 853 x 7). Essa descrição Groups, acaba nos informando a coluna (ou o conjunto de colunas) envolvidas nessa definição, além do número de grupos que estão contidos em nossa tabela. Logo, pelo resultado do exemplo acima, temos 13 grupos, ou 13 regiões intermediárias diferentes presentes na coluna Intermediaria.\nComo um outro exemplo, dessa vez, em um contexto relativamente atual, podemos utilizar os dados de COVID-19 presentes na tabela abaixo, denominada covid. Nessa tabela, temos o acumulado do número de casos confirmados do vírus em cada estado brasileiro, durante o período de 25 de Fevereiro a 27 de Julho de 2020.\n\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo &lt;- \"covid.csv\"\ncovid &lt;- read_csv2(paste0(github, pasta, arquivo))\ncovid\n\n# A tibble: 3,625 × 4\n  data       estado casos mortes\n  &lt;date&gt;     &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 2020-03-17 AC         3      0\n2 2020-03-18 AC         3      0\n3 2020-03-19 AC         4      0\n4 2020-03-20 AC         7      0\n5 2020-03-21 AC        11      0\n# ℹ 3,620 more rows\n\n\nPortanto, uma atividade muito comum com os dados da COVID-19, seria calcularmos a variação diária no número de casos acumulados. Tal cálculo pode ser atingido, através dos valores acumulados na coluna casos, ao subtrairmos do valor da linha corrente, o valor da linha anterior nessa mesma coluna. Para incluirmos o valor da linha anterior em nosso cálculo, podemos usar a função lag(), como no código abaixo:\n\ncovid %&gt;%\n  mutate(\n    casos_var = casos - lag(casos),\n    mortes_var = mortes - lag(mortes)\n  )\n\nPorém, temos um problema nessa operação, que emerge do fato de que não delimitamos os grupos da tabela. Sem esses grupos definidos, a função mutate() vai aplicar a expressão casos - lag(casos) sobre toda a tabela de uma vez só. O correto, seria que nós aplicássemos essa operação separadamente sobre os dados de cada estado.\nDito de outra forma, ao não dizermos que cada estado deveria ser tratado de forma separada dos demais, estamos invadindo os limites de cada estado com o cálculo pertencente a outros estados. Em outras palavras, o problema que emerge do código anterior, em que não definimos os grupos, se encontra nas linhas que definem os limites entre cada estado, ou as linhas que marcam a transição entre os dados do estado A para os dados do estado B. Logo, caso não definirmos esses grupos, estaremos utilizando no cálculo da variação presente na primeira linha referente ao estado de São Paulo, o número acumulado de casos localizado na última linha pertencente ao estado que vem antes de São Paulo na base (o estado de Sergipe).\nPor isso, ao utilizarmos a função group_by() sobre a tabela covid, faremos com que a função mutate() esteja consciente dos limites entre os dados de cada estado, e que, portanto, respeite esses limites durante o cálculo dessa variação.\n\ncovid_novo &lt;- covid %&gt;%\n  group_by(estado) %&gt;% \n  mutate(\n    casos_var = casos - lag(casos),\n    mortes_var = mortes - lag(mortes)\n  )\n\ncovid_novo \n\n# A tibble: 3,625 × 6\n# Groups:   estado [27]\n  data       estado casos mortes casos_var mortes_var\n  &lt;date&gt;     &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 2020-03-17 AC         3      0        NA         NA\n2 2020-03-18 AC         3      0         0          0\n3 2020-03-19 AC         4      0         1          0\n4 2020-03-20 AC         7      0         3          0\n5 2020-03-21 AC        11      0         4          0\n# ℹ 3,620 more rows\n\n\nAgora que vimos a função group_by(), podemos prosseguir para a função summarise(), que busca sumarizar, sintetizar ou reduzir múltiplos valores de seu data.frame em poucas linhas. Logo, se eu aplicar a função summarise() sobre a tabela minas_pop, um novo data.frame será gerado, e ele irá conter provavelmente uma única linha. O seu trabalho é definir os valores que vão ocupar essa única linha.\nPor isso, dentro da função summarise(), devemos fornecer expressões, exatamente da mesma forma que fornecemos em mutate(). Essas expressões vão ser responsáveis por calcular os valores que vão preencher as linhas presentes no novo data.frame criado. Contudo, ao invés de retornar múltiplos valores, essas expressões delineadas por você devem retornar um único valor ou uma única estatística sumária, de modo que o novo data.frame resultante de summarise() vai possuir uma única linha, e uma coluna para cada expressão definida. Como exemplo, podemos calcular o somatório total e a média da coluna Populacao da seguinte forma:\n\nminas_pop %&gt;% \n  summarise(\n    total_pop = sum(Populacao),\n    media_pop = mean(Populacao)\n  )\n\n# A tibble: 1 × 2\n  total_pop media_pop\n      &lt;dbl&gt;     &lt;dbl&gt;\n1  21040662    24667.\n\n\nApesar dessas características, a função summarise() é normalmente utilizada em conjunto com a função group_by(). Pois ao definirmos os grupos de nossa tabela, a função summarise() passa a produzir uma linha para cada grupo presente em nossa tabela. Logo, o cálculo da população total e da população média anterior, que antes produzia uma única linha, passa a gerar 13 valores diferentes e, portanto, 13 linhas diferentes ao agruparmos os dados de acordo com a coluna Intermediaria. Podemos ainda aplicar a função n(), com o objetivo de descobrirmos quantas linhas, ou quantos municípios representam cada região intermediária do estado.\n\nminas_pop %&gt;% \n  group_by(Intermediaria) %&gt;% \n  summarise(\n    total_pop = sum(Populacao),\n    media_pop = mean(Populacao),\n    numero_municipios = n()\n  )\n\n# A tibble: 13 × 4\n  Intermediaria        total_pop media_pop numero_municipios\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;             &lt;int&gt;\n1 Barbacena               772694    15769.                49\n2 Belo Horizonte         6237890    84296.                74\n3 Divinópolis            1300658    21322.                61\n4 Governador Valadares    771775    13306.                58\n5 Ipatinga               1022384    23236                 44\n# ℹ 8 more rows\n\n\nNeste momento, vale a pena comentar também, sobre a função count(), que se traduz como um atalho para a junção das funções group_by(), summarise() e n(). Logo, ao invés de construirmos toda a estrutura de group_by() e summarise(), nós poderíamos rapidamente contabilizar o número de municípios em cada região intermediária, através da função count(), como no exemplo abaixo. Lembrando que cada coluna fornecida à count(), será repassada a group_by() e, portanto, será responsável por definir os grupos nos quais a contagem será aplicada. Logo, se definíssemos a função como count(minas_pop, Intermediaria, Ano), estaríamos calculando o número de municípios existentes em cada região intermediária, dentro de um dado ano descrito em nossa tabela.\n\nminas_pop %&gt;% count(Intermediaria)\n\n# A tibble: 13 × 2\n  Intermediaria            n\n  &lt;chr&gt;                &lt;int&gt;\n1 Barbacena               49\n2 Belo Horizonte          74\n3 Divinópolis             61\n4 Governador Valadares    58\n5 Ipatinga                44\n# ℹ 8 more rows\n\n\nPara além desses pontos, vale destacar que certos momentos em que você necessita de várias colunas para identificar um único grupo de sua tabela, não são incomuns. Por isso, você pode incluir mais de uma coluna dentro da função group_by(). Por exemplo, suponha que você possua na tabela covid, uma coluna que apresenta o mês ao qual cada linha se encontra. Suponha ainda, que você deseja calcular a média mensal de novos casos diários em cada estado. Para realizar essa ação, você precisa aplicar o cálculo da média não apenas dentro de cada estado, mas também, dentro de cada mês disponível na base. Logo, precisamos fornecer tanto a coluna estado quanto a coluna mes à função group_by(), como no exemplo abaixo.\n\ncovid_novo %&gt;% \n  ungroup() %&gt;% \n  mutate(mes = as.integer(format(data, \"%m\"))) %&gt;% \n  group_by(estado, mes) %&gt;% \n  summarise(\n    media_novos_casos = mean(casos_var, na.rm = T)\n  )\n\n# A tibble: 136 × 3\n# Groups:   estado [27]\n  estado   mes media_novos_casos\n  &lt;chr&gt;  &lt;int&gt;             &lt;dbl&gt;\n1 AC         3              2.79\n2 AC         4             12.1 \n3 AC         5            188.  \n4 AC         6            234.  \n5 AC         7            205.  \n# ℹ 131 more rows\n\n\nPerceba também acima, que utilizamos a função ungroup() sobre a tabela covid_novo, antes de aplicarmos a função group_by(). O motivo para tal operação, está no fato de que a tabela covid_novo já se encontrava agrupada desde o momento em que ela foi criada. Por isso, antes de aplicarmos novamente a função group_by() com o uso das colunas estado e mes, precisamos remover a definição de grupos anterior. Tudo que a função ungroup() faz é remover a definição de grupos anterior da tabela (caso uma definição de grupos de fato exista na tabela).\nPortanto, a partir do momento em que você “terminou” de utilizar as operações “por grupo” em sua tabela, e deseja ignorar novamente esses grupos em suas próximas etapas, você deve retirar a definição dos grupos de sua tabela, por meio da função ungroup().",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#distribuindo-cálculos-com-a-função-across",
    "href": "Capítulos/04-transformacao.html#distribuindo-cálculos-com-a-função-across",
    "title": "5  Transformando dados com dplyr",
    "section": "5.10 Distribuindo cálculos com a função across()",
    "text": "5.10 Distribuindo cálculos com a função across()\nA função across() lhe permite aplicar os métodos de seleção que vimos em select() dentro dos demais verbos do pacote dplyr (mutate(), summarise() e arrange()). Para mais, o principal objetivo dessa função está em prover uma maneira muito mais prática de empregarmos uma mesma operação ao longo de (daí o nome de across) várias colunas.\nPor exemplo, suponha que você desejasse calcular o logaritmo de todas as colunas numéricas da tabela mpg. Temos então, que aplicar a mesma operação sobre 5 colunas diferentes, mais especificamente, as colunas displ, year, cyl, cty e hwy. Com o que vimos até o momento, você provavelmente faria tal ação da seguinte forma:\n\nmpg %&gt;% \n  mutate(\n    displ = log(displ),\n    year = log(year),\n    cyl = log(cyl),\n    cty = log(cty),\n    hwy = log(hwy)\n  )\n\nPorém, além de ser tedioso repetir o mesmo código várias vezes, você incorre em uma grande chance de erro. Pois os nossos olhos tendem a prestar atenção no que é diferente dos demais, no que se destaca do ambiente, e não sobre blocos e blocos de comandos que são basicamente idênticos.\nCom isso, a função across() provê um excelente mecanismo para automatizarmos essa aplicação. Nessa função, temos dois argumentos principais a serem preenchidos: 1).cols, que representa o conjunto de colunas onde a ação desejada será aplicada; 2) .fns, a função ou a expressão que será empregada em cada coluna (neste argumento, você pode fornecer apenas o nome da função). Com isso, poderíamos reescrever a operação anterior como:\n\n## Aplicar log() na terceira, quarta,\n## quinta, oitava e nona coluna da tabela mpg:\nmpg %&gt;% \n  mutate(across(.cols = c(3:5, 8:9), .fns = log))\n\n# A tibble: 234 × 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 audi         a4    0.588  7.60  1.39 auto(l5)   f      2.89  3.37 p     compa…\n2 audi         a4    0.588  7.60  1.39 manual(m5) f      3.04  3.37 p     compa…\n3 audi         a4    0.693  7.60  1.39 manual(m6) f      3.00  3.43 p     compa…\n4 audi         a4    0.693  7.60  1.39 auto(av)   f      3.04  3.40 p     compa…\n5 audi         a4    1.03   7.60  1.79 auto(l5)   f      2.77  3.26 p     compa…\n# ℹ 229 more rows\n\n\nPortanto, em across() você é capaz de aplicar qualquer um dos 5 métodos que vimos em select(). Como um outro exemplo, podemos aplicar a função log() sobre qualquer coluna que se inicie pela letra “h”, com o comando abaixo:\n\nmpg %&gt;% \n  mutate(across(.cols = starts_with(\"h\"), .fns = log))\n\n# A tibble: 234 × 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 audi         a4      1.8  1999     4 auto(l5)   f        18  3.37 p     compa…\n2 audi         a4      1.8  1999     4 manual(m5) f        21  3.37 p     compa…\n3 audi         a4      2    2008     4 manual(m6) f        20  3.43 p     compa…\n4 audi         a4      2    2008     4 auto(av)   f        21  3.40 p     compa…\n5 audi         a4      2.8  1999     6 auto(l5)   f        16  3.26 p     compa…\n# ℹ 229 more rows\n\n\nPor outro lado, caso você necessite aplicar várias funções em cada coluna, é melhor que você crie uma nova função (a partir da palavra-chave function) dentro de across(), contendo as operações que você deseja aplicar. Pois dessa maneira, você possui um melhor controle sobre em que partes do cálculo, os valores de cada coluna serão posicionados.\nPor exemplo, podemos normalizar todas as colunas numéricas da tabela mpg, por uma estatística Z. Perceba abaixo, que nesse caso, precisamos utilizar o valor da coluna em 3 ocasiões: duas vezes no numerador, para calcularmos o desvio de cada valor da coluna em relação a sua média; e uma vez no denominador, para calcularmos o desvio padrão. Repare também, que ao menos quatro funções são utilizadas dentro desse cálculo: as funções mean() e sd(), além dos operadores de subtração (-) e de divisão (/).\n\nmpg %&gt;% \n  mutate(across(\n    .cols = where(is.numeric),\n    .fns = function(x) x - mean(x) / sd(x)\n  ))\n\n# A tibble: 234 × 11\n  manufacturer model  displ  year   cyl trans      drv     cty   hwy fl    class\n  &lt;chr&gt;        &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1 audi         a4    -0.887 1555. 0.346 auto(l5)   f      14.0  25.1 p     comp…\n2 audi         a4    -0.887 1555. 0.346 manual(m5) f      17.0  25.1 p     comp…\n3 audi         a4    -0.687 1564. 0.346 manual(m6) f      16.0  27.1 p     comp…\n4 audi         a4    -0.687 1564. 0.346 auto(av)   f      17.0  26.1 p     comp…\n5 audi         a4     0.113 1555. 2.35  auto(l5)   f      12.0  22.1 p     comp…\n# ℹ 229 more rows\n\n\nCom isso, a função summarise() também se torna um local extremamente útil para o emprego da função across(). Pois através de across(), nós podemos rapidamente aplicar uma função sobre cada coluna que desejamos sintetizar com summarise(). Por exemplo, somos capazes de extrair o valor total de todas as colunas numéricas da tabela mpg, por meio dos seguintes comandos:\n\nmpg %&gt;% \n  group_by(cyl) %&gt;% \n  summarise(across(\n    .cols = where(is.numeric),\n    .fns = sum\n  ))\n\n# A tibble: 4 × 5\n    cyl displ   year   cty   hwy\n  &lt;int&gt; &lt;dbl&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     4  174. 162243  1702  2333\n2     5   10    8032    82   115\n3     6  269. 158227  1281  1803\n4     8  359. 140317   880  1234",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#removendo-duplicatas-com-distinct",
    "href": "Capítulos/04-transformacao.html#removendo-duplicatas-com-distinct",
    "title": "5  Transformando dados com dplyr",
    "section": "5.11 Removendo duplicatas com distinct()",
    "text": "5.11 Removendo duplicatas com distinct()\nÀs vezes, os nossos dados chegam com algum erro de registro, e usualmente, esse erro se manifesta na forma de registros duplicados. Nessa seção, veremos o uso da função distinct() como um mecanismo útil para eliminarmos observações duplicadas em sua tabela. Como um exemplo inicial, podemos utilizar a tabela ponto, criada pelos comandos abaixo:\n\nponto &lt;- tibble(\n  usuario = \"Ana\",\n  dia = c(1, 1, 1, 2, 2),\n  hora = c(14, 14, 18, 8, 13),\n  minuto = c(30, 30, 50, 0, 30),\n  tipo = c(\"E\", \"E\", \"S\", \"E\", \"E\"),\n  mes = 3,\n  ano = 2020\n)\n\nponto\n\n# A tibble: 5 × 7\n  usuario   dia  hora minuto tipo    mes   ano\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Ana         1    14     30 E         3  2020\n2 Ana         1    14     30 E         3  2020\n3 Ana         1    18     50 S         3  2020\n4 Ana         2     8      0 E         3  2020\n5 Ana         2    13     30 E         3  2020\n\n\nInicialmente, a função distinct() funciona da mesma maneira que a função unique(). Porém, a função unique(): 1) pode ser aplicada em praticamente qualquer tipo de estrutura; 2) o tipo de estrutura adotado em seu resultado tende a variar em diversas aplicações. Já a função distinct() (assim como as demais funções do pacote dplyr) irá sempre aceitar um data.frame como input e gerar um novo data.frame como output. Logo, se aplicarmos distinct() sobre a tabela ponto, temos o seguinte resultado:\n\nponto_dis &lt;- distinct(ponto)\nponto_dis\n\n# A tibble: 4 × 7\n  usuario   dia  hora minuto tipo    mes   ano\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Ana         1    14     30 E         3  2020\n2 Ana         1    18     50 S         3  2020\n3 Ana         2     8      0 E         3  2020\n4 Ana         2    13     30 E         3  2020\n\n\nRepare no resultado acima, que a função distinct() eliminou a segunda linha da tabela ponto, pois essa era uma duplicata da primeira linha. Para mais, a função distinct() nos permite aplicar a função sobre colunas específicas do data.frame em questão. No exemplo acima, nós omitimos essa funcionalidade, e pedimos para que a função distinct() fosse aplicada sobre a toda a tabela. Isso significa, que ao não definirmos uma coluna ou um conjunto de colunas em particular, distinct() vai utilizar a combinação dos valores de todas as colunas para determinar os valores únicos presentes em sua tabela e, portanto, eliminar os valores duplicados segundo essa abordagem.\nComo exemplo, podemos aplicar a função sobre as colunas usuario e tipo. Dessa forma, distinct() nos retorna um novo data.frame contendo os valores únicos presentes nessas colunas. No entanto, perceba que um efeito colateral foi gerado, pois nós perdemos todas as demais colunas da tabela ponto durante o processo. Isso ocorre em todas as ocasiões em que listamos uma combinação de colunas em distinct(). Para evitar esse comportamento, você pode definir o argumento .keep_all para TRUE, como no exemplo abaixo.\n\nponto_dis &lt;- distinct(ponto, usuario, tipo)\nponto_dis\n\n# A tibble: 2 × 2\n  usuario tipo \n  &lt;chr&gt;   &lt;chr&gt;\n1 Ana     E    \n2 Ana     S    \n\nponto_dis &lt;- distinct(ponto, usuario, tipo, .keep_all = TRUE)\nponto_dis\n\n# A tibble: 2 × 7\n  usuario   dia  hora minuto tipo    mes   ano\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Ana         1    14     30 E         3  2020\n2 Ana         1    18     50 S         3  2020\n\n\nCom isso, se desejamos eliminar os valores duplicados em nossas tabelas, podemos rapidamente aplicar a função distinct() sobre toda a tabela. Contudo, haverá momentos em que combinações específicas de colunas devem ser utilizadas para determinarmos as observações únicas da tabela, ao invés de todas as colunas disponíveis. Para isso, você deve listar os nomes das colunas a serem utilizadas pela função distinct() neste processo. Além disso, você geralmente vai desejar utilizar a configuração .keep_all = TRUE durante essa situação, com o objetivo de conservar as demais colunas da tabela no resultado de distinct().\nAdemais, lembre-se que você pode utilizar a função across() para ter acesso aos mecanismos de seleção de select(), para definir o conjunto de colunas a ser empregado por distinct(). Por exemplo, eu posso encontrar todos os valores únicos criados pela combinação entre as colunas dia e tipo, por meio do seguinte comando:\n\ndistinct(ponto, across(c(2, 5)), .keep_all = TRUE)\n\n# A tibble: 3 × 7\n  usuario   dia  hora minuto tipo    mes   ano\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Ana         1    14     30 E         3  2020\n2 Ana         1    18     50 S         3  2020\n3 Ana         2     8      0 E         3  2020",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#combinando-tabelas-com-bind_cols-e-bind_rows",
    "href": "Capítulos/04-transformacao.html#combinando-tabelas-com-bind_cols-e-bind_rows",
    "title": "5  Transformando dados com dplyr",
    "section": "5.12 Combinando tabelas com bind_cols() e bind_rows()",
    "text": "5.12 Combinando tabelas com bind_cols() e bind_rows()\nOs pacotes básicos do R oferecem as funções rbind() e cbind(), que lhe permite combinar objetos. Porém, o pacote dplyr oferece implementações mais rápidas e completas desse mecanismo, através das funções bind_cols() e bind_rows(). Do mesmo modo que as demais funções do pacote, bind_cols() e bind_rows() aceitam um conjunto de data.frame’s como input, e lhe retornam um novo data.frame como output.\nComo exemplo inicial, suponha que você possua o conjunto de tabelas abaixo. Essas tabelas contêm dados das vendas de três lojas diferentes.\n\nsavassi &lt;- tibble(\n  dia = as.Date(c(\"2020-03-01\", \"2020-03-02\", \"2020-03-03\",\n                  \"2020-03-04\")),\n  produtoid = c(\"10241\", \"10241\", \"10032\", \"15280\"),\n  loja = \"Savassi\",\n  unidades = c(1, 2, 1, 1),\n  valor = c(15.5, 31, 12.4, 16.7)\n)\n\nprado &lt;- tibble(\n  dia = as.Date(c(\"2020-03-10\", \"2020-03-11\", \"2020-03-12\")),\n  produtoid = c(\"15280\", \"10032\", \"10032\"),\n  loja = \"Prado\",\n  unidades = c(3, 4, 2),\n  valor = c(50.1, 49.6, 24.8)\n)\n\ncentro &lt;- tibble(\n  dia = as.Date(c(\"2020-03-07\", \"2020-03-10\", \"2020-03-12\")),\n  produtoid = c(\"15280\", \"15280\", \"15280\"),\n  loja = \"Centro\",\n  unidades = c(5, 1, 1),\n  valor = c(83.5, 16.7, 16.7)\n)\n\nSupondo que você seja um analista da empresa dona dessas lojas, e que foi delegado a você, a tarefa de analisar os dados dessas tabelas, você terá no mínimo o triplo de trabalho, caso mantenha essas tabelas separadas. Pois cada etapa de sua análise teria de ser replicar em três lugares diferentes. Por isso, a melhor opção é reunir essas tabelas em um lugar só. Pois dessa maneira, você precisa aplicar as suas operações em um único lugar.\nOu seja, a motivação para o uso das funções bind_rows() e bind_cols(), surge em geral, a partir da dificuldade que temos em aplicar a mesma função em diversos pontos de nosso trabalho, além da manutenção e monitoramento dos resultados gerados em cada um desses pontos envolvidos nesse serviço. Portanto, se você possui um grande conjunto de tabelas, que são semelhantes entre si, e você precisa aplicar os mesmos passos sobre cada uma delas, é interessante que você tente juntar essas tabelas em uma só. Dessa maneira, você pode direcionar o seu foco e as suas energias para um só local.\nComo as tabelas savassi, prado e centro possuem as mesmas colunas, faz mais sentido unirmos as linhas de cada tabela para formarmos a nossa tabela única. Para isso, basta listarmos essas tabelas dentro da função bind_rows(), como demonstrado abaixo. Uma outra opção, seria provermos uma lista de data.frame’s à função, o que também está demonstrado abaixo:\n\nbind_rows(savassi, prado, centro)\n\n# A tibble: 10 × 5\n  dia        produtoid loja    unidades valor\n  &lt;date&gt;     &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 2020-03-01 10241     Savassi        1  15.5\n2 2020-03-02 10241     Savassi        2  31  \n3 2020-03-03 10032     Savassi        1  12.4\n4 2020-03-04 15280     Savassi        1  16.7\n5 2020-03-10 15280     Prado          3  50.1\n# ℹ 5 more rows\n\n\n\n## Uma alternativa seria fornecermos uma lista\n## contendo as tabelas a serem unidas:\nlista &lt;- list(savassi, prado, centro)\nbind_rows(lista)\n\nPortanto, ao unir as linhas de cada tabela, a função bind_rows() está de certa forma “empilhando” uma tabela em cima da outra. Mas para que este tipo de operação ocorra de maneira adequada, é importante que as colunas de todas as tabelas estejam nomeadas igualmente. Dito de outra forma, as tabelas envolvidas nesse cálculo, devem ser formadas pelo mesmo grupo de colunas. Essas colunas podem se encontrar em ordens diferentes ao longo das tabelas, mas elas precisam necessariamente estar nomeadas da mesma maneira. Caso alguma coluna em pelo menos uma das tabelas possua um nome diferente de seus pares, a função vai alocar os seus valores em uma coluna separada das demais, e isso geralmente não é o que você deseja.\n\ncolnames(centro)[2:3] &lt;- c(\"ProdutoID\", \"Loja\")\nbind_rows(savassi, prado, centro)\n\n# A tibble: 10 × 7\n  dia        produtoid loja    unidades valor ProdutoID Loja \n  &lt;date&gt;     &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;\n1 2020-03-01 10241     Savassi        1  15.5 &lt;NA&gt;      &lt;NA&gt; \n2 2020-03-02 10241     Savassi        2  31   &lt;NA&gt;      &lt;NA&gt; \n3 2020-03-03 10032     Savassi        1  12.4 &lt;NA&gt;      &lt;NA&gt; \n4 2020-03-04 15280     Savassi        1  16.7 &lt;NA&gt;      &lt;NA&gt; \n5 2020-03-10 15280     Prado          3  50.1 &lt;NA&gt;      &lt;NA&gt; \n# ℹ 5 more rows\n\n\nPor outro lado, quando estamos planejando unir tabelas a partir de suas colunas, a nossa preocupação principal deve ser com o número de linhas de cada tabela. Com isso, quando utilizar a função bind_cols(), é essencial que as tabelas envolvidas possuam exatamente o mesmo número de linhas. Ou seja, no caso da função bind_cols(), é primordial que as tabelas fornecidas à função, possuam o mesmo número de linhas, pois caso contrário, um erro será acionado pela função, e você não poderá prosseguir.\nTendo esse ponto em mente, você utiliza a função bind_cols() do mesmo modo que a função bind_rows(). Basta listar as tabelas a serem unidas dentro da função, ou fornecer uma lista contendo os data.frame’s a serem fundidos. Veja abaixo, um exemplo com as tabelas tab1 e tab2.\n\ntab1 &lt;- tibble(\n  dia = 1:5,\n  valor = round(rnorm(5), 2)\n)\ntab2 &lt;- tibble(\n  id = c(\"104\", \"104\", \"105\", \"106\", \"106\"),\n  nome = \"Ana\"\n)\n\nbind_cols(tab1, tab2)\n\n# A tibble: 5 × 4\n    dia valor id    nome \n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1  1.13 104   Ana  \n2     2  1.11 104   Ana  \n3     3 -0.87 105   Ana  \n4     4  0.21 106   Ana  \n5     5  0.07 106   Ana  \n\n\n\n## Uma alternativa seria fornecermos uma lista\n## contendo as tabelas a serem unidas:\nlista &lt;- list(tab1, tab2)\nbind_cols(lista)\n\n\n\n\n\nPENG, R. D. R Programming for Data Science. [s.l.] Leanpub, 2015.\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/04-transformacao.html#footnotes",
    "href": "Capítulos/04-transformacao.html#footnotes",
    "title": "5  Transformando dados com dplyr",
    "section": "",
    "text": "https://dplyr.tidyverse.org/↩︎\nEssa função pertence ao pacote RcppRoll e, portanto, para ter acesso à função você deve possuir esse pacote instalado em sua máquina, e chamar por ele em sua sessão.↩︎",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Transformando dados com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/06-dados-relacionais.html",
    "href": "Capítulos/06-dados-relacionais.html",
    "title": "6  Introdução a base de dados relacionais com dplyr",
    "section": "",
    "text": "6.1 Introdução e pré-requisitos\nSegundo NIELD (2016, p. 53), joins são uma das funcionalidades que definem a linguagem SQL (Structured Query Language). Por isso, joins são um tipo de operação muito relacionado à RDBMS (Relational DataBase Management Systems), que em sua maioria, utilizam a linguagem SQL. Logo, essa seção será muito familiar para aqueles que possuem experiência com essa linguagem.\nPara executarmos uma operação de join, os pacotes básicos do R oferecem a função merge(). Entretanto, vamos abordar o pacote dplyr neste capítulo, que também possui funções especializadas neste tipo de operação. Com isso, para ter acesso às funções que vamos mostrar aqui, você pode chamar tanto pelo pacote dplyr quanto pelo tidyverse.\nlibrary(tidyverse)\nlibrary(dplyr)",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introdução a base de dados relacionais com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/06-dados-relacionais.html#sec:relational_data_keys",
    "href": "Capítulos/06-dados-relacionais.html#sec:relational_data_keys",
    "title": "6  Introdução a base de dados relacionais com dplyr",
    "section": "6.2 Dados relacionais e o conceito de key",
    "text": "6.2 Dados relacionais e o conceito de key\nNormalmente, trabalhamos com diversas bases de dados diferentes ao mesmo tempo. Pois é muito incomum, que uma única tabela contenha todas as informações das quais necessitamos e, por isso, transportar os dados de uma tabela para outra se torna uma atividade essencial em muitas ocasiões.\nLogo, de alguma maneira, os dados presentes nessas diversas tabelas se relacionam entre si. Por exemplo, suponha que você possua uma tabela contendo o PIB dos municípios do estado de Minas Gerais, e uma outra tabela contendo dados demográficos desses mesmos municípios. Se você deseja unir essas duas tabelas em uma só, você precisa de algum mecanismo que possa conectar um valor do município X na tabela A com o valor da tabela B correspondente ao mesmo município X, e através dessa conexão, conduzir o valor da tabela A para esse local específico da tabela B, ou vice-versa. O processo que realiza esse cruzamento entre as informações, e que por fim, mescla ou funde as duas tabelas de acordo com essas conexões, é chamado de join.\nPor isso, dizemos que os nossos dados são “relacionais”. Pelo fato de que nós possuímos diversas tabelas que descrevem os mesmos indivíduos, municípios, firmas ou eventos. Mesmo que essas tabelas estejam trazendo variáveis ou informações muito diferentes desses indivíduos, elas possuem essa característica em comum e, com isso, possuem uma relação entre si, e vamos frequentemente nos aproveitar dessa relação para executarmos análises mais completas.\nPorém, para transportarmos esses dados de uma tabela a outra, precisamos de alguma chave, ou de algum mecanismo que seja capaz de identificar as relações entre as duas tabelas. Em outras palavras, se temos na tabela A, um valor pertencente ao indivíduo X, e queremos transportar esse valor para a tabela B, nós precisamos de algum meio que possa identificar o local da tabela B que seja referente ao indivíduo X. O mecanismo que permite essa comparação, é o que chamamos de key ou de “chave”.\n\nd &lt;- c(\"1943-07-26\", \"1940-09-10\", \"1942-06-18\", \"1943-02-25\", \"1940-07-07\")\n\ninfo &lt;- tibble(\n  name = c(\"Mick\", \"John\", \"Paul\", \"George\", \"Ringo\"),\n  band = c(\"Rolling Stones\", \"Beatles\", \"Beatles\", \"Beatles\", \"Beatles\"),\n  born = as.Date(d),\n  children = c(TRUE)\n)\n\nband_instruments &lt;- tibble(\n  name = c(\"John\", \"Paul\", \"Keith\"),\n  plays = c(\"guitar\", \"bass\", \"guitar\")\n)\n\nComo exemplo inicial, vamos utilizar a tabela info, que descreve características pessoais de um conjunto de músicos famosos. Também temos a tabela band_instruments, que apenas indica qual o instrumento musical utilizado por parte dos músicos descritos na tabela info.\n\ninfo\n\n# A tibble: 5 × 4\n  name   band           born       children\n  &lt;chr&gt;  &lt;chr&gt;          &lt;date&gt;     &lt;lgl&gt;   \n1 Mick   Rolling Stones 1943-07-26 TRUE    \n2 John   Beatles        1940-09-10 TRUE    \n3 Paul   Beatles        1942-06-18 TRUE    \n4 George Beatles        1943-02-25 TRUE    \n5 Ringo  Beatles        1940-07-07 TRUE    \n\nband_instruments\n\n# A tibble: 3 × 2\n  name  plays \n  &lt;chr&gt; &lt;chr&gt; \n1 John  guitar\n2 Paul  bass  \n3 Keith guitar\n\n\nPortanto, precisamos de uma key para detectarmos as relações entre as tabelas info e band_instruments. Uma key consiste em uma variável (ou um conjunto de variáveis), que é capaz de identificar unicamente cada indivíduo descrito em uma tabela, sendo que essa variável (ou esse conjunto de variáveis), deve obrigatoriamente estar presente em ambas as tabelas em que desejamos aplicar o join. Dessa forma, podemos através dessa variável, discernir quais indivíduos estão presentes nas duas tabelas, e quais se encontram em apenas uma delas.\nAo observar as tabelas info e band_instruments, você talvez perceba que ambas possuem uma coluna denominada name. No nosso caso, essa é a coluna que representa a key entre as tabelas info e band_instruments. Logo, ao identificar o músico que está sendo tratado em cada linha, a coluna name nos permite cruzar as informações existentes em ambas tabelas. Com isso, podemos observar que os músicos John e Paul, estão disponíveis em ambas as tabelas, mas os músicos Mick, George e Ringo estão descritos apenas na tabela info, enquanto o músico Keith se encontra apenas na tabela band_instruments.\n\n\n\n\n\nCruzamento entre as tabelas info e band_instruments\n\n\n\n\nSegundo NIELD (2016), podemos ter dois tipos de keys existentes em uma tabela:\n\nPrimary key: uma variável capaz de identificar unicamente cada uma das observações presentes em sua tabela.\nForeign key: uma variável capaz de identificar unicamente cada uma das observações presentes em uma outra tabela.\n\nCom essas características em mente, podemos afirmar que a coluna name existente nas tabelas info e band_instruments, se trata de uma primary key. Pois em ambas as tabelas, mais especificamente em cada linha dessa coluna, temos um músico diferente, ou em outras palavras, não há um músico duplicado.\nPor outro lado, uma foreign key normalmente contém valores repetidos ao longo da base e, por essa razão, não são capazes de identificar unicamente uma observação na tabela em que se encontram. Porém, os valores de uma foreign key certamente fazem referência a uma primary key existente em uma outra tabela. Tendo isso em mente, o objetivo de uma foreign key não é o de identificar cada observação presente em uma tabela, mas sim, de indicar ou explicitar a relação que a sua tabela possui com a primary key presente em uma outra tabela.\nPor exemplo, suponha que eu tenha a tabela children abaixo. Essa tabela descreve os filhos de alguns músicos famosos, e a coluna father caracteriza-se como a foreign key dessa tabela. Não apenas porque os valores da coluna father se repetem ao longo da base, mas também, porque essa coluna pode ser claramente cruzada com a coluna name pertencente às tabelas info e band_instruments.\n\nchildren &lt;- tibble(\n  child = c(\"Stella\", \"Beatrice\", \"James\", \"Mary\",\n            \"Heather\", \"Sean\", \"Julian\", \"Zak\",\n            \"Lee\", \"Jason\", \"Dhani\"),\n  sex = c(\"F\", \"F\", \"M\", \"F\", \"F\", \"M\", \"M\", \"M\", \"F\", \"M\", \"M\"),\n  father = c(rep(\"Paul\", times = 5), \"John\", \"John\",\n             rep(\"Ringo\", times = 3), \"Harrison\")\n)\n\nchildren\n\n# A tibble: 11 × 3\n  child    sex   father\n  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; \n1 Stella   F     Paul  \n2 Beatrice F     Paul  \n3 James    M     Paul  \n4 Mary     F     Paul  \n5 Heather  F     Paul  \n# ℹ 6 more rows",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introdução a base de dados relacionais com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/06-dados-relacionais.html#introduzindo-joins",
    "href": "Capítulos/06-dados-relacionais.html#introduzindo-joins",
    "title": "6  Introdução a base de dados relacionais com dplyr",
    "section": "6.3 Introduzindo joins",
    "text": "6.3 Introduzindo joins\nTendo esses pontos em mente, o pacote dplyr nos oferece quatro funções voltadas para operações de join. Cada uma dessas funções executam um tipo de join diferente, que vamos comentar na próxima seção. Por agora, vamos focar apenas na função inner_join(), que como o seu próprio nome dá a entender, busca aplicar um inner join.\nPara utilizar essa função, precisamos nos preocupar com três argumentos principais. Os dois primeiros argumentos (x e y), definem os data.frame’s a serem fundidos pela função. Já no terceiro argumento (by), você deve delimitar a coluna, ou o conjunto de colunas que representam a key entre as tabelas fornecidas em x e y, usando a função join_by().\nBasta listar as colunas dentro de join_by() que representam as keys do seu join, e fornecer o resultado para o argumento by de inner_join(). Desse modo, os indivíduos serão relacionados/cruzados entre as tabelas A e B com base em um teste lógico de igualdade. Ou seja, “banana” na tabela A é cruzada com “banana” na tabela B, “maçã” com “maçã”, “abacaxi” com “abacaxi”, etc. Alguns autores chamam isso de equality join.\nAo realizarmos o join, as duas tabelas de input são unidas para formar uma nova tabela de output. Porém, em um inner join, apenas as linhas de indivíduos que se encontram em ambas as tabelas serão retornadas na nova tabela gerada. Perceba abaixo, que a função inner_join() criou uma nova tabela contendo todas as colunas presentes tanto na tabela info quanto em band_instruments. Perceba também que apenas as linhas referentes aos músicos John e Paul foram mantidas, pois esses são os únicos indivíduos que aparecem em ambas as tabelas.\n\ninner_join(info, band_instruments, by = join_by(name))\n\n# A tibble: 2 × 5\n  name  band    born       children plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;     &lt;lgl&gt;    &lt;chr&gt; \n1 John  Beatles 1940-09-10 TRUE     guitar\n2 Paul  Beatles 1942-06-18 TRUE     bass  \n\n\n\n## A mesma operação com o uso do pipe ( %&gt;% ):\ninfo %&gt;% \n  inner_join(band_instruments, by = join_by(name))\n\nAo observar esse resultado, você talvez chegue à conclusão de que um processo de join é equivalente ao processo executado pela função PROCV() do Excel. Essa é uma ótima comparação! A função PROCV() realiza uma espécie de join parcial, ao trazer para a tabela A, uma coluna pertencente a tabela B, de acordo com uma key que conecta as duas tabelas.\nPorém um join consiste em um processo de união, em que estamos literalmente fundindo duas tabelas em uma só. Já a função PROCV(), é capaz de transportar apenas uma única coluna por tabela, logo, não é de sua filosofia, fundir as tabelas envolvidas. Por isso, se temos cinco colunas em uma tabela A, as quais desejamos levar até a tabela B, nós precisamos de cinco PROCV()’s diferentes no Excel, enquanto no R, precisamos de apenas um inner_join() para realizarmos tal ação.\nPor último, vale destacar uma característica muito importante de um join, que é o seu processo de pareamento. Devido a essa característica, a ordem das linhas presentes em ambas as tabelas se torna irrelevante para o resultado. Por exemplo, veja na Figura 6.1, um exemplo de join, onde a coluna ID representa a key entre as duas tabelas. Repare que as linhas na tabela à esquerda que se referem, por exemplo, aos indivíduos de ID 105, 107 e 108, se encontram em linhas diferentes na tabela à direita. Mesmo que esses indivíduos estejam em locais diferentes, a função responsável pelo join, vai realizar um pareamento entre as duas tabelas, antes de fundi-las. Dessa maneira, podemos nos certificar que as informações de cada indivíduo são corretamente posicionadas na tabela resultante.\n\n\n\n\n\n\n\n\nFigura 6.1: Representação de um join entre duas tabelas",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introdução a base de dados relacionais com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/06-dados-relacionais.html#sec:config_colunas_keys",
    "href": "Capítulos/06-dados-relacionais.html#sec:config_colunas_keys",
    "title": "6  Introdução a base de dados relacionais com dplyr",
    "section": "6.4 Configurações sobre as colunas e keys utilizadas no join",
    "text": "6.4 Configurações sobre as colunas e keys utilizadas no join\nHaverá momentos em que uma única coluna não será o bastante para identificarmos cada observação de nossa base. Para essas ocasiões, nós devemos utilizar a combinação entre várias colunas, com o objetivo de formarmos uma primary key em nossa tabela.\nPor exemplo, suponha que você trabalhe diariamente com o registro de entradas no estoque de um supermercado. Imagine que você possua a tabela registro abaixo, que contém dados da seção de bebidas do estoque, e que apresentam o dia e mes em que uma determinada carga chegou ao estoque da empresa, além de uma descrição de seu conteúdo (descricao), seu valor de compra (valor) e as unidades inclusas (unidades).\n\nregistro &lt;- tibble(\n  dia = c(3, 18, 18, 25, 25),\n  mes = c(2, 2, 2, 2, 3),\n  ano = 2020,\n  unidades = c(410, 325, 325, 400, 50),\n  valor = c(450, 1400, 1150, 670, 2490),\n  descricao = c(\"Fanta Laranja 350ml\", \n                \"Coca Cola 2L\", \"Mate Couro 2L\",\n                \"Kapo Uva 200ml\", \"Absolut Vodka 1L\")\n)\n\nregistro\n\n# A tibble: 5 × 6\n    dia   mes   ano unidades valor descricao          \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;              \n1     3     2  2020      410   450 Fanta Laranja 350ml\n2    18     2  2020      325  1400 Coca Cola 2L       \n3    18     2  2020      325  1150 Mate Couro 2L      \n4    25     2  2020      400   670 Kapo Uva 200ml     \n5    25     3  2020       50  2490 Absolut Vodka 1L   \n\n\nNessa tabela, as colunas dia, mes, ano, valor, unidades e descricao, sozinhas, são insuficientes para identificarmos cada carga registrada na tabela. Mesmo que, atualmente, cada valor presente na coluna descricao seja único, essa característica provavelmente não vai resistir por muito tempo. Pois o supermercado pode muito bem receber amanhã, por exemplo, uma outra carga de refrigerantes de 2 litros da Mate Couro.\nPor outro lado, a combinação dos valores presentes nas colunas dia, mes, ano, valor, unidades e descricao, pode ser o suficiente para criarmos um código de identificação único para cada carga. Por exemplo, ao voltarmos à tabela registro, podemos encontrar duas cargas que chegaram no mesmo dia 18, no mesmo mês 2, no mesmo ano de 2020, e trazendo as mesmas 325 unidades. Todavia, essas duas cargas, possuem descrições diferentes: uma delas incluía garrafas preenchidas com Coca Cola, enquanto a outra, continha Mate Couro. Concluindo, ao aliarmos as informações referentes a data de entrada (18/02/2020), as quantidades inclusas nas cargas (325 unidades), e as suas descrições (Coca Cola 2L e Mate Couro 2L), podemos enfim diferenciar essas duas cargas.\nComo um outro exemplo, podemos utilizar as bases flights e weather, provenientes do pacote nycflights13. Perceba abaixo, que a base flights já possui um número grande colunas. Essa tabela apresenta dados diários, referentes a diversos voos que partiram da cidade de Nova York (EUA) durante o ano de 2013. Já a tabela weather, contém dados meteorológicos em uma dada hora, e em diversas datas do mesmo ano, e que foram especificamente coletados nos aeroportos da mesma cidade de Nova York.\n\nlibrary(nycflights13)\n\n\nflights\n\n# A tibble: 336,776 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n# ℹ 336,771 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nweather\n\n# A tibble: 26,115 × 15\n  origin  year month   day  hour  temp  dewp humid wind_dir wind_speed wind_gust\n  &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 EWR     2013     1     1     1  39.0  26.1  59.4      270      10.4         NA\n2 EWR     2013     1     1     2  39.0  27.0  61.6      250       8.06        NA\n3 EWR     2013     1     1     3  39.0  28.0  64.4      240      11.5         NA\n4 EWR     2013     1     1     4  39.9  28.0  62.2      250      12.7         NA\n5 EWR     2013     1     1     5  39.0  28.0  64.4      260      12.7         NA\n# ℹ 26,110 more rows\n# ℹ 4 more variables: precip &lt;dbl&gt;, pressure &lt;dbl&gt;, visib &lt;dbl&gt;, …\n\n\nAo aplicarmos um join entre essas tabelas, poderíamos analisar as características meteorológicas que um determinado avião enfrentou ao levantar voo. Entretanto, necessitaríamos empregar ao menos cinco colunas diferentes para formarmos uma key adequada entre essas tabelas. Pois cada situação meteorológica descrita na tabela weather, ocorre em um uma dada localidade, e em um horário específico de um determinado dia. Com isso, teríamos de utilizar as colunas: year, month e day para identificarmos a data correspondente a cada situação; mais a coluna hour para determinarmos o momento do dia em que essa situação ocorreu; além da coluna origin, que marca o aeroporto de onde cada voo partiu e, portanto, nos fornece uma localização no espaço geográfico para cada situação meteorológica.\nPortanto, em todos os momentos em que você precisar utilizar um conjunto de colunas para formar uma key, como o caso das tabelas weather e flights acima, você deve listar os nomes dessas colunas em join_by() e fornecer o resultado para o argumento by da função de join que está utilizando, assim como no exemplo abaixo.\nComo ambas as tabelas tem um número grande de colunas, eu vou selecionar as colunas que desejo trazer de ambas as tabelas para dentro do join, antes de aplicar de fato a operação de join. Isso garante que a tabela resultante do join não fique muito abarrotada de colunas que são desnecessárias para a nossa análise. Agora, um detalhe importante, sempre se lembre de incluir nessa seleção, as colunas que formam a key para o seu join. Pois caso contrário, essas colunas deixam de existir nas tabelas, e, como resultado, o join não vai conseguir relacionar as observações entre as tabelas.\nPor exemplo, supondo que você precisasse em seu resultado apenas das colunas dep_time e dep_delay da tabela flights, você poderia fornecer os comandos a seguir:\n\ncols_para_key &lt;- c(\n  \"year\", \"month\", \"day\", \"hour\", \"origin\"\n)\ncols_desejadas &lt;- c(\"dep_time\", \"dep_delay\")\ncols_c &lt;- c(cols_para_key, cols_desejadas)\ninner_join(\n  flights %&gt;% select(all_of(cols_c)),\n  weather,\n  by = join_by(year, month, day, hour, origin)\n)\n\n# A tibble: 335,220 × 17\n   year month   day  hour origin dep_time dep_delay  temp  dewp humid wind_dir\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1  2013     1     1     5 EWR         517         2  39.0  28.0  64.4      260\n2  2013     1     1     5 LGA         533         4  39.9  25.0  54.8      250\n3  2013     1     1     5 JFK         542         2  39.0  27.0  61.6      260\n4  2013     1     1     5 JFK         544        -1  39.0  27.0  61.6      260\n5  2013     1     1     6 LGA         554        -6  39.9  25.0  54.8      260\n# ℹ 335,215 more rows\n# ℹ 6 more variables: wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;, …\n\n\n\n## Ou selecionando as colunas por subsetting:\ninner_join(\n  flights[ , cols_c],\n  weather,\n  by = join_by(year, month, day, hour, origin)\n)\n\nAntes de partirmos para a próxima seção, vale a pena comentar sobre um outro aspecto importante do join. Por padrão, o join sempre espera que as colunas que formam a sua key estejam nomeadas da mesma maneira em ambas as tabelas. Por exemplo, se nós voltarmos às tabelas info e band_instruments, e renomearmos a coluna name para member em uma das tabelas, um erro será levantado ao tentarmos aplicar novamente um join sobre as tabelas.\n\ncolnames(band_instruments)[1] &lt;- \"member\"\ninner_join(info, band_instruments, by = join_by(name))\n\nError in `inner_join()`:\n! Join columns in `y` must be present in the data.\n✖ Problem with `name`.\nRun `rlang::last_trace()` to see where the error occurred.\nLogo, precisamos ajustar a função join_by() para que o join saiba da existência dessa diferença existente entre os nomes dados às colunas que representam a key entre as tabelas. Para realizar esse ajuste, você deve usar o operador de igualdade (==) entre o nome dados à coluna da tabela A e o nome dado à coluna correspondente na tabela B, dentro de join_by(), como está demonstrado abaixo:\n\ninner_join(info, band_instruments, by = join_by(name == member))\n\n# A tibble: 2 × 5\n  name  band    born       children plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;     &lt;lgl&gt;    &lt;chr&gt; \n1 John  Beatles 1940-09-10 TRUE     guitar\n2 Paul  Beatles 1942-06-18 TRUE     bass",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introdução a base de dados relacionais com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/06-dados-relacionais.html#diferentes-tipos-de-join",
    "href": "Capítulos/06-dados-relacionais.html#diferentes-tipos-de-join",
    "title": "6  Introdução a base de dados relacionais com dplyr",
    "section": "6.5 Diferentes tipos de join",
    "text": "6.5 Diferentes tipos de join\nPortanto, um join busca construir uma união entre duas tabelas. Porém, podemos realizar essa união de diferentes formas, e até o momento, apresentei apenas uma de suas formas, o inner join, que é executado pela função inner_join(). Nesse método, o join mantém apenas as linhas que puderam ser encontradas em ambas as tabelas. Logo, se um indivíduo está presente na tabela A, mas não se encontra na tabela B, esse indivíduo será descartado em um inner join entre as tabelas A e B. Como foi destacado por WICKHAM; GROLEMUND (2017, p. 181), essa característica torna o inner join pouco apropriado para a maioria das análises, pois uma importante perda de observações pode ser facilmente gerada neste processo.\nOs demais tipos de joins dos quais podemos nos aproveitar, são comumente chamados de outer joins. Tal nome se deve ao fato de que esses tipos buscam preservar as linhas de pelo menos uma das tabelas envolvidas no join em questão. Sendo eles:\n\nleft_join(): mantém todas as linhas da tabela definida no argumento x, ou a tabela à esquerda do join, mesmo que os indivíduos descritos nessa tabela não tenham sido encontrados em ambas as tabelas.\nright_join(): mantém todas as linhas da tabela definida no argumento y, ou a tabela à direita do join, mesmo que os indivíduos descritos nessa tabela não tenham sido encontrados em ambas as tabelas.\nfull_join(): mantém todas as linhas de ambas as tabelas definidas nos argumentos x e y, mesmo que os indivíduos de uma dessas tabelas não tenham sido encontrados em ambas as tabelas.\n\nEm todas as funções de join mostradas aqui, o primeiro argumento é chamado de x, e o segundo, de y, sendo esses os argumentos que definem as duas tabelas a serem utilizadas no join. Simplificadamente, a diferença entre left_join(), right_join() e full_join() reside apenas em quais linhas das tabelas utilizadas, são conservadas por essas funções no produto final do join.\nComo essas diferenças são simples, as descrições acima já lhe dão uma boa ideia de quais serão as linhas conservadas em cada função. Todavia, darei a seguir, uma visão mais formal desses comportamentos, com o objetivo principal de fornecer uma segunda visão que pode, principalmente, facilitar a sua memorização do que cada função faz.\n\n\n\n\n\n\n\n\nFigura 6.2: As tabelas ocupam lados em um join\n\n\n\n\n\nPara seguir esse caminho, é interessante que você tente interpretar um join a partir de uma perspectiva mais visual e menos minuciosa do processo. Ao aplicarmos um join entre as tabelas A e B, estamos basicamente, extraindo as colunas da tabela B e as adicionando à tabela A.\nCom isso, temos nessa concepção, a tabela fonte (isto é, a tabela de onde as colunas são retiradas), e a tabela destinatária (ou seja, a tabela para onde essas colunas são levadas). Portanto, segundo esse ponto de vista, o join possui sentido e direção, assim como um vetor em um espaço tridimensional. Pois o processo sempre parte da tabela fonte em direção a tabela destinatária. Dessa forma, em um join, estamos resumidamente extraindo as colunas da tabela fonte e as incorporando à tabela destinatária.\nCom isso, eu quero criar a perspectiva, de que a tabela fonte e a tabela destinatária, ocupam lados do join, como na Figura 6.2. Ou seja, por esse ângulo, estamos compreendendo o join como uma operação que ocorre sempre da direita para esquerda, ou um processo em que estamos sempre carregando um conjunto de colunas da tabela à direita em direção a tabela à esquerda.\nSe mesclarmos essa visão, com as primeiras descrições dos outer joins que fornecemos, temos que o argumento x corresponde a tabela destinatária, e o argumento y, a tabela fonte. Dessa maneira, a tabela destinatária (ou o argumento x) é sempre a tabela que ocupa o lado esquerdo do join, enquanto a tabela fonte (ou o argumento y) sempre se trata da tabela que ocupa o lado direito da operação.\nLogo, a função left_join() busca manter as linhas da tabela destinatária (ou a tabela “à esquerda”, que você definiu no argumento x da função) intactas no resultado do join. Isso significa, que caso a função left_join() não encontre na tabela fonte, uma linha que corresponde a um certo indivíduo presente na tabela destinatária, essa linha será mantida no resultado final do join.\nPorém, como está demonstrado abaixo, em todas as situações em que a função não pôde encontrar esse indivíduo na tabela fonte, left_join() vai preencher as linhas correspondentes nas colunas que ele transferiu dessa tabela, com valores NA, indicando justamente que não há informações daquele respectivo indivíduo na tabela fonte.\n\nleft_join(info, band_instruments, by = join_by(name))\n\n# A tibble: 5 × 5\n  name   band           born       children plays \n  &lt;chr&gt;  &lt;chr&gt;          &lt;date&gt;     &lt;lgl&gt;    &lt;chr&gt; \n1 Mick   Rolling Stones 1943-07-26 TRUE     &lt;NA&gt;  \n2 John   Beatles        1940-09-10 TRUE     guitar\n3 Paul   Beatles        1942-06-18 TRUE     bass  \n4 George Beatles        1943-02-25 TRUE     &lt;NA&gt;  \n5 Ringo  Beatles        1940-07-07 TRUE     &lt;NA&gt;  \n\n\nEm contrapartida, a função right_join() realiza justamente o processo contrário, ao manter as linhas da tabela fonte (ou a tabela “à direita”, que você forneceu ao argumento y). Por isso, para todas as linhas da tabela fonte que se referem a um indivíduo não encontrado na tabela destinatária, right_join() acaba preenchendo os campos provenientes da tabela destinatária, com valores NA, indicando assim que a função não conseguiu encontrar mais dados sobre aquele indivíduo na tabela destinatária. Você pode perceber esse comportamento, pela linha referente ao músico Keith, que está disponível na tabela fonte, mas não na tabela destinatária.\n\nright_join(info, band_instruments, by = join_by(name))\n\n# A tibble: 3 × 5\n  name  band    born       children plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;     &lt;lgl&gt;    &lt;chr&gt; \n1 John  Beatles 1940-09-10 TRUE     guitar\n2 Paul  Beatles 1942-06-18 TRUE     bass  \n3 Keith &lt;NA&gt;    NA         NA       guitar\n\n\nPor fim, a função full_join() executa o processo inverso da função inner_join(). Ou seja, se por um lado, a função inner_join() mantém as linhas de todos os indivíduos que puderam ser localizados em ambas as tabelas, por outro, a função full_join() sempre traz todos os indivíduos de ambas as tabelas em seu resultado.\nEm outras palavras, a função full_join() mantém todas as linhas de ambas as tabelas. De certa forma, a função full_join() busca encontrar sempre o maior número possível de combinações entre as tabelas, e em todas as ocasiões que full_join() não encontra um determinado indivíduo, por exemplo, na tabela B, a função vai preencher os campos dessa tabela B com valores NA para as linhas desse indivíduo. Veja o exemplo abaixo.\n\nfull_join(info, band_instruments, by = join_by(name))\n\n# A tibble: 6 × 5\n  name   band           born       children plays \n  &lt;chr&gt;  &lt;chr&gt;          &lt;date&gt;     &lt;lgl&gt;    &lt;chr&gt; \n1 Mick   Rolling Stones 1943-07-26 TRUE     &lt;NA&gt;  \n2 John   Beatles        1940-09-10 TRUE     guitar\n3 Paul   Beatles        1942-06-18 TRUE     bass  \n4 George Beatles        1943-02-25 TRUE     &lt;NA&gt;  \n5 Ringo  Beatles        1940-07-07 TRUE     &lt;NA&gt;  \n# ℹ 1 more row\n\n\nComo o primeiro data.frame fornecido à função *_join(), será na maioria das situações, a sua principal tabela de trabalho, o ideal é que você adote o left_join() como o seu padrão de join (WICKHAM; GROLEMUND, 2017). Pois dessa maneira, você evita uma possível perda de observações em sua tabela mais importante.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introdução a base de dados relacionais com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/06-dados-relacionais.html#relações-entre-keys-primary-keys-são-menos-comuns-do-que-você-pensa",
    "href": "Capítulos/06-dados-relacionais.html#relações-entre-keys-primary-keys-são-menos-comuns-do-que-você-pensa",
    "title": "6  Introdução a base de dados relacionais com dplyr",
    "section": "6.6 Relações entre keys: primary keys são menos comuns do que você pensa",
    "text": "6.6 Relações entre keys: primary keys são menos comuns do que você pensa\nNa seção Dados relacionais e o conceito de key, nós estabelecemos que variáveis com a capacidade de identificar unicamente cada observação de sua base, podem ser caracterizadas como primary keys. Mas para que essa característica seja verdadeira para uma dada variável, os seus valores não podem se repetir ao longo da base, e isso não acontece com tanta frequência na realidade.\nComo exemplo, podemos voltar ao join entre as tabelas flights e weather que mostramos na seção Configurações sobre as colunas e keys utilizadas no join. Para realizarmos o join entre essas tabelas, nós utilizamos as colunas year, month, day, hour e origin como key. Porém, a forma como descrevemos essas colunas na seção passada, ficou subentendido que a combinação entre elas foi capaz de formar uma primary key. Bem, porque não conferimos se essas colunas assumem de fato esse atributo:\n\nflights %&gt;% \n  count(year, month, day, hour, origin) %&gt;% \n  filter(n &gt; 1)\n\n# A tibble: 18,906 × 6\n   year month   day  hour origin     n\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;\n1  2013     1     1     5 EWR        2\n2  2013     1     1     5 JFK        3\n3  2013     1     1     6 EWR       18\n4  2013     1     1     6 JFK       17\n5  2013     1     1     6 LGA       17\n# ℹ 18,901 more rows\n\n\nComo podemos ver acima, há diversas combinações entre as cinco colunas que se repetem ao longo da base. Com isso, podemos afirmar que a combinação entre as colunas year, month, day, hour e origin não forma uma primary key. Perceba abaixo, que o mesmo vale para a tabela weather:\n\nweather %&gt;% \n  count(year, month, day, hour, origin) %&gt;% \n  filter(n &gt; 1)\n\n# A tibble: 3 × 6\n   year month   day  hour origin     n\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;int&gt;\n1  2013    11     3     1 EWR        2\n2  2013    11     3     1 JFK        2\n3  2013    11     3     1 LGA        2\n\n\nPortanto, circunstâncias em que não há uma primary key definida entre duas tabelas, são comuns, inclusive em momentos que você utiliza a combinação de todas as colunas disponíveis em uma das tabelas para formar uma key. Com isso, eu quero destacar principalmente, que não há problema algum em utilizarmos foreign keys em joins.\nNão seja obcecado por primary keys! Ao invés de ficar procurando por uma primary key, você deve sempre procurar pela key que tenha o significado mais apropriado para o seu join, baseado no seu conhecimento sobre esses dados (WICKHAM; GROLEMUND, 2017). Logo, durante esse processo, nós não estamos perseguindo primary keys de maneira obsessiva, mas sim, pesquisando por relações verdadeiras e lógicas entre as tabelas.\nPor exemplo, no caso das tabelas flights e weather, utilizamos as colunas year, month, day, hour e origin como key, pelo fato de que eventos climáticos ocorrem um dado momento (hour) de um dia específico (year, month e day), além de geralmente se restringir a uma dada região geográfica (origin). Curiosamente, essas colunas não foram suficientes para produzirmos uma primary key, mas foram suficientes para representarmos uma conexão lógica entre as tabelas flights e weather.\nAssim sendo, qualquer que seja o tipo de key empregado, o processo de join irá ocorrer exatamente da mesma forma. Porém, o tipo que a key assume em cada tabela pode alterar as combinações geradas no resultado do join. Como temos duas tabelas em cada join, temos três possibilidades de relação entre as keys de cada tabela: 1) primary key \\(\\rightarrow\\) primary key; 2) primary key \\(\\rightarrow\\) foreign key; 3) foreign key \\(\\rightarrow\\) foreign key. Ou seja, em cada uma das tabelas envolvidas em um join, as colunas a serem utilizadas como key podem se caracterizar como uma primary key ou como uma foreign key.\nComo exemplo, o join formado pelas tabelas info e band_instruments, possui uma relação de primary key \\(\\rightarrow\\) primary key. Pois a coluna name é uma primary key em ambas as tabelas. Por outro lado, o join formado pelas tabelas flights e weather, possui uma relação de foreign key \\(\\rightarrow\\) foreign key, visto que as cinco colunas utilizadas como key não são capazes de identificar unicamente cada observação nas duas tabelas, como comprovamos acima.\n\n\n\n\n\n\n\n\nFigura 6.3: Resumo das relações possíveis entre keys, inspirado em Wickham e Grolemund (2017)\n\n\n\n\n\nCom isso, temos a opção de compreendermos a relação entre as keys, como uma relação de quantidade de cópias, fazendo referência direta ao fato de que uma primary key não possui valores repetidos ao longo da base, enquanto o mesmo não pode ser dito de uma foreign key. Logo, uma relação primary key \\(\\rightarrow\\) primary key pode ser identificada como uma relação de um para um, pois sempre vamos contar com uma única chave para cada observação em ambas as tabelas. Para mais, podemos interpretar uma relação primary key \\(\\rightarrow\\) foreign key, como uma relação de um para muitos, pois para cada chave única presente em uma das tabelas, podemos encontrar múltiplas irmãs gêmeas presentes na outra tabela.\nEm contrapartida, se tivermos uma relação foreign key \\(\\rightarrow\\) foreign key, ou uma relação de muitos para muitos, para cada conjunto de keys repetidas em ambas as tabelas, todas as possibilidades de combinação serão geradas. Em outras palavras, nesse tipo de relação, o resultado do join será uma produto cartesiano como demonstrado pela Figura 6.3.\nRelações de um para um são raras e, por essa razão, você geralmente irá lidar com relações de um para muitos e de muitos para muitos em suas tabelas. No caso de relações de um para muitos, as primary keys são replicadas no resultado do join, para cada repetição de sua key correspondente na outra tabela, como pode ser visto na Figura 6.3. Por padrão, as funções de join do pacote dplyr sempre emitem um warning de aviso, caso elas descubram que as keys que você escolheu criam uma relação de “um para muitos” ou de “muitos para muitos” entre as suas tabelas.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introdução a base de dados relacionais com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/06-dados-relacionais.html#portanto-joins-podem-ser-uma-fonte-de-repetições-indesejadas-em-seus-dados",
    "href": "Capítulos/06-dados-relacionais.html#portanto-joins-podem-ser-uma-fonte-de-repetições-indesejadas-em-seus-dados",
    "title": "6  Introdução a base de dados relacionais com dplyr",
    "section": "6.7 Portanto, joins podem ser uma fonte de repetições indesejadas em seus dados",
    "text": "6.7 Portanto, joins podem ser uma fonte de repetições indesejadas em seus dados\nAo explicar as relações de um para muitos e de muitos para muitos entre keys, eu estava querendo destacar que produtos cartesianos são extremamente comuns em todos os tipos de joins. Quando os alunos são introduzidos pela primeira vez ao mundo dos joins, muitos tendem a interpretar que, por exemplo, a função left_join() produz exatamente o mesmo número de linhas que a tabela destinatária (ou a tabela x) utilizada no join. Ou ainda, que se as duas tabelas utilizadas no join possuírem o mesmo número de linhas, que a função inner_join() vai necessariamente retornar um número menor ou igual de linhas em seu resultado.\nEssa é uma confusão tão comum, que Hadley Wickham chegou a escrever uma votação no Twitter1 que demonstra como um produto cartesiano pode ser gerado devido a essa relação entre keys. Como exemplo prático, vamos recriar exatamente a situação que Hadley estava descrevendo nesse tweet. Repare que temos duas tabelas abaixo, df1 e df2. Ambas as tabelas, possuem uma coluna chamada de x. Porém, apenas a tabela df1 possui uma coluna y, e apenas a tabela df2 possui uma coluna z.\n\ndf1 &lt;- data.frame(x = c(1, 1), y = c(1, 2))\ndf2 &lt;- data.frame(x = c(1, 1), z = c(3, 4))\n\nprint(df1)\n\n  x y\n1 1 1\n2 1 2\n\nprint(df2)\n\n  x z\n1 1 3\n2 1 4\n\n\nAo aplicarmos um inner_join() entre essas tabelas, quantas linhas você espera encontrar no resultado do join? Você provavelmente pensou em 2 linhas, mas na realidade, são retornadas 4 linhas diferentes. Além disso, vale destacar que, para esse exemplo específico, o resultado de inner_join() é idêntico aos resultados produzidos por full_join(), left_join() e right_join(). Ao observarmos atentamente as combinações entre as colunas y e z, podemos compreender melhor o que está acontecendo neste resultado.\nEm ambas as tabelas, a coluna x não é capaz de identificar sozinha cada observação única da tabela, logo, a relação criada pela coluna x é uma relação de muitos para muitos entre as duas tabelas. Por essa razão, o join entre as tabelas df1 e df2 acaba gerando um produto cartesiano entre as duas observações de cada tabela, de modo que, no final, temos \\(2 \\times 2 = 4\\) linhas retornadas. Portanto, todas as combinações possíveis entre \\((y, z)\\) foram retornadas, sendo elas: \\((1,3); (1,4); (2,3); (2,4)\\).\n\ninner_join(df1, df2, by = join_by(x))\n\n  x y z\n1 1 1 3\n2 1 1 4\n3 1 2 3\n4 1 2 4\n\n\nSendo assim, caso você esteja trabalhando sobre uma tabela A que contém exatas 1000 linhas, e você aplica diversas transformações sobre essa tabela (incluindo a aplicação de joins), e, no final, acaba gerando uma tabela de 1200 linhas, você pode suspeitar que os joins que você está aplicando e os possíveis produtos cartesianos que eles estejam gerando, sejam a fonte de tal expansão de sua tabela.\nEm meu trabalho como analista, estou o tempo todo analisando como diversos usuários estão navegando por um determinado fluxo. E para tal análise estou constantemente aplicando joins entre tabelas, e as relações entre as keys dessas tabelas são parte fundamental desse trabalho. Pois caso eu não tenha cuidado com essas relações, eu posso acabar gerando repetições indesejadas de um mesmo usuário, devido ao produto cartesiano gerado no join, e por causa dessas repetições, eu posso acabar interpretando que 100 usuários passaram por um ponto x do fluxo, quando na verdade, apenas 77 usuários de fato passaram por este ponto.\nPortanto, quando estiver trabalhando com joins, é importante que você sempre os interprete como uma relação entre os indivíduos ou categorias descritas em cada tabela, e não como um filtro baseado no número de linhas de cada tabela. Um left join não busca gerar um resultado que tem o mesmo número de linhas da tabela destinatária, mas sim, um resultado que contém os mesmos indivíduos ou categorias descritas na tabela destinatária. Lembre-se disso.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introdução a base de dados relacionais com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/06-dados-relacionais.html#a-função-join_by-e-joins-de-desigualdade",
    "href": "Capítulos/06-dados-relacionais.html#a-função-join_by-e-joins-de-desigualdade",
    "title": "6  Introdução a base de dados relacionais com dplyr",
    "section": "6.8 A função join_by() e joins de desigualdade",
    "text": "6.8 A função join_by() e joins de desigualdade\nAté aqui, nós falamos muito pouco da função join_by() e das alternativas que ela oferece para desempenharmos outros tipos de join, especialmente, os joins de desigualdade. Nas seções e exemplos anteriores, mostramos apenas exemplos de joins de igualdade, pois estávamos sempre interessados em relacionar as observações das duas tabelas com um teste de igualdade.\nOu seja, estávamos sempre relacionando “banana na tabela A com banana na tabela B”, “maçã na tabela A com maçã na tabela B”, etc. Sempre procurando por e relacionando as observações que possuíam a mesma key (ou chave) entre si. Por isso que muitas pessoas caracterizam essas operações como um join de igualdade.\nMas existe um outro caminho, que são os “joins de desigualdade”. Em resumo, nesse tipo de join, nós queremos relacionar as observações entre as tabelas, com base em operadores lógicos em que a igualdade se torna opcional, ou então, que indicam desigualdade mesmo. Por exemplo, os operadores de “maior que” (&gt;), ou “maior que ou igual” (&gt;=). O operador “maior que” indica explicitamente que os dois valores envolvidos no teste lógico precisam ser diferentes um do outro, um deve ser maior que o outro. Já no operador “maior que ou igual”, a igualdade se torna opcional. O valor pode ser igual, mas ele também pode ser maior que o outro.\nComo exemplo, um join com o operador de “maior que” indica que uma determinada key na tabela A vai ser relacionada com qualquer key na tabela B cujo valor seja maior que o valor da key na tabela A. Você talvez perceba com essa descrição que, relações entre keys de “um para um” são ainda mais raras (ou quase inexistentes) em joins de desigualdade, mais do que são já são em joins de igualdade.\nPortanto, lembre-se que, o tipo do join (inner, left, right ou full) determina quais indivíduos vão aparecer no resultado final do join. Se vão ser os indivíduos presentes em ambas as tabelas, ou se vão ser os indivíduos presentes em apenas uma das tabelas, ou se vão ser todos os indivíduos de ambas as tabelas. Por outro lado, a questão que estamos descrevendo aqui, de ser um join de igualdade ou um join de desigualdade, afeta o join de um modo diferente. Mais especificamente, isso determina como as observações são cruzadas entre as tabelas.\nHoje, o pacote dplyr possui 3 métodos diferentes de joins de desigualdade que podemos realizar através da função join_by(). Eles são: 1) o join de desigualdade “clássico”; 2) rolling join; e 3) overlap join. Todos esses métodos são diferentes subtipos de joins de desigualdade. Logo, todos eles são baseados em desigualdades criadas pelos operadores &lt;, &lt;=, &gt; e &gt;=.\n\n6.8.1 Desigualdade clássica\nVamos começar pelo join de desigualdade “clássico”. Você pode interpretar que esse é o subtipo de join de desigualdade que não tem nenhum comportamento extra, ou especial. Em outras palavras, ele funciona exatamente como você esperaria que um join de desigualdade funcionasse.\nComo exemplo, vamos usar as tabelas reference e segments abaixo:\n\nsegments &lt;- tibble(\n  segment_id = 1:4,\n  chromosome = c(\"chr1\", \"chr2\", \"chr2\", \"chr1\"),\n  start = c(140, 210, 380, 230),\n  end = c(150, 240, 415, 280)\n)\n\nreference &lt;- tibble(\n  reference_id = 1:4,\n  chromosome = c(\"chr1\", \"chr1\", \"chr2\", \"chr2\"),\n  start = c(100, 200, 300, 415),\n  end = c(150, 250, 399, 450)\n)\n\nPor exemplo, suponha que eu queira unir essas tabelas, usando a coluna chromosome como key. Mas além disso, eu quero trazer apenas as linhas da tabela B cujo o valor na coluna start for maior ou igual ao valor da coluna start na tabela A.\nPerceba no exemplo abaixo, que, a primeira linha da tabela reference (chromosome = \"ch1\" e start = 100) foi relacionada com duas linhas distintas da tabela segments. Pois em ambos os casos, o valor da coluna chormosome é igual, e também, o valor na coluna start na tabela segments é maior que o valor dessa mesma coluna na tabela reference. Em contrapartida, a segunda linha da tabela reference (chromosome = \"ch1\" e start = 200) foi relacionada com uma única linha da tabela segments. Pois apenas nesse caso, o valor na coluna start na tabela segments é maior que o valor dessa mesma coluna na tabela reference.\n\nby &lt;- join_by(chromosome, start &lt;= start)\ninner_join(reference, segments, by = by)\n\n# A tibble: 4 × 7\n  reference_id chromosome start.x end.x segment_id start.y end.y\n         &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;      &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1            1 chr1           100   150          1     140   150\n2            1 chr1           100   150          4     230   280\n3            2 chr1           200   250          4     230   280\n4            3 chr2           300   399          3     380   415\n\n\n\n\n6.8.2 Rolling join\nEm resumo, enquanto um join de desigualdade clássico pode relacionar \\(n\\) linhas da tabela B com 1 linha na tabela A, um rolling join sempre relaciona apenas 1 linha da tabela B com 1 linha da tabela A. Mais especificamente, a linha da tabela B cujo valor seja o mais próximo possível de seu par na tabela A. Portanto, um rolling join é uma espécie de join que está interessado em encontrar as observações da tabela B que são as mais próximas possíveis das observações da tabela A.\nPara transformar um join de desigualdade clássico em um rolling join, tudo o que você precisa fazer é encapsular a expressão de desigualdade dentro da função closest(). Se pegarmos exatamente o mesmo exemplo da seção anterior, podemos encapsular a expressão start &lt;= start dentro da função closest(), e como resultado, temos um resultado diferente da seção anterior.\nPerceba que, dessa vez, a primeira linha da tabela reference (chromosome = \"ch1\" e start = 100) foi relacionada com uma única linha da tabela segments, ao invés de duas linhas. Pois dessa vez, o join não quer encontrar todas as linhas em que o valor na coluna start da tabela segments é maior que o valor na mesma coluna na tabela reference. Dessa vez, o join quer encontrar as linhas na tabela segments onde o valor na coluna start é o mais próximo possível de seu par na tabela reference.\n\nby &lt;- join_by(chromosome, closest(start &lt;= start))\ninner_join(reference, segments, by = by)\n\n# A tibble: 3 × 7\n  reference_id chromosome start.x end.x segment_id start.y end.y\n         &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;      &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1            1 chr1           100   150          1     140   150\n2            2 chr1           200   250          4     230   280\n3            3 chr2           300   399          3     380   415\n\n\n\n\n6.8.3 Overlap join\nUm overlap join é um subtipo de join que se preocupa principalmente com intervalos (ou ranges) de valores. Então para cada intervalo encontrado na tabela A, o join vai procurar por observações na tabela B que estejam dentro deste intervalo de alguma forma.\nPara esse subtipo de join, você pode dizer que cada observação na tabela B precisa estar dentro do intervalo na tabela A (função between()); ou então, você pode dizer que um intervalo na tabela B precisa estar contido/dentro do intervalo na tabela A (função within()); ou ainda, você pode dizer que o intervalo na tabela B deve estar invadindo (ou sobrepondo) em algum nível o intervalo da tabela A (função overlaps()).\nComo um primeiro exemplo, se eu fornecer a expressão between( y$start, x$start, x$end ) para join_by(), eu estou dizendo ao join, que encontre observações na tabela segments cujo valor na coluna start esteja dentro do intervalo criado pelas colunas start e end na tabela reference. Ou seja, eu poderia atingir exatamente o mesmo resultado incluindo as expressões y$start &gt;= x$start e y$start &lt;= x$end em join_by(), pois o significado seria o mesmo.\nNo exemplo abaixo, a primeira linha de reference (chromosome = \"ch1\", start = 100, end = 150) foi relacionada com a primeira linha de segments. Pois o valor de 140 na coluna start na tabela segments está dentro do intervalo \\([100, 150]\\).\n\nby &lt;- join_by(chromosome, between(y$start, x$start, x$end))\ninner_join(reference, segments, by = by)\n\n# A tibble: 3 × 7\n  reference_id chromosome start.x end.x segment_id start.y end.y\n         &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;      &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1            1 chr1           100   150          1     140   150\n2            2 chr1           200   250          4     230   280\n3            3 chr2           300   399          3     380   415\n\n\nPor outro lado, com a expressão within( y$start, y$end, x$start, x$end ) em join_by(), eu estou dizendo ao join, que encontre observações na tabela segments cujo o intervalo criado pelas colunas start e end, esteja contido/dentro do intervalo criado pelas colunas start e end na tabela reference. No exemplo abaixo, somente a primeira linha de ambas as tabelas foram relacionadas entre si. Pois somente nesse caso, o intervalo criado na tabela reference (\\([140, 150]\\)) está contido dentro do intervalo criado na tabela segments (\\([100, 150]\\)).\n\nby &lt;- join_by(\n  chromosome,\n  within(y$start, y$end, x$start, x$end)\n)\ninner_join(reference, segments, by = by)\n\n# A tibble: 1 × 7\n  reference_id chromosome start.x end.x segment_id start.y end.y\n         &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;      &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1            1 chr1           100   150          1     140   150\n\n\nJá a expressão overlaps( x$start, x$end, y$start, y$end ) em join_by(), significa que o join vai procurar por observações na tabela segments cujo o intervalo criado pelas colunas start e end, esteja sobrepondo (ou “invadindo”) em algum nível o intervalo criado pelas colunas start e end na tabela reference. No exemplo abaixo, perceba que o intervalo \\([200, 250]\\) da tabela reference está invadindo ou sobrepondo parte do intervalo \\([230, 280]\\) da tabela segments. Por isso essas observações foram relacionadas/conectadas.\n\nby &lt;- join_by(\n  chromosome,\n  overlaps(x$start, x$end, y$start, y$end)\n)\ninner_join(reference, segments, by = by)\n\n# A tibble: 4 × 7\n  reference_id chromosome start.x end.x segment_id start.y end.y\n         &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;      &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1            1 chr1           100   150          1     140   150\n2            2 chr1           200   250          4     230   280\n3            3 chr2           300   399          3     380   415\n4            4 chr2           415   450          3     380   415",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introdução a base de dados relacionais com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/06-dados-relacionais.html#estudo-de-caso-analisando-eventos-de-usuários",
    "href": "Capítulos/06-dados-relacionais.html#estudo-de-caso-analisando-eventos-de-usuários",
    "title": "6  Introdução a base de dados relacionais com dplyr",
    "section": "6.9 Estudo de caso: analisando eventos de usuários",
    "text": "6.9 Estudo de caso: analisando eventos de usuários\nApós vermos os joins de desigualdade, creio que esta é a oportunidade perfeita para vermos um estudo de caso bem rápido. Aqui nesta seção, vamos usar dados de eventos de usuários em algum fluxo de vendas. Suponha que você tenha duas tabelas diferentes:\n\nA tabela incomings contém dados sobre as entradas dos usuários para dentro do fluxo.\nA tabela events contém dados sobre os eventos que cada usuário realizou dentro do fluxo.\n\nOu seja, na tabela incomings eu consigo entender como cada usuário entrou para dentro do fluxo. Que horário ele entrou, por qual canal ele entrou, etc. Já na tabela events eu consigo entender o que ele fez dentro do fluxo. Para importar essas tabelas para sua sessão, use os comandos abaixo:\n\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo1 &lt;- \"user_events.csv\"\narquivo2 &lt;- \"incoming_users.csv\"\n\nincomings &lt;- read_csv2(paste0(github, pasta, arquivo2))\nevents &lt;- read_delim(\n  paste0(github, pasta, arquivo1),\n  delim = \";\",\n  escape_backslash = TRUE,\n  escape_double = FALSE\n)\n\nPerceba no resultado abaixo, que a tabela incomings descreve a entrada de 3 usuários distintos no fluxo, todos eles no dia 06/07/2023. Perceba também que o usuário pedrobc67 realizou duas visitas diferentes ao fluxo. A primeira foi as 08hrs da manhã, enquanto a outra foi as 11hrs da manhã.\n\nincomings\n\n# A tibble: 4 × 4\n  user_id user_name     channel   dt_enter           \n    &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;     &lt;dttm&gt;             \n1       1 pedrobc67     Instagram 2023-07-06 08:04:09\n2       1 pedrobc67     Instagram 2023-07-06 11:13:42\n3       2 anne_marie992 Instagram 2023-07-06 11:45:00\n4       3 &lt;NA&gt;          Website   2023-07-06 12:25:06\n\n\nAgora, olhando para a tabela events, perceba que, na primeira visita ao fluxo do usuário pedrobc67, ele não realizou nenhuma ação após navegar para a página \"/transport/select\". Já na segunda visita desse mesmo usuário, ele de fato realizou outras ações após essa navegação. Esse comportamento não é incomum, pois muitos usuários entram na plataforma, mas acabam desistindo de continuar no meio do caminho, pois precisam fazer outra coisa naquele momento (e.g. filho está chorando e precisa de atenção, esqueceu de colocar comida para o cachorro, etc.), ou ainda, estão mentalmente exaustos naquele momento e precisam de um tempo para respirar.\n\nevents\n\n# A tibble: 6 × 5\n  user_id event_id dt_event            event_type      event_value              \n    &lt;dbl&gt;    &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;           &lt;chr&gt;                    \n1       1        1 2023-07-06 08:37:02 page-navigation \"{\\\"type\\\": \\\"page-navig…\n2       1        2 2023-07-06 11:15:49 page-navigation \"{\\\"type\\\": \\\"page-navig…\n3       1        3 2023-07-06 11:18:21 select-option   \"{\\\"type\\\": \\\"select-opt…\n4       1        4 2023-07-06 11:20:08 sent-input      \"{\\\"type\\\": \\\"sent-input…\n5       3        5 2023-07-06 12:25:35 page-navigation \"{\\\"type\\\": \\\"page-navig…\n# ℹ 1 more row\n\n\nO meu trabalho envolve muitas vezes analisar como os usuários estão navegando pelo fluxo de vendas, e com isso, identificar possíveis pontos de atrito, ou pontos em que o usuário tem mais dificuldade para prosseguir e completar o processo de compra do produto.\nPorém, para desenvolver esse tipo de análise, é útil relacionarmos cada entrada no fluxo que um determinado usuário realiza, com, os eventos que esse usuário realizou ao longo do fluxo durante essa visita que ele fez ao fluxo. Cada vez que um mesmo usuário entra no fluxo, uma nova visita se inicia, e portanto, um novo conjunto de eventos começa a ser gravado.\nComo podemos relacionar corretamente a tabela events à tabela incomings de modo que a gente consiga relacionar cada visita ao fluxo de cada usuário com o respectivo conjunto de eventos que esse usuário realizou no fluxo nesta visita específica? A resposta está em um join de desigualdade.\n\nby &lt;- join_by(user_id, dt_event &gt;= dt_enter)\nevents_with_incomings &lt;- events |&gt;\n  inner_join(incomings, by = by) |&gt;\n  select(user_id, event_id, dt_enter, dt_event) |&gt;\n  arrange(user_id, dt_event)\n\nevents_with_incomings\n\n# A tibble: 9 × 4\n  user_id event_id dt_enter            dt_event           \n    &lt;dbl&gt;    &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n1       1        1 2023-07-06 08:04:09 2023-07-06 08:37:02\n2       1        2 2023-07-06 08:04:09 2023-07-06 11:15:49\n3       1        2 2023-07-06 11:13:42 2023-07-06 11:15:49\n4       1        3 2023-07-06 08:04:09 2023-07-06 11:18:21\n5       1        3 2023-07-06 11:13:42 2023-07-06 11:18:21\n# ℹ 4 more rows\n\n\nPorém, se você reparar atentamente no resultado acima, você talvez perceba que, os eventos produzidos pelo usuário pedrobc67 na sua segunda visita ao fluxo foram relacionados não apenas com o horário de entrada de sua segunda visita (11:13), mas também, com o horário de entrada de sua primeira visita (08:04) ao fluxo. Ou seja, o join acaba relacionando a primeira visita no fluxo com eventos que pertencem à segunda visita ao fluxo.\nExistem diferentes formas de resolvermos esta inconsistência. Uma delas seria calcular a distância do horário de cada evento em relação ao horário de entrada, e filtrar todos os registros que possuem a menor distância possível. Veja o resultado abaixo como exemplo:\n\nevents_with_incomings &lt;- events_with_incomings |&gt;\n  mutate(df_diff = dt_event - dt_enter) |&gt;\n  group_by(event_id) |&gt;\n  filter(df_diff == min(df_diff))\n\nevents_with_incomings\n\n# A tibble: 6 × 5\n# Groups:   event_id [6]\n  user_id event_id dt_enter            dt_event            df_diff  \n    &lt;dbl&gt;    &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;              &lt;drtn&gt;   \n1       1        1 2023-07-06 08:04:09 2023-07-06 08:37:02 1973 secs\n2       1        2 2023-07-06 11:13:42 2023-07-06 11:15:49  127 secs\n3       1        3 2023-07-06 11:13:42 2023-07-06 11:18:21  279 secs\n4       1        4 2023-07-06 11:13:42 2023-07-06 11:20:08  386 secs\n5       3        5 2023-07-06 12:25:06 2023-07-06 12:25:35   29 secs\n# ℹ 1 more row\n\n\nPorém, a melhor forma de corrigir esse problema, seria usar um rolling join, ao invés de um join de desigualdade clássico. Pense um pouco nisso. Nós queremos relacionar os eventos com o horário de entrada que esteja mais próximo possível dos horários desses eventos. Proximidade é a especialidade de rolling joins com a função closest()!\nPortanto, tudo o que precisamos fazer é encapsular a nossa expressão de desigualdade com a função closest(). Perceba no resultado abaixo que, dessa vez, os eventos foram relacionados corretamente com a visita ao fluxo correspondente. Pois nesse caso, o join passa a relacionar cada evento que o usuário realizou dentro do fluxo com o horário de entrada que está mais próximo, como demonstrado no resultado abaixo:\n\nby &lt;- join_by(user_id, closest(dt_event &gt;= dt_enter))\nevents_with_incomings &lt;- events |&gt;\n  inner_join(incomings, by = by) |&gt;\n  select(user_id, event_id, dt_enter, dt_event) |&gt;\n  arrange(user_id)\n\nevents_with_incomings\n\n# A tibble: 6 × 4\n  user_id event_id dt_enter            dt_event           \n    &lt;dbl&gt;    &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n1       1        1 2023-07-06 08:04:09 2023-07-06 08:37:02\n2       1        2 2023-07-06 11:13:42 2023-07-06 11:15:49\n3       1        3 2023-07-06 11:13:42 2023-07-06 11:18:21\n4       1        4 2023-07-06 11:13:42 2023-07-06 11:20:08\n5       3        5 2023-07-06 12:25:06 2023-07-06 12:25:35\n# ℹ 1 more row",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introdução a base de dados relacionais com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/06-dados-relacionais.html#utilizando-joins-como-a-base-de-um-filtro",
    "href": "Capítulos/06-dados-relacionais.html#utilizando-joins-como-a-base-de-um-filtro",
    "title": "6  Introdução a base de dados relacionais com dplyr",
    "section": "6.10 Utilizando joins como a base de um filtro",
    "text": "6.10 Utilizando joins como a base de um filtro\nDurante as seções anteriores mostramos os joins dos tipos inner, full, left e right. Esses tipos de joins são conjuntamente conhecidos como mutating joins, pois eles adicionam novas variáveis a sua tabela (como se fossem uma cópia da função mutate()) baseando-se em um pareamento com as linhas de outra tabela (WICKHAM; GROLEMUND, 2017).\nPara além desses tipos de join, temos o conjunto de filtering joins, o qual abarca os anti joins e os semi joins. Para esses dois tipos de joins, o pacote dplyr nos oferece as funções anti_join() e semi_join(). A principal diferença entre os filtering joins e os mutating joins, é que os filtering joins não adicionam novas variáveis à sua tabela, eles apenas filtram as linhas de sua tabela a depender se elas puderam ou não ser encontradas na outra tabela.\nComeçando pelo anti join, se você possui uma tabela A e uma tabela B, e aplica um anti join sobre essas tabelas, você vai encontrar todas as linhas da tabela A que não foram encontradas na tabela B. Portanto, a função anti_join() é uma forma prática e eficiente de você descobrir quais indivíduos de uma tabela A não são descritos em uma tabela B. Portanto, se voltarmos às tabelas info e band_instruments, perceba abaixo, que apenas as linhas referentes à Mick, George e Ringo são retornadas em um anti join, pois esses músicos da tabela info não estão presentes na tabela band_instruments.\n\nanti_join(\n  info,\n  band_instruments,\n  by = join_by(name)\n)\n\n# A tibble: 3 × 4\n  name   band           born       children\n  &lt;chr&gt;  &lt;chr&gt;          &lt;date&gt;     &lt;lgl&gt;   \n1 Mick   Rolling Stones 1943-07-26 TRUE    \n2 George Beatles        1943-02-25 TRUE    \n3 Ringo  Beatles        1940-07-07 TRUE    \n\n\nPor outro lado, um semi join representa justamente a operação contrária. Isto é, um semi join entre as tabelas A e B, lhe retorna todas as linhas da tabela A que foram encontradas na tabela B. Sendo assim, se aplicarmos a função semi_join() sobre as tabelas info e band_instruments, temos como resultado as linhas referentes aos músicos John e Paul, pelo fato destes músicos estarem presentes em ambas as tabelas.\n\nsemi_join(\n  info,\n  band_instruments,\n  by = join_by(name)\n)\n\n# A tibble: 2 × 4\n  name  band    born       children\n  &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;     &lt;lgl&gt;   \n1 John  Beatles 1940-09-10 TRUE    \n2 Paul  Beatles 1942-06-18 TRUE    \n\n\n\n\n\n\nNIELD, T. Getting Started with SQL: A Hands-on Approach for Beginners. 1. ed. Sepastopol, CA: O’Reilly Media, 2016.\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introdução a base de dados relacionais com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/06-dados-relacionais.html#footnotes",
    "href": "Capítulos/06-dados-relacionais.html#footnotes",
    "title": "6  Introdução a base de dados relacionais com dplyr",
    "section": "",
    "text": "https://twitter.com/hadleywickham/status/1435952016224886784↩︎",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introdução a base de dados relacionais com `dplyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/07-tidy-data.html",
    "href": "Capítulos/07-tidy-data.html",
    "title": "7  Tidy Data: uma abordagem para organizar os seus dados com tidyr",
    "section": "",
    "text": "7.1 Introdução e pré-requisitos\nEm qualquer análise, o formato no qual os seus dados se encontram, é muito importante. O que vamos discutir neste capítulo, será como reformatar as suas tabelas, corrigir valores não disponíveis, ou “vazios” que se encontram no formato incorreto, ou então, como preencher as suas colunas que estão incompletas de acordo com um certo padrão.\nVocê rapidamente descobre a importância que o formato de sua tabela carrega para o seu trabalho, na medida em que você possui pensamentos como: “Uhmm…se essa coluna estivesse na forma x, eu poderia simplesmente aplicar a função y() e todos os meus problemas estariam resolvidos”; ou então: “Se o Arnaldo não tivesse colocado os totais junto dos dados desagregados, eu não teria todo esse trabalho!”; ou talvez: “Qual é o sentido de colocar o nome dos países nas colunas? Assim fica muito mais difícil de acompanhar os meus dados!”.\nPara corrigir o formato das nossas tabelas, vamos utilizar neste capítulo as funções do pacote tidyr que está incluso no tidyverse. Pelo próprio nome do pacote (tidy, que significa “arrumar”), já sabemos que ele inclui diversas funções que tem como propósito, organizar os seus dados. Portanto, lembre-se de chamar pelo pacote (seja pelo tidyr diretamente, ou pelo tidyverse) antes de prosseguir:\nlibrary(tidyverse)\n## Ou\nlibrary(tidyr)",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>*Tidy Data*: uma abordagem para organizar os seus dados com `tidyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/07-tidy-data.html#o-que-é-tidy-data",
    "href": "Capítulos/07-tidy-data.html#o-que-é-tidy-data",
    "title": "7  Tidy Data: uma abordagem para organizar os seus dados com tidyr",
    "section": "7.2 O que é tidy data?",
    "text": "7.2 O que é tidy data?\nEm geral, nós passamos grande parte do tempo, reorganizando os nossos dados, para que eles fiquem no formato adequado para a nossa análise. Logo, aprender técnicas que facilitem o seu trabalho nesta atividade, pode economizar uma grande parte de seu tempo.\nIsso é muito importante, pois uma base de dados que está bagunçada, é em geral, bagunçada em sua própria maneira. Como resultado, cada base irá exigir um conjunto de operações e técnicas diferentes das outras bases, para que ela seja arrumada. Em alguns casos, são problemas simples de serem resolvidos, já em outros, podemos ter bases que estão desarrumadas em um padrão não muito bem definido, e por isso, vão te demandar mais trabalho.\n\n“Tidy datasets are all alike, but every messy dataset is messy in its own way”. WICKHAM (2014, p. 2).\n\nToda essa problemática, ocorre não apenas pelo erro humano, mas também porque podemos representar os nossos dados de diversas maneiras dentro de uma tabela. Cada maneira pode tanto facilitar muito o seu trabalho, quanto tornar o trabalho de outros, num inferno. Veja por exemplo, as tabelas abaixo. Ambas, apresentam os mesmos dados, mas em estruturas diferentes.\n\ntable2\n\n# A tibble: 12 × 4\n  country      year type          count\n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n1 Afghanistan  1999 cases           745\n2 Afghanistan  1999 population 19987071\n3 Afghanistan  2000 cases          2666\n4 Afghanistan  2000 population 20595360\n5 Brazil       1999 cases         37737\n# ℹ 7 more rows\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n# ℹ 1 more row\n\n\nAntes de partirmos para a prática, vou fornecer uma base teórica que irá sustentar as suas decisões sobre como padronizar e estruturar os seus dados. Eu expliquei anteriormente, que o tidyverse é um conjunto de pacotes que dividem uma mesma filosofia. Isso significa, que esses pacotes possuem uma conexão forte entre si. Por exemplo, as funções desses pacotes, retornam os seus resultados em tibble’s, e todas as suas funções foram construídas de forma a trabalharem bem com o operador pipe (%&gt;%). Todas essas funções também foram projetadas seguindo as melhores práticas e técnicas em análise de dados. Sendo uma dessas práticas, o que é comumente chamado na comunidade de tidy data.\nO conceito de tidy data foi definido por WICKHAM (2014), e remete a forma como você está guardando os dados em sua tabela. Eu não estou dizendo aqui que todas as funções do tidyverse que apresentei até aqui, trabalham apenas com tidy data, mas sim, que essas funções são mais eficientes com essa estrutura tidy. Uma base de dados que está no formato tidy, compartilha das três seguintes características:\n\nCada variável de sua tabela, deve possuir a sua própria coluna.\nCada observação de sua tabela, deve possuir a sua própria linha.\nCada valor de sua tabela, deve possuir a sua própria célula.\n\nPrimeiro, vou definir o que quero dizer exatamente com linhas, colunas e células de sua tabela. Em Figura 7.1 temos uma representação de uma base qualquer. O interesse nessa representação, não se trata dos valores e nomes inclusos nessa tabela, mas sim as áreas sombreadas dessa tabela, que estão lhe apresentando cada um dos componentes supracitados.\n\n\n\n\n\n\n\n\nFigura 7.1: Definindo colunas, linhas e células de uma tabela\n\n\n\n\n\nAgora, vamos definir o que são variáveis, observações e valores. Você já deve ter percebido, que toda base de dados, possui uma unidade básica que está sendo descrita ao longo dela. Ou seja, toda base lhe apresenta dados sobre um grupo específico (ou uma amostra) de algo. Esse “algo” pode ser um conjunto de municípios, empresas, sequências genéticas, animais, clientes, realizações de um evento estocástico, dentre outros.\nLogo, se a minha base contém dados sobre os municípios do estado de Minas Gerais (MG), cada um desses municípios são uma observação de minha base. Ao dizer que cada observação deve possuir a sua própria linha, eu estou dizendo que todas as informações referentes a um município específico, devem estar em uma única linha. Em outras palavras, cada uma das 853 (total de municípios em MG) linhas da minha base, contém os dados de um município diferente do estado.\nEntretanto, se a minha base descreve a evolução do PIB desses mesmos municípios nos anos de 2010 a 2020, eu não possuo mais um valor para cada município, ao longo da base. Neste momento, eu possuo 10 valores diferentes, para cada município, e mesmo que eu ainda esteja falando dos mesmos municípios, a unidade básica da minha base, se alterou. Cada um desses 10 valores, representa uma observação do PIB deste município em um ano distinto. Logo, cada um desses 10 valores para cada município, deve possuir a sua própria linha. Se o estado de Minas Gerais possui 853 municípios diferentes, isso significa que nossa base deveria ter \\(10 \\times 853 = 8.530\\) linhas. Por isso, é importante que você preste atenção em seus dados, e identifique qual é a unidade básica que está sendo tratada.\nAgora, quando eu me referir as variáveis de sua base, eu geralmente estou me referindo as colunas de sua base, porque ambos os termos são sinônimos em análises de dados. Porém, alguns cuidados são necessários, pois as variáveis de sua base podem não se encontrar nas colunas de sua tabela. Como eu disse anteriormente, há diversas formas de representar os seus dados, e por isso, há diversas formas de alocar os componentes de seus dados ao longo de sua tabela.\nUma variável de sua base de dados, não é apenas um elemento que (como o próprio nome dá a entender) varia ao longo de sua base, mas também é um elemento que lhe apresenta uma característica das suas observações. Ou seja, cada variável descreve uma característica (cor de pele, população, receita, …) de cada observação (pessoa, município, empresa, …) da minha base. O que é ou não, uma característica de sua unidade básica, irá depender de qual é essa unidade básica que está sendo descrita na base.\nA população total, é uma característica geralmente associada a regiões geográficas (municípios, países, etc.), já a cor de pele pode ser uma característica de uma amostra de pessoas entrevistadas em uma pesquisa de campo (como a PNAD contínua), enquanto o número total de empresas é uma característica associada a setores da atividade econômica (CNAE - Classificação Nacional de Atividades Econômicas).\nPor último, os valores de sua base, correspondem aos registros das características de cada observação de sua base. Como esse talvez seja o ponto mais claro e óbvio de todos, não vou me prolongar mais sobre ele. Pois as três características de tidy data que citamos anteriormente são interrelacionadas, de forma que você não pode satisfazer apenas duas delas. Logo, se você está satisfazendo as duas primeiras, você não precisa se preocupar com a característica que diz respeito aos valores.\n\n\n\n\n\nTrês propriedades que caracterizam o formato tidy data\n\n\n\n\nPortanto, sempre inicie o seu trabalho, identificando a unidade básica de sua base. Em seguida, tente encontrar quais são as suas variáveis, ou as características dessa unidade básica que estão sendo descritas na base. Após isso, basta alocar cada variável em uma coluna, e reservar uma linha para cada observação diferente de sua base, que você automaticamente estará deixando uma célula para cada valor da base.\n\n7.2.1 Será que você entendeu o que é tidy data?\nNessa seção vamos fazer um teste rápido, para saber se você entendeu o que é uma tabela no formato tidy. Olhe por algum tempo para os exemplos abaixo, e reflita sobre qual dessas tabelas está no formato tidy. Tente também descobrir quais são os problemas que as tabelas “não tidy” apresentam, ou em outras palavras, qual das três definições que apresentamos anteriormente, que essas tabelas “não tidy” acabam rompendo.\n\ntable1\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n# ℹ 1 more row\n\ntable2\n\n# A tibble: 12 × 4\n  country      year type          count\n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n1 Afghanistan  1999 cases           745\n2 Afghanistan  1999 population 19987071\n3 Afghanistan  2000 cases          2666\n4 Afghanistan  2000 population 20595360\n5 Brazil       1999 cases         37737\n# ℹ 7 more rows\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n# ℹ 1 more row\n\n\nComo eu disse anteriormente, a primeira coisa que você deve fazer, é identificar a unidade básica que está sendo tratada na tabela. Nos exemplos acima, essas tabelas dizem respeito à dados de três países (Brasil, China e Afeganistão) em dois anos diferentes (1999 e 2000). Logo, a nossa tabela possui \\(3 \\times 2 = 6\\) observações diferentes. Se uma das regras, impõe que todas as linhas devem possuir informações de uma única observação, a nossa tabela deveria possuir 6 linhas. Com isso, nós já sabemos que algo está errado com a tabela 2, pois ela possui o dobro de linhas.\nNa verdade, o problema na tabela 2 é que ela está quebrando a regra de que cada variável na tabela deve possuir a sua própria coluna. Por causa dessa regra, a tabela 2 acaba extrapolando o número de linhas necessárias. Olhe para as colunas type e count. A coluna count lhe apresenta os principais valores que estamos interessados nessa tabela. Porém, a coluna type, está lhe apresentando duas variáveis diferentes.\nLembre-se de que variáveis, representam características da unidade básica de sua tabela. No nosso caso, essa unidade básica se trata dos dados anuais de países, logo, cases e population, são variáveis ou características diferentes desses países. Uma dessas variáveis está lhe apresentando um dado demográfico (população total), já a outra, está lhe trazendo um indicador epidemiológico (número de casos de alguma doença). Por isso, ambas variáveis deveriam possuir a sua própria coluna.\nOk, mas e as tabelas 1 e 3? Qual delas é a tidy? Talvez, para responder essa pergunta, você deveria primeiro procurar pela tabela “não tidy”. Veja a tabela 3, e se pergunte: “onde se encontram os valores de população e de casos de cada país nessa tabela?”. Ao se fazer essa pergunta, você provavelmente já irá descobrir qual é o problema nessa tabela.\n\n\n\n\n\n\n\n\nFigura 7.2: Formas gerais que a sua tabela pode adquirir\n\n\n\n\n\nA tabela 3, também rompe com a regra de que cada variável deve possuir a sua própria coluna. Pois o número de casos e a população total, estão guardados em uma mesma coluna! Ao separar os valores de população e de número de casos na tabela 3, em duas colunas diferentes, você chega na tabela 1, que é um exemplo de tabela tidy, pois agora todas as três definições estão sendo respeitadas.\n\n\n7.2.2 Uma breve definição de formas\nApenas para que os exemplos das próximas seções, fiquem mais claros e fáceis de se visualizar mentalmente, vou definir dois formatos gerais que a sua tabela pode assumir, que são: long (longa) e wide (larga)1. Ou seja, qualquer que seja a sua tabela, ela vai em geral, estar em algum desses dois formatos, de uma forma ou de outra.\nEsses termos (long e wide) são bem descritivos por si só. A ideia é que se uma tabela qualquer, está no formato long, ela adquire um aspecto visual de longa, ou em outras palavras, visualmente ela aparenta ter muitas linhas, e poucas colunas. Já uma tabela que está no formato wide, adquire um aspecto visual de larga, como se essa tabela possuísse mais colunas do que o necessário, e poucas linhas. Tais formas estão apresentadas em Figura 7.2.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>*Tidy Data*: uma abordagem para organizar os seus dados com `tidyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/07-tidy-data.html#operações-de-pivô",
    "href": "Capítulos/07-tidy-data.html#operações-de-pivô",
    "title": "7  Tidy Data: uma abordagem para organizar os seus dados com tidyr",
    "section": "7.3 Operações de pivô",
    "text": "7.3 Operações de pivô\nAs operações de pivô são as principais operações que você irá utilizar para reformatar a sua tabela. Uma operação de pivô basicamente altera as dimensões de sua tabela, ou dito de outra maneira, essas operações buscam transformar colunas em linhas, ou vice-versa. Para exemplificar essas operações, vamos utilizar as tabelas que vem do próprio pacote tidyr. Logo, se você chamou pelo tidyverse através de library(), você tem acesso a tabela abaixo. Basta chamar no console pelo objeto relig_income.\n\nrelig_income\n\n# A tibble: 18 × 11\n  religion  `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 Agnostic       27        34        60        81        76       137        122\n2 Atheist        12        27        37        52        35        70         73\n3 Buddhist       27        21        30        34        33        58         62\n4 Catholic      418       617       732       670       638      1116        949\n5 Don’t kn…      15        14        15        11        10        35         21\n# ℹ 13 more rows\n# ℹ 3 more variables: `$100-150k` &lt;dbl&gt;, `&gt;150k` &lt;dbl&gt;, …\n\n\nEssa tabela está nos apresentando o salário médio de pessoas pertencentes a diferentes religiões. Veja que em cada coluna dessa tabela, você possui os dados de uma faixa salarial específica. Essa é uma estrutura que pode ser fácil e intuitiva em alguns momentos, mas certamente irá trazer limites importantes para você dentro do R. Devido a especialidade que o R possui sobre operações vetorizadas, o ideal seria transformarmos essa tabela para o formato tidy.\nA unidade básica dessa tabela, são os grupos religiosos, e a faixa salarial representa uma característica desses grupos. Há diferentes níveis salariais na tabela, que estão sendo distribuídos ao longo de diferentes colunas. Tendo em vista isso, uma das regras não está sendo respeitada. Pois todos esses diferentes níveis salarias, representam uma única característica, ou em outras palavras, eles transmitem o mesmo tipo de informação, que é um nível salarial daquele grupo religioso. Por isso, todas essas características da tabela, deve estar em uma única coluna. A Figura 7.3 nos apresenta, em uma representação visual, o que precisamos fazer.\n\n\n\n\n\n\n\n\nFigura 7.3: Representação de uma operação de pivô\n\n\n\n\n\nPor isso, quando você estiver em um momento como este, em que você deseja transformar as suas linhas em colunas, ou vice-versa, você está na verdade, procurando por uma operação de pivô.\n\n7.3.1 Adicionando linhas à sua tabela com pivot_longer()\nAtualmente, a tabela relig_income possui poucas linhas e muitas colunas, e por isso, ela adquire um aspecto visual de “larga” (ou “wide”). Como eu disse, seria muito interessante para você, que transformasse essa tabela, de modo a agrupar as diferentes faixas de níveis salarias em uma única coluna. Logo, se estamos falando em reduzir o número de colunas, estamos querendo alongar a base, ou dito de outra forma, aumentar o número de linhas da base. Para fazermos isso, devemos utilizar a função pivot_longer().\nEssa função possui três argumentos principais: 1) cols, os nomes das colunas que você deseja transformar em linhas; 2) names_to, o nome da nova coluna onde serão alocados os nomes, ou os rótulos das colunas que você definiu em cols; 3) values_to, o nome da nova coluna onde serão alocados os valores da sua tabela, que se encontram nas colunas que você definiu em cols. Como nós queremos transformar todas as colunas da tabela relig_income, que contém faixas salariais, eu posso simplesmente colocar no argumento cols, um símbolo de menos antes do nome da coluna religion, que é a única coluna da tabela, que não possui esse tipo de informação. Ou seja, dessa forma, eu estou dizendo à pivot_longer(), para transformar todas as colunas (exceto a coluna religion).\n\nrelig_income %&gt;% \n  pivot_longer(\n    cols = -religion,\n    names_to = \"income\",\n    values_to = \"values\"\n  )\n\n# A tibble: 180 × 3\n  religion income  values\n  &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt;\n1 Agnostic &lt;$10k       27\n2 Agnostic $10-20k     34\n3 Agnostic $20-30k     60\n4 Agnostic $30-40k     81\n5 Agnostic $40-50k     76\n# ℹ 175 more rows\n\n\nVale destacar, que você pode selecionar as colunas que você deseja transformar em linhas (argumento cols), através dos mesmos mecanismos que utilizamos na função select(). Ao eliminarmos a coluna religion com um sinal de menos (-) estávamos utilizando justamente um desses métodos. Mas podemos também, por exemplo, selecionar todas as colunas, que possuem dados de tipo numérico, com a função is.numeric(), atingindo o mesmo resultado anterior. Ou então, poderíamos selecionar todas as colunas que possuem em seu nome, algum dígito numérico, através da expressão regular \"\\\\d\" (digit) na função matches().\n\nrelig_income %&gt;% \n  pivot_longer(\n    # A linha abaixo também poderia ser: cols = matches(\"\\\\d\")\n    cols = is.numeric,\n    names_to = \"income\",\n    values_to = \"values\"\n  )\n\nPortanto, sempre que utilizar a função pivot_longer(), duas novas colunas serão criadas. Em uma dessas colunas (values_to), a função irá guardar os valores que se encontravam nas colunas que você transformou em linhas. Já na outra coluna (names_to), a função irá criar rótulos em cada linha, que lhe informam de qual coluna (que você transformou em linhas) veio o valor disposto na coluna anterior (values_to). Você sempre deve definir como texto o nome dessas duas novas colunas. Isto é, sempre forneça os nomes dessas colunas, entre aspas duplas ou simples.\nComo um outro exemplo, temos a tabela billboard, que também está disponível no pacote tidyr. Nessa tabela, temos a posição que diversas músicas ocuparam na lista da Billboard das 100 músicas mais populares no mundo, durante o ano de 2000. Portanto a posição que cada uma dessas músicas ocuparam nessa lista, ao longo do tempo, é a unidade básica que está sendo tratada nessa tabela. Agora, repare que a tabela possui muitas colunas (79 no total), onde em cada uma delas, temos a posição de uma música em uma dada semana desde a sua entrada na lista.\n\nbillboard\n\n# A tibble: 317 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby… 2000-02-26      87    82    72    77    87    94    99    NA\n2 2Ge+her     The … 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n3 3 Doors Do… Kryp… 2000-04-08      81    70    68    67    66    57    54    53\n4 3 Doors Do… Loser 2000-10-21      76    76    72    69    67    65    55    59\n5 504 Boyz    Wobb… 2000-04-15      57    34    25    17    17    31    36    49\n# ℹ 312 more rows\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;, …\n\n\nSão ao todo, 76 colunas contendo a posição de cada música no ranking na semana correspondente. Novamente, quando há um conjunto muito grande de colunas que desejamos selecionar, podemos utilizar os métodos alternativos de seleção que vimos em select(). Repare que os nomes dessas 76 colunas estão sempre no formato (wk...). Logo, você pode se aproveitar desse padrão, e selecionar todas essas colunas de uma vez só, usando a função starts_with() no argumento cols de pivot_longer(). Também podemos selecionar todas essas colunas pelos seus índices, fornecendo o vetor 4:79 para o argumento cols.\n\nbillboard_long &lt;- billboard %&gt;% \n  pivot_longer(\n    # A linha abaixo também poderia ser: cols = 4:79\n    cols = starts_with(\"wk\"),\n    names_to = \"week\",\n    values_to = \"position\"\n  )\n\nbillboard_long\n\n# A tibble: 24,092 × 5\n  artist track                   date.entered week  position\n  &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt;    &lt;dbl&gt;\n1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1         87\n2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2         82\n3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3         72\n4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4         77\n5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5         87\n# ℹ 24,087 more rows\n\n\n\n\n7.3.2 Adicionando colunas à sua tabela com pivot_wider()\nPor outro lado, você talvez deseje realizar a operação contrária. Ou seja, se você deseja transformar linhas de sua tabela, em novas colunas, você deve utilizar a função pivot_wider(), que possui argumentos muito parecidos com os de pivot_longer().\nVamos começar com um exemplo simples. Veja a tabela df que estou criando logo abaixo. Nessa tabela, temos dados como o peso, a idade e a altura de cinco pessoas diferentes. Porém, perceba que essa tabela, não está no formato tidy. Pois temos três informações (peso, idade e altura) que representam características diferentes da unidade básica da tabela (pessoas), condensadas em uma mesma coluna (variavel).\n\ndf &lt;- tibble(nome = c(\"Ana\", \"Ana\", \"Ana\", \"Eduardo\", \"Eduardo\", \n\"Eduardo\", \"Paulo\", \"Paulo\", \"Paulo\", \"Henrique\", \"Henrique\", \n\"Henrique\", \"Letícia\", \"Letícia\", \"Letícia\"), variavel = c(\"idade\", \n\"peso\", \"altura\", \"idade\", \"peso\", \"altura\", \"idade\", \"peso\", \n\"altura\", \"idade\", \"peso\", \"altura\", \"idade\", \"peso\", \"altura\"\n), valor = c(20, 61, 1.67, 18, 90, 1.89, 19, 68, 1.67, 23, 82, \n1.72, 27, 56, 1.58))\n\ndf\n\n# A tibble: 15 × 3\n  nome    variavel valor\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n1 Ana     idade    20   \n2 Ana     peso     61   \n3 Ana     altura    1.67\n4 Eduardo idade    18   \n5 Eduardo peso     90   \n# ℹ 10 more rows\n\n\nPortanto, tendo identificado o problema, precisamos agora, separar as três variáveis contidas na coluna variavel, em três novas colunas da tabela df. Logo, precisamos alargar a nossa base, pois estamos eliminando linhas e adicionando colunas à tabela.\nJá sabemos que podemos utilizar a função pivot_wider() para esse trabalho, e os seus argumentos são: 1) id_cols, que são as colunas suficientes para (ou capazes de) identificar uma única observação de sua base; 2) names_from, que é a coluna de sua tabela que contém as linhas a serem dividas, ou transformadas, em várias outras colunas; 3) values_from, que é a coluna com os valores a serem posicionados nas novas células, que serão criadas durante o processo de “alargamento” da sua tabela.\nAntes de prosseguirmos para os exemplos práticos, é provavelmente uma boa ideia, refletirmos sobre o que o argumento id_cols significa. As colunas a serem estipuladas no argumento id_cols são aquelas que conseguem identificar cada observação de sua base. No nosso caso, a tabela df, contém dados sobre características físicas ou biológicas, de cinco pessoas diferentes. Logo, a unidade básica dessa tabela, são as pessoas que estão sendo descritas nela, e por isso, a coluna nome é capaz de identificar cada observação (unidade básica) da tabela, pois ela nos traz justamente um código social de identificação, isto é, o nome dessas pessoas.\nPensando em um outro exemplo, se você dispõe de uma base que descreve o PIB de cada município do estado de Minas Gerais, você precisa definir em id_cols, a coluna (ou o conjunto de colunas) que é capaz de identificar cada um dos 853 municípios de MG, pois esses municípios são a unidade básica da tabela. Porém, se a sua base está descrevendo o PIB desses mesmos municípios, mas agora ao longo dos anos de 2010 a 2020, a sua unidade básica passa a ter um componente temporal, e se torna a evolução desses municípios ao longo do tempo. Dessa forma, você precisaria não apenas de uma coluna que seja capaz de identificar qual o município que está sendo descrito na base, mas também de uma outra coluna que possa identificar qual o ano que a informação desse município se refere.\nTendo isso em mente, vamos partir para os próximos dois argumentos. No nosso caso, queremos pegar as três variáveis que estão ao longo da coluna variavel, e separá-las em três colunas diferentes. Isso é exatamente o que devemos definir em names_from. O que este argumento está pedindo, é o nome da coluna que contém os valores que vão servir de nome para as novas colunas que pivot_wider() irá criar. Ou seja, ao fornecermos a coluna variavel para names_from, pivot_wider() irá criar uma nova coluna para cada valor único que se encontra na coluna variavel. Como ao longo da coluna variavel, temos três valores diferentes (peso, altura e idade), pivot_wider() irá criar três novas colunas que possuem os nomes de peso, altura e idade.\nAo criar as novas colunas, você precisa preenchê-las de alguma forma, a menos que você deseja deixá-las vazias. Em outras palavras, a função pivot_wider() irá lhe perguntar: “Ok, eu criei as colunas que você me pediu para criar, mas eu devo preenchê-las com que valores?”. Você deve responder essa pergunta, através do argumento values_from, onde você irá definir qual é a coluna que contém os valores que você deseja alocar ao longo dessas novas colunas (que foram criadas de acordo com os valores contidos na coluna que você definiu em names_from). Na nossa tabela df, é a coluna valor que contém os registros, ou os valores que cada variável (idade, altura e peso) assume nessa amostra. Logo, é essa coluna que devemos conectar à values_from.\n\ndf %&gt;% \n  pivot_wider(\n    id_cols = nome,\n    names_from = variavel,\n    values_from = valor\n  )\n\n# A tibble: 5 × 4\n  nome     idade  peso altura\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Ana         20    61   1.67\n2 Eduardo     18    90   1.89\n3 Paulo       19    68   1.67\n4 Henrique    23    82   1.72\n5 Letícia     27    56   1.58\n\n\nEsse foi um exemplo simples de como utilizar a função, e que vai lhe servir de base para praticamente qualquer aplicação de pivot_wider(). Porém, em algumas situações que você utilizar pivot_wider(), pode ser que a sua tabela não possua colunas o suficiente, que possam identificar unicamente cada observação de sua base, e isso, ficará mais claro com um outro exemplo.\nCom o código abaixo, você é capaz de recriar a tabela vendas, em seu R. Lembre-se de executar a função set.seed() antes de criar a tabela vendas, pois é essa função que garante que você irá recriar exatamente a mesma tabela que a minha. Nessa tabela vendas, possuímos vendas hipóteticas de diversos produtos (identificados por produtoid), realizadas por alguns vendedores (identificados por usuario) que arrecadaram em cada venda os valores descritos na coluna valor. Perceba também, que essas vendas são diárias, pois possuímos outras três colunas (ano, mes e dia) que definem o dia em que a venda ocorreu.\n\nnomes &lt;- c(\"Ana\", \"Eduardo\", \"Paulo\", \"Henrique\", \"Letícia\")\nproduto &lt;- c(\"10032\", \"10013\", \"10104\", \"10555\", \"10901\")\nset.seed(1)\nvendas &lt;- tibble(\n    ano = sample(2010:2020, size = 10000, replace = TRUE),\n    mes = sample(1:12, size = 10000, replace = TRUE),\n    dia = sample(1:31, size = 10000, replace = TRUE),\n    usuario = sample(nomes, size = 10000, replace = TRUE),\n    valor = rnorm(10000, mean = 5000, sd = 1600),\n    produtoid = sample(produto, size = 10000, replace = TRUE)\n  ) %&gt;% \n  arrange(ano, mes, dia, usuario)\n\nPerceba pelos resultados abaixo, que nós temos cinco vendedores e cinco produtos diferentes que estão sendo descritos ao longo da tabela vendas.\n\nunique(vendas$usuario)\n\n[1] \"Ana\"      \"Henrique\" \"Letícia\"  \"Eduardo\"  \"Paulo\"   \n\nunique(vendas$produtoid)\n\n[1] \"10104\" \"10013\" \"10555\" \"10032\" \"10901\"\n\n\nSe você tentar distribuir tanto os vendedores (usuario), quanto os produtos vendidos (produtoid), em novas colunas dessa tabela, utilizando pivot_wider(), um aviso será levantado, e o resultado dessa operação (apesar de correto) será provavelmente, muito estranho para você:\n\nvendas_wide &lt;- vendas %&gt;% \n  pivot_wider(\n    id_cols = c(\"ano\", \"mes\", \"dia\", \"produtoid\"),\n    names_from = usuario,\n    values_from = valor\n  )\n\nWarning: Values from `valor` are not uniquely identified; output will contain list-cols.\n• Use `values_fn = list` to suppress this warning.\n• Use `values_fn = {summary_fun}` to summarise duplicates.\n• Use the following dplyr code to identify duplicates.\n  {data} |&gt;\n  dplyr::summarise(n = dplyr::n(), .by = c(ano, mes, dia, produtoid, usuario))\n  |&gt;\n  dplyr::filter(n &gt; 1L)\n\nvendas_wide\n\n# A tibble: 7,845 × 9\n    ano   mes   dia produtoid Ana       Henrique  Letícia   Eduardo   Paulo \n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;     &lt;list&gt;    &lt;list&gt;    &lt;list&gt;    &lt;list&gt;    &lt;list&gt;\n1  2010     1     1 10104     &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt;    &lt;NULL&gt;    &lt;NULL&gt;\n2  2010     1     2 10013     &lt;NULL&gt;    &lt;dbl [1]&gt; &lt;NULL&gt;    &lt;NULL&gt;    &lt;NULL&gt;\n3  2010     1     3 10555     &lt;dbl [1]&gt; &lt;NULL&gt;    &lt;dbl [1]&gt; &lt;NULL&gt;    &lt;NULL&gt;\n4  2010     1     4 10555     &lt;dbl [1]&gt; &lt;NULL&gt;    &lt;NULL&gt;    &lt;NULL&gt;    &lt;NULL&gt;\n5  2010     1     4 10013     &lt;NULL&gt;    &lt;NULL&gt;    &lt;NULL&gt;    &lt;dbl [1]&gt; &lt;NULL&gt;\n# ℹ 7,840 more rows\n\n\nComo podemos ver pelo resultado acima, uma mensagem de aviso apareceu, nos informando que os valores não podem ser unicamente identificados através das colunas que fornecemos em id_cols (Values are not uniquely identified), e que por isso, a função pivot_wider(), acabou transformando as novas colunas que criamos, em listas (output will contain list-cols.).\nOu seja, cada uma das colunas que acabamos de criar com pivot_wider(), são listas (e.g. list). Isso pode ser estranho para muitos usuários, pois na maioria das vezes, as colunas de suas tabelas serão vetores atômicos2. Um outro motivo que provavelmente levantou bastante dúvida em sua cabeça é: “Como assim as colunas que forneci não são capazes de identificar unicamente os valores? Em que sentido elas não são capazes de realizar tal ação?”.\nA resposta curta simples é que, existem alguns casos dentro da tabela vendas em que, um mesmo vendedor conseguiu vender o mesmo produto, em uma mesma data, mais de uma única vez. Por causa disso, a combinação de colunas ano, mes, dia e produtoid se torna insuficiente para diferenciar uma venda da outra. Por exemplo, observe abaixo, que os vendedores Ana e Henrique venderam no dia 01/01/2010, uma unidade do produto de ID 10104:\n\nvendas |&gt;\n  filter(\n    produtoid == 10104,\n    ano == 2010, mes == 1, dia == 1\n  )\n\n# A tibble: 2 × 6\n    ano   mes   dia usuario  valor produtoid\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;    \n1  2010     1     1 Ana      3907. 10104    \n2  2010     1     1 Henrique 6139. 10104    \n\n\nNeste ponto, se pergunte: “Ok, Ana vendeu uma unidade do produto 10104, no dia 01. Mas e se ela tivesse vendido duas unidades desse mesmo produto 10104, no dia 01?”. Tente imaginar para onde os valores dessas vendas seriam movidos após a operação de pivô que realizamos no exemplo anterior. Isso não é uma questão trivial. Pois temos agora dados de duas vendas diferentes…mas apenas uma célula disponível em nossa tabela, para guardar esses dados. É a partir deste choque, que podemos identificar qual foi o motivo para o uso de listas nas novas colunas.\nOu seja, temos uma única célula na tabela (localizada na primeira linha, e quinta coluna da tabela), que deve conter o valor arrecadado na venda do produto 10104, realizada pela vendedora Ana no dia 01/01/2010. Você poderia pensar: “Bem, por que não somar os valores dessas duas vendas? Dessa forma, temos apenas um valor para encaixar nessa célula”. Essa é uma alternativa possível, porém, ela gera perda de informação, especialmente se o valor arrecadado nas duas operações forem diferentes. Por exemplo, se a receita da primeira venda foi de 3907, e da segunda, de 4530. Com essa alternativa, nós sabemos que a soma das duas vendas ocorridas naquele dia, geraram 8437 reais de receita, mas nós não sabemos mais qual das duas vendas teve o maior valor de venda.\nIsso é particularmente importante, pois podemos gerar o mesmo valor (8437 reais) de múltiplas formas. Pode ser que a Ana tenha vendido cinco unidades do produto 10104, tendo arrecadado em cada venda, o valor de 1687,4 reais. Mas ela poderia atingir o mesmo valor, ao vender dez unidades do produto 10104, dessa vez, arrecadando um valor médio bem menor, de 843,7 reais. Portanto, se utilizarmos a soma desses valores, como forma de contornarmos o problema posto anteriormente, os administradores da loja não poderão mais inferir da tabela vendas, se as suas vendas tem se reduzido em quantidade, ou se o valor arrecadado em cada venda, tem caído ao longo dos últimos anos.\nApesar de ser uma alternativa ruim em muitos casos, ela pode fazer sentido para o seu caso específico. Nesta situação, as versões mais recentes do pacote tidyr, oferecem na função pivot_wider() o argumento values_fn, onde você pode fornecer o nome de uma função a ser aplicada sobre os valores dispostos em cada célula. Logo, se quiséssemos somar os valores de vendas de cada célula criada na tabela vendas_wide, poderíamos realizar os comandos abaixo:\n\nvendas %&gt;% \n  pivot_wider(\n    id_cols = c(\"ano\", \"mes\", \"dia\", \"produtoid\"),\n    names_from = usuario,\n    values_from = valor,\n    values_fn = sum\n  )\n\n# A tibble: 7,845 × 9\n    ano   mes   dia produtoid   Ana Henrique Letícia Eduardo Paulo\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1  2010     1     1 10104     3907.    6139.     NA      NA     NA\n2  2010     1     2 10013       NA     5510.     NA      NA     NA\n3  2010     1     3 10555     5296.      NA    3525.     NA     NA\n4  2010     1     4 10555     5102.      NA      NA      NA     NA\n5  2010     1     4 10013       NA       NA      NA    6051.    NA\n# ℹ 7,840 more rows\n\n\nPortanto, a função pivot_wide() foi obrigada a transformar as novas colunas criadas em colunas de lista (i.e. list-cols) pelo simples fato de que a função encontrou casos em que um mesmo vendedor vendeu o mesmo produto mais de uma vez na mesma data, e que por isso, o conjunto de colunas fornecidos no argumento id_cols se tornou insuficiente para identificar uma única observação da base.\nVocê talvez pense: “Por que não fornecemos então todas as colunas da tabela para id_cols?”. Primeiro, esse questionamento carrega um pressuposto que não necessariamente se confirma, que é o de que os valores das vendas realizadas por um mesmo vendedor, de um mesmo produto, e no mesmo dia, são diferentes em todas as ocasiões. Algo que é possível, mas não necessariamente ocorre ao longo de toda a base. O segundo problema, é que a coluna valor não está mais disponível para ser utilizada por id_cols, pois se você se lembrar, nós conectamos essa coluna a values_from. Isso significa, que essa coluna já está sendo utilizada para preencher as novas células que estão sendo criadas por pivot_wider(), e, portanto, ela não pode ocupar dois espaços ao mesmo tempo. Tanto que se você tentar adicionar a coluna valor a id_cols, você irá perceber que nada se altera, e o mesmo resultado é gerado.\nPortanto, não há uma resposta fácil para uma situação como essa, onde mesmo fornecendo todas as colunas para id_cols em pivot_wider(), a função ainda não é capaz de identificar unicamente cada valor da coluna que você forneceu em value_from. Você pode utilizar uma solução que gera perda de informação, ao aplicar uma função sumária, ou seja, uma função para agregar esses valores de forma que eles se tornem únicos, dados os conjuntos de colunas que você forneceu em id_cols. Uma outra possibilidade, é que você esteja utilizando a operação de pivô errada. Ou seja, a melhor alternativa seria alongar (pivot_longer()) a sua base, ao invés de alargá-la.\nAgora, uma última possibilidade mais promissora, é que você esteja realizando a operação correta, e que faz sentido lógico manter essas colunas como listas de acordo com o que você deseja realizar com a base. Isso inclui o uso de um ferramental que está um pouco além desse capítulo. Por outro lado, lidar com nested data, é mais uma questão de experiência, de se acostumar com tal estrutura, e saber as funções adequadas, do que aprender algo muito diferente do que mostramos aqui. Um outro conhecimento que é de extrema importância nessas situações, é conhecer muito bem como as listas funcionam no R. Se você conhecer bem essa estrutura, você não terá dificuldades em navegar por nested data. Para uma visão melhor do potencial que nested data pode trazer para sua análise, eu recomendo que você procure por uma excelente palestra de Hadley Wickham, entitulada “Managing many models with R”3.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>*Tidy Data*: uma abordagem para organizar os seus dados com `tidyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/07-tidy-data.html#trabalhando-com-dados-aninhados-ou-em-árvores-json-html-xml",
    "href": "Capítulos/07-tidy-data.html#trabalhando-com-dados-aninhados-ou-em-árvores-json-html-xml",
    "title": "7  Tidy Data: uma abordagem para organizar os seus dados com tidyr",
    "section": "7.4 Trabalhando com dados aninhados ou em árvores (JSON, HTML, XML)",
    "text": "7.4 Trabalhando com dados aninhados ou em árvores (JSON, HTML, XML)\nUma área em que o tidyr se desenvolveu muito nos últimos anos é a área de dados aninhados. Essa área envolve todo tipo de dado e estrutura que possui altos níveis de aninhamento (ou nesting). Ou seja, são estruturas que contém outras estruturas, que por sua vez contém um outro grupo de estruturas dentro delas, e assim por diante, seguindo um nível de profundidade grande.\nEsses dados são tipicamente encontrados no mundo real em formatos que representam árvores (ou trees) de informação. Grandes exemplos são dados em JSON, em HTML, ou em XML. Esses formatos são massivamente utilizados dentro da Web, isto é, em sistemas e plataformas que são acessadas pela internet, como APIs, plataformas de streaming, redes sociais, e outros tipos de Web Application’s. Como a internet e a Web são parte fundamental hoje da vida humana como um todo, um volume monumental de dados em JSON, HTML, etc. é produzido a todo momento. Por isso, analisar esse tipo de dado em formato de árvores tem sido cada vez mais comum e necessário dentro do mundo da estatística e da análise de dados.\nQuando trazidos para dentro do R, esses tipos de dados (JSON, HTML, etc.) são tipicamente representados através de listas (i.e. list), e geralmente, essas listas contém múltiplos níveis de aninhamento (i.e. listas que contém listas, que contém mais listas, etc.). Dentro do tidyr, o trabalho com esse tipo de dado é tipicamente associado com o termo rectangling (que seria algo próximo do verbo “enquadrar”). A ideia é utilizarmos o tidyr para encaixar (ou “enquadrar”) esse tipo de dado aninhado de modo eficiente dentro de um data.frame. Hoje, o tidyr tem três funções principais para fazer esse trabalho, que são unnest_longer(), unnest_wider(), e hoist().\nComo exemplos nessa seção, vamos usar os dados fornecidos pelo pacote repurrrsive, que contém alguns exemplos de dados aninhados perfeitos para as demonstrações feitas aqui. Lembre-se de instalar esse pacote usando install.packages(), e, em seguida, carregar ele para sua sessão com library().\n\nlibrary(repurrrsive)\n\n\n7.4.1 Criando colunas a partir dos atributos da lista\nA função unnest_wider() busca transformar os atributos encontrados em cada elemento de uma lista, em novas colunas de seu data.frame/tibble. Como exemplo, vamos analisar os dados no objeto gh_users. Se você conseguiu carregar o pacote repurrrsive com sucesso para a sua sessão, você tem acesso a este objeto.\nEm resumo, gh_users é uma lista contendo dados sobre seis usuários diferentes do GitHub. Cada elemento dessa lista contém uma outra lista com os atributos/características que descrevem um usuário específico. Portanto, temos uma “lista de seis listas”. Em cada elemento dessa lista, temos uma nova lista contendo vários atributos diferentes, como username desse usuário, a sua cidade (location), o seu email, a empresa onde trabalha (company). Enfim, temos várias informações diferentes de cada usuário.\nPrimeiro, vamos armazenar essa lista dentro de um tibble. Perceba que, por ser uma lista, o tibble resultante cria uma coluna do tipo list para armazenar esse objeto. Perceba também pela notação list[30] presente nas linhas dessa coluna, que cada uma das seis listas que estão dentro dessa lista inicial, possuem em torno de 30 atributos diferentes.\n\nusers &lt;- tibble(user = gh_users)\nusers\n\n# A tibble: 6 × 1\n  user             \n  &lt;list&gt;           \n1 &lt;named list [30]&gt;\n2 &lt;named list [30]&gt;\n3 &lt;named list [30]&gt;\n4 &lt;named list [30]&gt;\n5 &lt;named list [30]&gt;\n# ℹ 1 more row\n\n\nEm resumo, a função unnest_wider() vai “expandir” os atributos dessa lista em novas colunas de nossa tabela. Em outras palavras, os atributos presentes em cada “sublista” (ou em cada elemento) da lista inicial vai virar uma nova coluna dentro da nossa tabela. Como vimos acima que cada “sublista” da lista parece ter em torno de 30 atributos diferentes, significa que a função unnest_wider() vai criar em torno de 30 colunas novas.\nPara usarmos essa função, basta fornecermos o tibble com os nossos dados em seu primeiro argumento, e, em seguida, escrevemos no segundo argumento, o nome da coluna dentro desse tibble que contém a lista que queremos “expandir” em novas colunas. Como armazenamos o objeto gh_users em uma coluna chamada user em nossa tabela, eu escrevo o nome dessa coluna no segundo argumento da função.\nComo esperado, um novo tibble foi criado, contendo 30 colunas e 6 linhas. Cada linha nessa tabela representa um dos elementos da lista gh_users, e cada coluna nessa tabela, contém os dados de um atributo que estava armazenado dentro de cada “sublista”.\n\nusers_wide &lt;- users |&gt; unnest_wider(user)\nusers_wide\n\n# A tibble: 6 × 30\n  login     id avatar_url gravatar_id url   html_url followers_url following_url\n  &lt;chr&gt;  &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;        \n1 gabo… 6.60e5 https://a… \"\"          http… https:/… https://api.… https://api.…\n2 jenn… 5.99e5 https://a… \"\"          http… https:/… https://api.… https://api.…\n3 jtle… 1.57e6 https://a… \"\"          http… https:/… https://api.… https://api.…\n4 juli… 1.25e7 https://a… \"\"          http… https:/… https://api.… https://api.…\n5 leep… 3.51e6 https://a… \"\"          http… https:/… https://api.… https://api.…\n# ℹ 1 more row\n# ℹ 22 more variables: gists_url &lt;chr&gt;, starred_url &lt;chr&gt;, …\n\n\n\n\n7.4.2 Criando linhas a partir dos atributos da lista\nEnquanto a função unnest_wider() cria uma nova coluna para cada atributo encontrado dentro de cada elemento da lista, a função unnest_longer() faz o processo inverso. Isto é, ela cria uma nova linha para cada atributo encontrado em cada elemento da lista.\nApesar dessa diferença, unnest_longer() tem os mesmos argumentos que o seu par, unnest_wider(). Ou seja, no primeiro argumento da função, você fornece o tibble que contém os seus dados, e, em seguida, no segundo argumento, você fornece o nome da coluna dentro desse tibble que contém a lista que você gostaria de “expandir” em novas linhas de sua tabela. Se aplicarmos unnest_longer() sobre a tabela users, teremos como resultado, uma nova tabela contendo \\(6 \\times 30 = 180\\) linhas. Cada linha conteria o dado de um único atributo de um indivíduo específico.\nPorém, o objeto gh_users é um mal exemplo de uso da unnest_longer(). Um exemplo melhor de uso para essa função é o objeto gh_repos que também é uma lista com vários níveis de aninhamento. No primeiro nível, essa lista contém 6 elementos. Cada elemento corresponde a uma nova lista. Ou seja, temos 6 “sublistas”. Cada “sublista” contém os dados de um usuário específico. Dentro de cada uma dessas 6 “sublistas”, temos novamente, mais um nível de “sublistas”. Cada sublista presente nesse terceiro nível contém dados e atributos que descrevem um repositório Git que o usuário correspondente possui dentro da plataforma do GitHub.\nOu seja, no fim das contas, o objeto gh_repos é uma lista de repositórios que cada usuário possui dentro da plataforma GitHub, e está num nível de aninhamento em 3 níveis de profundidade, i.e. uma lista que contém listas de usuários, que por sua vez, contém listas de repositórios (list -&gt; list -&gt; list). No exemplo abaixo, podemos ver alguns dos atributos que estão disponíveis sobre o primeiro repositório pertencente ao primeiro usuário descrito nessa lista. Temos ao todo 68 atributos diferentes sobre o repositório, porém, no código abaixo usei a função head() para mostrar apenas uma parte desses 68 atributos.\n\ngh_repos[[1]][[1]] |&gt; names() |&gt; head()\n\n[1] \"id\"        \"name\"      \"full_name\" \"owner\"     \"private\"   \"html_url\" \n\n\nNovamente, eu posso armazenar essa lista dentro de um tibble, e começar a aplicar as nossas funções de unnest_*() para “desembaraçar” essas listas em um formato mais amigável. Veja abaixo que ao aplicarmos a função unnest_longer() sobre essa lista, temos como resultado um novo tibble com 176 linhas. Cada linha agora contém os dados de um repositório diferente. Isso significa que, dentro da lista gh_repos temos no total 176 repositórios descritos ao longo dos 6 usuários. Logo, cada usuário tem aproximadamente 30 repositórios dentro da plataforma.\n\nrepos &lt;- tibble(repo = gh_repos)\nrepos_longer &lt;- repos |&gt; unnest_longer(repo)\nrepos_longer\n\n# A tibble: 176 × 1\n  repo             \n  &lt;list&gt;           \n1 &lt;named list [68]&gt;\n2 &lt;named list [68]&gt;\n3 &lt;named list [68]&gt;\n4 &lt;named list [68]&gt;\n5 &lt;named list [68]&gt;\n# ℹ 171 more rows\n\n\nAgora que temos esses dados nesse formato, podemos aplicar uma segunda transformação, com a função unnest_wider(), para transformar os atributos de cada repositório em novas colunas da tabela. Com isso, temos uma nova tabela com 68 colunas e 176 linhas, em um formato que é ideal para o R, e que é amigável para o nosso cérebro.\n\nrepos_wider &lt;- repos_longer |&gt;\n  unnest_wider(repo)\n\nrepos_wider\n\n# A tibble: 176 × 68\n        id name  full_name owner        private html_url description fork  url  \n     &lt;int&gt; &lt;chr&gt; &lt;chr&gt;     &lt;list&gt;       &lt;lgl&gt;   &lt;chr&gt;    &lt;chr&gt;       &lt;lgl&gt; &lt;chr&gt;\n1 61160198 after gaborcsa… &lt;named list&gt; FALSE   https:/… Run Code i… FALSE http…\n2 40500181 argu… gaborcsa… &lt;named list&gt; FALSE   https:/… Declarativ… FALSE http…\n3 36442442 ask   gaborcsa… &lt;named list&gt; FALSE   https:/… Friendly C… FALSE http…\n4 34924886 base… gaborcsa… &lt;named list&gt; FALSE   https:/… Do we get … FALSE http…\n5 61620661 cite… gaborcsa… &lt;named list&gt; FALSE   https:/… Test R pac… TRUE  http…\n# ℹ 171 more rows\n# ℹ 59 more variables: forks_url &lt;chr&gt;, keys_url &lt;chr&gt;, …\n\n\nDe forma análoga, você poderia encadear (ou conectar) as transformações executadas por essas duas funções, através do operador pipe (%&gt;% ou |&gt;). Desse modo, você eliminaria os objetos intermediários.\n\n# Produz o mesmo resultado que o exemplo anterior:\nrepos |&gt;\n  unnest_longer(repo) |&gt;\n  unnest_wider(repo)\n\n\n\n7.4.3 Coletando atributos específicos de sua lista\nA função hoist() é quase idêntica à função unnest_wider(). Ou seja, essa função te permite acessar atributos de sua lista, e transformar esses atributos em novas colunas de sua tabela. Contudo, a função unnest_wider() vai, por padrão, transformar todos os atributos que ela encontrar pela frente em novas colunas. Por outro lado, a função hoist() é mais seletiva, pois ela te permite selecionar especificamente quais atributos você deseja coletar de sua lista e transformar em novas colunas.\nEntão, você usa a função unnest_wider() quando você quer transformar em uma tacada só, todos os atributos de sua lista em colunas. Enquanto a função hoist() é mais apropriada para aqueles momentos em que você quer extrair apenas um conjunto pequeno de atributos de sua lista. No primeiro argumento da função hoist(), você deve fornecer como input, o tibble que contém todos os seus dados. Já no segundo argumento, você deve fornecer o nome da coluna que contém a lista que você deseja transformar. Em seguida, você deve fornecer uma sequência de key-value pairs na estrutura &lt;nome-nova-coluna&gt; = &lt;nome-atributo-selecionado&gt;. Cada par descreve um atributo específico que você deseja extrair da lista.\nNo exemplo abaixo, eu estou usando novamente a tabela repos_longer que criamos na sessão anterior. Porém, ao invés de usar a função unnest_wider() e extrair todos os atributos de uma vez só, vamos extrair só alguns atributos de cada repositório. Perceba nesse exemplo, que seleciono apenas 5 atributos (id, name, full_name, private e url) da lista, e como resultado, temos uma tabela de apenas 6 colunas, ao invés das 68 colunas produzidas por unnest_wider():\n\nrepos_longer |&gt;\n  hoist(\n    repo,\n    id = \"id\",\n    name = \"name\",\n    full_name = \"full_name\",\n    private = \"private\",\n    url = \"url\"\n  )\n\n# A tibble: 176 × 6\n        id name        full_name               private url          repo        \n     &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;                   &lt;lgl&gt;   &lt;chr&gt;        &lt;list&gt;      \n1 61160198 after       gaborcsardi/after       FALSE   https://api… &lt;named list&gt;\n2 40500181 argufy      gaborcsardi/argufy      FALSE   https://api… &lt;named list&gt;\n3 36442442 ask         gaborcsardi/ask         FALSE   https://api… &lt;named list&gt;\n4 34924886 baseimports gaborcsardi/baseimports FALSE   https://api… &lt;named list&gt;\n5 61620661 citest      gaborcsardi/citest      FALSE   https://api… &lt;named list&gt;\n# ℹ 171 more rows\n\n\nAlém disso, a função hoist() te permite facilmente acessar múltiplos níveis de sua lista, através de uma sintaxe que se assemelha ao XPath em arquivos XML, ou ao JSON Path em arquivos JSON, onde você consegue “encadear” em sequência vários indíces, e com isso, facilmente acessar um atributo que está bem no fundo de sua lista. No exemplo acima, eu forneci os nomes dos atributos a serem extraídos, como simples strings (exemplo: \"name\" ou \"private\"). Mas para utilizar essa sintaxe especial disponível em hoist(), tudo que você precisa fazer é fornecer uma lista como input.\nDentro dessa lista de input, você pode definir uma sequência de índices, que vão ser conectados em sequência para formar o endereço completo do atributo que você deseja selecionar. Como um exemplo, se você fornece a lista list(\"sales\", 1L, \"sale_id\") como input, você essencialmente está pedindo à função que extraia o atributo \"sale_id\" do primeiro elemento descrito em \"sales\". Traduzindo isso para um código, supondo que essa lista esteja armazenada em um objeto chamado recorded_sales, podemos traduzir esse input para a seguinte seleção: recorded_sales[[\"sales\"]][[1]][[\"sale_id\"]].\nVamos para um exemplo prático, usando dessa vez o objeto recorded_sales, o qual você pode importar para dentro da sua sessão usando os comandos abaixo. Esse objeto é uma lista de vendas feitas por cada loja (ou “franquia”) de uma firma hipotética. Em outras palavras, esse objeto contém uma lista com 2 lojas, e dentro de cada loja, temos uma lista das vendas feitas por essa loja específica.\nRecomendo que você analise a estrutura dessa lista recorded_sales com calma, usando a função str() que introduzimos no capítulo 2.\n\nlibrary(jsonlite)\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo &lt;- \"recorded_sales.json\"\nrecorded_sales &lt;- read_json(paste0(github, pasta, arquivo))\nsales &lt;- tibble(store = recorded_sales)\nsales\n\n# A tibble: 1 × 1\n  store       \n  &lt;named list&gt;\n1 &lt;list [2]&gt;  \n\n\nNo exemplo abaixo, estou usando hoist() para extrair dados específicos (sale_id, value e currency) da primeira venda (índice 1L) feita por cada loja.\n\nsales |&gt;\n  unnest_longer(store) |&gt;\n  hoist(\n    store,\n    sale_id = list(\"sales\", 1L, \"sales_id\"),\n    value = list(\"sales\", 1L, \"value\"),\n    currency = list(\"sales\", 1L, \"currency\")\n  )\n\n# A tibble: 2 × 4\n  sale_id value currency store           \n    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;list&gt;          \n1       1  32.6 R$       &lt;named list [2]&gt;\n2       4  21.5 R$       &lt;named list [2]&gt;",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>*Tidy Data*: uma abordagem para organizar os seus dados com `tidyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/07-tidy-data.html#completando-e-expandindo-a-sua-tabela",
    "href": "Capítulos/07-tidy-data.html#completando-e-expandindo-a-sua-tabela",
    "title": "7  Tidy Data: uma abordagem para organizar os seus dados com tidyr",
    "section": "7.5 Completando e expandindo a sua tabela",
    "text": "7.5 Completando e expandindo a sua tabela\nA operação que vou mostrar a seguir, serve para completar, ou inserir linhas que estão faltando em sua tabela. Em outras palavras, essa operação busca tornar os valores que estão implicitamente faltando em sua tabela, em valores não disponíveis explícitos. Você também pode enxergar esse processo, como uma forma rápida de expandir a sua tabela, a partir de combinações de valores. Um exemplo lógico do uso dessa operação, seriam datas que você gostaria que estivessem em sua tabela, mas que não se encontram nela no momento. Vamos supor por exemplo, que você possua a tabela abaixo:\n\nlibrary(tidyverse)\ndias &lt;- c(\"2020-09-01\", \"2020-09-05\", \"2020-09-07\", \"2020-09-10\")\nset.seed(1)\nvendas &lt;- tibble(\n  datas = as.Date(dias),\n  nome = c(\"Ana\", \"Julia\", \"Joao\", \"Julia\"),\n  valor = rnorm(4, mean = 500, sd = 150)\n)\n\nvendas\n\n# A tibble: 4 × 3\n  datas      nome  valor\n  &lt;date&gt;     &lt;chr&gt; &lt;dbl&gt;\n1 2020-09-01 Ana    406.\n2 2020-09-05 Julia  528.\n3 2020-09-07 Joao   375.\n4 2020-09-10 Julia  739.\n\n\nPortanto, temos nessa tabela vendas, o nome de alguns vendedores e os valores de suas vendas efetuadas em alguns dias diferentes. No momento, temos vendas explícitas apenas nos dias 01, 05, 07 e 10 de setembro de 2020, mas o que ocorreu nos dias que estão entre essas datas (dias 02, 03, 04, 06, 08 e 09 de setembro de 2020)? Caso você estivesse apresentando esses dados para o seu chefe, por exemplo, essa seria uma questão que ele provavelmente faria a você. Bem, vamos supor que não tenham ocorrido vendas durante esses dias, e que por isso eles não estão sendo descritos na tabela vendas. Talvez seja de seu desejo, introduzir esses dias na tabela para que ninguém fique em dúvida a respeito desses dias. Com isso, precisamos então completar a tabela vendas, com linhas que estão implicitamente faltando nela.\n\n7.5.1 Encontrando possíveis combinações com a função expand()\nNessa seção, vamos introduzir alguns métodos para encontrarmos todas as combinações possíveis de seus dados. Pois isso é de certa forma um pré-requisito, ou um dos mecanismos por detrás do processo que desejamos aplicar sobre a tabela vendas.\nPara calcular todas as combinações possíveis de seus dados, podemos utilizar a função expand() do pacote tidyr. Essa função busca expandir uma tabela, de forma que ela inclua todas as possíveis combinações de certos valores. Em maiores detalhes, essa função irá criar (com base nos dados que você fornecer a ela) uma nova tabela, ou um novo tibble, que irá incluir todas as combinações únicas e possíveis dos valores que você definiu. Portanto, se eu fornecer a tabela vendas à função, e pedir a ela que encontre todas as combinações possíveis entre os valores contidos nas colunas datas e nomes, esse será o resultado:\n\nexpand(vendas, datas, nome)\n\n# A tibble: 12 × 2\n  datas      nome \n  &lt;date&gt;     &lt;chr&gt;\n1 2020-09-01 Ana  \n2 2020-09-01 Joao \n3 2020-09-01 Julia\n4 2020-09-05 Ana  \n5 2020-09-05 Joao \n# ℹ 7 more rows\n\n\nPortanto, expand() irá criar uma nova tabela, contendo todas as possíveis combinações entre os valores das colunas datas e nomes da tabela vendas. Incluindo aquelas combinações que não aparecem na tabela inicial. Por exemplo, as combinações (2020-09-01, Julia), ou (2020-09-05, Joao) e (2020-09-10, Joao) não estão presentes na tabela vendas, e mesmo assim foram introduzidas no resultado de expand().\nPorém, expand() não definiu novas combinações com as datas que estão faltando na tabela vendas (por exemplo, os dias 02, 03, 04 e 08 de setembro de 2020). Ou seja, em nenhum momento expand() irá adicionar algum dado à sua tabela, seja antes ou depois de encontrar todas as combinações únicas. Em outras palavras, expand() irá sempre encontrar todas as combinações possíveis, se baseando somente nos valores que já se encontram nas colunas que você forneceu a ela. Por isso, mesmo que a combinação (2020-09-01, Julia) não esteja definida na tabela vendas, ela é uma combinação possível, pois os valores 2020-09-01 e Julia estão presentes na tabela vendas.\nVale destacar, que você pode combinar as variáveis de sua tabela com vetores externos. Por exemplo, eu posso utilizar seq.Date() para gerar todas as datas que estão entre o dia 01 e 10 de setembro de 2020. No exemplo abaixo, perceba que expand() pega cada um dos 3 nomes únicos definidos na coluna nome de vendas, e combina eles com cada uma das 10 datas guardadas no vetor vec_d, gerando assim, uma nova tabela com 30 linhas (\\(3\\) nomes \\(\\times 10\\) datas \\(= 30\\) combinações).\n\nvec_d &lt;- seq.Date(min(vendas$datas), max(vendas$datas), by = \"day\")\nexpand(vendas, nome, vec_d)\n\n# A tibble: 30 × 2\n  nome  vec_d     \n  &lt;chr&gt; &lt;date&gt;    \n1 Ana   2020-09-01\n2 Ana   2020-09-02\n3 Ana   2020-09-03\n4 Ana   2020-09-04\n5 Ana   2020-09-05\n# ℹ 25 more rows\n\n\nAlém disso, a função expand() conta com uma função auxiliar útil (nesting()), que restringe quais combinações serão válidas para expand(). Ao incluir variáveis dentro da função nesting(), você está dizendo à expand(), que encontre apenas as combinações únicas (entre os valores dessas variáveis) que já estão presentes em sua base. Ou seja, se eu colocar as colunas datas e nome dentro de nesting(), a função expand() irá basicamente repetir a tabela vendas. Pois cada uma das 4 linhas (ou 4 combinações entre datas e nome), aparecem uma única vez nessa tabela.\n\nexpand(vendas, nesting(datas, nome))\n\n# A tibble: 4 × 2\n  datas      nome \n  &lt;date&gt;     &lt;chr&gt;\n1 2020-09-01 Ana  \n2 2020-09-05 Julia\n3 2020-09-07 Joao \n4 2020-09-10 Julia\n\n\nDessa maneira, o uso de nesting() acima, é análogo ao uso da função unique() que vêm dos pacotes básicos do R. Logo, poderíamos atingir exatamente o mesmo resultado, utilizando qualquer uma das duas funções. Podemos por exemplo, adicionarmos uma quinta linha à tabela vendas, que repete os valores contidos na quarta linha da tabela. Se utilizarmos unique() ou nesting(), em ambos os casos, essa quinta linha repetida desaparece. Pois ambas as funções buscam encontrar todas as combinações únicas que aparecem ao longo da tabela vendas.\n\nvendas[5, ] &lt;- data.frame(as.Date(\"2020-09-10\"), \"Julia\", 739.29)\nvendas\n\n# A tibble: 5 × 3\n  datas      nome  valor\n  &lt;date&gt;     &lt;chr&gt; &lt;dbl&gt;\n1 2020-09-01 Ana    406.\n2 2020-09-05 Julia  528.\n3 2020-09-07 Joao   375.\n4 2020-09-10 Julia  739.\n5 2020-09-10 Julia  739.\n\n# O mesmo resultado pode ser\n# atingido com o uso de nesting() em expand()\nunique(vendas[ , 1:2])\n\n# A tibble: 4 × 2\n  datas      nome \n  &lt;date&gt;     &lt;chr&gt;\n1 2020-09-01 Ana  \n2 2020-09-05 Julia\n3 2020-09-07 Joao \n4 2020-09-10 Julia\n\n\nVale destacar que você pode combinar o comportamento restrito e irrestrito de expand(). Ou seja, você pode restringir as combinações com o uso de nesting() para algumas variáveis, enquanto outras permanecem de fora dessa função, permitindo uma gama maior de combinações. No exemplo abaixo, expand() vai encontrar primeiro, cada combinação única entre nome e valor que está presente na tabela vendas, em seguida, a função irá encontrar todas as combinações possíveis entre as combinações anteriores (entre nome e valor) e todas as datas descritas na base.\nEm outras palavras, nós podemos encontrar no resultado abaixo, uma combinação como (2020-09-01, Julia, 528.). Pois a combinação (Julia, 528.) existe nas colunas nome e valor da tabela vendas, e como deixamos a coluna datas de fora de nesting(), expand() irá combinar (Julia, 528.) com toda e qualquer data disponível na tabela vendas.\nPorém, nós não podemos encontrar no resultado abaixo, uma combinação como (2020-09-01, Ana, 739.). Pois a única combinação entre as colunas nome e valor, presente na tabela vendas, que possui o valor 739 na coluna valor, é a linha que contém a combinação (Julia, 739.). Logo, se não há nas colunas nome e valor alguma combinação entre Ana e o valor 739., expand() não irá combinar esses valores com todas as datas disponíveis na base. Pois as combinações entre as colunas nome e valor estão sendo restringidas por nesting().\n\nvendas %&gt;% \n  expand(datas, nesting(nome, valor))\n\n# A tibble: 16 × 3\n  datas      nome  valor\n  &lt;date&gt;     &lt;chr&gt; &lt;dbl&gt;\n1 2020-09-01 Ana    406.\n2 2020-09-01 Joao   375.\n3 2020-09-01 Julia  528.\n4 2020-09-01 Julia  739.\n5 2020-09-05 Ana    406.\n# ℹ 11 more rows\n\n\n\n\n7.5.2 A metodologia por detrás do processo\nApesar de próximo, a função expand() não é suficiente para produzirmos o resultado que desejamos sobre a tabela vendas. Lembre-se que desejamos completar essa tabela com os dados referentes aos dias 02, 03, 04, 06, 08 e 09 de setembro de 2020, que estão “em teoria” faltando nessa tabela.\n\nvendas\n\n# A tibble: 4 × 3\n  datas      nome  valor\n  &lt;date&gt;     &lt;chr&gt; &lt;dbl&gt;\n1 2020-09-01 Ana    406.\n2 2020-09-05 Julia  528.\n3 2020-09-07 Joao   375.\n4 2020-09-10 Julia  739.\n\n\nPrimeiro, precisamos encontrar todos valores possíveis da variável que está incompleta na tabela vendas. Ou seja, queremos encontrar todas as datas possíveis entre os dias 01 e 10 de setembro de 2020, pois esses dias são os limites da tabela. Para isso, podemos utilizar a função seq.Date() em conjunto com tibble(). Dessa forma, nos criamos uma nova tabela, que contém uma sequência de datas que vai do dia 01 até o dia 10 de setembro. O mesmo resultado, poderia ser atingido, caso utilizássemos seq.Date() dentro de expand(), já que expand() cria por padrão uma nova tabela com todas as combinações possíveis dos dados que você fornece a ela.\n\nnova_tab &lt;- tibble(\n  datas = seq.Date(min(vendas$datas), max(vendas$datas), by = \"day\")\n)\n\nnova_tab\n\n# A tibble: 10 × 1\n  datas     \n  &lt;date&gt;    \n1 2020-09-01\n2 2020-09-02\n3 2020-09-03\n4 2020-09-04\n5 2020-09-05\n# ℹ 5 more rows\n\n\n\n# O mesmo resultado poderia ser atingido com:\nnova_tab &lt;- expand(\n  datas = seq.Date(min(vendas$datas), max(vendas$datas), by = \"day\")\n)\n\nEm seguida, podemos utilizar a função full_join()4 do pacote dplyr, para trazermos os dados disponíveis na tabela vendas para essa nova tabela nova_tab. Agora, nós temos uma nova tabela, que contém todos os dados que já estão definidos na tabela vendas, além dos dias que estavam faltando anteriormente, e que agora também estão definidos.\n\nnova_tab &lt;- nova_tab %&gt;% \n  full_join(vendas, by = \"datas\")\n\nnova_tab\n\n# A tibble: 10 × 3\n  datas      nome  valor\n  &lt;date&gt;     &lt;chr&gt; &lt;dbl&gt;\n1 2020-09-01 Ana    406.\n2 2020-09-02 &lt;NA&gt;    NA \n3 2020-09-03 &lt;NA&gt;    NA \n4 2020-09-04 &lt;NA&gt;    NA \n5 2020-09-05 Julia  528.\n# ℹ 5 more rows\n\n\nO que resta agora, é preenchermos os campos com valores não-disponíveis (NA) com algum outro valor que seja mais claro, ou que indique de uma forma melhor, que não houve vendas realizadas naquele dia. Visando esse objetivo, temos a função replace_na() do pacote tidyr. Nessa função, você irá fornecer uma lista (list()) contendo os valores que vão substituir os valores NA em cada coluna de sua tabela. Essa lista precisa ser nomeada. Basta nomear cada valor substituto com o nome da coluna em que você deseja utilizar esse valor. Logo, se eu quero substituir todos os valores NA na coluna valor, por um zero, basta eu nomear esse zero com o nome dessa coluna, dentro da lista (list()) que eu forneci à replace_na().\n\nnova_tab %&gt;% \n  replace_na(\n    list(nome = \"Não houve vendas\", valor = 0)\n  )\n\n# A tibble: 10 × 3\n  datas      nome             valor\n  &lt;date&gt;     &lt;chr&gt;            &lt;dbl&gt;\n1 2020-09-01 Ana               406.\n2 2020-09-02 Não houve vendas    0 \n3 2020-09-03 Não houve vendas    0 \n4 2020-09-04 Não houve vendas    0 \n5 2020-09-05 Julia             528.\n# ℹ 5 more rows\n\n\n\n\n7.5.3 A função complete() como um atalho útil\nA função complete() é um wrapper, ou uma função auxiliar do pacote tidyr, que engloba as funções expand(), full_join(), e replace_na(). Ou seja, a função complete() é um atalho para aplicarmos a metodologia que acabamos de descrever na seção anterior. A função possui três argumentos principais: 1) data, o nome do objeto onde a sua tabela está salva; 2) ..., a especificação das colunas a serem completadas, ou “expandidas” por complete(); 3) fill, uma lista nomeada (como a que fornecemos em replace_na()), que atribui para cada variável (ou coluna) de sua tabela, um valor a ser utilizado (ao invés de NA) para as combinações faltantes.\nVou explicar o argumento fill mais a frente, por isso, vamos nos concentrar nos outros dois. A tabela que contém os nossos dados se chama vendas, e por isso, é esse valor que devemos atribuir ao argumento data. Porém, como estamos utilizando o pipe (%&gt;%) no exemplo abaixo, ele já está realizando esse serviço para nós. Já o segundo argumento (...), diz respeita a lista de especificações que vão definir como a função complete() deve completar cada coluna da nossa tabela.\nEm outras palavras, o segundo argumento (...) é a parte da função complete() que diz respeito ao uso de expand(). Você deve, portanto, preencher este argumento, da mesma forma que você faria com a função expand(). No exemplo abaixo, o primeiro argumento (data), já está sendo definido pelo operador pipe (%&gt;%). Perceba que eu preencho a função complete(), da mesma forma em que preenchi a função expand() na seção anterior. Perceba também, que complete() já me retorna como resultado, a tabela expandida após o uso de full_join().\n\nvendas %&gt;% \n  complete(\n    datas = seq.Date(min(datas), max(datas), by = \"day\")\n  )\n\n# A tibble: 10 × 3\n  datas      nome  valor\n  &lt;date&gt;     &lt;chr&gt; &lt;dbl&gt;\n1 2020-09-01 Ana    406.\n2 2020-09-02 &lt;NA&gt;    NA \n3 2020-09-03 &lt;NA&gt;    NA \n4 2020-09-04 &lt;NA&gt;    NA \n5 2020-09-05 Julia  528.\n# ℹ 5 more rows\n\n\nO último passo que resta agora, seria o uso de replace_na() para preencher os valores não-disponíveis por algum outro valor mais claro. Nós ainda podemos utilizar a função complete() para executarmos esse passo. Basta você fornecer à complete() através de seu terceiro argumento (fill), a mesma lista que você forneceria à replace_na(). Dessa forma, temos:\n\nvendas %&gt;% \n  complete(\n    datas = seq.Date(min(datas), max(datas), by = \"day\"),\n    fill = list(nome = \"Não houve vendas\", valor = 0)\n  )\n\n# A tibble: 10 × 3\n  datas      nome             valor\n  &lt;date&gt;     &lt;chr&gt;            &lt;dbl&gt;\n1 2020-09-01 Ana               406.\n2 2020-09-02 Não houve vendas    0 \n3 2020-09-03 Não houve vendas    0 \n4 2020-09-04 Não houve vendas    0 \n5 2020-09-05 Julia             528.\n# ℹ 5 more rows",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>*Tidy Data*: uma abordagem para organizar os seus dados com `tidyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/07-tidy-data.html#preenchendo-valores-não-disponíveis-na",
    "href": "Capítulos/07-tidy-data.html#preenchendo-valores-não-disponíveis-na",
    "title": "7  Tidy Data: uma abordagem para organizar os seus dados com tidyr",
    "section": "7.6 Preenchendo valores não-disponíveis (NA)",
    "text": "7.6 Preenchendo valores não-disponíveis (NA)\n\n7.6.1 Utilizando-se de valores anteriores ou posteriores\nAs operações que vou mostrar a seguir, servem para preencher linhas com dados não-disponíveis (NA), com valores anteriores ou posteriores que estão disponíveis em sua tabela. Vamos começar com um exemplo simples através da tabela df, que você pode criar em seu R utilizando os comandos abaixo. Nessa tabela, temos algumas vendas anuais hipotéticas. Agora, perceba que por algum motivo, o ano em que as vendas ocorreram, só foram guardadas na primeira linha de cada ID (id). Isso é algo que devemos corrigir nessa tabela.\n\nlibrary(tidyverse)\nv &lt;- 2001:2004\nset.seed(1)\ndf &lt;- tibble(\n  id = rep(1:4, each = 3),\n  ano = NA_real_,\n  valor = rnorm(12, mean = 1000, sd = 560)\n)\n\ndf[seq(1, 12, by = 3), \"ano\"] &lt;- v\ndf\n\n# A tibble: 12 × 3\n     id   ano valor\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1  2001  649.\n2     1    NA 1103.\n3     1    NA  532.\n4     2  2002 1893.\n5     2    NA 1185.\n# ℹ 7 more rows\n\n\nPortanto, o que queremos fazer, é completar as linhas de NA’s, com o ano correspondente a essas vendas. Pelo fato dos anos estarem separados por um número constante de linhas, ou seja, a cada 3 linhas de NA’s, temos um novo ano, podemos pensar em algumas soluções relativamente simples como a definida abaixo. Porém, a simplicidade do problema, depende dos intervalos entre cada valor, serem constantes. A partir do momento em que esses valores começarem a se dispersar em distâncias inconsistentes, uma solução como a definida abaixo, não servirá.\n\nniveis &lt;- unique(df$ano)\nniveis &lt;- niveis[!is.na(niveis)]\nrepair_vec &lt;- df$ano\nrepair_vec[is.na(repair_vec)] &lt;- rep(niveis, each = 2)\n\ndf$ano &lt;- repair_vec\ndf\n\n# A tibble: 12 × 3\n     id   ano valor\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1  2001  649.\n2     1  2001 1103.\n3     1  2001  532.\n4     2  2002 1893.\n5     2  2002 1185.\n# ℹ 7 more rows\n\n\nApesar de ser um problema simples, podemos alcançar uma solução ainda mais simples, ao utilizarmos funções que são especializadas nesses problemas. Esse é o caso da função fill() do pacote tidyr, que foi criada justamente para esse propósito. Portanto, sempre que você possuir em sua tabela, uma coluna onde você deseja substituir uma sequência de NA’s pelo último (ou próximo) valor disponível, você pode utilizar essa função para tal tarefa.\nA função fill() possui três argumentos: 1) data, o objeto onde a tabela com que deseja trabalhar, está salva; 2) ..., a lista de colunas em que você deseja aplicar a função; 3) .direction, define a direção que a função deve seguir na hora de preencher os valores.\n\nlibrary(tidyverse)\ndf %&gt;% fill(ano)\n\n# A tibble: 12 × 3\n     id   ano valor\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1  2001  649.\n2     1  2001 1103.\n3     1  2001  532.\n4     2  2002 1893.\n5     2  2002 1185.\n# ℹ 7 more rows\n\n\nA função fill() trabalha a partir de uma dada direção vertical em sua tabela. Por padrão, a função fill() irá preencher os valores indo para baixo, ou seja, partindo do topo da tabela, até a sua base. Logo, a função irá substituir qualquer NA com o último valor disponível, ou em outras palavras, com o valor disponível anterior ao NA em questão. A função lhe oferece o argumento .direction, caso você deseja alterar esse comportamento. Logo, se você deseja preencher esses valores NA’s com o próximo valor disponível em relação ao NA em questão. Isto é, preencher os valores para cima, partindo da base da tabela, e seguindo para o seu topo. Você precisa definir o argumento da seguinte maneira:\n\ndf %&gt;% fill(ano, .direction = \"up\")\n\n# A tibble: 12 × 3\n     id   ano valor\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1  2001  649.\n2     1  2002 1103.\n3     1  2002  532.\n4     2  2002 1893.\n5     2  2003 1185.\n# ℹ 7 more rows\n\n# Caso prefira não utilizar o pipe ( %&gt;% ),\n# ficaria dessa forma:\n# fill(df, ano, .direction = \"up\")\n\nPortanto, se tivéssemos que colocar essas operações em uma representação visual, teríamos algo como a Figura 7.4. Lembrando que a função usa por padrão, a direção down, logo, no primeiro caso mostrado na Figura 7.4, você não precisaria definir explicitamente o argumento .direction.\n\n\n\n\n\n\n\n\nFigura 7.4: Representação do processo executado pela função fill\n\n\n\n\n\nApesar de serem os exemplos mais claros de aplicação, serão raras as ocasiões em que você terá esse problema posto claramente já de início em sua tabela. Com isso, eu quero dizer que serão raros os momentos em que você desde o início terá uma tabela, onde por algum motivo, os registros aparecem apenas na primeira (ou na última) linha que diz respeito aquele registro.\nUsualmente, você irá utilizar a função fill() quando você já estiver realizando diversas outras transformações em sua tabela, para se chegar aonde deseja. Um exemplo claro dessa ideia, seria uma tabela onde os valores são registrados no primeiro dia de cada semana (basicamente você possui dados semanais), mas você precisa calcular uma média móvel diária. Isso significa que para calcular essa média móvel, você teria que completar os dias faltantes de cada semana, e ainda utilizar o fill() para transportar o valor do primeiro dia, para os dias restantes da semana.\nVale ressaltar, que você pode utilizar em fill(), todos os mecanismos de seleção que introduzimos em select(), para selecionar as colunas em que você deseja aplicar a função fill(). Isso também significa, que com fill() você pode preencher várias colunas ao mesmo tempo. Agora, para relembrarmos esses mecanismos, vamos criar uma tabela inicialmente vazia, que contém o total de vendas realizadas nos 6 primeiros meses de 2020, por cada funcionário de uma loja.\n\nset.seed(2)\nfuncionarios &lt;- tibble(\n  mes = rep(1:6, times = 4),\n  vendas = floor(rnorm(24, mean = 60, sd = 24)),\n  nome = NA_character_,\n  salario = NA_real_,\n  mes_ent = NA_real_,\n  ano_ent = NA_real_,\n  unidade = NA_character_\n)\n\nfuncionarios\n\n# A tibble: 24 × 7\n    mes vendas nome  salario mes_ent ano_ent unidade\n  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  \n1     1     38 &lt;NA&gt;       NA      NA      NA &lt;NA&gt;   \n2     2     64 &lt;NA&gt;       NA      NA      NA &lt;NA&gt;   \n3     3     98 &lt;NA&gt;       NA      NA      NA &lt;NA&gt;   \n4     4     32 &lt;NA&gt;       NA      NA      NA &lt;NA&gt;   \n5     5     58 &lt;NA&gt;       NA      NA      NA &lt;NA&gt;   \n# ℹ 19 more rows\n\n\nEm seguida, vamos preencher as colunas vazias (nome, salario, mes_ent, …) de forma com que as informações de cada vendedor, apareçam apenas na última linha que diz respeito aquele vendedor. Como exemplo, as informações do vendedor Henrique, aparecem apenas na sexta linha da tabela, que é a última linha da tabela que se refere a ele.\n\nvalores &lt;- list(\n  salario = c(1560, 2120, 1745, 1890),\n  nome = c(\"Henrique\", \"Ana\", \"João\", \"Milena\"),\n  ano_ent = c(2000, 2001, 2010, 2015),\n  mes_ent = c(2, 10, 5, 8),\n  unidade = c(\"Afonso Pena\", \"Savassi\", \"São Paulo\", \"Amazonas\")\n)\n\ncolunas &lt;- colnames(funcionarios)[3:7]\nfor(i in colunas){\n  funcionarios[1:4 * 6, i] &lt;- valores[[i]]\n}\n# Com isso, temos o seguinte resultado:\nfuncionarios %&gt;% print(n = 12)\n\n# A tibble: 24 × 7\n     mes vendas nome     salario mes_ent ano_ent unidade    \n   &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;      \n 1     1     38 &lt;NA&gt;          NA      NA      NA &lt;NA&gt;       \n 2     2     64 &lt;NA&gt;          NA      NA      NA &lt;NA&gt;       \n 3     3     98 &lt;NA&gt;          NA      NA      NA &lt;NA&gt;       \n 4     4     32 &lt;NA&gt;          NA      NA      NA &lt;NA&gt;       \n 5     5     58 &lt;NA&gt;          NA      NA      NA &lt;NA&gt;       \n 6     6     63 Henrique    1560       2    2000 Afonso Pena\n 7     1     76 &lt;NA&gt;          NA      NA      NA &lt;NA&gt;       \n 8     2     54 &lt;NA&gt;          NA      NA      NA &lt;NA&gt;       \n 9     3    107 &lt;NA&gt;          NA      NA      NA &lt;NA&gt;       \n10     4     56 &lt;NA&gt;          NA      NA      NA &lt;NA&gt;       \n11     5     70 &lt;NA&gt;          NA      NA      NA &lt;NA&gt;       \n12     6     83 Ana         2120      10    2001 Savassi    \n# ℹ 12 more rows\n\n\nPortanto, o que precisamos é aplicar a função fill() usando .direction = \"up\", em cada uma dessas colunas vazias, de forma a preencher o restante das linhas com as informações de cada vendedor. Dada a natureza dessa tabela, os dois melhores mecanismos que aprendemos em select(), para selecionarmos essas colunas vazias, são: 1) usar os índices dessas colunas; 2) nos basearmos nos tipos de dados contidos em cada coluna; 3) usar um vetor externo com os nomes das colunas que desejamos.\nPara utilizar o método 3 que citei acima, podemos utilizar o vetor colunas que criamos agora a pouco ao preenchermos a tabela, e já contém os nomes das colunas que desejamos. Porém, para o exemplo abaixo do método 2, você talvez se pergunte: “Se estamos aplicando a função fill() sobre todas as colunas que contém ou dados de texto (character), ou dados numéricos (numeric), nós também estamos aplicando a função sobre as colunas mes e vendas, das quais não necessitam de ajuste. O que acontece?”. Nada irá ocorrer com as colunas mes e vendas, caso elas já estejam corretamente preenchidas, portanto, podemos aplicar a função sobre elas sem medo.\n\n# Todas as três alternativas abaixo\n# geram o mesmo resultado:\nfuncionarios %&gt;% \n  fill(\n    3:7,\n    .direction = \"up\"\n  )\n\nfuncionarios %&gt;% \n  fill(\n    all_of(colunas),\n    .direction = \"up\"\n  )\n\n\nfuncionarios %&gt;% \n  fill(\n    where(is.character),\n    where(is.numeric),\n    .direction = \"up\"\n  )\n\n# A tibble: 24 × 7\n    mes vendas nome     salario mes_ent ano_ent unidade    \n  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;      \n1     1     38 Henrique    1560       2    2000 Afonso Pena\n2     2     64 Henrique    1560       2    2000 Afonso Pena\n3     3     98 Henrique    1560       2    2000 Afonso Pena\n4     4     32 Henrique    1560       2    2000 Afonso Pena\n5     5     58 Henrique    1560       2    2000 Afonso Pena\n# ℹ 19 more rows\n\n\n\n\n\n\nWICKHAM, H. Tidy Data. The Journal of Statistical Software, v. 59, 2014.",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>*Tidy Data*: uma abordagem para organizar os seus dados com `tidyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/07-tidy-data.html#footnotes",
    "href": "Capítulos/07-tidy-data.html#footnotes",
    "title": "7  Tidy Data: uma abordagem para organizar os seus dados com tidyr",
    "section": "",
    "text": "Esses são termos comuns na comunidade de R, mas estes formatos também são conhecidos, ou chamados por indexed data (long) e por cartesian data (wide).↩︎\nApesar de serem um caso raro no R, as tabelas que possuem listas como colunas, tem se tornado cada vez mais comuns ao longo de diversas análises, e são comumente chamadas pela comunidade de nested tables, ou de nested data. Alguns pacotes tem se desenvolvido, de maneira muito forte nessa área, e por isso, essas estruturas tem se tornado de grande utilidade em diversas aplicações. Alguns desses pacotes incluem o próprio tidyr, além do pacote broom.↩︎\nhttps://www.youtube.com/watch?v=rz3_FDVt9eg&ab_channel=PsychologyattheUniversityofEdinburgh↩︎\nCaso você não conheça a função full_join(), lembre-se que ela é descrita em detalhes no capítulo “Introdução a base de dados relacionais”.↩︎",
    "crumbs": [
      "Importando, organizando e transformando dados",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>*Tidy Data*: uma abordagem para organizar os seus dados com `tidyr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/08-ggplot.html",
    "href": "Capítulos/08-ggplot.html",
    "title": "8  Visualização de dados com ggplot2",
    "section": "",
    "text": "8.1 Introdução e pré-requisitos\nEsse é o primeiro capítulo em que vamos introduzir o pacote ggplot2, ou simplesmente ggplot. O ggplot é um pacote voltado para a visualização de dados, ou em outras palavras, para a construção de gráficos. Para que você possa acompanhar os exemplos dessa seção, você precisa ter o pacote instalado em sua máquina. Após instalá-lo, você pode tanto chamar diretamente pelo pacote ggplot2, quanto pelo tidyverse, que também o inclui, através da função library().\nlibrary(ggplot2)\nlibrary(tidyverse)",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Visualização de dados com `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/08-ggplot.html#o-que-é-o-ggplot-e-a-sua-gramática",
    "href": "Capítulos/08-ggplot.html#o-que-é-o-ggplot-e-a-sua-gramática",
    "title": "8  Visualização de dados com ggplot2",
    "section": "8.2 O que é o ggplot e a sua gramática",
    "text": "8.2 O que é o ggplot e a sua gramática\nA linguagem R é conhecida por sua capacidade gráfica, e MURRELL (2006) oferece ótimos exemplos que atestam essa afirmação. Mesmo que a linguagem R ofereça “já de fábrica”, o pacote lattice, que já é capaz de muita coisa, o ggplot é sem dúvidas, o pacote mais popular da linguagem no que tange a criação de gráficos, pois ele oferece algo que os outros pacotes não tem, que é a sua flexibilidade1.\n\n\n\n\n\n\n\n\nFigura 8.1: phases9032 por Thomas Lin Pedersen\n\n\n\n\n\nFlexibilidade é uma das principais características (e a principal vantagem) do ggplot, e é o que amplia a sua utilização para além dos gráficos sérios e frios de um jornal científico, permitindo ao usuário criar gráficos vistosos, e um tanto peculiares. Veja por exemplo, a arte criada por Thomas Lin Pedersen, mostrada na Figura 8.1. O que lhe dá essa liberdade dentro do ggplot, é a sua gramática.\nO pacote ggplot (ou seu nome oficial - ggplot2) foi inicialmente desenvolvido por WICKHAM (2016), e lançado pela primeira vez no ano de 2005. O pacote representa uma implementação da teoria desenvolvida por WILKINSON (2005), chamada de The Grammar of Graphics (ou “a gramática dos gráficos”). Portanto, o ggplot busca abstrair os principais conceitos da teoria de WILKINSON (2005), e implementá-los dentro da linguagem R.\nSegundo a teoria de WILKINSON (2005), todo e qualquer gráfico estatístico, pode ser descrito por um conjunto de camadas, ou componentes, que estão apresentados na Figura 8.2. Dessa forma, na visão de WILKINSON (2005) todos os tipos de gráfico que conhecemos (pizza, barras, dispersão, boxplot, etc.) fazem parte de um mesmo grupo, e a característica que os tornam diferentes entre si, se encontra na forma como as camadas abaixo estão definidas em cada gráfico.\n\n\n\n\n\n\n\n\nFigura 8.2: Camadas de um gráfico do ggplot, baseado em Wickham (2016)\n\n\n\n\n\nTendo isso em mente, um gráfico do ggplot é composto por várias camadas, que em conjunto formam o gráfico desejado. A ideia por trás do pacote, portanto, é utilizar uma gramática para descrever de forma concisa, cada uma das camadas apresentadas na Figura 8.2. Após definirmos essas camadas, nós podemos somá-las para construirmos o nosso gráfico final. Em outras palavras, você vai adicionando aos poucos, novas camadas ao gráfico, onde cada uma dessas camadas fica responsável por definir um componente específico do gráfico (escalas, formas geométricas, legendas, facetas, anotações, …). Caso seja de seu desejo, você pode deixar o próprio ggplot responsável por definir várias das camadas apresentadas na Figura 8.2. Porém, em todo gráfico do ggplot, você deve obrigatoriamente definir as três camadas (em negrito na Figura 8.2) apresentadas a seguir, sendo portanto, as camadas essenciais que formam a base de todo gráfico do ggplot.\n\nDados: os dados que o gráfico deve expor.\nMapeamento estético (aesthetic mapping): uma descrição de como as variáveis dispostas em seus dados devem ser mapeadas para elementos visuais (ou estéticos) de seu gráfico.\nGeometrias: são as formas geométricas do gráfico que representam os seus dados, ou seja, em um gráfico de dispersão, seus dados são representados no gráfico por pontos, enquanto em um gráfico de barras, seus dados são representados por retângulos.\n\nA gramática do ggplot, representa, portanto, as regras que definem o emprego das funções necessárias, e de seus possíveis parâmetros para acessarmos e controlarmos cada uma das camadas mostradas na Figura 8.2. Logo, cada uma dessas camadas, são controladas por uma função (ou por um conjunto de funções) diferente, que lhe permite o uso de diferentes mecanismos e valores em sua definição.",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Visualização de dados com `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/08-ggplot.html#sec-iniciando-ggplot",
    "href": "Capítulos/08-ggplot.html#sec-iniciando-ggplot",
    "title": "8  Visualização de dados com ggplot2",
    "section": "8.3 Iniciando um gráfico do ggplot",
    "text": "8.3 Iniciando um gráfico do ggplot\n\n8.3.1 Dados\nPrimeiro, vamos definir os dados que vamos utilizar em nossos gráficos. A tabela datasus, contém a contagem de mortes por homicídios dolosos em 2018 no Brasil, coletados a partir dos microdados do SIM/DATASUS. Nessa mesma tabela, temos a distribuição dessas mortes, por sexo, por faixa etária, pelo estado (Unidade da Federação - UF) em que as mortes ocorreram, e pela cor de pele dos indivíduos.\n\nlibrary(readr)\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo &lt;- \"datasus.csv\"\ndatasus &lt;- read_csv2(paste0(github, pasta, arquivo))\ndatasus\n\n# A tibble: 1,836 × 6\n  `Faixa etaria` Genero    Cor    `Nome UF` UF    Contagem\n  &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;\n1 10 a 14        Feminino  Parda  Acre      AC           4\n2 10 a 14        Masculino Parda  Acre      AC           4\n3 15 a 19        Feminino  Branca Acre      AC           2\n4 15 a 19        Feminino  Parda  Acre      AC           4\n5 15 a 19        Masculino Branca Acre      AC           6\n# ℹ 1,831 more rows\n\n\nVamos começar a montar o nosso gráfico. Você sempre inicia um gráfico de ggplot, pela função base do pacote - ggplot(). Essa função é responsável por criar o objeto base para o gráfico, e nela, possuímos dois argumentos que compõe duas das três camadas essenciais (que definimos na Figura 8.2) desse gráfico, e que podem ou não ser fornecidos nessa função. Esses dois argumentos são: data, que é o nome da tabela onde estão os dados que serão utilizados no gráfico; e mapping, que é o aesthetic mapping, ou o mapeamento de variáveis de sua tabela, para componentes estéticos do gráfico. Ou seja, você não precisa necessariamente fornecer esses argumentos já na função ggplot(), pois você pode defini-los dentro das funções que formam as figuras geométricas (as funções geom). O importante, é que você sempre deve começar um gráfico ggplot, com a função ggplot().\nMas então, qual é a diferença entre eu fornecer esses argumentos na função ggplot() ou dentro das funções geom? Pense em um exemplo, no qual você busca mostrar em um mesmo gráfico, duas informações diferentes. Você pode utilizar dois geom’s (ou formas geométricas) diferentes para mostrar e diferenciar essas duas informações no gráfico. Por exemplo, podemos ter um gráfico que contenha barras mostrando a evolução da dívida pública, e linhas mostrando a evolução do salário médio no país.\nCaso você forneça os dois argumentos (data e mapping) na função ggplot(), você está dizendo ao programa, que ele deve utilizar a mesma base de dados, e o mesmo aesthetic mapping, em todos os formatos geométricos (geom) do gráfico. Enquanto, ao fornecer esses argumentos dentro de cada função geom, você estaria dizendo ao programa que utilize essa base de dados, e esse aesthetic mapping, apenas naquele formato geométrico (ou geom) especificamente. Tendo isso em mente, não conseguiríamos montar o gráfico descrito no parágrafo anterior, ao dar os argumentos já na função ggplot(). Pois o gráfico mostra duas informações diferentes (salário médio e dívida pública), ao longo dos geom’s do gráfico. Ou seja, os dois formatos geométricos dispostos no gráfico, utilizam dois aesthetic mapping diferentes. Quando chegarmos à seção 8.4 vou explicar isso em mais detalhes.\nNo nosso caso, os dados que vamos utilizar, estão na tabela datasus, por isso forneço ao argumento data o nome dessa tabela. Ao rodar o código logo abaixo, você vai perceber que ele gera apenas um quadro cinza vazio. Isso ocorre porque definimos apenas uma das camadas essenciais para compor o gráfico, que são os dados utilizados. Temos que definir as outras duas, para completarmos a base de um gráfico, por isso, vamos passar agora para o aesthetic mapping.\n\nggplot(data = datasus)\n\n\n\n8.3.2 Mapeamento de variáveis (Aesthetic Mapping)\nO aesthetic mapping representa o mapeamento, ou a conexão de variáveis em sua tabela (ou sua base de dados), com os componentes estéticos e visuais do gráfico. Nós controlamos esse mapeamento através da função aes(). Há diversos desses componentes visuais que compõe um gráfico, e os primeiros que vêm a sua mente, são provavelmente as cores e as formas geométricas. Mas também os próprios eixos, ou melhor dizendo, as escalas utilizadas nos eixos, são componentes visuais do gráfico. Pois essas escalas definem como as formas geométricas vão se posicionar dentro do espaço do gráfico.\nPense por exemplo, no globo terrestre. Você pode representar esse globo dentro do ggplot, mas para que os formatos sejam corretamente posicionados em um “globo”, você precisa usar uma escala e um sistema de coordenadas diferentes do plano cartesiano. Um outro exemplo, seria o gráfico de pizza. Ao pesquisar sobre, você irá perceber que um gráfico de pizza no ggplot, é feito a partir do formato geométrico de barras (geom_bar()). Ou seja, um gráfico de barras, é o ponto de partida para gerar um gráfico de pizza no ggplot, e o que diferencia esses dois gráficos, é a escala usada. Em um gráfico de pizza, utilizamos uma coordenada circular, chamada de coordenada polar, ao invés do plano cartesiano.\nAgora, vamos continuar montando nosso gráfico. Primeiro, vamos tentar montar um gráfico de barras, que mostre a distribuição do total de mortes ao longo das faixas etárias no país, baseado nos dados apresentados na tabela datasus. Tendo isso em mente, o número de mortes, deve ficar no eixo y de nosso gráfico, enquanto os grupos (faixas etárias), devem ficar no eixo x.\nEssa é a base do nosso mapeamento de variáveis. Estamos definindo que o número de mortes deve ficar no eixo y, e as faixas etárias no eixo x, e nós fornecemos essa descrição ao ggplot, dentro da função aes() (abreviação para aesthetic mapping). No exemplo abaixo, temos dois gráficos. No gráfico da esquerda você pode perceber que um plano cartesiano foi montado, onde temos uma escala para a faixa etária no eixo x, e outra escala para o total de mortes no eixo y. Porém, esse plano cartesiano continua vazio, pois ainda não definimos a última camada essencial do gráfico, que é a forma geométrica que deve representar os nossos dados.\n# Gráfico esquerdo, com o aesthetic mapping:\nggplot(\n  data = datasus,\n  mapping = aes(x = `Faixa etaria`, y = Contagem)\n)\n# Gráfico direito, agora também com o geom:\nggplot(\n  data = datasus,\n  mapping = aes(x = `Faixa etaria`, weight = Contagem)\n) + geom_bar()\n\n\n\n\n\n\n\n\n\n\nPortanto, no gráfico da direita estamos adicionando este último componente para formarmos a base completa do nosso gráfico. Perceba que nesse gráfico, usamos a nossa primeira função geom. Cada função geom, se refere a um formato geométrico diferente. No nosso caso, queremos um gráfico de barras, que é formado pela função geom_bar(). O padrão dessa função (ou formato geométrico) no ggplot, é calcular uma contagem dos dados. Em outras palavras, o gráfico de barras no ggplot, se comporta inicialmente (por padrão) como um histograma. Ao invés de calcular a soma total de certa variável, ele irá contar, quantas vezes cada valor ocorre naquela variável dentro da base de dados.\nEntretanto, não queremos uma contagem dos dados, pois a coluna Contagem já representa uma contagem em si. O que queremos é a soma total dessa contagem em cada faixa etária. Por isso, ao invés de fornecer Contagem ao argumento y de aes(), eu forneço essa coluna para o argumento weight, no código que produz o gráfico à direita no exemplo acima.\nAlém disso, você talvez tenha percebido o operador de soma + nessa parte do código. O operador de soma é muito importante para o ggplot! Pois é ele que interliga as várias camadas que compõe o seu gráfico. Portanto, todas as funções que adicionarmos às várias camadas do nosso gráfico no ggplot, devem ser conectadas por um sinal de +, por isso lembre-se de colocar esse sinal sempre que adicionar uma nova função ao seu gráfico.\nAgora que definimos as três camadas essenciais (dados, aesthethic mapping e geom), temos enfim, no gráfico à direita mostrado no exemplo acima, o nosso primeiro gráfico completo montado. Há várias coisas que poderíamos fazer a partir daqui. Podemos por exemplo, colorir as barras de acordo com a participação do sexo no número de mortes. Ou seja, essas cores irão representar em cada barra, o número de mortes que correspondem ao sexo masculino e ao sexo feminino. Por padrão, o geom_bar() empilha esses agrupamentos um em cima do outro. Dessa forma, essas cores não apenas nos apresenta o número de mortes em cada sexo, mas indiretamente, elas também nos mostram o quanto que aquele grupo representa (qual a sua porcentagem) do total de mortes naquela faixa etária.\nDesta maneira, estamos definindo um outro componente visual do gráfico (cores das barras) à uma outra variável de nossos dados (coluna Genero). Logo, estamos falando novamente do aesthethic mapping do gráfico, e por isso, devemos definir essa ligação dentro da função aes(). Há duas formas de você colorir formas geométricas no ggplot, que dependem da forma geométrica e do resultado que você quer atingir. Uma barra (ou retângulo), é tratada como uma forma geométrica de área, enquanto outras formas (como pontos e linhas) são tratadas de uma maneira diferente. Nesses formatos de área, você deve utilizar o argumento fill, para preencher o interior deste formato de uma cor.\nPerceba no gráfico da esquerda mostrado no exemplo abaixo, que conseguimos colorir as barras, e que também, uma parte muito pequena das mortes correspondem ao sexo feminino, em todas as faixas etárias. Agora, e se mudássemos a variável no eixo x, por exemplo, para a cor de pele (gráfico à direita). Perceba, que o restante do aesthetic mapping continua o mesmo, e portanto, o gráfico mantém essas outras “conexões” enquanto modificamos a variável ligada ao eixo x.\n# Colorindo as barras de acordo com o sexo:\nggplot(\n    data = datasus,\n    mapping = aes(\n      x = `Faixa etaria`,\n      weight = Contagem,\n      fill = Genero\n    )\n  ) + geom_bar()\n# Com uma variável diferente no eixo x:\nggplot(\n    data = datasus,\n    mapping = aes(\n      x = Cor,\n      weight = Contagem,\n      fill = Genero\n    )\n  ) + geom_bar()\n\n\n\n\n\n\n\n\n\n\nComo disse anteriormente, há outros componentes visuais que você pode ligar às variáveis de sua tabela de dados. Você pode por exemplo, em alguns geom’s, conectar o formato desse geom a uma variável. Temos um exemplo dessa estratégia na seção 8.4.\n\n\n8.3.3 Formatos geométricos - funções geom\nCada função geom utiliza um formato geométrico e um método de desenho diferentes para representar os seus dados. No ggplot há vários geom’s distintos que você pode utilizar. Abaixo estou listando os geom’s mais comuns, mas basta consultar a cola oficial do ggplot22, ou o site oficial de referências do pacote3, que você ficará um pouco perdido com tantas opções. Um excelente repositório, com ótimos exemplos de gráficos dos quais você pode tirar inspirações de como e onde utilizar cada geom, é o R Graph Gallery4.\n\ngeom_bar(): desenha um gráfico de barras.\ngeom_point(): desenha um gráfico de pontos (ou um gráfico de dispersão).\ngeom_line(): desenha um gráfico de linha.\ngeom_boxplot(): desenha um gráfico de boxplot.\ngeom_histogram(): desenha um histograma.\ngeom_sf(): desenha um mapa (geom para dados espaciais).\ngeom_smooth(): desenha uma linha de média condicional (muito utilizado para desenhar linhas que representam modelos de regressão linear e de outros modelos econométricos).\ngeom_text(): utilizado para inserir texto.\ngeom_label(): utilizado para inserir rótulos, ou basicamente, textos envoltos por uma caixa.\n\nPor exemplo, um gráfico de barras, é geralmente utilizado para apresentar estatísticas descritivas dos nossos dados. Ou seja, esse tipo de gráfico (por padrão) tenta resumir características dos seus dados em poucos números (médias, totais, contagens). Já um gráfico de dispersão (por padrão) nos apresenta diretamente os dados, de forma crua no plano cartesiano. Isto é, diferentes geom’s vão tratar (e principalmente, representar) os seus dados de formas distintas.\nVamos por exemplo, adicionar pontos ao nosso gráfico anterior, com o geom_point(). Você pode ver o resultado no gráfico à esquerda no exemplo abaixo. Para facilitar a visualização, eu limitei os valores do eixo y no gráfico (para o intervalo de 0 a 1500) por meio da função lims(). Dessa forma, estamos dando um zoom em uma área específica do gráfico. Repare que cada ponto representa uma das observações encontradas na nossa base, e que vários deles estão se sobrepondo.\n# Gráfico à esquerda\nggplot(\n    data = datasus,\n    mapping = aes(\n      x = Cor,\n      weight = Contagem,\n      fill = Genero\n    )\n  ) +\n  geom_bar() +\n  geom_point(aes(y = Contagem)) +\n  lims(y = c(0,1500))\n\n# Gráfico à direita\nggplot(\n    data = datasus,\n    mapping = aes(\n      x = Cor,\n      y = Contagem,\n      fill = Genero\n    )\n  ) +\n  geom_point() +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nAo substituirmos as barras por boxplot’s produzimos o gráfico à direita no exemplo acima, que além de mostrar todas observações da base com o geom_point(), ele também mostra como a distribuição de ambos os sexos se encaixam ao longo do alcance (ou range) desses dados. Se você abrir esse gráfico dentro do R, você vai perceber que nos indivíduos de cor parda, temos a maior contagem para o sexo feminino em toda a base, que atinge em torno de 175 mortes, enquanto para o sexo masculino, esses valores podem atingir mais de 1000 mortes, apesar de que ambos os valores são outliers em suas respectivas distribuições.\nUma outra forma de visualizarmos a diferença entre homens e mulheres nesses dados, seria utilizando geom’s de erro, como as linhas de alcance. Os geom’s de erro são muito úteis para visualizar medidas de variação ao longo dos grupos. O geom_ribbon() por exemplo, é utilizado em gráficos de séries temporais, para desenhar os intervalos de confiança ou desvios padrão ao redor da linha que representa a série. No nosso caso, iremos utilizar o geom_linerange(), para desenharmos a diferença média entre o número de mortes entre os dois gêneros.\nO que o geom_linerange() faz é desenhar uma reta de um ponto A a um ponto B. A ideia por traz desse geom é desenharmos um linha que representa (pelo seu comprimento), por exemplo, o desvio padrão de uma variável, ou no nosso caso, a diferença na média de vítimas de homicídios dolosos entre dois gêneros. Isto significa que temos dois novos componentes visuais que podemos controlar no gráfico através do aesthetic mapping, que são as coordenadas do ponto A e do ponto B. Esses componentes (pontos A e B) representam os “limites” (máximo e mínimo) dessa linha, por isso, são controlados pelos argumentos ymax e ymin dentro da função aes(). Há outros geom’s que podem ser controlados por esses argumentos, porém, os que vimos anteriormente (geom_point() e geom_bar()) não possuem esses argumentos.\nPrimeiro, precisamos calcular o número médio de mortes de cada gênero e em cada cor de pele, e em seguida, modificar a estrutura da tabela, para que possamos mapear os limites (ymin e ymax) do linerange de acordo com o sexo. Para isso utilizo as funções dos pacotes dplyr e tidyr que vimos anteriormente. Perceba também que eu inverti o plano cartesiano, utilizando a função coord_flip().\n\ndatasus_agrup &lt;- datasus %&gt;% \n  group_by(Cor, Genero) %&gt;% \n  summarise(Media = mean(Contagem)) %&gt;% \n  pivot_wider(\n    id_cols = \"Cor\",\n    names_from = \"Genero\",\n    values_from = \"Media\"\n  )\n\nggplot(\n    data = datasus_agrup,\n    aes(x = Cor)\n  ) +\n  geom_linerange(aes(ymax = Masculino, ymin = Feminino)) +\n  geom_point(aes(y = Feminino, color = \"Feminino\")) +\n  geom_point(aes(y = Masculino, color = \"Masculino\")) +\n  coord_flip()\n\n\n\n\n\n\n\n\nAgora, muitas coisas estão ocorrendo neste gráfico. Primeiro, o geom_linerange() constrói uma linha para cada cor de pele, que vai da média de mortes no sexo feminino até a média no sexo masculino. Segundo, dois geom_point() são utilizados, onde cada um deles fica responsável por um dos sexos, e desenha um único ponto para cada cor de pele que indica a média de mortes para o sexo correspondente. Em seguida, eu uso coord_flip() para inverter o plano cartesiano. Ou seja, a variável que estava no eixo y (média de mortes) vai para o eixo x, e a variável que estava no eixo x (cor de pele) vai para o eixo y.\nCertamente, esse gráfico dá um pouco mais de trabalho de construir. Porém, é uma forma mais simples de se mostrar essa diferença, e com isso, você consegue atingir um público maior. Pode ser que o seu leitor não saiba o que é um boxplot, e há motivos razoáveis para se acreditar nisso. No Brasil, o boxplot não é comumente tratado no ensino básico, e sim no ensino superior, e mais especificamente, em cursos que sejam da área de exatas, ou que possuam matérias de estatística na grade curricular. Nós sabemos também que o acesso da população brasileira ao ensino superior é restrito, sendo considerado um local de “elitismo”.\nPor outro lado, os alunos em geral veem as principais medidas estatísticas de posição central (média, mediana e moda) já no ensino básico, e alguns chegam a revê-las no ensino superior. Logo, as chances de seu leitor compreender a mensagem que você quer passar: “em média, os homens são as principais vítimas de homicídios dolosos, entretanto, nas populações indígenas e de cor de pele amarela, esse padrão não parece ser significativo” são maiores. Essa consideração pode ter menor peso a depender de qual seja o público que você busca atingir. Se você está publicando um artigo científico em sua área, é bem provável que os potenciais leitores deste material conheçam um boxplot, e portanto, saibam interpretá-lo corretamente.",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Visualização de dados com `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/08-ggplot.html#uma-outra-forma-de-se-compreender-o-aesthetic-mapping",
    "href": "Capítulos/08-ggplot.html#uma-outra-forma-de-se-compreender-o-aesthetic-mapping",
    "title": "8  Visualização de dados com ggplot2",
    "section": "8.4 Uma outra forma de se compreender o aesthetic mapping",
    "text": "8.4 Uma outra forma de se compreender o aesthetic mapping\nNas seções anteriores, eu defini o aesthetic mapping, como a conexão entre as variáveis de sua tabela, com os componentes visuais de seu gráfico. Porém, temos uma outra forma útil de enxergarmos esse sistema. Podemos entender o aesthetic mapping, como um mecanismo para determinarmos quais componentes visuais vão variar, e quais vão permanecer constantes ao longo do gráfico. Ou seja, se você está definindo, por exemplo, as cores da forma geométrica (geom) que representa os seus dados, você pode utilizar o aesthetic mapping para definir se e como essas cores vão variar ao longo do gráfico.\nPor exemplo, vamos voltar ao gráfico de barras que montamos na seção 8.3, que mostra o número total de mortes ao longo das diferentes cores de pele e gênero da base. Perceba no gráfico à esquerda no exemplo abaixo, que a cor está variando dentro de cada barra (e não entre cada uma delas), de acordo com a variável Genero. Nós podemos modificar a forma como essas cores variam dentro de cada barra, ao mudarmos a variável que define essa variação. Em outras palavras, podemos alterar o comportamento das cores, ao conectar esse componente em aes(), a uma outra variável de nossa tabela. O gráfico à direita é um exemplo disso, pois agora temos as UF’s conectadas ao argumento fill de aes(). Como resultado, temos uma variação muito maior de cores dentro de cada barra.\n# Gráfico à esquerda\ndatasus %&gt;% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor, weight = Contagem, fill = Genero)\n  )\n# Gráfico à direita\ndatasus %&gt;% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor, weight = Contagem, fill = UF)\n  )\n\n\n\n\n\n\n\n\n\n\nNós podemos ainda, atribuir a mesma variável alocada no eixo x para definir a variação dessas cores ao longo do gráfico. Dessa forma, temos um gráfico onde cada uma das barras terá a sua própria cor. Isso não é particularmente útil, mas talvez você deseja ter uma cor separada para cada barra, e caso você esteja com preguiça de pensar e definir quais cores serão essas, deixar essa tarefa nas mãos do próprio ggplot é uma solução e um atalho simples para atingir um bom resultado.\n\ndatasus %&gt;% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor, weight = Contagem, fill = Cor)\n  )\n\n\n\n\n\n\n\n\nPortanto, ao conectarmos diferentes variáveis ao argumento fill em aes(), que define como as cores de cada barra são compostas, podemos modificar a forma como essas cores variam ao longo do gráfico. Mas e se nós quisermos manter uma única cor para essas barras, ou seja, e se é de seu desejo manter as cores constantes/fixas ao longo de todo o gráfico? Para isso, basta que você defina essas cores, fora de aes().\nEm outras palavras, a função aes() trabalha com variáveis, ou atributos que tendem a variar ao longo de sua tabela. Quando você estiver trabalhando com valores constantes, ou com atributos que possuem um único valor possível ao longo de toda a sua base, a função aes() provavelmente não será o lugar ideal para trabalharmos com tais valores.\nPor exemplo, o R possui diversas cores pré-programadas em seu sistema, e sempre que você quiser acessar essas cores ao longo do ggplot, você pode se referir a elas diretamente pelos seus nomes registrados. Caso queira uma lista com os nomes dessas cores pré-programadas, você pode utilizar a função colors(). Dentre essas diversas cores, temos uma chamada de steelblue. Logo, caso eu queira que todas as barras do meu gráfico estejam coloridas de acordo com essa cor, eu preciso fornecer o nome dessa cor ao argumento fill, porém, do lado de fora da função aes(). O gráfico à esquerda no exemplo abaixo demonstra essa ideia.\nPortanto, você pode aplicar essa metodologia para qualquer outro componente visual de seu gráfico que você quiser definir. Ou seja, se você deseja manter um componente visual de seu gráfico constante/fixo ao longo de seu gráfico, você precisa apenas definir o argumento correspondente (fill, color, size, fontface, linetype, shape, etc.) do lado de fora de aes(). Por outro lado, caso você queira controlar a forma como esse componente visual varia ao longo do gráfico, você precisa definir o argumento correspondente dentro de aes().\n# Gráfico à esquerda\ndatasus %&gt;% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor, weight = Contagem),\n    fill = \"steelblue\"\n  )\n# Gráfico à direita\ndatasus %&gt;% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor, weight = Contagem, fill = \"steelblue\")\n  )\n\n\n\n\n\n\n\n\n\n\nPorém, você talvez se pergunte: o que ocorre se eu fornecer a cor steelblue dentro de aes()? Será que o ggplot reconhece que queremos aplicar essa cor sobre as formas geométricas do gráfico? A resposta curta é não, mas o resultado em geral é um pouco estranho, ou no mínimo algo inesperado. Pois em um caso como esse, a função aes() irá entender que você deseja colorir as barras no gráfico, de acordo com uma nova variável em sua tabela, chamada fill, e que possui um único valor possível ao longo da base, mais especificamente, o texto steelblue. Você pode ver esse resultado no gráfico à direita no exemplo acima.\nEsse comportamento ocorre sempre que você fornece um valor em texto (um string) à algum argumento de aes(). Em uma situação como essa, o ggplot() parece criar uma nova variável em sua tabela chamada fill, e que contém o valor em texto que você forneceu a esse argumento. Isso não necessariamente é um comportamento inadequado, mas ele certamente surpreende alguns usuários, e como ele tem se mantido ao longo das últimas versões do ggplot, é possível que ele continue a funcionar dessa forma, por um bom tempo.",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Visualização de dados com `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/08-ggplot.html#sobrepondo-o-aesthetic-mapping-inicial-em-diversas-camadas",
    "href": "Capítulos/08-ggplot.html#sobrepondo-o-aesthetic-mapping-inicial-em-diversas-camadas",
    "title": "8  Visualização de dados com ggplot2",
    "section": "8.5 Sobrepondo o aesthetic mapping inicial em diversas camadas",
    "text": "8.5 Sobrepondo o aesthetic mapping inicial em diversas camadas\nAgora, vou explicar em maiores detalhes qual é a diferença entre: preenchermos os argumentos de data e mapping já na função inicial do gráfico (ggplot()), e de preenchê-los nas funções geom.\nPara isso, vamos usar outros dados. Na tabela PIB eu possuo uma série histórica mensal do índice de faturamento real da indústria (Faturamento_indus), da porcentagem do PIB que representa a dívida pública líquida (Divida_liq_perc), e a média mensal da taxa de investimento produtivo (taxa de formação bruta de capital fixo - FBCF) na economia brasileira, além de dados de PIB, coletados do IPEAData5.\n\nPIB\n\n# A tibble: 184 × 6\n  Data           PIB PIB_acumulado Divida_liq_perc  FBCF Faturamento_indus\n  &lt;date&gt;       &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt;             &lt;dbl&gt;\n1 2005-01-01 163540.         100              42.3 103.              102. \n2 2005-02-01 160702.          98.3            42.7  99.1              98.9\n3 2005-03-01 175469.         107.             43.1 112.               98.3\n4 2005-04-01 177179          108.             42.5 108.              107. \n5 2005-05-01 177497.         109.             42.4 113.              100. \n# ℹ 179 more rows\n\n\nNa seção 8.3, expliquei que ao preencher os argumentos já no ggplot() você estaria pedindo ao programa, que utilize a mesma base de dados e/ou o mesmo aesthetic mapping ao longo de todas as camadas do gráfico. Como exemplo, veja o que acontece no gráfico abaixo.\nComo o geom_bar() busca resumir os nossos dados em poucas estatísticas, eu coloquei dessa vez o valor “identity” no argumento stat. Isso impede que ele agrupe os dados em alguma medida estatística, fazendo com que o geom apenas identifique os valores que aparecem na base, da mesma forma que um geom_point() faria. Perceba também, que eu estou utilizando três geom’s diferentes no gráfico. Mas como eu não defini um aesthetic mapping específico em cada um deles, todos esses geom’s estão mostrando exatamente a mesma informação. Dito de outra forma, estes geom’s estão utilizando o mesmo aesthetic mapping, o qual definimos na função ggplot().\n\nggplot(\n  data = PIB,\n  aes(x = Data, y = Faturamento_indus)\n  ) +\n  geom_bar(stat = \"identity\", fill = \"darkgray\") +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"red\")\n\n\n\n\n\n\n\n\nVocê deve estar pensando: “Ok, mas isso não faz sentido! Por que eu usaria três geom’s diferentes para uma mesma informação?”. Bem, pode ser que você queira utilizar mais de um geom que mostre a mesma informação, por questões estéticas no gráfico. Um exemplo simples, seria marcar a borda de uma linha criada por geom_line(). Ou seja, não há uma forma direta e simples em geom_line() (algo que já é possível de ser feito no geom_point()), de pintar essas bordas de uma cor mais escura (ou clara) do que o interior da linha, dando assim uma maior ênfase para aquela linha. Portanto, a ideia seria criarmos duas camadas de geom_line(): uma interna, com uma linha mais estreita e de cor mais clara (ou mais escura); e uma externa, com uma linha mais larga (de forma que ela “transborde” para fora da linha interna) e de cor mais escura (ou mais clara).\nDe qualquer maneira, esses geom’s não fazem muito sentido da forma como estão dispostos no momento, portanto, vamos mudar de estratégia. Por que não utilizamos um só geom para apresentar três informações diferentes?! Para isso, temos que modificar a nossa base levemente. O objetivo é pegar as três colunas com as variáveis que vamos plotar (Faturamento_indus, FBCF e Divida_liq_perc), e agrupá-las em duas colunas: uma com os valores dessas variáveis, e outra coluna com os nomes dessas variáveis, para identificar qual variável o valor na primeira coluna se refere. Realizamos esse trabalho pela função pivot_longer().\n\nPIB_remodelado &lt;- PIB %&gt;% \n  select(Data, Faturamento_indus, FBCF, Divida_liq_perc) %&gt;% \n  pivot_longer(\n    cols = c(\"Faturamento_indus\", \"FBCF\", \"Divida_liq_perc\"),\n    names_to = \"Nome_variavel\",\n    values_to = \"Valor\"\n  )\n\nggplot(\n  data = PIB_remodelado,\n  aes(x = Data, y = Valor, linetype = Nome_variavel)\n  ) +\n  geom_line() \n\n\n\n\n\n\n\n\nNovamente, como não incluímos uma função aes(), ou definimos o argumento data dentro do geom_line(), ele irá utilizar o data e o aesthetic mapping (aes()) que definimos em ggplot(). Lembra de quando eu disse que você poderia controlar o formato de um geom de acordo com uma variável? O gráfico acima é um exemplo prático disso. Estamos utilizando apenas um geom para mostrar três informações diferentes, e o componente estético que utilizamos para diferenciar essas informações no gráfico, é o formato dessas linhas. Portanto, ao definirmos o componente linetype para Nome_variavel, estamos modificando o formato da linha (tracejada ou sólida), de acordo com os valores dessa variável. Poderíamos usar a mesma estratégia em geom_point(), ao definirmos o argumento shape para Nome_variavel. O resultado, seria um gráfico com pontos de três formatos diferentes (triângulos, quadrados e pontos comuns).\nEntretanto, para utilizarmos essa estratégia, nós tivemos que reestruturar a nossa base de dados pela função pivot_longer(). E se você não quisesse modificar essa base? Infelizmente, sem essa modificação, não poderíamos mostrar as três variáveis utilizando apenas uma função geom, mas poderíamos realizar o mesmo trabalho com uma função geom para cada variável. Neste caso, teremos que utilizar um aesthetic mapping diferente para cada geom, pois cada um deles, ficará responsável por mostrar os valores de uma variável diferente.\nNo primeiro gráfico dessa seção, utilizamos três geom’s diferentes para mostrar uma mesma informação. Se você comparar o código desse primeiro gráfico, ao código do gráfico abaixo, você perceberá que eles são quase idênticos, o que mudou, é a presença da função aes() nos dois últimos geom’s.\n\nggplot(\n  data = PIB,\n  aes(x = Data, y = Faturamento_indus)\n  ) +\n  geom_bar(stat = \"identity\", fill = \"darkgray\") +\n  geom_line(aes(y = FBCF), color = \"blue\") +\n  geom_line(aes(y = Divida_liq_perc), color = \"red\")\n\n\n\n\n\n\n\n\nO único geom que não possui uma função aes() definida, é o geom_bar(), logo, esse geom vai seguir o aesthetic mapping que definimos em ggplot(). Já os outros dois geom’s, vão seguir o aesthetic mapping que definimos em seus respectivos aes(). Porém, repare que em ambos geom’s, eu apenas defini a variável mapeada para o eixo y, não cheguei a definir uma nova variável para o eixo x. Quando isso ocorre, a função irá novamente recorrer ao aesthetic mapping que você definiu em ggplot(). Ou seja, como não definimos uma nova variável para o eixo x, todos os geom’s do gráfico acabam utilizando a variável no eixo x definida em ggplot().\nPortanto, você pode sobrepor por completo, ou parcialmente, o aesthetic mapping definido em ggplot() em cada geom, basta omitir os termos dos quais você não deseja sobrepor na nova função aes(). Um outro detalhe, é que não chegamos a definir em nenhum momento, um novo valor para o argumento data em algum geom. Logo, apesar de estarmos utilizando diferentes aesthetic mappings, todos os geom’s estão utilizando a mesma base de dados.\n\n8.5.1 Resumo da estrutura básica de um gráfico ggplot()\nEm resumo, todo gráfico do ggplot() possui três camadas essenciais, que formam a base do gráfico: 1) data, a base (ou bases) de dados utilizada no gráfico em questão; 2) aesthetic mapping, o mapeamento, ou a ligação de variáveis presentes na base de dados, para componentes estéticos e visuais do gráfico; 3) geom, a forma geométrica (retângulos, pontos, polígonos, linhas, etc) que irá representar os seus dados no gráfico.\nPara construir um gráfico do ggplot(), você deve sempre definir esses componentes. Os dois primeiros (data e aesthetic mapping), podem ser definidas dentro da função ggplot(), já o terceiro (geom), você define ao utilizar uma (ou várias) das funções geom, em uma (ou em várias) das camadas do gráfico. Com isso, temos uma estrutura básica como a definida abaixo, para construirmos um gráfico do ggplot:\n\nggplot(\n  data = &lt;sua base de dados&gt;,\n  aes(&lt;aesthetic mapping&gt;)\n  ) +\n  &lt;geom_...&gt; #uma função geom a seu gosto\n\nLembre-se que essa é apenas uma estrutura básica. Como mostramos na seção 8.4, podemos sobrepor de diversas formas essa estrutura. E podemos definir diversos outros parâmetros sobre essa estrutura como foi mostrado ao longo do capítulo.",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Visualização de dados com `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/08-ggplot.html#uma-discussão-sobre-os-principais-geoms",
    "href": "Capítulos/08-ggplot.html#uma-discussão-sobre-os-principais-geoms",
    "title": "8  Visualização de dados com ggplot2",
    "section": "8.6 Uma discussão sobre os principais geom’s",
    "text": "8.6 Uma discussão sobre os principais geom’s\nNas próximas seções vamos descrever rapidamente como grande parte dos principais geom’s se comportam, e quais são os argumentos (ou os componentes estéticos) que podemos controlar através da função aes(). Dessa forma, você pode rapidamente se familiarizar com esses geom’s, adquirindo um vocabulário das funções que os representam, e que cobrem a maior parte dos gráficos realizados no dia-a-dia.\nLembre-se que existem várias funções geom diferentes disponíveis, das quais muitas não serão descritas aqui. Muitas dessas outras funções geom utilizam os mesmos formatos geométricos que descrevemos aqui (como linhas, retângulos, etc.), entretanto, desenham esse formato geométrico de uma maneira diferente, além de possuírem outros componentes estéticos que podem ser controlados pelo aesthetic mapping do gráfico.\nCaso você não encontre aqui, o formato geométrico que está procurando, ou a função geom que realiza o desenho da forma como você deseja, você pode consultar a lista completa de funções geom na página oficial do pacote6. A página não possui uma versão em português, porém, você deve se virar razoavelmente bem com ferramentas de tradução (como o Google Tradutor) nessas situações. Se isso não for suficiente, você talvez encontre suas dúvidas em outros materiais construídos por brasileiros, como o blog Curso R7, o material do departamento de Estatística da UFPR8, ou dentro de alguma pergunta postada na página em português do StackOverflow9.\nO R Graph Gallery10 também é um excelente repositório (em inglês) que possui vários exemplos dos mais diversos geom’s, e que serve como a referência perfeita para os momentos em que você não lembra qual o geom que desenha o tipo de gráfico que você está procurando.\n\n8.6.1 Gráficos de dispersão e gráficos de bolha\nGráficos de dispersão são formados por geom_point(). Esse geom (por padrão) não transforma os seus dados, ou em outras palavras, ele não busca resumi-los de alguma maneira. Cada ponto desenhado no plano cartesiano representa cada uma das linhas presentes em sua base de dados. Os geoms que possuem este comportamento, são comumente chamados de geom’s individuais. Por este padrão, você deve obrigatoriamente definir as variáveis de ambos os eixos (x e y), neste geom.\nNos exemplos abaixo, estou utilizando a tabela mpg que vêm junto do ggplot, e nos apresenta dados de consumo de combustível de diversos modelos de carro, para mais detalhes desses dados, execute ?mpg no console. Os gráficos nos mostram uma relação aparentemente negativa entre volume ocupado pelos pistões no motor (displ), e a quilometragem por litro de gasolina (hwy).\nApós definir os eixos, você pode pintar os pontos de acordo com uma terceira variável, por exemplo, a classe do carro (compacto, SUV, minivan, …), através do argumento color. A classe do carro é uma variável categórica, e por isso, o ggplot() irá buscar cores contrastantes para pintar os pontos. Mas você também pode definir uma variável contínua a este argumento, onde neste caso, o ggplot() irá criar um gradiente de cores para pintar os pontos. Uma outra possibilidade deste geom, é variar o formato dos pontos através do argumento shape.\nA partir de geom_point() você também pode construir um gráfico de bolha, através do argumento size. Este tipo de gráfico em geral, piora o overplotting, ou a sobreposição dos pontos, já que alguns ficam muito grandes. Nestas situações, o argumento alpha é bem útil, sendo ele definido por um número de 0 a 1, indicando uma porcentagem de opacidade do geom. Por padrão, ele é configurado para 1 (100%), já no exemplo, eu reduzo essa opacidade para 40%.\n# Gráfico à esquerda\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy))\n# Gráfico à direita\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy, color = class))\n\n\n\n\n\n\n\n\n\n\n# Gráfico à esquerda\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy, color = class, shape = drv))\n# Gráfico à direita\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy, size = cyl), alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\nVocê pode se aproveitar do componente shape para diferenciar, ou destacar as bordas dos pontos, ao escolher o shape 21. Este método é esteticamente atraente, e fica muito bom em conjunto com linhas. Dessa forma, você pode pintar o interior dos pontos de uma cor, utilizando fill, e a borda desse ponto de outra cor, utilizando color. Lembre-se que isso só é possível, pelo shape que escolhemos para estes pontos, em outras situações, você poderá colorir pontos apenas com uma cor, utilizando o color. No exemplo abaixo, eu deixo todos os três argumentos de fora de aes(), dessa forma, o ggplot mantém os valores que dei a cada um deles, constantes ao longo de todo o gráfico.\n\nggplot(data = mpg) +\n  geom_point(\n    aes(x = displ, y = hwy),\n    shape = 21,\n    color = \"black\",\n    fill = \"steelblue\"\n  )\n\n\n\n\n\n\n\n\n\n\n8.6.2 Gráficos de barra\nComo descrevi anteriormente, os gráficos de barras no ggplot() são formados pelo geom_bar(), e em geral, são utilizados para apresentar estatísticas que resumem os dados em poucos números (como totais, médias, medianas). Em outras palavras, os geom’s que tem este comportamento, buscam representar várias observações de sua base, com um único formato geométrico, e são comumente chamados de geom’s coletivos. Por essa razão, o argumento stat é importante neste geom, pois nele você pode conceder o valor identity, que evita este comportamento, e faz com que o geom apenas identifique os valores que você fornece a ele.\nNo ggplot, este geom foi criado com o intuito de permitir que o usuário construa rapidamente gráficos de contagens e somatórios. Portanto, este geom possui mecanismos para calcular essas estatísticas, você não precisa calculá-las por conta própria antes de gerar o ggplot. Por padrão, este geom calcula inicialmente uma contagem dos seus dados. Logo, caso você não defina qual a estatística que deseja mostrar, ele irá contar a quantidade que cada valor aparece na base. Por exemplo, o gráfico abaixo nos mostra que dentro da tabela mpg, temos em torno de 80 modelos com motores de 4 ou 6 cilindradas, e menos de 10 modelos com 5 cilindradas.\n\n  ggplot(\n    data = mpg,\n    aes(x = cyl)\n  ) +\n  geom_bar()\n\n\n\n\n\n\n\n\nTendo essas considerações em mente, você tem duas opções básicas ao lidar com este geom: 1) fornecer diretamente os dados, e pedir ao geom que calcule as estatísticas que você deseja mostrar (contagem ou somatório); ou 2) você primeiro calcula as estatísticas que deseja, e pede ao geom que apenas as identifique, sem realizar nenhuma transformação desses dados. Caso opte pela opção 2, você deve tomar muito cuidado com o argumento stat = \"identity\", por razões que vou explicar abaixo.\nEste geom não possui um mecanismo próprio para calcular médias (e muitas outras estatísticas), e portanto, se você quiser mostrá-las utilizando este geom, você terá de calcular separadamente essas médias, e pedir ao geom que apenas as identifique com stat = \"identity\" (gráfico à esquerda). Porém, caso você queira calcular o total, ou o somatório em cada grupo, você pode apenas definir a coluna com os valores a serem somados, para o argumento weight dentro de aes() (gráfico à direita).\nmedias &lt;- mpg %&gt;% \n  group_by(cyl) %&gt;% \n  summarise(media = mean(hwy))\n\n# Gráfico à esquerda\nggplot(\n    data = medias,\n    aes(x = cyl, y = media)\n  ) + geom_bar(stat = \"identity\")\n# Gráfico à direita\nggplot(\n    data = mpg,\n    aes(x = cyl, weight = hwy)\n  ) + geom_bar()\n\n\n\n\n\n\n\n\n\n\nAgora, lembra quando eu disse que você pode pedir ao geom que apenas “identifique” os valores de sua base (com stat = \"identity\") ? Com este argumento, o geom_bar() irá ter um comportamento diferente, caso os valores em cada grupo não sejam únicos. No exemplo anterior, em que calculei as médias de cada cyl em mpg, o geom apenas identificou as médias de cada cyl, pois há apenas uma única média para cada cyl. No exemplo abaixo, estou criando rapidamente uma tabela, e nela você pode perceber que há dois valores para o grupo \"c\". Agora, repare o que acontece no gráfico, o geom_bar() acaba somando estes valores.\n\ntab &lt;- data.frame(\n  grupo = c(\"a\",\"b\",\"c\",\"c\",\"d\"),\n  valor = c(1,2,3,2,2)\n)\n\nggplot(tab, aes(x = grupo, y = valor)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nEm outras palavras, se os seus dados estiverem agrupados, o geom_bar() com stat = \"identity\" irá de fato apenas identificar estes valores. Mas caso os seus dados estiverem desagregados, com mais de um valor por grupo, o geom_bar() irá somar estes valores. Isso significa, que stat = \"identity\" representa uma outra alternativa (além de weight), para criar gráficos de somatório. Bastaria fornecer a coluna com os valores a serem somados para o eixo y em aes(), e adicionar stat = \"identity\" à geom_bar().\nUm outro ponto importante neste geom, é o posicionamento das barras. Por padrão, o geom empilha barras que ocupam o mesmo valor no eixo x no gráfico. Isso nos permite visualizarmos a participação dos grupos de uma outra variável categórica (cor de pele, faixa etária, …), em cada valor presente no eixo x. Por outro lado, você talvez esteja interessado na diferença entre os grupos, e não a sua participação. Logo, você talvez queira jogar essas barras uma do lado da outra, e para isso você deve utilizar o argumento position, dando o valor “dodge”. No exemplo abaixo, retorno a base de dados datasus, com o objetivo de mostrar a diferença em cada cor de pele, da média de vítimas para cada sexo.\nmedias &lt;- datasus %&gt;% \n  group_by(Cor, Genero) %&gt;% \n  summarise(media = mean(Contagem))\n\n# Gráfico à esquerda\nggplot(\n    data = medias,\n    aes(x = Cor, y = media, fill = Genero)\n  ) +\n  geom_bar(stat = \"identity\", position = \"dodge\") \n\n# Gráfico à direita\nggplot(\n    data = datasus,\n    aes(x = `Faixa etaria`, weight = Contagem, fill = Cor)\n  ) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\n\n\nPortanto, caso você não definisse position para dodge, o ggplot iria empilhar essas barras (azul e vermelho) uma em cima da outra. Em um gráfico de médias como o acima, não faria muito sentido empilhar essas barras, porém, este posicionamento faz muito sentido em gráficos de somatório, como os que fizemos ao longo da Seção 8.3. Pois dessa forma você consegue visualizar o quanto que cada grupo representa do total.\nVocê talvez queira ir um pouco além, e observar as diferenças na participação de cada cor de pele, ao longo dos totais de vários grupos. Para isso, você pode dar o valor fill ao argumento position. Dessa forma, o ggplot calcula qual é a proporção de cada grupo para cada valor do eixo x, em uma escala de 0 a 1. Nesta situação, você deve definir a variável do eixo y, para o argumento weight em aes().\n\n\n8.6.3 Gráficos de linha\nGráficos de linha são muito utilizados em séries temporais, para mostrar a evolução de algum índice ao longo do tempo. Este tipo de gráfico é criado pelo geom_line(), que possui um comportamento de “conector”.\nO geom_line() (diferentemente de seu irmão geom_path()) sempre ordena os valores da base (antes de conectá-los), segundo a variável alocada no eixo x, na ordem que seja mais lógica para essa variável. Veja o exemplo abaixo, onde dou um vetor de datas (fora de ordem) para o eixo x. Independente da ordem em que os valores estiverem em sua base, a função irá reordenar a base antes de conectar os pontos.\n\ntab &lt;- data.frame(\n  dia = as.Date(c(\"2020-01-01\",\"2020-01-04\",\"2020-01-02\",\"2020-01-03\")),\n  valor = c(10,27,14,23)\n)\n\nggplot(tab, aes(dia, valor)) + geom_line()\n\n\n\n\n\n\n\n\nIsso significa, que este geom funciona com qualquer variável no eixo x que possua uma ordem lógica, seja ela contínua ou categórica. Veja no exemplo abaixo, onde eu substituo a coluna dia, por um simples vetor de texto (gráfico à esquerda). Ao detectar o tipo de dado presente na coluna, a função reordena os valores de acordo com a ordem lógica para este tipo de dado (no exemplo abaixo, ordem alfabética).\nConhecer essa funcionalidade é importante, ao fornecer para o geom dados dos quais ele não consegue reconhecer o formato e a ordem correta. Pense por exemplo, se você fornecesse um vetor de datas, mas no formato “abril/2020”. Como os valores começam por um nome, ele reconhece estes valores como texto, e, portanto, ordena-os em ordem alfabética, ao invés de ordená-los como meses do ano. Nessas situações, transformar esses valores para fatores, e definir a sua ordem em seu atributo levels (gráfico à direita), pode ser uma boa alternativa.\ntab$dia &lt;- c(\"a\",\"c\",\"d\",\"b\")\n# Gráfico à esquerda\nggplot(tab, aes(dia, valor, group = 1)) + geom_line()\n\ntab$dia &lt;- c(\"Janeiro/2020\", \"Abril/2020\", \"Fevereiro/2020\", \"Março/2020\")\nordem &lt;- c(\"Janeiro/2020\", \"Fevereiro/2020\", \"Março/2020\", \"Abril/2020\")\n# Gráfico à direita\nggplot(\n    tab,\n    aes(factor(dia, levels = ordem), valor, group = 1)\n  ) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\nEu costumo aumentar a grossura dessas linhas através do argumento linewidth, que por padrão está configurado para 0.5. Geralmente 1 já é um bom nível para mim, mas você pode aumentar o quanto quiser. Como eu quero que a grossura, permaneça constante ao longo de toda a linha, eu mantenho o argumento linewidth de fora do aes(). Isso significa que você poderia variar essa grossura ao longo da linha, apesar de que o resultado seria um tanto esquisito. Tente por exemplo, adicionar ao aes() do exemplo anterior, o valor linewidth = valor, e veja o resultado.\nNeste geom, o argumento group em aes() é muito importante. Este argumento controla como o geom considera os grupos da base, na hora de desenhar o formato geométrico em questão. No primeiro exemplo dessa seção, nós não utilizamos este argumento, pois a variável ligado ao eixo x (dia) era uma variável contínua. Entretanto, no instante em que mudamos os valores dessa coluna para texto, tivemos que adicionar um group = 1 ao aes(). Logo, quando você ligar uma variável contínua ao eixo x, muito provavelmente você não precisará mexer com o group. Caso a variável seja categórica, é certo que algum valor deve ser dado ao argumento group.\nIsso é apenas uma simplificação, que serve como um guia inicial, mas que nem sempre se aplica. Pois o group não diz respeito ao tipo de variável (contínua ou categórica), e sim se você quer separar ou não as linhas por algum agrupamento. Se você está apenas querendo mostrar uma única linha no gráfico, essa simplificação será útil. Mas com o tempo você vai se pegar utilizando o group, para mostrar em um mesmo gráfico a evolução de vários índices diferentes ao longo do tempo, mesmo que a variável no eixo x (datas) seja uma variável contínua. Basta relembrar o exemplo da seção 8.4, em que utilizamos linetype para diferenciar as curvas de três indicadores diferentes em um mesmo geom_line(). Você poderia replicar o mesmo gráfico utilizando group, ao invés do linetype.\nEssa questão fica mais clara, ao utilizarmos uma base que possui mais de um valor por grupo. Veja por exemplo a base Oxboys, que vem do pacote mlmRev. Essa base é resultado de uma pesquisa, onde os pesquisadores acompanharam durante vários anos, o crescimento de alguns indivíduos.\n\nhead(mlmRev::Oxboys, n = 10)\n\n   Subject     age height Occasion\n1        1 -1.0000  140.5        1\n2        1 -0.7479  143.4        2\n3        1 -0.4630  144.8        3\n4        1 -0.1643  147.1        4\n5        1 -0.0027  147.7        5\n6        1  0.2466  150.2        6\n7        1  0.5562  151.7        7\n8        1  0.7781  153.3        8\n9        1  0.9945  155.8        9\n10       2 -1.0000  136.9        1\n\n\nPortanto, a coluna Subject identifica qual o indivíduo os valores da linha se referem. Repare que várias linhas dizem respeito ao mesmo indivíduo. Agora, pense como o geom_line() trataria esses diversos valores que se encaixam no mesmo grupo (no nosso caso, no mesmo Subject). Neste caso, o geom_line() irá conectar (incorretamente) todos os valores em conjunto da base, pois ele não sabe que cada um desses valores pertence a sujeitos diferentes, o geom pensa que todos esses valores pertencem a um único sujeito. O resultado seria um gráfico com um aspecto de “serra”.\nPara que isso fique claro, eu adicionei um geom_point() para que você veja cada um dos valores presentes na base. Primeiro, preste atenção nas variáveis que conectamos aos eixos do gráfico (idade e altura do indivíduo). Ambas as variáveis são contínuas, mas neste momento, não há qualquer variável no gráfico que possa identificar a qual dos indivíduos, cada um desses valores se refere. Logo, o geom_line() acaba conectando todos esses pontos juntos.\n# Gráfico à esquerda\nggplot(\n  Oxboys,\n  aes(x = age, y = height)\n) +\n  geom_line()\n# Gráfico à direita\nggplot(\n  Oxboys,\n  aes(x = age, y = height)\n) +\n  geom_line() +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nAo invés do geom_line() conectar todos esses pontos em conjunto, o geom deveria conectar todos os pontos que dizem respeito ao mesmo indivíduo, e é para isso que o argumento group serve. Você define neste argumento, qual a coluna que identifica qual é o grupo (ou no nosso caso, o indivíduo) que está sendo tratado em cada observação de sua base de dados.\nUma outra forma de definirmos esses grupos para o geom, é colorindo as linhas com o argumento color, ou então variando o formato dessas linhas com o argumento linetype. Basta você fornecer a estes argumentos, uma coluna que seja capaz de identificar cada um dos grupos ou indivíduos (no nosso caso, Subject) que estão sendo tratados no gráfico.\n# Gráfico à esquerda\nggplot(\n  Oxboys,\n  aes(x = age, y = height, group = Subject)\n) +\n  geom_line() +\n  geom_point()\n# Gráfico à direita\nggplot(\n  Oxboys,\n  aes(x = age, y = height, color = Subject)\n) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\nPortanto, toda vez em que utilizar este geom em uma base que possui mais de um valor por grupo, você muito provavelmente terá de utilizar group, especialmente se você precisa diferenciar as curvas de cada grupo no gráfico.\nSe você quiser mostrar uma única linha no gráfico, você vai mexer obrigatoriamente com o group caso a variável do eixo x seja categórica, onde neste caso, você deve dar uma constante qualquer ao argumento (eu geralmente defino para 1: aes(group = 1)). Isso é necessário, porque geom_line() entende que cada um dos valores dessa variável categórica, representa um grupo diferente. Dessa forma, cada um desses grupos irá possuir apenas um valor em toda a base. Caso você se esqueça de definir este valor para group nesta situação, o seguinte erro irá aparecer:\n\n# Each group consists of only one observation. Do you need to adjust the group\n# aesthetic?\n\n\n\n8.6.4 Histogramas e outros gráficos de frequência\nHistogramas e polígonos de frequência são gráficos “unidimensionais”, ou dito de outra forma, apresentam informações sobre apenas uma variável, mais especificamente uma variável contínua. Por essa razão, você precisa definir apenas um dos eixos do gráfico, geralmente, o eixo x. Estes gráficos são criados por geom_histogram() e geom_freqpoly().\n# Gráfico à esquerda\nggplot(mpg, aes(hwy)) + geom_histogram()\n# Gráfico à direita\nggplot(mpg, aes(hwy)) + geom_freqpoly()\n\n\n\n\n\n\n\n\n\n\nAmbos os gráficos funcionam da mesma forma, apenas a forma geométrica utilizada é diferente. Eles pegam a distribuição da variável ligada ao eixo x, e dividem essa distribuição em vários intervalos (chamados de bin’s), e contam quantos valores se encaixam em cada um destes intervalos. Neste geom, é importante que você teste diferentes larguras para estes intervalos, através do argumento binwidth. Por padrão, o geom tenta dividir a distribuição em 30 intervalos diferentes.\nVocê pode separar as distribuições por alguma variável categórica, dando essa variável ao argumento group. Porém, essas distribuições estarão sobrepostas no gráfico, sendo impossível diferenciá-las. Logo, é necessário que você mostre essas distribuições separadas em diferentes facetas do gráfico (através da função facet_wrap()).\n\nggplot(mpg, aes(hwy, group = cyl)) +\n  geom_histogram() +\n  facet_wrap(~class)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nO geom_freqpoly() não sofre seriamente deste problema, pois a sua forma geométrica é “oca”. Mas é interessante de qualquer forma, que você ou separe essas distribuições em diferentes facetas do gráfico, ou então, que colora as distribuições de acordo com a variável categórica utilizada.\n# Gráfico à esquerda\nggplot(mpg, aes(hwy, color = class)) +\n  geom_freqpoly() \n# Gráfico à direita\nggplot(mpg, aes(hwy, fill = class)) +\n  geom_histogram() +\n  facet_wrap(~class)\n\n\n\n\n\n\n\n\n\n\nUma alternativa a estes geom’s, é o geom_density() que calcula uma função de densidade para a variável escolhida. Caso esteja interessado em separar essa distribuição de acordo com uma variável categórica, eu recomendo que dê uma olhada no pacote ggridges. Este pacote fornece novos geom’s, que posicionam essas distribuições separadas de uma forma esteticamente atraente, sem a necessidade de construir diferentes facetas do mesmo gráfico, além de fornecer mecanismos para marcar os percentis da distribuição no gráfico. É mais fácil ver com seus próprios olhos 11, do que eu explicar.\nCaso você prefira permanecer com o geom padrão do ggplot e ainda separar a distribuição por uma variável categórica, você pode utilizar o argumento alpha para reduzir a opacidade dessas distribuições, como um meio de combater a sobreposição. Mas o ideal, é que você as separe em diferentes facetas, utilizando facet_wrap() da mesma forma que fizemos para os histogramas.\n\nggplot(mpg, aes(hwy, fill = class)) + geom_density(alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\n8.6.5 Adicionando textos ao gráfico\nVocê pode adicionar rótulos ao seu gráfico com geom_label(), ou adicionar textos simples com geom_text(). Estes geom’s funcionam exatamente como o geom_point(), porém, ao invés de desenharem pontos, eles desenham textos. Em outras palavras, eles são geom’s individuais, em que desenham um texto, ou um rótulo, para cada uma das observações de sua base de dados.\nDessa vez, você deve definir a coluna que contém os rótulos/textos que deseja mostrar no gráfico, no argumento label em aes(). Os rótulos serão posicionados no plano cartesiano de acordo com os valores definidos pelas variáveis ligadas aos eixos x e y.\n# Gráfico à esquerda\nggplot(mpg, aes(x = displ, y = hwy, label = model)) +\n  geom_text()\n# Gráfico à direita\nggplot(mpg, aes(x = displ, y = hwy, label = model)) +\n  geom_label()\n\n\n\n\n\n\n\n\n\n\nAo colocar textos em um gráfico, você dificilmente não enfrentará algum nível de sobreposição. O ggplot oferece algumas ferramentas que em muitas ocasiões não resolvem o problema, mas que em outras podem ser suficientes. Ambos os geom’s descritos aqui, possuem o argumento check_overlap. Caso ele seja configurado para TRUE, o ggplot irá criar os rótulos na ordem em que eles aparecem na sua base, e eliminar todos os rótulos consecutivos que sobreporem os anteriores. O código ficaria dessa forma:\n\nggplot(mpg, aes(x = displ, y = hwy, label = model)) +\n  geom_text(check_overlap = TRUE)\n\nApesar de uma solução, ela pode muito bem eliminar justamente os rótulos que queremos destacar no gráfico, e por isso é pouco desejada. Você poderia também reduzir o tamanho da fonte através de size. Um detalhe é que este argumento trabalha por padrão com valores em milímetros (mm), mas como é um pouco confuso trabalhar com tamanho de fontes nesta unidade, eu geralmente transformo os valores para pontos (pt). No exemplo abaixo, estou reduzindo o tamanho das fontes para 7 pt. O problema dessa opção, é que ela representa um trade-off entre a sobreposição de pontos, e a legibilidade dos rótulos, cabe a você definir o equilíbrio entre essas opções.\n\nggplot(mpg, aes(x = displ, y = hwy, label = model)) +\n  geom_text(size = 7/.pt)\n\n\n\n\n\n\n\n\nA melhor solução possível, seria ajustarmos a posição de cada um dos pontos individualmente. Entretanto, se você tem vários textos que exigem desvios diferentes, essa solução facilmente se torna muito trabalhosa. A ideia, seria criarmos duas novas colunas em nosso data.frame, onde em cada uma você define um valor de desvio vertical (y_desvio), e na outra o valor de desvio horizontal (x_desvio) para o rótulo definido naquela linha. Em seguida, você conecta essas colunas aos argumentos de posição responsáveis por realizar estes deslocamentos de textos (nudge_y e nudge_x) em seu aesthetic mapping (aes()). Veja o código abaixo.\n\nggplot(\n  mpg,\n  aes(\n    x = displ,\n    y = hwy,\n    label = model,\n    nudge_x = x_desvio,\n    nudge_y = y_desvio\n  )) +\n  geom_text()\n\nVamos separar uma seção para descrevermos outras soluções mais eficazes para esse problema. Também vamos separar, uma seção para descrevermos quais são as estratégias possíveis para você trocar a fonte dos textos mostrados no gráfico, algo que ainda é difícil de ser realizado, especialmente se você trabalha no Windows. Agora vou explicar o que os argumentos de posição (nudge_x e nudge_y), e os de justificação (hjust e vjust) fazem.\nDurante muito tempo, eu sofri de uma leve confusão entre esses argumentos. Como você muito provavelmente vai querer ajustar o posicionamento desses textos, vou tentar explicar a diferença entre os dois da forma mais clara possível, para que você não sofra do mesmo efeito.\nVamos começar pelos argumentos de justificação, que são hjust (justificação horizontal) e vjust (justificação vertical). Estes argumentos, servem para alterar a justificação, ou o alinhamento da cadeia de texto em relação ao seu ponto de referência (ou de coordenadas).\n\ndf &lt;- data.frame(\n  x = c(1, 1, 2, 2, 1.5),\n  y = c(1, 2, 1, 2, 1.5),\n  text = c(\n    \"bottom-left\", \"bottom-right\",\n    \"top-left\", \"top-right\", \"center\"\n  )\n)\n\nggplot(df, aes(x, y)) +\n  geom_point(color = \"darkgray\", size = 7/.pt) +\n  geom_text(aes(label = text))\n\n\n\n\n\n\n\n\nPor padrão, hjust é configurado para center, e vjust para middle. Logo, todos os rótulos são centralizados (tanto verticalmente, quanto horizontalmente) no ponto que define a sua localização. Para mudar o alinhamento de todos os rótulos de uma vez, você pode configurar estes argumentos, por fora do aes(), fornecendo um dos valores pré-definidos.\nNo caso de hjust, há outros quatro valores pré-definidos possíveis (left, right, inward, outward). Caso você coloque left ou right neste argumento, todos os rótulos serão alinhados à esquerda, ou à direita dos pontos. Porém, caso você coloque inward ou outward, os textos serão alinhados (horizontalmente em relação aos pontos de sua localização) em um sentido para o para o centro do gráfico, ou se afastando do centro do gráfico. Dito de outra forma, os textos serão alinhados à esquerda, ou à direita do ponto de referência, a depender da sua localização em relação ao centro do plano cartesiano e do sentido escolhido (inward ou outward).\nPara vjust, há também quatro outros valores pré-definidos (bottom, top, inward, outward). Os valores bottom e top alinham os textos na base ou no topo do ponto de referência do texto. Enquanto os valores inward e outward funcionam no mesmo sentido que em hjust, porém eles controlam o alinhamento vertical dos textos.\n\nggplot(df, aes(x, y)) +\n  geom_point(color = \"gray\", size = 7/.pt) +\n  geom_text(aes(label = text), vjust = \"inward\", hjust = \"inward\")\n\n\n\n\n\n\n\n\nPara deixar claro o que estes argumentos fazem, trago um novo exemplo abaixo que contém cadeias de texto de duas linhas. Caso você queira variar a justificação destes textos, ao longo do gráfico, significa que você deve conectar uma coluna de seu data.frame a estes argumentos em aes(). Porém, estes argumentos não aceitam os valores pré-definidos ao estarem dentro de aes(). Nestas situações, você deve fornecer um número: 0 (justificado à esquerda); 0.5 (centralizado); ou 1 (justificado à direita).\n\ntab &lt;- data.frame(\n  y = rep(1:3, times = 3),\n  x = rep(1:3, each = 3),\n  texto = rep(c(\"Um texto alinhado\\nà esquerda\",\n            \"Um texto\\ncentralizado\",\n            \"Um texto alinhado\\nà direita\"),\n            each = 3\n          ),\n  hjust = rep(c(0, 0.5, 1), each = 3),\n  vjust = rep(c(0, 0.5, 1), times = 3)\n)\n\nggplot(tab, aes(x, y)) +\n  geom_point(size = 7/.pt, color = \"darkgray\") +\n  geom_text(aes(\n    label = texto,\n    hjust = hjust,\n    vjust = vjust\n  ))\n\n\n\n\n\n\n\n\nEu acredito que é justamente essa opção numérica, que gera toda a confusão sobre a função verdadeira destes argumentos. Pois o ggplot não gera nenhum erro caso você dê valores diferentes, e se você aumentar progressivamente estes valores, você irá perceber que o deslocamento dos textos também aumenta. Muitos que se deparam com este comportamento, podem acreditar que estes argumentos servem para deslocar os textos, e não para alinhá-los em relação ao ponto de suas coordenadas. Por isso eu recomendo nestes argumentos, que você utilize um dos valores pré-definidos que citei anteriormente, e utilize essa escala numérica, apenas em situações em que você precisa dessa variação utilizando aes().\nUma outra razão pela qual estes argumentos não são apropriados, caso você queira deslocar os textos em um sentido, é que eles não trabalham em sintonia com as escalas dos eixos. No exemplo abaixo, eu configuro o valor de vjust para -4. Porém, o ggplot não deslocou verticalmente os textos em 4 unidades. O texto de valor center, por exemplo, não foi deslocado para as coordenadas (x = 1.5, y = 5.5), e se você quiser que ele chegue nessa coordenada? O que você faz? Triplica? Quadruplica o valor anterior? Tudo isso, significa que não há como você prever o quanto o texto irá deslocar, e por isso, você pode perder muito tempo testando diversos valores em um argumento inadequado para o resultado que deseja.\n\nggplot(df, aes(x, y)) +\n  geom_point(color = \"gray\", size = 7) +\n  geom_text(aes(label = text), vjust = -4)\n\n\n\n\n\n\n\n\nAgora, vou explicar como os argumentos de posição funcionam. Como o próprio sufixo deles dá a entender, o nudge_y irá deslocar verticalmente os textos, e nudge_x, vai deslocá-los horizontalmente. O verbo nudge em inglês se refere ao ato de “cutucar”, ou empurrar gentilmente alguém, logo, estes argumentos servem para “empurrar” os textos de suas posições originais no plano cartesiano. Para demonstrarmos a sua aplicação, vamos tentar rotular um gráfico de barras, que apresente um somatório da quilometragem em cada cilindro.\nComo descrevi anteriormente, o geom_bar() é um geom coletivo, enquanto os geom’s de texto são geom’s individuais. Por isso, caso você adicionar diretamente um geom_text() ao geom_bar(), sem levar em conta essa diferença, ele irá rotular cada uma das observações da base resumidas em cada barra, e não o total que ela representa.\nPara rotular corretamente essas barras, você tem duas opções: 1) calcular o somatório em um objeto separado, e em seguida fornecer este objeto ao argumento data, e ajustar o aesthetic mapping de acordo com este objeto, em geom_text(); ou 2) usar as transformações estatísticas que o ggplot já disponibiliza para esse trabalho. No exemplo abaixo, estou demonstrando a opção 1, mas darei um exemplo da opção 2 quando chegarmos à seção de transformações estatísticas do ggplot.\n\nsomatorios &lt;- mpg %&gt;% \n  group_by(cyl) %&gt;% \n  summarise(soma = sum(hwy))\n\nggplot() +\n  geom_bar(\n    mapping = aes(x = cyl, weight = hwy),\n    data = mpg\n  ) +\n  geom_text(\n    mapping = aes(x = cyl, y = soma, label = soma),\n    data = somatorios\n  )\n\n\n\n\n\n\n\n\nPortanto, neste exemplo as duas camadas de geom utilizam não apenas aesthetic mapping’s, mas também fontes de dados, diferentes. Como você pode reparar acima, os rótulos estão sobre o topo da barra. Por isso, eu posso utilizar o nudge_y para adicionar um pequeno desvio vertical nestes rótulos, dando assim um maior espaço entre ele e a barra. Veja o exemplo abaixo, no gráfico à esquerda.\nDiferentemente dos argumentos de alinhamento, os argumentos de posição (nudge_y e nudge_x) funcionam em sintonia com a escala dos eixos. Como a escala do eixo y termina em aproximadamente 2500, um desvio de 100 é provavelmente suficiente. Isso significa que caso o limite dessa escala fosse 1 décimo disso (250), por exemplo, um desvio de 100 em nudge_y iria gerar um deslocamento considerável nestes rótulos.\nAlém dessas opções, caso você insira textos de 2 ou mais linhas no gráfico, você pode se interessar em reduzir ou aumentar o espaço entrelinhas destes textos. Neste caso, você pode controlar este espaço pelo argumento lineheight que define a proporção em relação à altura das letras. Um outro ponto possível de customização, é o ângulo dos textos, que é definido pelo argumento angle. Neste argumento, basta fornecer um número (de 0 a 360) que represente o ângulo desejado. Veja no exemplo abaixo o gráfico à direita.\n# Gráfico à esquerda\nggplot() +\n  geom_bar(\n    mapping = aes(x = cyl, weight = hwy),\n    data = mpg\n  ) +\n  geom_text(\n    mapping = aes(x = cyl, y = soma, label = soma),\n    data = somatorios, \n    nudge_y = 100\n  )\n# Gráfico à direita\nggplot() +\n  geom_bar(\n    mapping = aes(x = cyl, weight = hwy),\n    data = mpg\n  ) +\n  geom_text(\n    mapping = aes(x = cyl, y = soma, label = soma),\n    data = somatorios, \n    nudge_y = 100,\n    angle = 45\n  )",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Visualização de dados com `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/08-ggplot.html#sec:devices_graficos",
    "href": "Capítulos/08-ggplot.html#sec:devices_graficos",
    "title": "8  Visualização de dados com ggplot2",
    "section": "8.7 Exportando os seus gráficos do ggplot",
    "text": "8.7 Exportando os seus gráficos do ggplot\nApós gerar os seus gráficos com o ggplot, você provavelmente quer exportá-los para algum arquivo de imagem, para que você possa inseri-los em seu artigo em Word (.docx), ou em seu PowerPoint (.pptx) que você deve apresentar ao seu chefe no dia seguinte. Para realizarmos essa tarefa, precisamos utilizar funções que possam construir esses arquivos de imagem, nos quais podemos guardar os nossos gráficos. Com isso, temos duas alternativas mais comuns no R, que são:\n\natravés da função ggsave(), que é exposta por (WICKHAM, 2016, seç. 8.5).\nutilizando o método tradicional de se exportar gráficos no R, descrita por (MURRELL, 2006, Cáp. 1).\n\nUma outra referência que também descreve ambas alternativas, se encontra em CHANG (2012, Cáp. 14). A primeira alternativa citada, seria uma forma mais prática de se exportar os seus gráficos no R, através da função ggsave() (que vem do próprio pacote ggplot). Entretanto, essa função nada mais é, do que um wrapper sobre as funções do pacote grDevices, que são utilizadas na segunda alternativa citada acima. Ou seja, a função ggsave() é apenas um atalho para o método descrito por MURRELL (2006).\nEm mais detalhes, o pacote grDevices (que está incluso nos pacotes básicos da linguagem) oferece um conjunto de funções capazes de acessar diversos devices gráficos. Cada device gráfico, representa uma engine diferente que vai ser responsável por construir o arquivo onde o seu gráfico será guardado. Portanto, cada uma dessas engines, vão gerar um tipo arquivo diferente, ou em outras palavras, arquivos de extensões diferentes. Você já utiliza muitos desses devices gráficos, praticamente o tempo todo em sua rotina. Você apenas não sabia, que esse era o nome técnico dado às engines, que normalmente constroem esses tipos de arquivos. Sendo os exemplos mais famosos, os arquivos: JPEG/JPG (.jpeg, .jpg), PNG (.png), SVG (.svg) e PDF (.pdf).\n\n8.7.1 Tipos de representação geométrica em devices gráficos\nAo longo das últimas décadas, a área da computação gráfica desenvolveu diversos modelos computacionais que fossem capazes de representar visualmente e virtualmente, o nosso mundo real (HUGHES et al., 2014). Com isso, eu quero destacar que nós possuímos hoje, formas diferentes de se representar uma mesma imagem em nosso computador.\nIsso significa, que cada um dos devices gráficos disponíveis, que podemos utilizar para guardar os nossos gráficos no R, utilizam um modelo ou método de representação geométrica diferente para representar a sua imagem. Cada um desses modelos, possuem características diferentes, e com isso, incorrem em erros distintos na representação virtual de sua imagem. Logo, conhecer, mesmo que de maneira sutil, esses modelos de representação, as suas vantagens e características, se torna importante para fundamentarmos as nossas decisões sobre como vamos salvar os nossos gráficos no R.\nNós temos atualmente, dois modelos principais de representação geométrica que são utilizados para representar imagens, ao longo de toda a indústria da computação gráfica, sendo elas:\n\nVetorial.\nMatricial.\n\nA representação vetorial (Figura 8.3), como o próprio nome dá a entender, busca conectar um conjunto de vetores (ou de linhas) para construir uma forma geométrica presente em sua imagem. Em outras palavras, a representação vetorial funciona como aqueles desenhos infantis de “conecte os pontos”. Nesse sistema, qualquer forma presente em nosso gráfico, seja ela um quadrado, um círculo, uma letra, ou uma garrafa, é formada por um conjunto de linhas que conectam os “vértices” de cada forma.\n\n\n\n\n\n\n\n\nFigura 8.3: Diferenças entre as representações vetorial e matricial\n\n\n\n\n\nPor outro lado, imagens que se encontram em representação matricial (Figura 8.3), são popularmente conhecidas por raster image, ou bitmap image, e utilizam-se de uma malha quadricular (ou de um grid), no qual cada célula é preenchida, a fim de representar cada parte de sua imagem. Uma forma típica de identificarmos esse tipo de representação, está no efeito “escada”, ou no efeito pixelado (ou quadriculado) que adquirimos ao darmos um zoom grande nesse tipo de imagem.\nOs principais devices gráficos disponíveis no R, que utilizam a representação vetorial, são os que constroem arquivos PDF (.pdf) e SVG (.svg). Além desses, temos alguns outros devices menos comuns, como os arquivos encapsulated PostScript (.eps) que são mais utilizados em programas da Adobe, como o PhotoShop. Imagens produzidas através de representações vetoriais, são em geral, mais bem definidas do que imagens produzidas por representações matriciais, e, mesmo que o usuário dê um zoom grande sobre a imagem, elas são capazes de manter essa definição. Logo, como foi destacado por WICKHAM (2016, p. 185), imagens que utilizam uma representação vetorial parecem mais atraentes em um número maior de lugares. Especialmente pelo fato, de que o sistema vetorial consegue representar formas geométricas (principalmente polígonos), de maneira mais precisa, do que o sistema matricial.\nApesar dessa vantagem, não são todos os programas que suportam o uso de imagens provenientes de representações vetoriais (por exemplo, o Word aceita o uso de arquivos SVG, mas não aceita o uso de PDF’s para inserção de imagens). Em contrapartida, arquivos de raster image (ou bitmap image), são aceitos na grande maioria dos programas, e portanto, representam uma forma mais portátil de transportar os seus gráficos ao longo de diversos programas e sistemas. Os devices gráficos mais conhecidos, que usam a representação matricial, são os arquivos PNG (.png), JPEG/JPG (.jpeg) e TIFF (.tiff).\nLogo, ao escolher o device gráfico que irá gerar o seu arquivo de imagem, você deve refletir sobre qual o formato que mais se adequa as suas necessidades. Mesmo que você possa produzir imagens mais fiéis através de uma representação vetorial, isso não se configura na maioria das ocasiões, como uma grande vantagem. Pois, você pode se aproveitar da maior flexibilidade dos devices de representação matricial, e ainda assim, produzir imagens muito bem definidas e de alta resolução. Sobretudo com o uso de um arquivo PNG (.png) ou TIFF (.tiff), que produzem em geral, resultados melhores do que um arquivo JPEG/JPG (.jpeg).\nEm resumo, caso o uso de um arquivo PDF (.pdf), ou SVG (.svg), não represente uma limitação para o seu trabalho, você geralmente vai preferi-los em detrimento de outros devices gráficos. Entretanto, caso você precise de uma maior portabilidade de seu gráfico, você ainda pode atingir ótimos resultados com um device gráfico de representação matricial, como um arquivo PNG (.png) ou TIFF (.tiff). Basta que você utilize uma resolução alta, e aplique um anti-aliasing sobre o arquivo em que você irá salvar o gráfico. Um bom nível de resolução para esses tipos de arquivos, se encontra na casa dos 300 dpi, sendo essa a resolução mínima requisitada pela maioria dos jornais e revistas científicas.\n\n\n8.7.2 A função ggsave()\nA função ggsave() pertence ao pacote ggplot, e representa um atalho útil para o método descrito por MURRELL (2006). Por padrão, essa função vai sempre salvar o último gráfico gerado em sua sessão. Ou seja, para utilizar essa função, você deve primeiro gerar o seu gráfico, ou melhor dizendo, o seu gráfico deve estar aparecendo na área direita e inferior do seu RStudio, na seção de Plots. Pois é a partir do cache dessa seção, que ggsave() irá coletar o seu gráfico, e, portanto, salvá-lo em algum local de seu computador.\nDessa forma, o código necessário para utilizar essa função é semelhante ao código abaixo. Você primeiro gera o gráfico, e, em seguida, executa a função ggsave() para salvá-lo.\n\nggplot(mpg, aes(displ, cty)) + geom_point()\nggsave(\"output.png\")\n\nPor outro lado, se você deseja salvar qualquer outro gráfico que não seja o último gerado em sua sessão, você pode primeiro salvar esse gráfico em um objeto, e, em seguida, fornecer esse objeto ao argumento plot da função, como exposto no exemplo abaixo:\n\ngrafico &lt;- mpg %&gt;% \n  ggplot() +\n  geom_point(aes(displ, cty))\n\nggsave(\"output.pdf\", plot = grafico)\n\nO primeiro argumento (filename) da função ggsave(), corresponde ao nome que você deseja dar ao arquivo onde seu gráfico será salvo. Já no segundo argumento (device), você pode selecionar o device gráfico desejado. Vale ressaltar, que você não precisa definir esse segundo argumento. Pois você pode escolher esse device de forma implícita, através da extensão que você define no nome do arquivo - no primeiro argumento (filename).\nOu seja, se no primeiro argumento, eu colocar o nome do arquivo como output.pdf, devido a extensão .pdf ao final do nome, a função ggsave() vai automaticamente gerar um arquivo PDF para você. Por outro lado, caso o nome do arquivo seja output.png, ggsave() vai construir um arquivo PNG. E assim por diante. Em resumo, todas as extensões abaixo estão disponíveis através da função ggsave(), e em todos os sistemas operacionais:\n\n.eps - encripted PostScript.\n.ps - PostScript.\n.tex - PicTex.\n.pdf - Portable Document Format (PDF).\n.jpeg - Joint Photographic Experts Group (JPEG).\n.tiff - Tag Image File Format (TIFF).\n.png - Portable Network Graphics (PNG).\n.bmp - Bitmap Image File (BMP).\n.svg - Scalable Vector Graphics (SVG).\n\nPor padrão, ggsave() vai sempre salvar o arquivo resultante em seu diretório de trabalho atual do R. Entretanto, se você deseja salvar esse arquivo em um diretório diferente, você pode utilizar o argumento path para selecionar a pasta desejada, ao fornecer um caminho absoluto até ela. Por exemplo, caso eu queira salvar o arquivo em minha pasta de Gráficos, localizada em minha pasta de Pesquisa, eu posso utilizar os seguintes comandos:\n\ngrafico &lt;- mpg %&gt;% \n  ggplot() +\n  geom_point(aes(displ, cty))\n\nggsave(\n  \"output.pdf\", plot = grafico,\n  path = \"C:/Users/Pedro/Pesquisa/Gráficos\"\n)\n\nOutros argumentos a serem utilizados, são os argumentos width, height e dpi, que definem a largura, a altura e a resolução do arquivo resultante, respectivamente. É importante frisar que os argumentos width e height de ggsave(), trabalham por padrão com a unidade de polegadas (inches - in). Como uma dica, você pode primeiro planejar a largura e altura de sua imagem, em pixels, e, em seguida, converter esses pixels para polegadas (1 polegada equivale a 60 pixels), encontrando assim, o valor que você deseja fornecer aos argumentos supracitados.\nEsses argumentos (width e height) são muito importantes, pois eles afetam diretamente a escala (ou o aspect ratio) da imagem. Dito de outra forma, esses argumentos acabam afetando a disposição dos elementos do gráfico, ao longo do espaço da imagem resultante. Logo, o uso desses argumentos envolve encontrar um certo equilíbrio, ou uma relação entre a altura e a largura da imagem, que melhor represente o seu gráfico.\nPor exemplo, o código abaixo vai criar dois arquivos PNG contendo o exato mesmo gráfico, e vão utilizar a mesma resolução de 300 dpi. Porém, a única diferença entre os dois arquivos, se encontra nos valores de altura e largura utilizados em cada imagem.\n\ngrafico &lt;- mpg %&gt;% \n  ggplot() +\n  geom_point(aes(displ, cty))\n\nggsave(\"imagem_grande.png\", plot = grafico,\n       dpi = 300, width = 20, height = 15)\n\nggsave(\"imagem_pequena.png\", plot = grafico,\n       dpi = 300, width = 8, height = 5)\n\nAo comparar os arquivos imagem_grande.png e imagem_pequena.png, você vai perceber que ao aumentarmos a altura e a largura da imagem, o gráfico resultante tende a ser mais “disperso”, e os seus elementos, menores. Essa característica é relevante, pois nós geralmente desejamos evitar um gráfico muito “disperso”, e com elementos muito pequenos.\nIsso se deve à função que um gráfico usualmente cumpre em uma análise. Nós frequentemente utilizamos gráficos, para nos comunicar com o nosso leitor, ao mostrarmos de forma visual, informações que são relevantes e que trazem novas perspectivas e questões sobre uma determinada análise.\nSe essas informações ficam menores e muito “dispersas” ao longo do espaço do nosso gráfico, o nosso leitor tem maior dificuldade de enxergar o padrão geral (ou a informação principal) do nosso gráfico. Não apenas porque a sua visão precisa cobrir um espaço mais amplo da tela, mas também porque as formas geométricas que representam os nossos dados, podem ficar muito pequenas, e com isso, mais difíceis de se identificar.\nPortanto, fique atento a essa relação. Tente evitar valores muito grandes para a largura e altura de seu gráfico, a menos que você compense esses valores com uma resolução muito alta, através do argumento dpi. Vale destacar que, este argumento dpi funciona somente para devices gráficos que utilizam representações matriciais (e.g. PNG, TIFF e JPEG/JPG).\nEm resumo, a resolução de uma imagem representa as dimensões da matriz, ou da malha quadricular que será utilizada para representar a imagem em questão. Resoluções maiores, vão utilizar matrizes de maiores dimensões (ou em outras palavras, uma matriz com maior número de células) para representar o seu gráfico. Como resultado, a imagem resultante será mais precisa, e irá sofrer menos com o efeito “pixelado” produzido por representações matriciais.\nComo exemplo prático, execute o código abaixo, e perceba a grande diferença entre as imagens alta_resolucao.png e baixa_resolucao.png.\n\ngrafico &lt;- mpg %&gt;% \n  ggplot() + \n  geom_point(aes(displ, cty))\n\n\nggsave(\"alta_resolucao.png\", plot = grafico, dpi = 450, width = 9, height = 6)\nggsave(\"baixa_resolucao.png\", plot = grafico, dpi = 72, width = 9, height = 6)\n\n\n\n8.7.3 A forma tradicional de se exportar gráficos no R\nApesar da função ggsave() ser um atalho útil, eu costumo utilizar diretamente as funções do pacote grDevices, sempre que desejo exportar algum gráfico produzido no R. Grande parte dessa preferência, reside no fato de que a função ggsave() não oferece até o momento, suporte para a função cairo_pdf(), que se torna essencial quando desejamos exportar gráficos que utilizam fontes personalizadas ou instaladas em seu sistema. Vale lembrar, que o pacote grDevices já está incluso nos pacotes básicos do R, e, por essa razão, ele é carregado automaticamente em toda sessão do R que você inicia.\nComo é descrito por MURRELL (2006, seç. 1.3), o processo tradicional de exportação de gráficos no R, é bem simples, e envolve três passos diferentes: 1) abrir um arquivo construído por algum device gráfico; 2) gerar o seu gráfico; 3) fechar o arquivo produzido pelo device gráfico.\nPortanto, no primeiro passo, vamos criar um novo arquivo de imagem (vazio) em nosso computador, de acordo com um device gráfico de nossa preferência. Dessa forma, o arquivo fica em aberto, à espera de algum input gráfico a ser armazenado. Em seguida, nós podemos gerar o nosso gráfico. A partir do momento em que abrimos um arquivo de imagem (como fizemos no passo 1), qualquer gráfico gerado no R não será mostrado no painel de Plots do RStudio. Pois esse gráfico é diretamente enviado para esse arquivo que abrimos. Por último, podemos fechar o arquivo que abrimos no primeiro passo, encerrando dessa forma, o processo de exportação.\nPara abrirmos um novo arquivo de imagem em nosso computador, temos as funções disponíveis abaixo. Perceba que a lista de arquivos abaixo, é praticamente idêntica à lista que mostramos na seção anterior. Pois como já destacamos anteriormente, a função ggsave() vai utilizar “por trás dos bastidores”, todas essas funções abaixo (exceto a função svg()12) para construir os seus arquivos de imagem.\n\npostscript() - encripted PostScript e PostScript.\npictex() - PicTex.\npdf() e cairo_pdf() - Portable Document Format (PDF).\njpeg() - Joint Photographic Experts Group (JPEG).\ntiff() - Tag Image File Format (TIFF).\npng() - Portable Network Graphics (PNG).\nbmp() - Bitmap Image File (BMP).\nsvg() - Scalable Vector Graphics (SVG).\n\nIndependente de qual seja o device gráfico, ou a função que você escolher para abrir um arquivo em seu computador, você irá sempre fechar esse arquivo (terceiro passo), por meio da função dev.off(). Dessa forma, o código necessário para gerarmos, por exemplo, um arquivo PNG, através desse método de exportação, é semelhante aos comandos abaixo. De certa forma, neste método de exportação, você utiliza as funções do pacote grDevices de modo que elas “contornem”, ou “envolvam” os comandos que geram o seu gráfico.\n\n# Abra um arquivo de imagem\n# com algum device gráfico\npng(\"output.png\")\n\n# Construa algum gráfico\nggplot(mpg, aes(displ, cty)) + geom_point()\n\n# Feche o arquivo que você criou\n# com dev.off()\ndev.off()\n\nAssim como na função ggsave(), o primeiro argumento (filename ou file) de todas as funções do pacote grDevices, é responsável por definir o nome do arquivo onde o seu gráfico será salvo. Porém, as semelhanças com a função ggsave() acabam por aqui.\nDiferentemente da função ggsave(), você precisa ficar mais atento ao definir as dimensões de sua imagem nas funções do pacote grDevices, pois as unidades utilizadas nos argumentos height e width ao longo dessas funções, variam. Uma boa forma de guardar essas unidades, é categorizar as funções de acordo com a representação geométrica que elas utilizam. As funções que utilizam representações vetoriais (PDF, SVG e EPS) usam a unidade de polegadas (inches), para definir as dimensões de sua imagem. Já as funções que utilizam representações matriciais (PNG, JPEG/JPG, TIFF, BMP) usam a unidade de pixels13.\nUma outra diferença presente nas funções do pacote grDevices, é que o argumento responsável por definir a resolução da imagem, se chama res (abreviação para resolution), ao invés de dpi como ocorre em ggsave(). Mas a unidade utilizada no argumento res, permanece a mesma, em relação ao argumento dpi.\n\n8.7.3.1 Arquivos PNG, JPEG/JPG, TIFF e BMP\nPara os exemplos dessa seção, vou utilizar a função png(), com o objetivo de expor um “formato padrão” para configurar esse conjunto de funções, que se referem a devices gráficos de representação matricial. Ou seja, você pode replicar normalmente os argumentos da função png(), para as demais funções desse conjunto (que funcionam de maneira idêntica), basta trocar a função png() por uma dessas funções: jpeg(), tiff() e bmp().\nEm todas as ocasiões que você utilizar uma dessas funções, você possui ao menos 5 argumentos que você provavelmente irá definir. O primeiro argumento (file ou filename) de todas essas funções, é onde você irá definir o nome do arquivo, em que você está salvando o seu gráfico. Além dele, temos também os dois argumentos que definem a largura (width) e a altura (height) do arquivo resultante (lembre-se que esses argumentos trabalham com a unidade de pixels). Em seguida, temos o argumento res, que é responsável por definir a resolução do arquivo de imagem. Por último, mas não menos importante, temos o argumento type, que é responsável por definir se o R irá utilizar o device gráfico nativo do sistema, ou a engine do Cairo Graphics para construir a sua imagem.\nTendo esses argumentos em mente, temos logo abaixo um código modelo, sobre como poderíamos configurar essa função. Ao utilizar esses devices gráficos, é sempre uma boa ideia configurar o argumento type para \"cairo\". Pois com isso, a imagem gerada vai incluir o recurso de anti-alising, o qual é sempre bem vindo.\n\npng(\n  filename = \"um_nome_qualquer.png\", \n  width = 2800,\n  height = 1800,\n  res = 300,\n  type = \"cairo\"\n)\n\nggplot(mpg, aes(displ, cty)) + geom_point()\n\ndev.off()\n\nLembre-se que, ao configurar a altura e largura de sua imagem, você enfrenta efeitos semelhantes aos que discutimos na função ggsave(). Isto é, quando você utiliza valores muito altos para esses argumentos, você deve compensar os seus efeitos ao aumentar a resolução de sua imagem (através do argumento res). Caso contrário, você terá um gráfico com elementos muito pequenos e dispersos entre si.\n\n\n8.7.3.2 Arquivos PDF e SVG\nNessa seção, vamos discutir três funções utilizadas para construirmos dois tipos de arquivos de imagem, que utilizam representações vetoriais, mais especificamente PDF (pdf() e cairo_pdf()) e SVG (svg()).\nVocê pode configurar as funções pdf(), cairo_pdf() e svg(), de maneira muito parecida com a função ggsave(). Temos três argumentos principais a serem tratados nessas funções. O argumento file, para dar um nome ao arquivo que você está criando. E os argumentos height e width para definir a altura e a largura da imagem. Lembre-se que para as funções de drives gráficos que utilizam representação vetorial, as dimensões da imagem são definidas em polegadas (inches), e não em pixels. Abaixo temos um exemplo de uso dessas funções.\n\npdf(\"output.pdf\", width = 8, height = 5)\nggplot(mpg) + geom_point(aes(x = displ, y = hwy))\ndev.off()\n\ncairo_pdf(\"output.pdf\", width = 8, height = 5)\nggplot(mpg) + geom_point(aes(x = displ, y = hwy))\ndev.off()\n\nsvg(\"output.svg\", width = 8, height = 5)\nggplot(mpg) + geom_point(aes(x = displ, y = hwy))\ndev.off()\n\nCuriosamente, se você está exportando um arquivo PDF, você pode salvar múltiplos gráficos em um mesmo arquivo, de modo que cada gráfico terá a sua própria página CHANG (2012, p. 324). Para fazer isso, nenhuma nova configuração é necessária sobre a função pdf(). Logo, independentemente de quantos gráficos você esteja planejando guardar nesse arquivo, você não precisa alterar nenhum argumento, em relação aos comandos anteriores. Tudo o que você precisa fazer, é abrir um novo arquivo com a função, e criar quantos gráficos você desejar antes de fechar o arquivo.\n\npdf(\"output.pdf\", width = 8, height = 5)\n\n# Gráfico 1\nggplot(mpg) + geom_point(aes(x = displ, y = hwy))\n# Gráfico 2\nggplot(mpg) + geom_bar(aes(x = cyl))\n# Gráfico 3\nggplot(mpg) + geom_histogram(aes(x = hwy), color = \"black\")\n\ndev.off()\n\nPorém, para atingir esse mesmo resultado com a função cairo_pdf(), você precisa ainda adicionar um novo argumento, chamado onefile. Tudo o que você deve fazer, é configurar esse argumento para verdadeiro (TRUE), como no exemplo abaixo. Dessa forma, todos os gráficos gerados por você, serão guardados em um mesmo arquivo.\n\ncairo_pdf(\"output.pdf\", width = 8, height = 5, onefile = TRUE)\n\n# Gráfico 1\nggplot(mpg) + geom_point(aes(x = displ, y = hwy))\n# Gráfico 2\nggplot(mpg) + geom_bar(aes(x = cyl))\n# Gráfico 3\nggplot(mpg) + geom_histogram(aes(x = hwy), color = \"black\")\n\ndev.off()\n\nComo o próprio nome da função cairo_pdf() dá a entender, essa função utiliza a engine gráfica do Cairo Graphics para construir o seu arquivo PDF. Em resumo, você só vai precisar da função cairo_pdf(), caso você tenha utilizado em seu gráfico, fontes personalizadas, ou que estão instaladas em seu sistema. Vamos discutir em mais detalhes esse assunto no próximo capítulo.\n\n\n\n8.7.4 Pontos importantes sobre anti-alising\nInfelizmente, os usuários do Windows enfrentam alguns problemas quanto ao uso de devices gráficos. Nessa seção, vamos abordar um desses problemas, que se trata do uso de anti-alising. Por padrão, o R vai sempre utilizar o device gráfico nativo do sistema, e, como foi pontuado por CHASE (2019), esse device padrão não é muito bom no Windows. Uma de suas principais fraquezas, é que ele não possui um mecanismo próprio de anti-aliasing.\nO anti-aliasing é um método de suavização de imagens produzidas por representações matriciais, onde o computador tenta preencher certas áreas ao redor dos limites de cada forma geométrica representada na imagem, de modo que os contornos fiquem mais suaves e precisos, eliminando grande parte do efeito pixelado (ou quadriculado) presente em imagens desse tipo.\nUm grande exemplo de uso desse recurso se encontra nos videogames, que quase sempre possuem uma opção de anti-alising em suas configurações gráficas, que lhe permite aplicar esse recurso sobre o gráfico do game. Para além desse exemplo, é sempre uma boa ideia utilizar esse recurso em todo tipo de gráfico que você produz, pois as suas imagens ficam mais bem definidas e, os seus gráficos, mais agradáveis de se observar.\nPortanto, se você trabalha no Windows, todas as imagens (produzidas por devices gráficos que usam representação matricial) que você exportar no R, não vão incluir, por padrão, o uso de um anti-aliasing. Apesar desse problema, os usuários de Windows possuem, hoje, duas soluções simples para esse problema.\nA primeira é descrita por CHASE (2019), que conciste em utilizar as engines gráficas produzidas por Cairo Graphics, que estão normalmente disponíveis em todo sistema Windows e oferecem, por padrão, um recurso de anti-aliasing. Já a segunda solução, conciste em utilizar os devices gráficos disponíveis no pacote ragg, que também incluem esse recurso.\nPara utilizar a primeira solução, você precisa apenas configurar o argumento type para \"cairo\" nas funções do pacote grDevices. Desse modo, o R vai utilizar as engines gráficas do Cairo para produzir o seu arquivo e, consequentemente, o anti-alising será aplicado:\n\npng(\n  \"output.png\", width = 2200, height = 1500,\n  res = 300, type = \"cairo\"\n)\n\nggplot(mpg) + geom_point(aes(hwy, displ))\n\ndev.off()\n\nPor outro lado, as versões mais recentes da função ggsave() vão sempre tentar utilizar os devices gráficos disponíveis no pacote ragg. Portanto, se esse pacote estiver instalado em sua máquina, ao utilizar a função ggsave(), você provavelmente não terá nenhuma dificuldade a mais para aplicar um anti-alising sobre as suas imagens.\n\nggplot(mpg, aes(displ, cty)) + geom_point()\n\n# ggsave() vai automaticamente procurar pelo\n# pacote ragg em sua máquina, caso ele encontre\n# esse pacote, ele vai automaticamente utilizar\n# os devices disponíveis nesse pacote.\nggsave(filename = \"output.png\", width = 7, height = 5)\n\nAlém disso, você também tem a opção de utilizar diretamente as funções do pacote ragg, caso você queira garantir que você está utilizando o device gráfico correto.\n\nragg::agg_png(\n  \"output.png\", width = 2200, height = 1500,\n  res = 300\n)\n\nggplot(mpg) + geom_point(aes(hwy, displ))\n\ndev.off()\n\n\n\n\n\nCHANG, W. R Graphics Cookbook. Sebastopol, CA: O’Reilly Media, Inc., 2012.\n\n\nCHASE, W. Custom fonts and plot quality with ggplot on Windows, 2019. Disponível em: &lt;https://www.williamrchase.com/post/custom-fonts-and-plot-quality-with-ggplot-on-windows/&gt;\n\n\nHUGHES, J. F. et al. Computer Graphics: Principles and Practice. 3. ed. [s.l.] Addison-Wesley, 2014.\n\n\nMURRELL, P. R Graphics. 1. ed. Boca Raton, FL: Chapman & Hall - CRC Press, 2006.\n\n\nWICKHAM, H. ggplot2: Elegant Graphics for Data Analysis. 2. ed. [s.l.] Springer International Publishing, 2016.\n\n\nWILKINSON, L. The Grammar of Graphics. 2. ed. Verlag, NY: Springer, 2005.",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Visualização de dados com `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/08-ggplot.html#footnotes",
    "href": "Capítulos/08-ggplot.html#footnotes",
    "title": "8  Visualização de dados com ggplot2",
    "section": "",
    "text": "Ou seja, em relação a seus concorrentes, o ggplot não é necessariamente o pacote que oferece praticidade, mas sim, um leque de possibilidades muito maior em relação a seus concorrentes.↩︎\nhttps://rstudio.github.io/cheatsheets/data-visualization.pdf↩︎\nhttps://ggplot2.tidyverse.org/reference/index.html↩︎\nhttps://www.r-graph-gallery.com/↩︎\nhttp://www.ipeadata.gov.br/Default.aspx↩︎\nhttps://ggplot2.tidyverse.org/reference/index.html↩︎\nhttps://www.curso-r.com/material/ggplot/↩︎\nhttp://www.leg.ufpr.br/~walmes/cursoR/data-vis/index.html↩︎\nhttps://pt.stackoverflow.com/↩︎\nhttps://www.r-graph-gallery.com/↩︎\nVeja a página oficial do pacote: https://cran.r-project.org/web/packages/ggridges/vignettes/introduction.html↩︎\nNo caso de arquivos do tipo SVG, a função ggsave() utiliza a função svglite(), que vem do pacote svglite.↩︎\nLembre-se que 1 polegada equivale a 60 pixels.↩︎",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Visualização de dados com `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/09-theme-ggplot.html",
    "href": "Capítulos/09-theme-ggplot.html",
    "title": "9  Configurando componentes estéticos do gráfico no ggplot2",
    "section": "",
    "text": "9.1 Introdução e pré-requisitos\nNo primeiro capítulo sobre o ggplot, vimos quatro das várias camadas que compõe um gráfico estatístico segundo a abordagem de WILKINSON (2005). Mais especificamente, vimos as três camadas essenciais que estão presentes em qualquer gráfico: os dados utilizados (data), o mapeamento (aesthetic mapping) de variáveis de sua tabela para atributos estéticos do gráfico, e as formas geométricas (geom’s) que representam os seus dados no gráfico. Além dessas camadas essenciais, também explicamos como você pode criar diferentes facetas de um mesmo gráfico.\nNeste capítulo, estaremos focando nas outras camadas, mais especificamente, aquelas que controlam aspectos visuais e estéticos do gráfico. Estaremos utilizando novamente neste capítulo, o mesmo gráfico (plot_exemplo) como base para os nossos exemplos.\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Configurando componentes estéticos do gráfico no `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/09-theme-ggplot.html#tema-theme-do-gráfico",
    "href": "Capítulos/09-theme-ggplot.html#tema-theme-do-gráfico",
    "title": "9  Configurando componentes estéticos do gráfico no ggplot2",
    "section": "9.2 Tema (theme) do gráfico",
    "text": "9.2 Tema (theme) do gráfico\nO tema do gráfico, diz respeito a todos os elementos e configurações estéticos que não afetam, ou que não estão conectadas aos dados dispostos no gráfico. Ou seja, os temas não alteram as propriedades perceptíveis do gráfico, mas ajuda você a torná-lo esteticamente agradável (WICKHAM, 2016, p. 169). Em outras palavras, o tema lhe dá controle sobre as fontes utilizadas, o alinhamento do texto, a grossura do grid e das marcações, a cor do plano de fundo do gráfico, etc.\nTodos os aspectos temáticos do gráfico são configurados pela função theme(), que possui vários argumentos. Cada argumento dessa função, lhe permite configurar um elemento de seu gráfico. Onde cada um destes elementos, são associados a um tipo de elemento diferente. Por exemplo, o título do gráfico, é um texto, logo, ele é associado ao elemento do tipo texto - element_text(), já as retas dos eixos são associadas ao elemento do tipo linha - element_line().\nOs tipos de elemento são apenas uma convenção, para que você saiba qual função element_*() é a apropriada para configurar o elemento desejado. Por exemplo, se o título do gráfico, é um elemento associado ao tipo “texto”, você deve usar a função element_text() para modificar este elemento. Porém, se você quer configurar o background do gráfico, você deve utilizar a função element_rect(), pois este elemento está associado ao tipo “retângulo”. Os diversos tipos de elemento são:\n\nTexto: element_text().\nRetângulo: element_rect().\nLinha: element_line().\nBranco ou vazio: element_blank().\n\nVocê provavelmente está se perguntando o porquê da existência de um tipo de elemento “vazio”. O jornalista americano William Chase, apresentou um ditado na última conferência internacional do RStudio, que representa bem o papel que este tipo de elemento tem a cumprir no ggplot. O ditado diz o seguinte:\n\n“O espaço em branco no gráfico é como o alho que tempera a sua comida. Pegue o tanto que você acha necessário, e então triplique essa quantidade”. William Chase, The Glamour of Graphics, rstudio::conf, 2020.\n\nA noção de espaço, é muito importante no seu gráfico, seja porque você tem itens que estão tomando muito espaço das formas geométricas que estão representando os seus dados no gráfico, ou então, porque você quer tornar a visão de seu gráfico mais leve (ou mais “dispersa”) para o leitor. Por isso, o elemento do tipo “vazio” serve para eliminar elementos que são desnecessários em seu gráfico, dando assim, maior espaço para aqueles elementos que são de fato importantes.\nAo longo dessa seção, estarei utilizando um mesmo gráfico, para exemplificar algumas das principais configurações possíveis em theme(). Para não repetir o código que gera o gráfico, toda vez que alterarmos algo nele, eu vou guardar este gráfico em um objeto que dou o nome de plot_exemplo. Dessa forma, toda vez que quiser alterar algum elemento do gráfico, basta que eu adicione a função theme() a este objeto, onde o gráfico está guardado.\n\nplot_exemplo &lt;- ggplot(data = penguins) +\n  geom_point(\n    aes(\n      x = flipper_length_mm,\n      y = body_mass_g,\n      color = species\n    )\n  ) +\n  labs(\n    title = \"Relação entre peso e comprimento da nadadeira \n    em diferentes\\nespécies de pinguim\",\n    x = \"Comprimento da nadadeira\",\n    y = \"Peso corporal\",\n    color = \"Espécie\"\n  )\n\nprint(plot_exemplo)",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Configurando componentes estéticos do gráfico no `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/09-theme-ggplot.html#eliminando-elementos-do-gráfico",
    "href": "Capítulos/09-theme-ggplot.html#eliminando-elementos-do-gráfico",
    "title": "9  Configurando componentes estéticos do gráfico no ggplot2",
    "section": "9.3 Eliminando elementos do gráfico",
    "text": "9.3 Eliminando elementos do gráfico\nComo eu disse, você muitas vezes vai querer eliminar elementos desnecessários e que estão tomando muito espaço de seu gráfico. Para esta tarefa, basta utilizar element_blank() sobre o argumento de theme() que controla este elemento em questão. No exemplo abaixo, estou eliminando o título da legenda, que é controlada por legend.title, e também estou eliminando o título do eixo y com axis.title.y.\n\nplot_exemplo +\n  theme(\n    legend.title = element_blank(),\n    axis.title.y = element_blank()\n  )",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Configurando componentes estéticos do gráfico no `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/09-theme-ggplot.html#alterando-a-temática-de-textos",
    "href": "Capítulos/09-theme-ggplot.html#alterando-a-temática-de-textos",
    "title": "9  Configurando componentes estéticos do gráfico no ggplot2",
    "section": "9.4 Alterando a temática de textos",
    "text": "9.4 Alterando a temática de textos\nVocê possui diversos elementos textuais em seu gráfico, logo abaixo, na Figura 9.1, estou relacionando cada elemento textual ao seu respectivo argumento em theme(). Vale ressaltar, que há outros elementos textuais, como o subtítulo do gráfico, que não está presente em nosso plot_exemplo. Portanto, até os próprios valores do eixo são tratados como textos do gráfico. Como mencionei antes, você precisa da função element_text() para configurar este tipo de elemento.\n\n\n\n\n\n\n\n\nFigura 9.1: Principais elementos textuais do gráfico e seus respectivos argumentos na função theme()\n\n\n\n\n\nVamos pensar primeiro no título, que é uma parte importante de seu gráfico e que deve possuir algum tipo de destaque. Por enquanto, o único fator que destaca o título do gráfico dos outros elementos textuais, é o tamanho da fonte usada. Porém, e se quiséssemos adicionar outros fatores de destaque? Como por exemplo, utilizar uma fonte em itálico, ou em negrito.\nO argumento de theme() responsável por controlar o título do gráfico, é o plot.title, e portanto, utilizo a função element_text() sobre este argumento, para acrescentarmos novos destaques a este título. O argumento de element_text() que afeta o estilo da fonte (negrito, itálico, etc.) é o face. No exemplo abaixo, eu dou o valor \"italic\" indicando a função que use o estilo itálico sobre o título:\nEu posso também destacar outras áreas do gráfico, como o título da legenda, que é controlado pelo argumento legend.title. Eu costumo reduzir o tamanho deste título, e colocá-lo em negrito, e para isso, utilizo os argumentos size e face. Para colocar algum texto em negrito, você deve utilizar o valor \"bold\", em face. Eu poderia inclusive, colocar este texto em itálico e negrito (para isso, você deve utilizar o valor \"bold.italic\").\nVale também destacar, que o argumento size, trabalha por padrão com a unidade milímetros (mm). Porém, como é um pouco contraintuitivo trabalhar com tamanho de fontes nesta unidade, eu costumo transformá-la para pontos (pt). Para isso, o ggplot oferece uma variável (.pt) que já contém o valor necessário para essa transformação. Assim, o que você precisa fazer é colocar o valor em pontos (pt) desejado, e dividi-lo por essa variável (.pt), que contém o valor necessário para a conversão. No exemplo abaixo, estou reduzindo o título da legenda ao tamanho 26 pt.\n# Gráfico à esquerda\nplot_exemplo +\n  theme(\n    plot.title = element_text(face = \"italic\")\n  )\n# Gráfico à direita\nplot_exemplo +\n  theme(\n    plot.title = element_text(face = \"italic\"),\n    legend.title = element_text(face = \"bold\", size = 26/.pt)\n  )\n\n\n\n\n\n\n\n\n\n\nAlém destas modificações, você talvez queira mudar o alinhamento do título do gráfico. Atualmente, você pode reparar que este título está alinhado à esquerda do gráfico, ou em outras palavras, está alinhado em relação a borda esquerda do gráfico.\nNeste caso, estou me referindo ao alinhamento horizontal do título, e por isso, utilizo o argumento hjust. Este argumento funciona da mesma forma em que o vimos anteriormente, ele pega um número de 0 a 1. Sendo que o valor 0 representa o alinhamento totalmente à esquerda, o valor 0.5 centraliza o texto, e o valor 1 representa o alinhamento totalmente à direita. No exemplo abaixo, estou centralizando o título do gráfico (gráfico à esquerda)\nUm outro ponto, que talvez seja de seu interesse, é alterar o espaço entre os elementos do gráfico. Você pode controlar este fator, através da função margin(), sobre o argumento margin de element_text(). Dentro da função margin(), temos 4 argumentos que se referem as bordas do seu texto. Dito de outra forma, esses argumentos definem a borda do texto, na qual você deseja acrescentar o espaço: t (top) se refere ao topo do texto; r (right) se refere à direita do texto; l (left) se refere à esquerda do texto; e b (bottom) se refere à base (ou a borda inferior) do texto.\nPor exemplo, podemos dar mais destaque ao título do gráfico, ao adicionar um pouco mais de espaço entre ele e a borda do gráfico. Neste caso, o gráfico está abaixo do título, logo, estamos querendo adicionar espaço na borda inferior (argumento b) do título do gráfico. Em seguida, basta que eu defina no argumento, quanto de espaço eu desejo adicionar (gráfico à direita).\n# Gráfico à esquerda \nplot_exemplo +\n  theme(\n    plot.title = element_text(face = \"italic\", hjust = 0.5),\n    legend.title = element_text(face = \"bold\", size = 26/.pt)\n  )\n# Gráfico à direita\nplot_exemplo +\n  theme(\n    plot.title = element_text(\n      face = \"italic\",\n      hjust = 0.5,\n      margin = margin(b = 20)\n    ),\n    legend.title = element_text(face = \"bold\", size = 26/.pt)\n  )",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Configurando componentes estéticos do gráfico no `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/09-theme-ggplot.html#plano-de-fundo-background-e-grid",
    "href": "Capítulos/09-theme-ggplot.html#plano-de-fundo-background-e-grid",
    "title": "9  Configurando componentes estéticos do gráfico no ggplot2",
    "section": "9.5 Plano de fundo (background) e grid",
    "text": "9.5 Plano de fundo (background) e grid\nO tema padrão do ggplot pode ser muito esquisito, ou simplesmente “feio” para muita gente. Um de seus elementos que mais recebem críticas, é o plano de fundo do gráfico, que por padrão é colorido de cinza claro. Todos os argumentos de theme(), que controlam os elementos que se encontram no plano de fundo, começam por panel.*. Você pode, por exemplo, alterar as configurações gerais do plano de fundo pelo argumento panel.background, que é associado ao tipo “retângulo” - element_rect().\nNo exemplo abaixo, estou alterando a cor deste plano de fundo, para uma cor levemente “amarelada”. Lembra quando eu defini que o ggplot trata de forma distinta as formas geométricas de área, onde se você quisesse preencher esta forma com uma cor, você deveria utilizar o argumento fill, ao invés de color? Aqui a mesma coisa ocorre, pois o plano de fundo do gráfico é associado a um formato de área (retângulo).\nPor isso, se utilizar o color, você irá colorir apenas as bordas do gráfico, e não preencher o plano de fundo com uma cor. Em ambos argumentos, você pode fornecer um dos nomes de cor que o R consegue reconhecer (por exemplo, \"white\", \"black\")1, ou então, você pode fornecer um código HTML dessa cor.\nSe antes você não gostava do cinza, você provavelmente está gostando menos ainda dessa cor amarelada. Bem, neste caso podemos ficar então mudar para um branco padrão. Vale destacar que, as linhas do grid já estão na cor branca, por isso, podemos colorir também essas linhas para uma cor diferente, de modo a mantê-las visíveis.\n# Gráfico à esquerda\nplot_exemplo +\n  theme(\n    panel.background = element_rect(fill = \"#fffab3\")\n  )\n# Gráfico à direita\nplot_exemplo +\n  theme(\n    panel.background = element_rect(fill = \"white\"),\n    panel.grid = element_line(color = \"#d4d4d4\")\n  )\n\n\n\n\n\n\n\n\n\n\nApesar do gráfico estar agora em um tema mais “padrão”, você talvez você ache estranho a forma como as linhas do grid estão no momento. Pois elas estão sem um “limite”, ou aparentam estar “invadindo” o espaço de outros elementos do gráfico. Talvez o que você precise, seja marcar a borda do gráfico, para construir uma caixa, e definir estes limites do grid. Tudo que você precisa fazer, é usar o color em panel.background, para colorir essas bordas.\nUm outro componente que faz parte do gráfico, é o plano de fundo de toda a área do gráfico. Ou seja, toda a área de sua tela que engloba os títulos, os valores, as legendas e o espaço do gráfico. Essa área é controlada pelo argumento plot.background. Não sei por que você faria isso, mas com esse argumento, você pode por exemplo, pintar toda a área do gráfico de azul claro.\n# Gráfico à esquerda\nplot_exemplo +\n  theme(\n    panel.background = element_rect(\n      fill = \"white\",\n      color = \"#222222\"\n    ),\n    panel.grid = element_line(color = \"#d4d4d4\")\n  )\n# Gráfico à direita\nplot_exemplo +\n  theme(\n    panel.background = element_rect(\n      fill = \"white\",\n      color = \"#222222\"\n    ),\n    panel.grid = element_line(color = \"#d4d4d4\"),\n    plot.background = element_rect(fill = \"#abb3ff\")\n  )",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Configurando componentes estéticos do gráfico no `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/09-theme-ggplot.html#eixos-do-gráfico",
    "href": "Capítulos/09-theme-ggplot.html#eixos-do-gráfico",
    "title": "9  Configurando componentes estéticos do gráfico no ggplot2",
    "section": "9.6 Eixos do gráfico",
    "text": "9.6 Eixos do gráfico\nTodos os elementos que se encontram nos eixos do gráfico, são controlados pelos argumentos de theme() que se iniciam por axis.*. Você pode ver os argumentos que controlam cada um dos componentes do eixo, pela Figura 9.2.\nNo tema padrão do ggplot, a linha do eixo (axis.line) já não aparece. Portanto, se você quiser eliminar completamente um eixo do seu gráfico, você precisa apagar apenas os outros três componentes. Sendo este, um outro motivo de estranhamento de várias pessoas sobre o tema padrão do ggplot. Por isso, talvez seja interessante para você incluir no seu gráfico, as linhas do eixo, e para esse fim, basta redefinir o seu argumento (axis.line) com element_line().\nUm detalhe muito importante, é que a função theme() possui tanto o argumento geral do componente do eixo (e.g. axis.line), que afeta ambos os eixos (x e y) ao mesmo tempo, quanto o argumento que afeta os eixos individualmente (e.g. axis.line.x e axis.line.y). Isso vale para todos os outros três componentes do eixo, e, portanto, caso você queira que a modificação afete apenas um dos eixos, você deve utilizar os argumentos que possuem o eixo no nome, ao invés dos argumentos gerais.\n\n\n\n\n\n\n\n\nFigura 9.2: Elementos que compõe um eixo do gráfico\n\n\n\n\n\nUma configuração que aplico com bastante frequência em meus gráficos, é escurecer os valores do eixo (axis.text). Por padrão, os valores vem em um cinza claro, e por causa disso, a leitura desses valores pode ficar muito prejudicada ao exportar esse gráfico, e incluí-lo em um artigo, informativo ou relatório que estou escrevendo. Desse modo, no exemplo abaixo, além de reposicionar as linhas dos eixos, eu também utilizo o argumento color em axis.text, para colorir esses valores com uma cor mais escura.\nAlém dessas modificações, para garantir que o meu leitor consiga ler esses números, eu ainda aumento levemente o tamanho dos valores do eixo, pelo argumento size. Como eu disse anteriormente, esse argumento trabalha, por padrão, com milímetros. Você pode novamente utilizar a variável .pt para transformar esse valor para pontos (pt).\n\nplot_exemplo +\n  theme(\n    axis.line = element_line(linewidth = 0.8, color = \"#222222\"),\n    axis.text = element_text(size = 11, color = \"#222222\")\n  )",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Configurando componentes estéticos do gráfico no `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/09-theme-ggplot.html#configurações-temáticas-em-uma-legenda",
    "href": "Capítulos/09-theme-ggplot.html#configurações-temáticas-em-uma-legenda",
    "title": "9  Configurando componentes estéticos do gráfico no ggplot2",
    "section": "9.7 Configurações temáticas em uma legenda",
    "text": "9.7 Configurações temáticas em uma legenda\nA legenda de seu gráfico, é um guia que lhe mostra como os elementos visuais percebidos em seu gráfico, se traduzem de volta aos valores observados em sua base de dados. Em outras palavras, é a legenda que mapeia as cores, formas e tamanhos dos elementos de seu gráfico, de volta aos valores apresentados em sua base de dados WILKINSON (2005), WICKHAM (2016). Sem a legenda, nós não sabemos qual o valor que a cor vermelha em nosso gráfico se refere, nem quanto o tamanho de um objeto, representa em nível de uma variável numérica.\n\n\n\n\n\n\n\n\nFigura 9.3: Itens que compõe uma legenda\n\n\n\n\n\nTemos na Figura 9.3, os componentes de uma legenda em um gráfico do ggplot, e os seus respectivos argumentos em theme(). Há outros argumentos relacionados em theme(), como legend.text.align, legend.margin e legend.position, que não afetam a temática de algum componente específico da legenda, mas sim, o alinhamento de certos componentes, ou a margem da legenda em relação ao gráfico, ou a posição geral da legenda.\nComo exemplo, podemos preencher o plano de fundo da legenda com alguma cor específica em legend.background (argumento fill), assim como podemos contornar as bordas dessa legenda com alguma outra cor (argumento color). Podemos alterar o alinhamento do texto da legenda, ou mais especificamente, os rótulos de cada item da legenda, através de legend.text.align, ao fornecermos um número entre 0 (alinhado totalmente à esquerda) e 1 (alinhado totalmente à direita). Também podemos utilizar a função element_text() em legend.title, para alterarmos a fonte (argumento family), o tamanho (argumento size) o estilo da fonte (argumento face: bold - negrito, italic - itálico, bold.italic - negrito e itálico), e inclusive a cor (argumento color) utilizada no título dessa legenda.\nAlém dessas configurações, possuímos um bom controle sobre a posição da legenda ao longo da área do gráfico, através do argumento legend.position. Por padrão, toda legenda gerada pelo ggplot, será posicionada à direita do gráfico, entretanto, esse padrão tende a ocupar muito espaço do gráfico, por isso eu particularmente prefiro posicionar as minhas legendas, na parte inferior do gráfico. Para isso podemos fornecer o valor bottom ao argumento. O argumento legend.position, aceita outros quatro valores pré-definidos: top (topo do gráfico); left (esquerda do gráfico); right (direita do gráfico); none (nenhum local do gráfico).\nVocê pode utilizar o valor pré-definido none em legend.position, para eliminar completamente a legenda do gráfico. Isso é uma boa forma de aumentar o espaço do gráfico, porém, você elimina uma fonte importante de informação, portanto, considere com cuidado se as informações dispostas em sua legenda, são irrelevantes para o seu gráfico. Para além das posições pré-definidas, podemos inclusive posicionar a nossa legenda, para dentro do gráfico, através de legend.position. Para isso, você precisa fornecer dentro de um vetor, a posição (x, y) no plano cartesiano em que você deseja centralizar a sua legenda, de acordo com um valor entre 0 e 1. Você pode interpretar esse sistema, como percentis da distribuição dos valores presentes no eixo. Ou seja, se você fornecer o vetor c(0.1, 0.9), a legenda será posicionada no 10° percentil da escala do eixo x, e no 90° percentil da escala do eixo y.\n# Gráfico à esquerda\nplot_exemplo + theme(\n  legend.background = element_rect(fill = \"#cffff0\", color = \"black\"),\n  legend.text.align = 0.5,\n  legend.title = element_text(face = \"bold\", color = \"#008059\"),\n)\n# Gráfico à direita\nplot_exemplo + theme(\n  legend.position = \"bottom\"\n)\n\n\n\n\n\n\n\n\n\n\n# Gráfico à esquerda\nplot_exemplo + theme(\n  legend.position = \"none\"\n)\n# Gráfico à direita\nplot_exemplo + theme(\n    legend.position = c(0.1, 0.8)\n)\n\n\n\n\n\n\n\n\n\n\nPara mais, temos algumas outras configurações possíveis sobre a margem da legenda em relação à área gráfico, através do argumento legend.margin e da função margin(). Ou seja, nós podemos afastar a legenda da área do gráfico, ou da base do gráfico. Em outras palavras, nós podemos adicionar espaço na base (b), no topo (t), à direita (r), ou à esquerda (l) da legenda, através da função margin().\nPor último, nós também podemos configurar os itens da legenda, através do argumento legend.key. Neste argumento, você possui todas as opções de customização oferecidas pela função element_rect(). Além de preencher o plano de fundo dos itens (argumento fill), ou de criar uma borda (argumento color), também temos a opção de alterar o tamanho desses itens (argumento size).\n# Gráfico à esquerda \nplot_exemplo + theme(\n  legend.margin = margin(l = 90, b = 70)\n)\n# Gráfico à direita\nplot_exemplo + theme(\n  legend.key = element_rect(fill = \"#c4e2ff\", color = \"black\")\n)",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Configurando componentes estéticos do gráfico no `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/09-theme-ggplot.html#alterando-a-temática-em-facetas",
    "href": "Capítulos/09-theme-ggplot.html#alterando-a-temática-em-facetas",
    "title": "9  Configurando componentes estéticos do gráfico no ggplot2",
    "section": "9.8 Alterando a temática em facetas",
    "text": "9.8 Alterando a temática em facetas\nQuando você adiciona facetas a um gráfico, você possui novos elementos que talvez sejam de seu interesse configurá-los. Por exemplo, o título de cada faceta, ou o plano de fundo desse título. Todos os argumentos de theme() que controlam elementos das facetas do gráfico, começam por strip.*. No exemplo abaixo, eu estou redefinindo as cores do interior e das bordas do plano de fundo da faceta, além da cor do título da faceta.\n\nplot_exemplo +\n  facet_wrap(~island, nrow = 3) +\n  theme(\n    strip.background = element_rect(color = \"#222222\", fill = \"#d1fff4\"),\n    strip.text = element_text(color = \"black\")\n  )",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Configurando componentes estéticos do gráfico no `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/09-theme-ggplot.html#alterando-as-fontes-do-seu-gráfico",
    "href": "Capítulos/09-theme-ggplot.html#alterando-as-fontes-do-seu-gráfico",
    "title": "9  Configurando componentes estéticos do gráfico no ggplot2",
    "section": "9.9 Alterando as fontes do seu gráfico",
    "text": "9.9 Alterando as fontes do seu gráfico\nEste é provavelmente o tópico de maior interesse para você ao customizar os seus gráficos, pois a tipografia traz, em geral, um grande impacto sobre o visual de uma imagem. A não muito tempo atrás, incluir diferentes fontes de seu sistema (ou fontes customizadas) em seus gráficos, era uma tarefa árdua e que podia gerar uma grande dor de cabeça.\nEssa dificuldade ocorre em qualquer programa2, linguagem ou sistema que trabalha com diversos device’s gráficos, como é o caso do R.\nPorém, tal situação mudou nos anos mais recentes. Hoje, incluir diferentes fontes em seus gráficos não é mais uma dor de cabeça tão grande, graças às melhorias feitas pelo time interno do R (The R Core Team) além de toda a comunidade internacional de R, que tem contribuído com pacotes como ragg e showtext.\nAntes de explicarmos quais são as soluções necessárias para que você possa utilizar qualquer fonte que esteja em sua máquina, em seus gráficos do ggplot, vou mostrar quais são as três opções de fonte, que são garantidas de funcionar no ggplot em qualquer máquina. Essas três opções são:\n\nsans: Fonte Arial.\nserif: Fonte Times New Roman.\nmono: Fonte Courier New.\n\nPortanto, em qualquer máquina que você estiver, você pode utilizar um desses três nomes (sans, serif e mono) para se referir a uma dessas três fontes acima, em seu gráfico do ggplot.\nNeste momento, vale a pena refletir se você deseja variar as fontes utilizadas ao longo do gráfico, ou se você deseja utilizar sempre a mesma fonte em todos os textos dispostos no gráfico. Caso você queira variar a fonte, você deve criar uma nova coluna em sua tabela, contendo o nome da fonte que você deseja utilizar para cada observação. Em seguida, você deve conectar essa variável ao argumento family, dentro de aes(). Contudo, se você quer manter essa fonte fixa, basta fornecer o nome dessa fonte ao argumento family, porém, dessa vez, fora da função aes().\nset.seed(1)\ntab &lt;- data.frame(\n  x = rnorm(100),\n  y = runif(100),\n  fonte = sample(\n    c(\"sans\", \"serif\", \"mono\"),\n    size = 100,\n    replace = TRUE\n  )\n)\n\n# Variar a fonte utilizada ao longo do gráfico\nggplot(tab) +\n  geom_text(\n    aes(x = x, y = y, family = fonte, label = fonte)\n  )\n\n# Ou mater a fonte fixa ao longo de todo o gráfico\nggplot(tab) +\n  geom_text(\n    aes(x = x, y = y, label = fonte),\n    family = \"serif\"\n  )\n\n\n\n\n\n\n\n\n\n\nPortanto, nós definimos a fonte utilizada nas funções geom através do argumento family, ao fornecer o nome da fonte que desejamos utilizar. Por outro lado, para alterarmos a fonte em elementos temáticos (elementos que não dizem respeito, ou que não estão diretamente conectados com os seus dados) do gráfico, essas configurações devem ser realizadas dentro da função theme. Basta utilizarmos novamente o argumento family presente em element_text(), e definirmos o nome da fonte que desejamos empregar.\nUm atalho útil, caso você deseja utilizar a mesma fonte em todos os elementos temáticos do gráfico, se trata do argumento text (que se refere a todos os elementos temáticos do tipo “texto”) na função theme(), e definir com a função element_text() a fonte utilizada:\nPorém, caso você deseja utilizar uma fonte diferente em cada componente temático do gráfico, você obrigatoriamente deve definir separadamente a fonte a ser utilizada, em cada argumento de theme() que corresponde a esses componentes estéticos.\n# Gráfico à esquerda\nggplot(tab) +\n  geom_point(aes(x = x, y = y)) +\n  labs(\n    title = \"Um título interessante\",\n    subtitle = \"Um subtítulo também interessante\"\n  ) +\n  theme(\n    text = element_text(family = \"sans\")\n  )\n\n# Gráfico à direita\nggplot(tab) +\n  geom_point(aes(x = x, y = y)) +\n  labs(\n    title = \"Um título interessante\",\n    subtitle = \"Um subtítulo também interessante\"\n  ) +\n  theme(\n    plot.title = element_text(family = \"serif\"),\n    plot.subtitle = element_text(family = \"mono\"),\n    axis.text = element_text(family = \"serif\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n9.9.1 Utilizando novas fontes em seus gráficos\n\n“At its core text and fonts are just very messy, with differences between operating systems and font file formats to name some of the challenges”. (PEDERSEN, 2020).\n\nPortanto, o ggplot oferece (de “fábrica”) 3 fontes diferentes. Mas e se você precisa utilizar uma outra fonte que não está entre essas 3 opções? Em resumo, para que você possa utilizar qualquer outra fonte em seus gráficos, o R precisa saber onde está essa fonte em seu sistema.\nPara que o R passe a “enxergar” uma fonte qualquer em seu sistema, precisamos de certa forma “importar” essa fonte para dentro do R. Em edições passadas desta obra, mostramos como realizar esse processo através do pacote extrafont. Porém, esse é um pacote já bem antigo do R e que depende de um outro programa ainda mais antigo. Pela falta de manutenção, o pacote extrafont deixou de funcionar tão bem em versões mais recentes do R, especialmente após a versão 4.1.\nPor esse motivo, vamos apresentar a seguir, as soluções mais recentes e modernas para esse problema. Hoje, temos três soluções principais, que são: 1) os devices gráficos do pacote ragg; 2) os devices gráficos produzidos por Cairo Graphics; 3) as funções do pacote showtext. Nessa seção vamos demostrar as duas primeiras soluções citadas.\n\n9.9.1.1 O pacote ragg\nO pacote ragg é um pacote do R que provê um conjunto de devices gráficos que são baseados na biblioteca AGG (Anti-Grain Geometry Library), desenvolvida por Maxim Shemanarev. Graças aos esforços de Thomas Lin Pedersen, e de muitos outros colegas, esse pacote trouxe uma certa “revolução” ao mundo dos gráficos do R.\n\ninstall.packages(\"ragg\")\n\nPois esse pacote oferece não apenas devices gráficos que são mais rápidos e que produzem imagens de maior qualidade do que os devices nativos do R, que pertencem ao pacote grDevices; mas também, ragg é o primeiro pacote que conseguiu efetivamente resolver todos os problemas do uso de fontes em gráficos do R, ao trazer um suporte incrível para praticamente todas as operações e configurações sobre textos que você pode imaginar.\nSempre que você faz uma referência a uma fonte “não-padrão” do R (por exemplo, a fonte Calibri), os devices do pacote ragg iniciam automaticamente um processo de busca atrás dessa fonte. Veja o exemplo abaixo, em que utilizo três fontes diferentes. Todas essas fontes geralmente já vem instaladas de “fábrica” em qualquer sistema Windows, logo, você deve ser capaz de executar o código abaixo sem problemas.\n\ngrafico &lt;- ggplot(mpg) +\n  geom_point(\n    aes(hwy, displ)\n  ) +\n  labs(\n    title = \"Relação entre quilometragem e a largura do pistão\",\n    subtitle = \"Baseado em uma amostra de 234 veículos\"\n  ) +\n  theme(\n    text = element_text(family = \"Segoe UI\"),\n    plot.title = element_text(family = \"Comic Sans MS\"),\n    plot.subtitle = element_text(family = \"Calibri\")\n  )\n\n\nragg::agg_png(\n  \"output.png\", width = 2000, height = 1400,\n  res = 300\n)\nprint(grafico)\ndev.off()\n\nO gráfico que foi armazenado neste arquivo output.png está exposto logo abaixo. Perceba que todas as três fontes foram encontradas pelo device agg_png() e, consequentemente, foram corretamente incluídas no gráfico.\n\n\n\n\n\nGráfico salvo no arquivo output.png\n\n\n\n\nPortanto, desde que a fonte que você deseja utilizar esteja instalada em seu sistema operacional, você pode tranquilamente utilizar essa fonte em seus gráficos do ggplot, ao salvá-lo em um arquivo utilizando um dos devices gráficos disponíveis no pacote ragg.\nAlém disso, em versões mais recentes do RStudio, você pode utilizar os devices gráficos do pacote ragg para visualizar os seus gráficos dentro do painel de Plots. Basta acessar o painel de configurações globais da ferramenta, através de Tools \\(\\rightarrow\\) Global options..., em seguida, selecionar a aba de Graphics dentro da seção General, depois, selecionar a opção AGG em Backend, como mostrado na Figura 9.4.\n\n\n\n\n\n\n\n\nFigura 9.4: Utilizando o pacote ragg no painel de Plots do RStudio\n\n\n\n\n\n\n\n9.9.1.2 Arquivos de representação vetorial (PDF, SVG e PS)\nVocê provavelmente percebeu na seção anterior que, o pacote ragg oferece apenas devices gráficos que utilizam representações matriciais (como PNG, JPEG e TIFF). Porém, e se você quisesse salvar o seu gráfico em um arquivo PDF? ou SVG? Como você faria para incluir as fontes que você deseja utilizar?\nA resposta para essa pergunta reside nas funções cairo_pdf(), svg() e cairo_ps(). Todas essas funções pertencem ao pacote grDevices (logo, são funções nativas do R). Porém, essas funções constroem os seus arquivos utilizando-se das engines produzidas por Cairo Graphics.\nPortanto, se desejamos salvar o exato mesmo gráfico que mostramos na seção anterior (o qual inclui três fontes diferentes), porém, dessa vez em um arquivo PDF por exemplo, precisamos apenas criar o arquivo PDF com a função cairo_pdf(), como demonstrado abaixo:\n\ngrafico &lt;- ggplot(mpg) +\n  geom_point(\n    aes(displ, hwy)\n  ) +\n  labs(\n    title = \"Relação entre quilometragem e a largura do pistão\",\n    subtitle = \"Baseado em uma amostra de 234 veículos\"\n  ) +\n  theme(\n    text = element_text(family = \"Segoe UI\"),\n    plot.title = element_text(family = \"Cambria\", face = \"bold\"),\n    plot.subtitle = element_text(family = \"Calibri\")\n  )\n\n\n\n\ncairo_pdf(\"output.pdf\", width = 8, height = 5)\nprint(grafico)\ndev.off()\n\nSendo assim, se o seu gráfico inclui alguma fonte não-padrão, mas que está instalada em seu computador, e você deseja salvá-lo em um arquivo PDF, SVG ou EPS, utilize as funções cairo_pdf(), svg() e cairo_ps(). Pois as engines produzidas por Cairo Graphics conseguem incluir um intervalo muito maior de fontes em seu arquivo.\n\n\n\n\nPEDERSEN, T. L. Updates to ragg and systemfonts, 2020. Disponível em: &lt;https://www.tidyverse.org/blog/2020/05/updates-to-ragg-and-systemfonts/&gt;\n\n\nWICKHAM, H. ggplot2: Elegant Graphics for Data Analysis. 2. ed. [s.l.] Springer International Publishing, 2016.\n\n\nWILKINSON, L. The Grammar of Graphics. 2. ed. Verlag, NY: Springer, 2005.",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Configurando componentes estéticos do gráfico no `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/09-theme-ggplot.html#footnotes",
    "href": "Capítulos/09-theme-ggplot.html#footnotes",
    "title": "9  Configurando componentes estéticos do gráfico no ggplot2",
    "section": "",
    "text": "Você pode ver a lista completa de nomes, ao rodar a função colors() no console.↩︎\nCaso você queira entrar em mais detalhes, um bom início é o artigo intitulado “Text Rendering Hates You”, de Alexis Beingessner: https://gankra.github.io/blah/text-hates-you/↩︎",
    "crumbs": [
      "Visualizando seus dados",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Configurando componentes estéticos do gráfico no `ggplot2`</span>"
    ]
  },
  {
    "objectID": "Capítulos/10-strings.html",
    "href": "Capítulos/10-strings.html",
    "title": "10  Manipulação e transformação de strings com stringr",
    "section": "",
    "text": "10.1 Introdução e pré-requisitos\nNeste capítulo, vamos aprender mais sobre operações especializadas em dados textuais (dados do tipo character), ou como são mais comumente denominados em programação, strings. Esse capítulo também oferece uma introdução a um dos principais e mais importantes tópicos em processamento de texto, as expressões regulares (regular expression), ou regex como é mais conhecida. Para aplicarmos as diversas operações expostas, vamos utilizar as funções disponíveis no pacote stringr. Esse pacote está incluso no tidyverse, logo, para ter acesso às funções apresentadas, você pode chamar pelo tidyverse ou pacote stringr diretamente, por meio do comando library().\nlibrary(stringr)\nlibrary(tidyverse)",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulação e transformação de *strings* com `stringr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/10-strings.html#algumas-noções-básicas",
    "href": "Capítulos/10-strings.html#algumas-noções-básicas",
    "title": "10  Manipulação e transformação de strings com stringr",
    "section": "10.2 Algumas noções básicas",
    "text": "10.2 Algumas noções básicas\nTextos ou strings no R, são criados ao contornarmos um determinado texto por aspas (duplas - \", ou simples - '), e cada letra, espaço, símbolo ou número que compõe esse texto, é comumente denominado de caractere. Caso você se esqueça de fechar o par de aspas que contorna o seu texto, o R vai esperar até que você complete a expressão. Ou seja, em seu console, estaria acontecendo algo parecido com o que está abaixo. Lembre-se que você pode apertar a tecla Esc, para abortar a operação, caso você não consiga completá-la.\n\n&gt; x &lt;- \"Olá eu sou Pedro!\n+ \n+ \n\nComo as aspas são responsáveis por delimitar esse tipo de dado, para que você possa incluir esse caractere em alguma cadeia de texto, você tem duas alternativas: 1) se você está contornando o texto com aspas duplas, utilize aspas simples, ou vice-versa; 2) contornar o comportamento especial das aspas, ao posicionar uma barra inclinada a esquerda antes de cada aspa (\\\" ou \\').\n\n\"Olá! Esse é um texto qualquer\"\n\n[1] \"Olá! Esse é um texto qualquer\"\n\n\"Para incluir aspas ('') em uma string\"\n\n[1] \"Para incluir aspas ('') em uma string\"\n\n\"Será que \\\"alienígenas\\\" existem de fato?\"\n\n[1] \"Será que \\\"alienígenas\\\" existem de fato?\"\n\n\nAlém disso, textos podem incluir diversos outros caracteres especiais. Sendo os principais exemplos, os caracteres de tabulação (\\t), e de quebra de linha (\\n). Entretanto, uma quantidade muito grande desses caracteres especiais, podem dificultar a nossa compreensão do conteúdo presente em um texto. Logo, há vários momentos em que desejamos visualizar o texto representado em uma string de maneira “crua”. Para isso, podemos aplicar a função writeLines() sobre o texto em questão.\n\ntexto &lt;- \"Receita:\\n\\t\\t2 ovos\\n\\t\\t3 copos e meio de farinha\n\\t\\t2 copos de achocolatado\\n\\t\\t1 copo de açúcar\\n\\t\\tMeio copo de óleo\n\\t\\t1 colher (de sopa) de fermento\n\\t\\t1 colher (de café) de bicabornato de sódio\\n\\t\\t...\"\nwriteLines(texto)\n\nReceita:\n        2 ovos\n        3 copos e meio de farinha\n        2 copos de achocolatado\n        1 copo de açúcar\n        Meio copo de óleo\n        1 colher (de sopa) de fermento\n        1 colher (de café) de bicabornato de sódio\n        ...\n\ntexto &lt;- \"Será que \\\"alienígenas\\\" existem de fato?\"\nwriteLines(texto)\n\nSerá que \"alienígenas\" existem de fato?\n\n\nOutro exemplo clássico de caracteres especiais, que são muito encontrados em páginas da internet (e.g. dados coletados em operações de web scrapping), são os códigos hexadecimais ou code points correspondentes a uma determinada letra presente no sistema Unicode. Descrevemos brevemente na seção Um pouco sobre fontes, encoding e tipografia, a importância do Unicode para a universalização dos sistemas de encoding, e consequentemente, para a internacionalização de conteúdo.\nCada caractere no sistema Unicode, é representado por um unicode code point (HARALAMBOUS, 2007). Em resumo, um code point é um número inteiro que pode identificar unicamente um caractere presente no sistema Unicode. Porém, caracteres que são codificados nesse sistema, são normalmente representados pelo código hexadecimal que equivale ao seu respectivo code point. Logo, ao invés de um número específico, você normalmente irá encontrar em strings, códigos que se iniciam por \\u, ou \\U, ou ainda U+, seguidos por uma combinação específica de letras e números. Como exemplo, os códigos hexadecimais abaixo equivalem aos code points que formam a palavra “Arigatōgozaimashita”, ou “Muito obrigado” em japonês.\n\nx &lt;- \"\\u3042\\u308a\\u304c\\u3068\\u3046\\u3054\\u3056\\u3044\\u307e\\u3057\\u305f\"\n\nUm outro ponto muito importante em strings está no uso de barras inclinadas à esquerda. Nós já vimos na seção Definindo endereços do disco rígido no R, que para representarmos uma barra inclinada à esquerda em uma string do R, precisarmos duplicar essa barra. Logo, em strings, a sequência \\\\ significa para o R \\. Existem alguns comandos e caracteres especiais que não requerem essa prática, como o comando que forma um Unicode code point (como demonstrado acima), que sempre se inicia por uma letra “u” antecedida por uma barra inclinada à esquerda (ex: \\u3042). Um outro exemplo são os comandos para tabulações e quebra de linha que acabamos de mostrar (\\t e \\n). Entretanto, essas exceções são a minoria. Portanto, tenha esse cuidado ao utilizar barras inclinadas à esquerda em suas strings.",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulação e transformação de *strings* com `stringr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/10-strings.html#concatenando-ou-combinando-strings-com-paste-e-str_c",
    "href": "Capítulos/10-strings.html#concatenando-ou-combinando-strings-com-paste-e-str_c",
    "title": "10  Manipulação e transformação de strings com stringr",
    "section": "10.3 Concatenando ou combinando strings com paste() e str_c()",
    "text": "10.3 Concatenando ou combinando strings com paste() e str_c()\nConcatenar, significa unir diferentes valores. Porém, essa união pode ocorrer de diferentes maneiras, e como ela ocorre, tende a depender das funções que você utiliza, como você as configura, e com quais tipos de estruturas você está trabalhando. Com isso, eu quero destacar, que o termo concatenar, pode se referir a muitas coisas (ou operações) diferentes. Na linguagem R, uma das principais operações de concatenação está presente na formação de vetores atômicos, mais especificamente, no uso da função c() (abreviação para combine), que introduzimos na seção de Vetores.\nO papel da função c() é criar uma sequência a partir de um conjunto de valores. Essa sequência de valores, é o que forma um vetor, e é o que estabelece uma relação de dependência ou de união entre esses valores, pois os torna parte de uma mesma estrutura. Cada um deles possuem uma ordem, ou uma posição dentro dessa sequência, mas nenhum deles é capaz de gerar essa sequência sozinho.\nEntretanto, ao concatenarmos textos, nós geralmente estamos nos referindo a uma operação um pouco diferente. Tradicionalmente, ao concatenarmos um conjunto de textos, nós já possuímos um vetor (ou mais vetores) em nossas mãos, e desejamos unir cada elemento, ou cada texto contido nesse vetor, de alguma forma lógica. Dentre os pacotes básicos do R, a principal função que realiza esse tipo de operação, é a função paste(). Um detalhe importante sobre essa função, é que ela converte, por padrão, qualquer tipo de input que você fornecer a ela, para o tipo character. Logo, você pode incluir dados numéricos ou de qualquer outro tipo nos input’s dessa função.\nA forma como a função paste() realiza essa união entre os textos, depende diretamente de como você configura os argumentos da função, sep e collapse, e de quais input’s você fornece à função. Se você está fornecendo um único input à função, é certo que você está preocupado apenas com o argumento collapse (em outras palavras, sep é irrelevante nesse caso). Em resumo, o argumento collapse define qual o texto que irá separar os diferentes elementos do input que você forneceu a função. Em outras palavras, se o input que fornecemos é, por exemplo, um vetor de textos, ao definirmos o argumento collapse, estamos pedindo à paste() que junte todos os diferentes elementos do vetor, dentro de um único texto, separando-os pelo texto que você definiu no argumento collapse.\nPor exemplo, se eu possuo o vetor vec abaixo, e utilizo a função paste() sobre ele, veja o que ocorre ao definirmos o argumento collapse. Perceba no exemplo abaixo, que todos os elementos do vetor vec, foram unidos dentro de um mesmo texto, onde cada um desses elementos são separados pelo texto \" : \" que definimos no argumento collapse.\n\nvec &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nconc_vec &lt;- paste(vec, collapse = \" : \")\nconc_vec\n\n[1] \"a : b : c : d : e\"\n\n## --------------------------\n## Um outro exemplo:\nnomes &lt;- c(\"Ana\", \"Fabrício\", \"Eduardo\", \"Mônica\")\nmensagem &lt;- paste(nomes, collapse = \" e \")\nmensagem\n\n[1] \"Ana e Fabrício e Eduardo e Mônica\"\n\n\nPortanto, o texto que você define em collapse, será o texto que vai separar cada um dos elementos do vetor que você fornece como input à função paste(). Por padrão, o argumento collapse é setado para nulo (NULL). Isso significa, que se você não definir algum texto para o argumento collapse, nada acontece ao aplicarmos a função paste() sobre o vetor. Como o argumento sep é irrelevante para um único input, se você não está interessado nesta operação que ocorre ao definirmos collapse, a função paste() não é o que você está procurando.\nPor outro lado, se você está fornecendo dois ou mais inputs à função paste(), é provável que você esteja interessado em definir apenas o argumento sep, apesar de que o argumento collapse pode também ser útil para o seu caso. Ao fornecermos dois ou mais vetores como inputs, a função paste(), por padrão, tenta unir os elementos desses vetores, de forma a produzir um novo vetor de texto. Por exemplo, se eu forneço dois vetores à função paste(), como os vetores vec e id abaixo, o primeiro elemento do vetor resultante de paste() vai possuir os textos presentes no primeiro elemento de ambos os vetores.\n\nid &lt;- 1:5\nvec &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nconc_vec &lt;- paste(id, vec)\nconc_vec\n\n[1] \"1 a\" \"2 b\" \"3 c\" \"4 d\" \"5 e\"\n\n\nO argumento sep é responsável por definir o texto que vai separar os valores de diferentes input’s da função paste(). Perceba no exemplo acima, os valores dos vetores id e vec, estão todos separados por um espaço em branco. Isso significa, que por padrão, o argumento sep é configurado como um espaço em branco (\" \"), e, portanto, você não precisa definir o argumento sep, caso você deseja separar esses valores por um espaço. Mas se há interesse em um texto diferente, para separar esses valores, você deve defini-lo através do argumento sep. Por exemplo, você talvez deseja que não haja espaço algum entre esses valores, como exemplo abaixo.\n\nid &lt;- 1:5\nvec &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nconc_vec &lt;- paste(id, vec, sep = \"\")\nconc_vec\n\n[1] \"1a\" \"2b\" \"3c\" \"4d\" \"5e\"\n\n\nAssim sendo, em uma representação visual, podemos identificar os papéis dos argumentos sep e collapse da forma apresentada na Figura 10.1.\n\n\n\n\n\n\n\n\nFigura 10.1: Resumo dos papéis desempenhados pelos argumentos sep e collapse em paste()\n\n\n\n\n\nPorém, na maioria das aplicações práticas dessa função, pelo menos um dos input’s fornecidos será constante. Por exemplo, uma situação muito comum de uso dessa função, é a construção de caminhos (ou paths) para diferentes arquivos. Essa é exatamente a aplicação que utilizamos na seção Um estudo de caso: uma demanda real sobre a distribuição de ICMS.\nNessa seção, em uma das primeiras etapas descritas, precisamos ler ao todo, 12 planilhas diferentes, e como descrevemos no capítulo 4, para importarmos qualquer arquivo, nós precisamos fornecer o caminho até esse arquivo para o R. Com isso, teríamos a tarefa tediosa de construirmos 12 caminhos diferentes (imagine se fossem 36, ou 320 planilhas diferentes a serem lidas). Porém, como todas essas planilhas se encontram dentro do mesmo diretório de meu computador, eu me aproveito dessa regularidade, para fabricar esses caminhos de uma maneira prática, através da função paste().\nInicialmente, temos apenas os nomes dessas planilhas contidos no objeto planilhas (que está replicado abaixo).\n\nplanilhas &lt;- list.files(\"./planilhas\")\nplanilhas\n\n[1]  \"Abril_2019.xlsx\"     \"Agosto_2019.xlsx\"\n[3]  \"Dezembro_2019.xlsx\"  \"Fevereiro_2019.xlsx\"\n[5]  \"Janeiro_2019.xlsx\"   \"Julho_2019.xlsx\"\n[7]  \"Junho_2019.xlsx\"     \"Maio_2019.xlsx\"     \n[9]  \"Marco_2019.xlsx\"     \"Novembro_2019.xlsx\"\n[11] \"Outubro_2019.xlsx\"   \"Setembro_2019.xlsx\" \nPara criarmos o endereço até cada uma dessas planilhas, precisamos juntar o caminho até o diretório em que elas se encontram (\"planilhas/\"), ao seus nomes. Com isso, podemos utilizar a função paste() da seguinte maneira. Perceba que dois input’s foram fornecidos a função: o primeiro, conciste apenas no texto \"planilhas/\"; o segundo, são os nomes das planilhas contidos no objeto planilhas. Além disso, repare que pelo fato de que o texto \"planilhas/\" ser “constante”, paste() acaba replicando-o para todos os 12 nomes presentes no objeto planilhas.\n\ncaminhos &lt;- paste(\"planilhas/\", planilhas, sep = \"\")\ncaminhos\n\n [1] \"planilhas/Abril_2019.xlsx\"     \"planilhas/Agosto_2019.xlsx\"   \n [3] \"planilhas/Dezembro_2019.xlsx\"  \"planilhas/Fevereiro_2019.xlsx\"\n [5] \"planilhas/Janeiro_2019.xlsx\"   \"planilhas/Julho_2019.xlsx\"    \n [7] \"planilhas/Junho_2019.xlsx\"     \"planilhas/Maio_2019.xlsx\"     \n [9] \"planilhas/Marco_2019.xlsx\"     \"planilhas/Novembro_2019.xlsx\" \n[11] \"planilhas/Outubro_2019.xlsx\"   \"planilhas/Setembro_2019.xlsx\" \n\n\nVocê talvez tenha percebido, especialmente durante o capítulo 4, que temos uma variante da função paste(), chamada paste0(). Essa irmã, nada mais é do que um atalho para a função paste(), que utiliza por padrão, a configuração sep = \"\". Ou seja, em todas as ocasiões em que você estiver concatenando textos de diferentes input’s com a função paste(), e deseja utilizar nenhum espaço como separador entre os valores de cada input, você pode rapidamente executar essa ação por meio da função paste0().\n\ncaminhos &lt;- paste0(\"planilhas/\", planilhas)\ncaminhos\n\n [1] \"planilhas/Abril_2019.xlsx\"     \"planilhas/Agosto_2019.xlsx\"   \n [3] \"planilhas/Dezembro_2019.xlsx\"  \"planilhas/Fevereiro_2019.xlsx\"\n [5] \"planilhas/Janeiro_2019.xlsx\"   \"planilhas/Julho_2019.xlsx\"    \n [7] \"planilhas/Junho_2019.xlsx\"     \"planilhas/Maio_2019.xlsx\"     \n [9] \"planilhas/Marco_2019.xlsx\"     \"planilhas/Novembro_2019.xlsx\" \n[11] \"planilhas/Outubro_2019.xlsx\"   \"planilhas/Setembro_2019.xlsx\" \n\n\n\n10.3.1 A função str_c() como uma alternativa para concatenação de strings\nPor ser uma operação muito comum e útil, o pacote stringr nos oferece a função str_c(), como uma alternativa à função paste(). Suas diferenças se restringem a dois pontos. Primeiro, a função str_c() foi escrita em C++, e consegue hoje, atingir uma maior eficiência se comparada a função paste(), como demonstrado abaixo. Logo, str_c() pode oferecer uma vantagem considerável, caso você esteja trabalhando com um grande conjunto de textos.\n\nlibrary(stringr)\nlibrary(microbenchmark)\ntexto &lt;- sample(letters, size = 1e6, replace = TRUE)\n\nmicrobenchmark(\n  paste(texto, collapse = \"\"),\n  str_c(texto, collapse = \"\")\n)\n\nUnit: milliseconds\n                        expr      min       lq      mean\n paste(texto, collapse = \"\") 104.7202 107.8384 124.43956\n str_c(texto, collapse = \"\")  26.3803  26.9155  28.33062\n   median        uq      max neval\n 115.8264 129.90345 277.5362   100\n  27.1933  29.02705  33.3686   100\nSegundo, temos também uma diferença importante sobre as configurações nativas utilizadas por essas funções. Pois a função str_c() adota sep = \"\" como a sua configuração padrão para o argumento sep (se igualando assim, à função paste0()), ao invés de sep = \" \", que é o padrão adotado por paste(). Veja um exemplo abaixo.\n\nstr_c(\"Dia\", 1:7)\n\n[1] \"Dia1\" \"Dia2\" \"Dia3\" \"Dia4\" \"Dia5\" \"Dia6\" \"Dia7\"\n\nstr_c(\"Dia\", 1:7, sep = \" \")\n\n[1] \"Dia 1\" \"Dia 2\" \"Dia 3\" \"Dia 4\" \"Dia 5\" \"Dia 6\" \"Dia 7\"\n\nstr_c(\"Dia\", 1:7, collapse = \"-\")\n\n[1] \"Dia1-Dia2-Dia3-Dia4-Dia5-Dia6-Dia7\"\n\n\nApesar dessas diferenças, a função str_c() se comporta exatamente da mesma maneira que a função paste(). Por isso, pode ser interessante que você adote essa função como o seu padrão para concatenação de textos, especialmente levando-se em conta, a sua maior eficiência.",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulação e transformação de *strings* com `stringr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/10-strings.html#vantagens-do-pacote-stringr",
    "href": "Capítulos/10-strings.html#vantagens-do-pacote-stringr",
    "title": "10  Manipulação e transformação de strings com stringr",
    "section": "10.4 Vantagens do pacote stringr",
    "text": "10.4 Vantagens do pacote stringr\nOs pacotes básicos da linguagem R oferecem algumas ferramentas para trabalharmos com strings, como a função paste() e a família grep(). Porém, essas ferramentas são em grande parte, inconsistentes em seus nomes e formas e, por isso, são mais difíceis de se lembrar. Mesmo com essa consideração, eu decidi mostrar a função paste() na seção anterior, pelo fato de que ela continua sendo uma função extremamente popular, e que você irá encontrar em todo lugar.\nDe qualquer forma, a partir de agora, vamos focar apenas nas funções do pacote stringr. As funções desse pacote, são em geral, mais rápidas do que as funções ofertadas pelos pacotes básicos. Além disso, os nomes de todas as funções do pacote stringr começam pela sequência str_*(), o que facilita muito a sua memorização de cada função.",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulação e transformação de *strings* com `stringr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/10-strings.html#comprimento-de-strings-com-str_length",
    "href": "Capítulos/10-strings.html#comprimento-de-strings-com-str_length",
    "title": "10  Manipulação e transformação de strings com stringr",
    "section": "10.5 Comprimento de strings com str_length()",
    "text": "10.5 Comprimento de strings com str_length()\nA função str_length() lhe permite contabilizar o número de caracteres presentes em uma string. Essa função é extremamente útil, quando desejamos aplicar operações que se baseiam em uma determinada posição de uma string, como extrair uma seção específica dessa string. Perceba abaixo, que ao se deparar com valores NA, a função nos retorna um valor NA correspondente. Repare também, pelo resultado do quarto elemento, referente a palavra “Partindo”, que espaços em branco também são contabilizados como caracteres, portanto, fique atento a este detalhe.\n\nvec &lt;- c(\n  \"Fui ao Paraná, e encontrei o Varadá\",\n  \"Abril\", \n  \"!\",\n  \"Partindo \",\n  NA\n)\n\nstr_length(vec)\n\n[1] 35  5  1  9 NA",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulação e transformação de *strings* com `stringr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/10-strings.html#lidando-com-capitalização-e-espaços-em-branco",
    "href": "Capítulos/10-strings.html#lidando-com-capitalização-e-espaços-em-branco",
    "title": "10  Manipulação e transformação de strings com stringr",
    "section": "10.6 Lidando com capitalização e espaços em branco",
    "text": "10.6 Lidando com capitalização e espaços em branco\nDiversas empresas que utilizam formulários, ou outros sistemas de registro, precisam estar constantemente corrigindo input’s fornecidos por seus usuários. Talvez, os erros mais comumente gerados, sejam no uso da capitalização e de espaços em branco. Por exemplo, ao preenchermos formulários, é muito comum que: 1) esqueçamos a tecla Caps Lock ligada; 2) ou simplesmente ignoramos o uso de capitalização por simplesmente estarmos com pressa para finalizar o formulário; 3) acrescentar espaços desnecessários ao final ou no meio do input.\nComo exemplo, suponha que você possua a tabela usuarios. Repare que os valores da coluna cidade, variam bastante quanto ao uso da capitalização. Repare também, que em alguns valores na coluna nome, temos para além de problemas com a capitalização, espaços em branco desnecessários, que as vezes se encontram a direita, ou a esquerda, ou em ambos os lados do nome.\n\nusuarios &lt;- tibble(\n  nome = c(\"Ana\", \" Eduardo\", \" Cláudio   \", \"VerÔNiCA \",\n           \"  hugo    \", \"JULIANA\", \"  Vitor de paula   \"),\n  cidade = c(\"BELÉM\", \"goiânia\", \"são paulo\", \"São paulo\", \"SÃO pAULO\",\n             \"rIO DE janeiro\", \"rio de janeiro\"),\n  profissao = c(\"Bióloga\", \"Biólogo\", \"Químico\", \"Socióloga\",\n                \"Administrador\", \"Administradora\", \"Economista\")\n)\n\nusuarios\n\n# A tibble: 7 × 3\n  nome          cidade    profissao    \n  &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt;        \n1 \"Ana\"         BELÉM     Bióloga      \n2 \" Eduardo\"    goiânia   Biólogo      \n3 \" Cláudio   \" são paulo Químico      \n4 \"VerÔNiCA \"   São paulo Socióloga    \n5 \"  hugo    \"  SÃO pAULO Administrador\n# ℹ 2 more rows\n\n\nNo Excel, você normalmente utilizaria a função ARRUMAR() para resolver os excessos de espaços, e as funções MAIÚSCULA(), MINÚSCULA() e PRI.MAIÚSCULA() para alterar a capitalização de todas as letras de cada nome. Sendo as funções str_trim(), str_to_upper(), str_to_lower() e str_to_title(), os seus equivalentes no pacote stringr, respectivamente.\nComo os próprios nomes das funções str_to_upper() e str_to_lower() dão a entender, elas convertem todos as letras contidas em um vetor do tipo character, para letras maiúsculas (upper) e minúsculas (lower). Por exemplo, ao aplicarmos essas funções sobre a coluna cidade, temos o seguinte resultado:\n\nusuarios %&gt;% \n  mutate(cidade = str_to_upper(cidade))\n\n# A tibble: 7 × 3\n  nome          cidade    profissao    \n  &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt;        \n1 \"Ana\"         BELÉM     Bióloga      \n2 \" Eduardo\"    GOIÂNIA   Biólogo      \n3 \" Cláudio   \" SÃO PAULO Químico      \n4 \"VerÔNiCA \"   SÃO PAULO Socióloga    \n5 \"  hugo    \"  SÃO PAULO Administrador\n# ℹ 2 more rows\n\nusuarios %&gt;% \n  mutate(cidade = str_to_lower(cidade))\n\n# A tibble: 7 × 3\n  nome          cidade    profissao    \n  &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt;        \n1 \"Ana\"         belém     Bióloga      \n2 \" Eduardo\"    goiânia   Biólogo      \n3 \" Cláudio   \" são paulo Químico      \n4 \"VerÔNiCA \"   são paulo Socióloga    \n5 \"  hugo    \"  são paulo Administrador\n# ℹ 2 more rows\n\n\nPor outro lado, a função str_to_title() representa a alternativa do meio, ao converter a primeira letra de cada palavra, para maiúsculo, e as letras restantes, para minúsculo, como demonstrado abaixo:\n\nusuarios %&gt;% \n  mutate(cidade = str_to_title(cidade))\n\n# A tibble: 7 × 3\n  nome          cidade    profissao    \n  &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt;        \n1 \"Ana\"         Belém     Bióloga      \n2 \" Eduardo\"    Goiânia   Biólogo      \n3 \" Cláudio   \" São Paulo Químico      \n4 \"VerÔNiCA \"   São Paulo Socióloga    \n5 \"  hugo    \"  São Paulo Administrador\n# ℹ 2 more rows\n\n\nQuanto ao excedente de espaços na coluna nome, podemos aplicar a função str_trim(). Por padrão, essa função retira qualquer espaço remanescente em ambos os lados de sua string. Mas caso seja de seu desejo, você pode especificar um lado específico para retirar espaços, por meio do argumento side, que aceita os valores \"both\", \"left\" ou \"right\".\n\nusuarios &lt;- usuarios %&gt;% \n  mutate(nome = str_trim(nome))\n\nusuarios\n\n# A tibble: 7 × 3\n  nome     cidade    profissao    \n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;        \n1 Ana      BELÉM     Bióloga      \n2 Eduardo  goiânia   Biólogo      \n3 Cláudio  são paulo Químico      \n4 VerÔNiCA São paulo Socióloga    \n5 hugo     SÃO pAULO Administrador\n# ℹ 2 more rows\n\n\nVale destacar também, que str_trim() é capaz apenas de remover excessos de espaços que se encontram ao redor de seu texto. Logo, a forma mais direta de resolvermos esse tipo de excesso, seria utilizarmos o método mais “abrangente” da função str_trim(), aplicado pela função str_squish(). Além de remover os espaços ao redor da palavra, a função str_squish() também é capaz de remover espaços repetidos que se encontram entre palavras. Veja abaixo, o exemplo do texto \"  São Carlos de   Santana   \".\n\nstr_trim(\"  São Carlos de   Santana   \")\n\n[1] \"São Carlos de   Santana\"\n\nstr_squish(\"  São Carlos de   Santana   \")\n\n[1] \"São Carlos de Santana\"",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulação e transformação de *strings* com `stringr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/10-strings.html#extraindo-partes-ou-subsets-de-uma-string-com-str_sub",
    "href": "Capítulos/10-strings.html#extraindo-partes-ou-subsets-de-uma-string-com-str_sub",
    "title": "10  Manipulação e transformação de strings com stringr",
    "section": "10.7 Extraindo partes ou subsets de uma string com str_sub()",
    "text": "10.7 Extraindo partes ou subsets de uma string com str_sub()\nPara extrairmos partes de uma string, podemos utilizar a função str_sub(), que se baseia na posição dos caracteres que delimitam o intervalo que você deseja capturar. Ou seja, nessa função, precisamos definir as posições dos caracteres que iniciam e terminam o intervalo que estamos extraindo. Como exemplo, eu posso extrair do primeiro ao quarto caractere de cada texto presente na coluna nome, da seguinte maneira:\n\nusuarios %&gt;% \n  mutate(parte = str_sub(nome, start = 1, end = 4))\n\n# A tibble: 7 × 4\n  nome     cidade    profissao     parte\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;         &lt;chr&gt;\n1 Ana      BELÉM     Bióloga       Ana  \n2 Eduardo  goiânia   Biólogo       Edua \n3 Cláudio  são paulo Químico       Cláu \n4 VerÔNiCA São paulo Socióloga     VerÔ \n5 hugo     SÃO pAULO Administrador hugo \n# ℹ 2 more rows\n\n\nDe forma semelhante, podemos extrair do terceiro ao quinto caractere dessa mesma coluna, de acordo com o seguinte comando:\n\nusuarios %&gt;% \n  mutate(parte = str_sub(nome, start = 3, end = 5))\n\n# A tibble: 7 × 4\n  nome     cidade    profissao     parte\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;         &lt;chr&gt;\n1 Ana      BELÉM     Bióloga       a    \n2 Eduardo  goiânia   Biólogo       uar  \n3 Cláudio  são paulo Químico       áud  \n4 VerÔNiCA São paulo Socióloga     rÔN  \n5 hugo     SÃO pAULO Administrador go   \n# ℹ 2 more rows\n\n\nAlém desses pontos, vale esclarecer que os textos inclusos em seu vetor, não precisam obrigatoriamente se encaixar no intervalo de caracteres que você delimitou. Por exemplo, veja abaixo que eu forneci um vetor contendo dois nomes (Ana e Eduardo), um possui 3 caracteres, enquanto o outro, possui 7. Logo, ao pedir à str_sub(), que retire do primeiro ao sexto caractere de cada texto contido no vetor, a função vai tentar extrair o máximo de caracteres possíveis que se encaixam nesse intervalo. Mesmo que algum desses textos não encaixe por completo nesse intervalo.\n\nstr_sub(c(\"Ana\", \"Eduardo\"), start = 1, end = 6)\n\n[1] \"Ana\"    \"Eduard\"\n\n\n\n10.7.1 Aliando str_sub() com str_length() para extrair partes de tamanho variável\nNa seção Um estudo de caso: uma demanda real sobre a distribuição de ICMS oferecemos um caso de uso das funções str_sub() e str_length. Nessa seção, temos um sistema que coleta o nome de cada planilha que importamos para o R. Por que precisamos dessa informação? Porque o nome de cada planilha especifica o mês e o ano a que os seus dados se referem. Logo, os dados presentes na planilha Abril_2019.xlsx diziam respeito ao mês de abril do ano de 2019.\nPortanto, ao final da coleta desses nomes, inserimos esses nomes em uma coluna de nosso data.frame, tendo como resultado algo parecido com a coluna origem, que se encontra na tabela periodo, e que pode ser recriada através dos comandos abaixo.\n\nmeses &lt;- c(\"Janeiro\", \"Fevereiro\", \"Março\", \"Abril\",\n           \"Maio\", \"Junho\", \"Julho\", \"Agosto\",\n           \"Setembro\", \"Outubro\", \"Novembro\", \"Dezembro\")\nmeses &lt;- rep(meses, times = 6)\nanos &lt;- rep(2015:2020, each = 12)\n\nperiodo &lt;- tibble(\n  origem = str_c(str_c(meses, anos, sep = \"_\"), \".xslx\")\n)\n\nperiodo\n\n# A tibble: 72 × 1\n  origem             \n  &lt;chr&gt;              \n1 Janeiro_2015.xslx  \n2 Fevereiro_2015.xslx\n3 Março_2015.xslx    \n4 Abril_2015.xslx    \n5 Maio_2015.xslx     \n# ℹ 67 more rows\n\n\nCom essa informação, podemos facilmente rastrear a origem de cada linha de nossa tabela. Entretanto, mesmo com essa informação, ainda não somos capazes de ordenar a tabela de maneira útil. Pois da forma como as informações são apresentadas na coluna origem, uma ordenação alfabética seria empregada sobre a coluna. Logo, valores como Abril_2018.xlsx e Abril_2017.xlsx, viriam a aparecer antes de valores como Março_2019.xlsx.\nPor isso, ainda temos a necessidade de extrair o mês e o ano desses nomes, e em seguida, alocar essas informações em colunas separadas. Com esse objetivo, utilizamos a função str_sub() para extrairmos a parte, ou a seção de cada nome, que corresponde ao mês que ele se refere. Porém, como você pode ver acima, o número de caracteres presentes em cada mês, ou em cada nome, varia de maneira drástica.\nEm momentos como esse, você pode tentar identificar se a parte final ou a parte inicial dos textos inclusos em sua coluna, são de alguma maneira, constantes. Ou seja, mesmo que o número de caracteres varie muito ao longo da coluna, talvez exista uma parte específica desses textos que sempre possui a mesma quantidade de caracteres.\nNo caso da coluna origem, temos três partes que são sempre constantes, que são a parte dos anos (mesmo que os anos variem, eles sempre são formados por 4 números, ou 4 caracteres), a parte da extensão do arquivo (.xlsx), e o underscore (_), que sempre separa as duas partes anteriores do mês em cada nome. Somando os caracteres dessas três partes, temos sempre 10 caracteres ao final do nome do arquivo, ao qual podemos eliminar para chegarmos à seção do texto que contém o nome do mês. Com isso, podemos utilizar a função str_length() para calcular o número total de caracteres de cada texto, e subtrair 10 desse valor, para chegarmos ao caractere que delimita o fim do mês em cada texto.\nPodemos empregar a mesma linha de raciocínio, para chegarmos aos limites do intervalo que contém o ano em cada texto. Contudo, tanto o limite inicial quanto o limite final desse intervalo, variam. Logo, temos que utilizar o resultado de str_length() para descobrirmos os dois limites dessa seção. Como estamos empregando os valores produzidos por str_length() em três locais diferentes, eu guardo o resultado dessa função em uma coluna denominada num, para não ter o trabalho de digitar repetidamente a função str_length().\n\nperiodo %&gt;% \n  mutate(\n    num = str_length(origem),\n    mes = str_sub(origem, start = 1, end = num - 10),\n    ano = str_sub(origem, start = num - 8, end = num - 5) %&gt;% as.integer()\n  )\n\n# A tibble: 72 × 4\n  origem                num mes         ano\n  &lt;chr&gt;               &lt;int&gt; &lt;chr&gt;     &lt;int&gt;\n1 Janeiro_2015.xslx      17 Janeiro    2015\n2 Fevereiro_2015.xslx    19 Fevereiro  2015\n3 Março_2015.xslx        15 Março      2015\n4 Abril_2015.xslx        15 Abril      2015\n5 Maio_2015.xslx         14 Maio       2015\n# ℹ 67 more rows",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulação e transformação de *strings* com `stringr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/10-strings.html#sec:stringr_regex",
    "href": "Capítulos/10-strings.html#sec:stringr_regex",
    "title": "10  Manipulação e transformação de strings com stringr",
    "section": "10.8 Expressões regulares (ou regex) com str_detect()",
    "text": "10.8 Expressões regulares (ou regex) com str_detect()\nExpressões regulares (regular expressions), ou simplesmente regex, são uma ferramenta extremamente poderosa para processamento de texto. Por essa característica, praticamente toda linguagem de programação possui em algum nível, uma implementação dessa funcionalidade. Você talvez não saiba ainda, mas expressões regulares estão em todo lugar. Como exemplo, quando você pesquisa por uma palavra em um PDF, você está aplicando uma expressão regular ao longo do arquivo.\nEm síntese, expressões regulares são como uma mini linguagem que lhe permite descrever de maneira concisa, um pedaço de texto (FRIEDL, 2006). Para utilizar uma expressão regular, você precisa utilizar uma função que possa aplicar esse tipo de mecanismo. Nos pacotes básicos do R, essa funcionalidade está disponível através das funções da família grep() (sendo grep(), grepl() e gsub(), as principais funções dessa família).\nPor outro lado, o pacote stringr oferece uma família um pouco maior de funções que são capazes de aplicar tal mecanismo. Sendo as funções str_which(), str_detect(), str_replace() e str_split(), as principais representantes dessa família.\nEm grande parte desse capítulo, estaremos utilizando a função str_detect() como a nossa ponte de acesso ao mundo das expressões regulares. Assim como todas as funções str_*() que citamos no parágrafo anterior, a função str_detect() aceita um vetor contendo os textos a serem pesquisados como primeiro argumento (string), e uma expressão regular como seu segundo argumento (pattern).\nA função str_which() é praticamente idêntica à str_detect(). Pois ambas as funções vão pesquisar pelos textos que são descritos pela expressão regular que você forneceu, e ambas as funções vão gerar um vetor contendo índices, que definem quais foram os textos encontrados. Entretanto, as funções se divergem no tipo de resultado gerado. A função str_which() nos retorna um vetor contendo índices numéricos. Em contrapartida, a função str_detect() gera um vetor de valores lógicos. Portanto, você pode utilizar o resultado de ambas as funções dentro da função de subsetting ([) para filtrar os textos encontrados, sendo a única diferença, o tipo de índice empregado no filtro.\n\n10.8.1 A expressão regular mais simples de todas\nA maneira mais simples de utilizarmos uma expressão regular, seria pesquisarmos por uma sequência específica de letras. Por exemplo, suponha que eu possua o conjunto de palavras presentes em vec, e desejasse encontrar a palavra “emissão”.\n\nvec &lt;- c(\"permissão\", \"demissão\", \"emissão\", \"penitência\",\n         \"jurisdição\", \"ordenação\", \"concluio\", \"vantagem\",\n         \"natação\", \"satisfação\", \"conclusão\", \"ilusão\")\n\nCom o conhecimento que você já possui, você provavelmente tentaria algo como o comando abaixo para encontrar essa palavra.\n\nvec[vec == \"emissão\"]\n\n[1] \"emissão\"\n\n\nPorém, você também poderia encontrar essa palavra inclusa no vetor vec, ao fornecer uma expressão regular que seja capaz de descrever o texto “emissão”. Em seu primeiro instinto, você provavelmente aplicaria o simples texto \"emissão\", todavia, como vemos abaixo, esse não é exatamente o resultado que desejamos.\n\nteste &lt;- str_detect(vec, \"emissão\")\nvec[teste]\n\n[1] \"demissão\" \"emissão\" \n\n\nO erro acima, está no fato de que estamos interpretando a expressão regular \"emissão\", como a palavra “emissão”. Você rapidamente irá descobrir, que expressões regulares não possuem qualquer noção do que é uma palavra, muito menos de onde uma começa ou termina. Ou seja, quando estiver utilizando expressões regulares, a menos que você defina explicitamente os limites físicos da pesquisa, o mecanismo estará procurando por uma sequência específica de caracteres, independentemente do local em que essa sequência seja detectada.\nPor isso, é importante que você comece a interpretar qualquer expressão regular, como uma descrição de uma sequência específica de caracteres, ao invés de uma palavra. Logo, quando fornecemos o texto \"emissão\" à str_detect() acima, estamos na verdade, buscando qualquer texto que contenha os caracteres “e-m-i-s-s-ã-o”, precisamente nessa ordem. Com isso, a palavra “demissão” foi incluída no resultado acima, pelo fato de possuir tal sequência de caracteres, mesmo que essa sequência esteja acompanhada por um “d”, o qual não faz parte da expressão regular definida.\nComo um outro exemplo, suponha que eu utilize a expressão \"is\". Lembre-se que nós não estamos procurando pela palavra is, mas sim, por qualquer texto que contenha um “i” imediatamente seguido por um “s”. Marcando de negrito, apenas as partes dos textos abaixo, que foram de fato encontradas pela expressão \"is\", temos: satisfação, demissão, permissão, emissão, jurisdição.\n\nteste &lt;- str_detect(vec, \"is\")\nvec[teste]\n\n[1] \"permissão\"  \"demissão\"   \"emissão\"    \"jurisdição\" \"satisfação\"\n\n\nPorém, a partir do momento em que acrescento um segundo “s” à expressão, as palavras “jurisdição” e “satisfação” não mais se encaixam na descrição fornecida pela expressão. Pois nenhuma dessas duas palavras possuem, em algum lugar, um “i” imediatamente seguido por duas letras “s”. Com isso, temos que as partes localizadas pela expressão são: permissão, demissão, emissão.\n\nteste &lt;- str_detect(vec, \"iss\")\nvec[teste]\n\n[1] \"permissão\" \"demissão\"  \"emissão\"  \n\n\nApenas para que os pontos abordados fiquem claros, a Figura 10.2 lhe permite visualizar as correspondências (marcadas em cinza) encontradas por cada uma das expressões regulares mostradas anteriormente.\n\n\n\n\n\n\n\n\nFigura 10.2: Correspondências encontradas por cada expressão regular, além de suas respectivas descrições.\n\n\n\n\n\n\n\n10.8.2 Conhecendo a função str_view()\nNas próximas seções, irei descrever os padrões mais importantes de expressão regulares. Porém, mesmo que eu explique em detalhes, a prática pode ser um pouco difícil no início. Muitas vezes, você imagina que a sua expressão regular representa um texto x, quando na realidade, ela representa um texto y. Como resultado, você pode acabar encontrando textos que você não queria encontrar, ou ainda, não encontrar nenhum texto sequer.\nSempre que eu me vejo nessa situação, em que não sei exatamente o que está errado em minha expressão regular, eu costumo utilizar as funções str_view() e str_view_all() para visualizar em mais detalhes, o texto encontrado (ou que deixou de ser encontrado) por essa expressão regular.\nEm resumo, as funções str_view() e str_view_all() aceitam um vetor do tipo character e uma expressão regular como inputs. Como output, essas funções retornam um arquivo HTML que expõe as partes exatas dos textos contidos no vetor de input, que foram encontradas pela expressão regular que você forneceu. Como diferença, str_view() mostra apenas a primeira correspondência encontrada pela expressão regular em cada texto, enquanto str_view_all() mostra todas as correspondências encontradas em cada texto.\nComo exemplo, o comando str_view(\"banana\", \"an\") retorna a visualização abaixo como resultado. Segundo essa visualização, a expressão regular \"an\" consegue encontrar o texto banana.\n\nstr_view(\"banana\", \"an\")\n\n\n\n\n\n\n\n\n\n\nCaso eu utilize a função str_view_all(), podemos perceber que mais partes da palavra “banana” podem ser encontrados pela mesma expressão.\n\nstr_view_all(\"banana\", \"an\")\n\n\n\n\n\n\n\n\n\n\nApesar dos exemplos acima serem bastante simples, o real valor dessas funções se mostra quando estamos tentando construir uma expressão regular razoavelmente longa e complexa. Por exemplo, durante a construção e manutenção deste livro, eu utilizo algumas expressões regulares para transformar citações do formato Latex para o formato universal de citações do Rmarkdown. Logo abaixo, temos um exemplo dessas expressões regulares.\n\nexpre &lt;- \"\\\\\\\\citeonline\\\\[([p. ]+)([0-9]+)\\\\{([a-zA-Z0-9_]+)\\\\}\"\n\nPara testarmos essa expressão regular, construí abaixo, um objeto contendo alguns exemplos de citações em formato Latex. Logo, é esperado que essa expressão regular encontre (ou cubra) todos os exemplos de citação abaixo.\n\nexemplos &lt;- c(\n  \"Segundo \\\\citeonline[p. 45]{wickham2017}, algo importante\",\n  \"\\\\citeonline[p. 3]{alvaro_2011} refutou tal modelo\",\n  \"Apresentado por \\\\citeonline[p. 842]{silva21}\"\n)\n\nEntretanto, quando fornecemos o objeto de exemplos, e a expressão regular à str_view(), vemos que nenhum texto é encontrado nos três exemplos.\n\nstr_view(exemplos, expre)\n\n\n\n\n\n\n\n\n\n\nO que tem de errado com essa expressão? Primeiro, precisamos descobrir onde está o problema. Será que é uma parte específica da expressão que está quebrando a busca? Ou será que toda essa expressão é inválida, e não serve de nada para o nosso objetivo?\nA melhor maneira de respondermos a essas questões é testar cada parte dessa expressão de forma separada. Se uma parte específica da expressão consegue encontrar o texto que nós esperávamos que essa parte encontrasse, temos um sinal de que o problema está em um outro lugar da expressão.\nComo exemplo, vamos testar primeiro a parte \\\\\\\\citeonline da expressão. Repare abaixo, que a expressão consegue localizar todos os exemplos de \\citeonline.\n\nstr_view(exemplos, \"\\\\\\\\citeonline\")\n\n\n\n\n\n\n\n\n\n\nAgora, vamos adicionar as partes \\\\[, ([p. ]+) e ([0-9]+) da expressão. Perceba novamente abaixo, que ainda não conseguimos encontrar o problema, pois as partes que nós esperávamos encontrar foram de fato encontradas.\n\nexpre &lt;- \"\\\\\\\\citeonline\\\\[([p. ]+)([0-9]+)\"\nstr_view(exemplos, expre)\n\n\n\n\n\n\n\n\n\n\nPorém, perceba agora, que, ao inserirmos a próxima parte da expressão (\\\\{), nenhum texto é encontrado. Por esse efeito, podemos inferir que há algo de errado nessa parte da expressão.\n\nexpre &lt;- \"\\\\\\\\citeonline\\\\[([p. ]+)([0-9]+)\\\\{\"\nstr_view(exemplos, expre)\n\n\n\n\n\n\n\n\n\n\nApós analisarmos por um tempo esse problema, podemos identificar que está faltando uma parte \\\\] antes de \\\\{. Pois o colchete aberto (identificado por \\\\[) precisa ser fechado (identificado por \\\\]). Ao adicionarmos essa parte à expressão, todo o problema é solucionado, e a expressão passa a encontrar corretamente todas as citações.\n\nexpre &lt;- \"\\\\\\\\citeonline\\\\[([p. ]+)([0-9]+)\\\\]\"\nexpre &lt;- str_c(expre, \"\\\\{([a-zA-Z0-9_]+)\\\\}\")\nstr_view(exemplos, expre)\n\n\n\n\n\n\n\n\n\n\nPortanto, sempre que você enfrentar alguma dificuldade com as suas expressões regulares, tente utilizar as funções str_view() e str_view_all() para identificar onde o problema está ocorrendo. Essas funções também podem ser muito úteis, quando você ainda não sabe exatamente como construir a expressão que você necessita. Nesse caso, você pode utilizar essas funções para testar várias possibilidades diferentes, atrás da primeira que funcione.\n\n\n10.8.3 Caracteres literais e metacharacters\nExpressões regulares são uma linguagem formada por duas categorias de caracteres (FRIEDL, 2006): 1) Caracteres literais, ou simples letras e números pelos quais pesquisamos; e 2) metacharacters, que são um conjunto de caracteres especiais que delimitam o escopo de sua pesquisa, ou a maneira como ela será executada.\nAté o momento, utilizamos apenas caracteres literais, ao pesquisarmos pelas sequências \"emissão\" ou \"is\". Ou seja, qualquer número ou letra que formam uma sequência de caracteres são considerados caracteres literais. Alguns símbolos também são considerados caracteres literais, pois não possuem nenhum comportamento especial que altere o comportamento da pesquisa. Como exemplo, a expressão \"A1_z-4!D8\" é formada apenas por caracteres literais, mesmo que ela descreva uma sequência bem esquisita (e provavelmente inútil) de caracteres.\nQualquer expressão que utilize apenas caracteres literais, busca efetuar uma simples pesquisa por uma sequência particular de caracteres. Consequentemente, a expressão \"1\" é capaz de detectar o texto “Álvaro chegou em 1° lugar!”, assim como “O aluguel chegou a R$3250,10 nesse mês”. Como um outro exemplo, ao empregarmos a expressão \"regi\", ela é capaz de encontrar os textos “região” e “registro”, mas não é capaz de detectar o nome “Reginaldo”, pelo simples fato de que a primeira letra do nome é um “r” maiúsculo, ao invés de um “r” minúsculo.\nEm síntese, expressões regulares já são uma ferramenta útil apenas com o uso de caracteres literais. Contudo, elas se tornam bastante limitadas sem o uso de metacharacters, que ampliam em muito as suas funcionalidades, e mudam drasticamente a forma como a pesquisa ocorre. Neste ponto, também reside uma importante dificuldade no domínio de expressões regulares. Pois são muitos metacharacters disponíveis e, por isso, memorizar o que cada um deles fazem, e quais são as suas aplicações mais úteis, não se trata de uma tarefa simples.\nApesar disso, haverá momentos em que você deseja encontrar ou incluir em sua expressão regular o caractere literal que um certo metacharacter representa. Em outras palavras, há ocasiões em que você deseja que certos metacharacters se comportem como caracteres literais. Por exemplo, um dos metacharacters que vamos mostrar nas próximas seções é ? (ponto de interrogação). Portanto, o caractere ? possui um comportamento especial em expressões regulares, mas se quisermos encontrar o caractere ? em si, ao longo do texto, nós precisamos contornar o comportamento especial desse metacharacter. Para isso, basta anteceder esse caractere por uma barra inclinada à esquerda (\\?).\nPorém, lembre-se que para escrevermos uma barra inclinada à esquerda, nós temos que digitar duas barras inclinadas à esquerda! Logo, para escrever em sua expressão regular, o termo \\?, você deve na verdade, digitar o termo \\\\?. Isso funciona para praticamente qualquer metacharacter. Logo, sempre que você precisar utilizar um certo metacharacter como um caractere literal, tente antecedê-lo por duas barras inclinadas à esquerda.\n\n\n10.8.4 Âncoras (anchors)\nO primeiro tipo de metacharacters que vou apresentar, são os do tipo “âncora”. Esse conjunto é composto pelos caracteres ^ e $, que são responsáveis por delimitar o início e o fim de uma linha, respectivamente.\nLogo, ao utilizar a expressão \"^emissão$\", eu estou pedindo à str_detect() que localize um texto que contém: o início de uma linha imediatamente seguido pela sequência “e-m-i-s-s-ã-o” de caracteres, que por sua vez, deve ser imediatamente seguido pelo fim dessa mesma linha. Com essa expressão, somos capazes de encontrar apenas a palavra “emissão” que está entre os valores do vetor vec.\n\nteste &lt;- str_detect(vec, \"^emissão$\")\nvec[teste]\n\n[1] \"emissão\"\n\n\nÉ importante destacar, que os caracteres ^ e $ são capazes de encontrar os limites de uma linha, e não de uma palavra. Por isso, a partir do momento em que a sequência “e-m-i-s-s-ã-o” não estiver encostando em pelo menos um dos limites da linha, str_detect() não será mais capaz de encontrar tal conjunto de caracteres. Como exemplo, perceba abaixo, que apenas o primeiro elemento de text pôde corresponder à expressão empregada em str_detect(). Ou seja, mesmo que o quarto, quinto e sexto elementos de text possuam a palavra “emissão”, eles não puderam ser encontrados pela expressão \"^emissão$\", devido ao fato de não estarem localizados em pelo menos um dos limites da linha.\n\ntext &lt;- c(\n  \"emissão\",\n  \"A Ford Brasil executou recentemente uma demissão em massa\",\n  \"remissão\",\n  \"Para mais, a emissão de CO2 cresceu no Brasil\",\n  \"emissão de S02 faz parte do processo\",\n  \"A firma foi processada por tal emissão\"\n)\n\nteste &lt;- str_detect(text, \"^emissão$\")\ntext[teste]\n\n[1] \"emissão\"\n\n\nVale destacar que você não precisa necessariamente utilizar os dois metacharacters ao mesmo tempo. Logo, temos a opção de construir uma expressão que possa encontrar uma certa sequência de caracteres ao final ou no início de uma linha. Por exemplo, a expressão abaixo, busca encontrar a sequência “e-m-i-s-s-ã-o” de caracteres quando ela é imediatamente seguida pelo final da linha.\n\nteste &lt;- str_detect(text, \"emissão$\")\ntext[teste]\n\n[1] \"emissão\"                               \n[2] \"remissão\"                              \n[3] \"A firma foi processada por tal emissão\"\n\n\nAlguns outros exemplos de expressões regulares que empregam metacharacters do tipo âncora, além de uma rápida reflexão sobre os caracteres ^ e $, são oferecidos na Figura 10.3. Repare que todas as partes do texto que foram detectadas pela expressão regular, foram novamente marcadas de cinza. Perceba também, que cada seta presente na figura, busca conectar cada uma das partes detectadas do texto, ao componente específico da expressão regular que foi responsável por detectá-la.\n\n\n\n\n\n\n\n\nFigura 10.3: Exemplos e uma reflexão sobre as correspondências encontradas por metacharacters do tipo âncora.\n\n\n\n\n\n\n\n10.8.5 Classes de caracteres (character classes)\nUma estrutura muito importante em expressões regulares são as classes de caracteres, ou character classes. Sendo construída a partir de um par de colchetes ([]), essa estrutura lhe permite listar os possíveis caracteres que você deseja encontrar em um ponto da sequência descrita por sua expressão regular.\nPor exemplo, suponha que você esteja lendo um livro-texto sobre a linguagem R, e que você queira encontrar todas as instâncias do livro que se referem ao termo regex. Você sabe que as regiões que descrevem o assunto no qual você está interessado, vão conter o termo regex, mas você não sabe como o termo regex está citado no texto. Digo, será que o autor está colocando a primeira letra em maiúsculo (Regex)? Ou será que todo o termo está em maiúsculo (REGEX)?\nTendo essa dúvida em mente, você pode criar uma expressão regular, que permita certas variações da palavra regex, ao listar todas as possibilidades em uma dada posição do termo. Primeiro, vamos imaginar que você deseja permitir que a primeira letra do termo seja tanto maiúscula quanto minúscula. No exemplo abaixo, ao incluirmos as letras “r” e “R” dentro da classe de caracteres ([]), estamos estabelecendo que no primeiro caractere da sequência, podemos ter uma letra “r” ou uma letra “R”.\n\ntexto &lt;- c(\n  \"Cada letra, número, ou símbolo presente no texto é um caractere.\",\n  \"Textos são criados ao contornados por aspas (duplas ou simples).\",\n  \"O termo regex é uma abreviação para regular expressions.\",\n  \"Regex é um termo comum no mundo da computação.\",\n  \"Metacharacters alteram consideravelmente o comportamento de um REGEX.\",\n  \"ReGEx? Ou reGex? Talvez RegEX?.\"\n)\n\nteste &lt;- str_detect(texto, \"[Rr]egex\")\ntexto[teste]\n\n[1] \"O termo regex é uma abreviação para regular expressions.\"\n[2] \"Regex é um termo comum no mundo da computação.\"          \n\n\nOu seja, uma classe de caracteres busca descrever os caracteres possíveis para uma única e particular posição da sequência. Logo, a expressão \"[Rr]egex\" não está descrevendo a sequência “[-R-r-]-e-g-e-x”, mas está afirmando que “r-e-g-e-x” e “R-e-g-e-x” são duas sequências de caracteres que queremos encontrar em nossa pesquisa. Com isso, se tivéssemos de permitir todas as possibilidades de capitalização em cada letra do termo, poderíamos fornecer a seguinte expressão à str_detect():\n\nteste &lt;- str_detect(texto, \"[Rr][Ee][Gg][Ee][Xx]\")\ntexto[teste]\n\n[1] \"O termo regex é uma abreviação para regular expressions.\"             \n[2] \"Regex é um termo comum no mundo da computação.\"                       \n[3] \"Metacharacters alteram consideravelmente o comportamento de um REGEX.\"\n[4] \"ReGEx? Ou reGex? Talvez RegEX?.\"                                      \n\n\nDessa maneira, estamos permitindo que str_detect() encontre todas as possibilidades do termo regex, quanto ao uso de capitalização (regex, Regex, REGEX, rEgex, reGex, regEx, regeX, …).\nAs classes de caracteres também são muito utilizadas para criar um intervalo de caracteres possíveis em um determinado ponto. Esses intervalos são rapidamente formados pelo metacharacter - (sinal de menos). Como exemplo, podemos utilizar o atalho [0-9] para listarmos todos os números de 0 a 9 dentro da classe. Esse atalho é extremamente útil quando desejamos encontrar alguma parte numérica em nosso texto, mas nós não sabemos previamente quais números em particular vão estar presentes nesse item.\nPor exemplo, suponha que uma comissão nacional tenha divulgado as colocações de diversos participantes em um torneio de xadrez. Você deseja analisar os participantes e suas respectivas colocações, entretanto, a comissão divulgou os dados como um texto simples em sua página da internet, ao invés de guardar esses dados em uma tabela, ou em alguma outra estrutura que fosse de fácil transposição para o R.\nCom isso, você precisa utilizar uma expressão regular que possa encontrar essas colocações ao longo do texto. Uma possibilidade, seria tentarmos localizar as ocorrências de um número seguido do símbolo de grau (°), ao longo do texto. No exemplo abaixo, as colocações variam de 1 a 6 e, por isso, precisamos listar todos os números neste intervalo dentro de uma classe, e acrescentar o símbolo de grau, formando assim, a expressão \"[123456]°\". Porém, ao invés de listarmos número por número, podemos aplicar o atalho [1-6] para criarmos uma lista contendo todos os números de 1 a 6.\n\ncolocacoes &lt;- c(\n  \"1°: Álvaro\",\n  \"2°: Melissa\",\n  \"3°: Ana\",\n  \"4°: Eduardo\",\n  \"5°: Daniela\",\n  \"6°: Matheus\",\n  \"Não é uma colocação\",\n  \"Também não é uma colocação\",\n  \"31°C\",\n  \"24°F\"\n)\n\nteste &lt;- str_detect(colocacoes, \"[1-6]°\")\ncolocacoes[teste]\n\n[1] \"1°: Álvaro\"  \"2°: Melissa\" \"3°: Ana\"     \"4°: Eduardo\" \"5°: Daniela\"\n[6] \"6°: Matheus\" \"31°C\"        \"24°F\"       \n\n\nComo podemos ver acima, conseguimos localizar todas as colocações. No entanto, perceba que a expressão \"[1-6]°\" também pôde encontrar informações que se referem a temperaturas (celsius e fahrenheit). Portanto, a expressão \"[1-6]°\" é muito abrangente para o nosso caso e, em função disso, precisamos descrever em mais detalhes o texto que desejamos. Tudo o que precisamos fazer para corrigir o resultado acima, é incluir uma expressão que encontre um número seguido por um símbolo de grau, exceto quando as letras C ou F estão logo após o símbolo de grau.\nPara essa tarefa, podemos utilizar o comportamento negativo de uma classe. Em outras palavras, além de listar os caracteres aceitos em uma certa posição, nós também temos a capacidade de utilizar uma classe de caracteres para listar todos os caracteres que não podem estar situados em uma determinada posição da sequência.\nPara definir os caracteres não desejados em uma posição, você deve iniciar a sua classe, por um acento circunflexo, logo antes de listar os caracteres em questão ([^...]). Com isso, se desejamos evitar as letras C e F (independente de sua capitalização) precisaríamos da sub expressão [^CcFf] logo após o símbolo de grau, formando assim, a expressão regular abaixo:\n\nteste &lt;- str_detect(colocacoes, \"[1-6]°[^CcFf]\")\ncolocacoes[teste]\n\n[1] \"1°: Álvaro\"  \"2°: Melissa\" \"3°: Ana\"     \"4°: Eduardo\" \"5°: Daniela\"\n[6] \"6°: Matheus\"\n\n\nPortanto, sempre que você encontrar uma classe que contém um acento circunflexo como seu primeiro item, você sabe que essa classe está negando os caracteres listados dentro dela (exemplo: \"[^1-6_!]\", não são permitidos nessa posição qualquer número entre 1 e 6, o símbolo underscore ou um ponto de exclamação). Logo, na posição que essa classe representa, não devem ser encontrados os caracteres que estão listados dentro dela. Mas se essa classe não possui tal acento, ou se esse acento circunflexo se encontra a partir do segundo caractere listado, a classe em análise está utilizando seu comportamento positivo (ou afirmativo), de modo que os caracteres listados em seu interior, podem sim estar naquela posição.\nComo um outro exemplo, veja abaixo, as correspondências geradas pela expressão \"[0-9][^Ffh]\", que utiliza ambos os modos de classe (negativa e positiva). Essa expressão, busca encontrar um número entre 0 e 9, que é imediatamente seguido por um caractere qualquer (que não seja as letras “F”, “f”e “h”). Repare no caso do texto \"A5\", no qual a expressão não é capaz de localizá-lo pelo simples fato de que o texto acaba no dígito 5. Lembre-se que cada classe de caracteres representa um caractere a ser encontrado em uma determinada posição da sequência. Logo, mesmo que a parte [^Ffh] esteje listando os caracteres que não podem ser encontrados, ela está automaticamente definindo que algum caractere deve ser encontrado na segunda posição da sequência.\n\n\n\n\n\nUm exemplo de expressão regular que emprega ambos os modos de classes de caractere (positiva e negativa)\n\n\n\n\nAlém desses pontos, repare acima, que o metacharacter ^ (acento circunflexo) tem um papel completamente diferente dentro de uma classe de caracteres, se comparado ao papel que ele exerce fora dela. Em resumo, o caractere ^ fora de uma classe, é um metacharacter do tipo âncora, sendo capaz de definir o início de uma linha; mas dentro de uma classe, ele está determinando o comportamento adotado pela classe em questão, de forma que os caracteres listados nessa classe não devem ser encontrados na posição que essa classe simboliza.\nLogo, é muito importante destacar o fato de que diversos caracteres possuem um comportamento profundamente diferente, quando inseridos em uma classe de caracteres. Fique atento a isso! Se algum metacharacter estiver se comportando de maneira inesperada, é possível que essa diferença entre os mundos de dentro e de fora de uma classe seja a fonte de sua surpresa. De certo modo, você pode compreender essa situação, como se as classes possuíssem a sua própria mini linguagem, com o seu próprio conjunto de metacharacters, separados da realidade de fora delas (FRIEDL, 2006).\nPor outro lado, e se você desejasse incluir os metacharacters - e ^ como possíveis caracteres para uma determinada posição? Como o caractere - cria uma sequência, você precisa listá-lo logo no início de sua classe (ex: \"[-1-6]\", que permite um número entre 1 e 6, além de um sinal de menos). Em contrapartida, o caractere ^ exerce o seu comportamento especial quando é posicionado como o primeiro item de uma classe. Por essa razão, você precisaria listá-lo em uma outra posição qualquer da classe, para que ele se comportasse como um simples acento circunflexo (ex: \"[ABC^]\", que permite as letras A, B e C, além de um acento circunflexo).\n\na &lt;- c(\"A-B\", \"CDE-F\", \"12^54\", \"R$1230,2\", \"BRA\")\nteste &lt;- str_detect(a, \"[-^]\")\na[teste]\n\n[1] \"A-B\"   \"CDE-F\" \"12^54\"\n\n\nAté o momento, mostramos apenas o atalho para listar uma sequência numérica (ex: \"[0-9]\"). Mas também temos um outro atalho para listarmos um intervalo específico (ou todas as letras) do alfabeto. Para isso, podemos utilizar o atalho [a-z] para letras minúsculas, e [A-Z] para letras maiúsculas. Por exemplo, suponha que você possua o conjunto de códigos mostrados no objeto codes. Suponha também, que os códigos que contém letras de “A” a “F”, correspondem a unidades manufaturadas em Belo Horizonte, enquanto os códigos que contém letras de “G” a “Z” dizem respeito a unidades fabricadas na região de São Paulo.\nCom isso em mente, para reunirmos todos os códigos de produtos construídos em Belo Horizonte, precisaríamos apenas encontrar os códigos que contém qualquer letra dentro do intervalo de “A” e “F”. Todavia, repare que a capitalização das letras presentes nos códigos, varia. Por isso, precisamos combinar o mesmo intervalo de letras em ambos os estilos de capitalização. Dessa maneira, geramos a expressão abaixo, que contém ambos os intervalos (\"[a-fA-F]\").\n\ncodes &lt;- c(\"AeF15\", \"CCd31\", \"17GHJ\", \"Lmm96\", \"ee3f8\", \"BA45B\",\n           \"EccF2\", \"675Cc\", \"hkJ78\", \"q401Q\", \"iop67\", \"DCa98\")\nteste &lt;- str_detect(codes, \"[a-fA-F]\")\ncodes[teste]\n\n[1] \"AeF15\" \"CCd31\" \"ee3f8\" \"BA45B\" \"EccF2\" \"675Cc\" \"DCa98\"\n\n\n\n10.8.5.1 Conclusão e algumas dicas extras\nPortanto, uma classe de caracteres busca listar os caracteres que podem ou não ser encontrados na posição da sequência que essa classe representa. Em síntese, podemos interpretar o seu uso da seguinte maneira:\n\n[abc]: encontre a ou b ou c.\n[^abc]: encontre qualquer caractere, exceto a, b ou c.\n\nAlém disso, uma classe de caracteres lhe permite criar ranges, ou intervalos de caracteres possíveis, como:\n\n[0-9]: encontre qualquer número entre 0 e 9.\n[a-z]: encontre qualquer letra (minúscula) entre a e z.\n[A-Z]: encontre qualquer letra (maiúscula) entre A e Z.\n\nPorém, para além dos usos apresentados até aqui, o R nos oferece alguns atalhos para essas construções, sendo os principais:\n\n\\d: encontre um dígito (atalho para [0-9]).\n\\s: encontre qualquer espaço em branco (atalho para [ \\t\\n]).\n\\w: encontre um caractere alfanumérico ou um underline (atalho para [a-zA-Z0-9_])\n\nLembre-se que, no R, para inserirmos uma barra inclinada à esquerda em uma string, nós precisamos escrever duas barras inclinadas à esquerda. Logo, para inserirmos, por exemplo, o atalho \\d em alguma de nossas expressões regulares, somos obrigados a digitar \\\\d.\n\n\n\n10.8.6 Representando qualquer caractere com um ponto\nVocê pode representar qualquer caractere em uma expressão regular, por meio do metacharacter . (ponto final). Ou seja, um ponto final em uma expressão regular é capaz de encontrar qualquer caractere (seja ele um número, um símbolo ou uma letra) na posição que ele representa. Logo, a expressão \"B.3\" significa na prática: uma letra “B”, imediatamente seguida por um caractere qualquer, que por sua vez, é imediatamente seguido por um número 3.\nPor exemplo, suponha que você queira encontrar a data “20/02/2019”, mas você sabe que essa data pode se encontrar em diferentes formatos, como 20.02.2019, ou 20-02-2019. Tendo isso em mente, você provavelmente tentaria uma expressão como \"20[-/.]02[-/.]2019\". Por outro lado, poderíamos atingir o mesmo resultado ao substituirmos as classes de caracteres por pontos finais, gerando assim, a expressão \"20.02.2019\".\n\nvec &lt;- c(\"20.02.2019\", \"20-02-2019\", \"20/02/2019\",\n         \"A senha é 2060212019\", \"20$02#2019\")\n\nteste &lt;- str_detect(vec, \"20.02.2019\")\nvec[teste]\n\n[1] \"20.02.2019\"           \"20-02-2019\"           \"20/02/2019\"          \n[4] \"A senha é 2060212019\" \"20$02#2019\"          \n\n\nPorém, é importante que você tenha cuidado ao utilizar esse metacharacter. Pois como podemos ver acima, a expressão \"20.02.2019\" também é capaz de encontrar o texto “20$02#2019”, assim como o texto “A senha é 2060212019”. Portanto, as chances de você encontrar o que você não deseja, podem aumentar a depender da maneira em que você aplica esse metacharacter em sua expressão.\n\n\n10.8.7 Criando alternativas (alternation)\nHá certos momentos, em que não conseguimos expor todos os nossos desejos com uma única expressão. Por essa razão, temos o metacharacter | (barra vertical) que nos permite combinar diferentes sub expressões em uma só. Dessa maneira, a função responsável pela pesquisa, irá procurar por qualquer texto que atenda a pelo menos uma dessas sub expressões. Sendo este efeito, comumente denominado de alternação (ou alternation).\nComo exemplo, na seção anterior estávamos tentando encontrar o termo regex, ao longo de várias sentenças, que estão reproduzidas logo abaixo, no vetor texto. Na primeira instância, fizemos uso de uma classe de caracter para permitirmos uma letra “r” tanto minúscula quanto maiúscula, no primeiro caractere da sequência de nossa expressão (\"[Rr]egex\").\nPorém, temos a capacidade de atingir o mesmo resultado, com o uso de alternação. Basta separarmos os dois casos que estamos tentando representar, pelo metacharacter |, formando assim, a expressão abaixo (\"Regex|regex\"):\n\ntexto &lt;- c(\n  \"Cada letra, número, ou símbolo presente no texto é um caractere.\",\n  \"Textos são criados ao contornados por aspas (duplas ou simples).\",\n  \"O termo regex é uma abreviação para regular expressions.\",\n  \"Regex é um termo comum no mundo da computação.\",\n  \"Metacharacters alteram consideravelmente o comportamento de um REGEX.\",\n  \"ReGEx? Ou reGex? Talvez RegEX?.\"\n)\n\nteste &lt;- str_detect(texto, \"Regex|regex\")\ntexto[teste]\n\n[1] \"O termo regex é uma abreviação para regular expressions.\"\n[2] \"Regex é um termo comum no mundo da computação.\"          \n\n\nLembre-se que a realidade dentro de uma classe de caracteres é completamente diferente de seu exterior. Logo, dentro de uma classe de caracteres, o caractere | é simplesmente um caractere literal, assim como as letras “x” e “r”. Por isso, uma expressão como \"Rege[x|r]egex\", estaria na verdade procurando por sequências como “R-e-g-e-x-e-g-e-x”, “R-e-g-e-|-e-g-e-x” e “R-e-g-e-r-e-g-e-x”.\nPara mais, é importante que você entenda que cada sub expressão conectada pelo metacharacter |, representa uma expressão regular diferente das demais.\nVeja como exemplo, a expressão abaixo. A primeira sub expressão (\"[3-6]°\") seleciona um texto que contenha um número entre 3 e 6 imediatamente seguido de um símbolo de grau. A segunda sub expressão (\"is[ao]\") seleciona um texto que contenha a sequência “i-s-a” ou “i-s-o” de caracteres. Já a terceira sub expressão (R\\\\$[0-9]+(,[0-9][0-9])?), que é bem mais elaborada do que as outras duas, busca selecionar um texto que contenha um valor monetário. Com isso, qualquer texto que se encaixe em alguma dessas condições, será selecionado pela função.\n\nvec &lt;- c(\"1230\", \"Tenho consulta no dia 25\", \"R$12,45\", \n         \"Essa máquina custa R$320,21\", \"Márcia\", \"Isotônico\",\n         \"Álcool isopropílico\", \"Hoje fez 30°\", \"4° é muito frio!\")\nteste &lt;- str_detect(vec, \"[3-6]°|is[ao]|R\\\\$[0-9]+(,[0-9][0-9])?\")\nvec[teste]\n\n[1] \"R$12,45\"                     \"Essa máquina custa R$320,21\"\n[3] \"Álcool isopropílico\"         \"4° é muito frio!\"           \n\n\nUm outro detalhe importante, é que você pode limitar o alcance das alternativas, ao contorná-las com parênteses. Em outras palavras, ao invés de fornecer várias sub expressões, você pode fornecer diferentes sub expressões dentro de uma expressão “geral”.\nPor exemplo, vamos voltar à expressão \"Regex|regex\". Se nós isolarmos a seção \"ex|re\", temos um resultado completamente diferente do que vimos anteriormente, pois as sub expressões passam a ser “e-x” e “r-e”, e não “r-e-g-e-x” e “R-e-g-e-x” como anteriormente. Dessa maneira, estamos na verdade procurando por textos que contenham a sequência “R-e-g-e-x-g-e-x” ou a sequência “R-e-g-r-e-g-e-x”.\n\nvec &lt;- c(\"regex\", \"Regex\", \"ISORegex-18930\", \"Regexgexgexgexgex\")\nteste &lt;- str_detect(vec, \"Reg(ex|re)gex\")\nvec[teste]\n\n[1] \"Regexgexgexgexgex\"\n\n\nDessa vez, importando um exemplo diretamente da obra de FRIEDL (2006), suponha que você possua um arquivo de texto, contendo uma lista de todos os e-mails de sua caixa de entrada. Com esse arquivo, poderíamos utilizar a expressão \"^(From|Subject|Date):\" para extraírmos apenas as linhas do arquivo que contém a referência do remetente (From:), do assunto (Subject:) e da data de envio (Date:) de cada e-mail. Perceba também, que a expressão \"^(From|Subject|Date):\" é equivalente à expressão \"^From:|^Subject:|^Date:\".\n\nemail &lt;- readr::read_lines(\"\nFrom: elena_campaio@gmail.com Jun 15 2019 07:05\nReceived: from elena_campaio@gmail.com\nTo: pedropark99@gmail.com\nDate: Thu, Jun 15 2019 07:05\nMessage-Id: &lt;20190322145154232.elena_campaio@gmail.com&gt;\nSubject: Nova reunião\nX-Mailer: by mailbox (Version 8.5.1) BellM Company, Copyright 2005-2019\n\nBom dia Pedro, poderíamos nos encontrar às 10hrs?\n\n\nFrom: pedropark99@gmail.com Jun 15 2019 08:10 \nReceived: from elena_campaio@gmail.com\nTo: elena_campaio@gmail.com\nDate: Thu, Jun 15 2019 08:10\nMessage-Id: &lt;20190322145155198.elena_campaio@gmail.com&gt;\nSubject: Re: Nova reunião\nReply-To: elena_campaio@gmail.com &lt;20190322145154232.elena_campaio@gmail&gt;\nX-Mailer: by mailbox (Version 8.5.1) BellM Company, Copyright 2005-2019\n\nOk Elena! Podemos nos encontrar esse horário.\")\n\n\nteste &lt;- str_detect(email, \"^(From|Subject|Date):\")\nemail[teste]\n\n## [1] \"From: elena_campaio@gmail.com Jun 15 2019 07:05\"\n## [2] \"Date: Thu, Jun 15 2019 07:05\"\n## [3] \"Subject: Nova reunião\"\n## [4] \"From: pedropark99@gmail.com Jun 15 2019 08:10 \"\n## [5] \"Date: Thu, Jun 15 2019 08:10\"\n## [6] \"Subject: Re: Nova reunião\"\n\n\n10.8.8 Quantificadores (quantifiers) ou definindo repetições\nHá certos momentos em que precisamos permitir que um certo conjunto de caracteres sejam encontrados múltiplas vezes em uma mesma sequência de caracteres. Um bom exemplo disso, é a expressão que utilizamos na seção anterior \"R\\\\$[0-9]+(,[0-9][0-9])?\" para encontrarmos um valor monetário. Temos três partes principais nessa expressão, sendo elas: 1) R\\\\$; 2) [0-9]+; e 3) (,[0-9][0-9])?.\nPrimeiro, o que seria um valor monetário? Certamente seria um valor numérico. Porém, um número pode significar qualquer coisa! Talvez uma medida de peso (Kg), idade (anos), volume (L) ou qualquer outra variável contínua que você imaginar. Logo, precisamos de algum item que possa identificar esse número como uma medida de valor, e esse item se trata do símbolo da moeda brasileira (R$). Qualquer valor numérico presente em seu texto que estiver acompanhado desse símbolo é um valor monetário.\nCom isso, teríamos a expressão \"R\\\\$[0-9]\" como uma tentativa inicial. Perceba que eu tive de contornar o comportamento especial do metacharacter $, ao antecedê-lo por duas barras inclinadas. Dessa maneira, a expressão \"\\\\$\" significa de fato o caractere $ (cifrão), e não o fim de uma linha como definimos na seção Âncoras (anchors).\n\nvec &lt;- c(\"Eu peso em torno de 65Kg\", \"Tenho consulta no dia 25\",\n         \"R$1630,45\", \"Eu possuo uma conta de R$74,85 a pagar\", \n         \"R$400\", \"R21\", \"Hoje, R$30 equivale a $5,77 dólares\")\nteste &lt;- str_detect(vec, \"R\\\\$[0-9]\")\nvec[teste]\n\n[1] \"R$1630,45\"                             \n[2] \"Eu possuo uma conta de R$74,85 a pagar\"\n[3] \"R$400\"                                 \n[4] \"Hoje, R$30 equivale a $5,77 dólares\"   \n\n\nEntretanto, não há um limite específico para o número que um valor monetário pode atingir. Em outras palavras, podemos estar nos referindo a míseros centavos ou a milhões de reais. Traduzindo essa afirmação na prática, podemos ter uma quantidade variável de dígitos em nosso valor monetário. O valor R$5 possui apenas 1 dígito, enquanto o valor R$1245 possui 4 dígitos.\nA princípio, essa questão não é tão importante, já que fomos capazes de encontrar todos os textos que contém algum valor monetário, com apenas a expressão \"R\\\\$[0-9]\". Ou seja, mesmo que alguns desses valores possuam 3, 4 ou 6 dígitos, precisamos apenas detectar o seu primeiro dígito antecedido pelo símbolo R$.\nTodavia, essa questão passa a ser crucial, na hipótese de aplicarmos alguma transformação sobre os valores monetários encontrados. Ou seja, se vamos, por exemplo, extrair os valores encontrados; ou substituí-los por algum outro texto; ou utilizá-los como pontos de quebra do texto que os contém; ou empregá-los em algum cálculo, é de extrema importância que possamos detectar todo o valor com a nossa expressão. Apenas para que fique claro, veja a representação abaixo, que mostra os resultados de ambas as expressões mostradas até aqui sobre o valor R$6530,58.\n\n\n\n\n\nExpressões regulares sobre valores monetários\n\n\n\n\nTendo como início, a expressão \"R\\\\$[0-9]\", precisamos permitir uma quantidade variável de dígitos, mais especificamente na parte \"[0-9]\". Em ocasiões como essa, nós podemos utilizar os metacharacters do tipo quantificadores, que incluem os caracteres ? (ponto de interrogação), + (sinal de mais), * (asterisco) e {} (par de chaves). Como o próprio nome do tipo dá a entender, esses metacharacters buscam delimitar a quantidade de vezes que podemos encontrar um certo caractere em nossa sequência. Em outras palavras, esses metacharacters definem o número mínimo e máximo de ocorrências possíveis para um caractere específico de nossa expressão.\nPrimeiro, o metacharacter * representa 0 ocorrências como mínimo e infinitas ocorrências como máximo. Com isso, podemos dizer que o metacharacter * significa: “tente encontrar esse caractere, o maior número de vezes possíveis, contudo, está tudo bem se não conseguirmos encontrá-lo em algum lugar”. Logo, a expressão \"A6*\" nos permite encontrar uma letra “A”, quando acompanhada, por exemplo, pelo “número do diabo” (“A666”), ou por qualquer outra quantidade do número 6, como o texto “A6”, ou “A6666666”. Porém, o metacharacter * também nos dá a possibilidade de não encontrarmos o número 6. Por isso, a expressão \"A6*\" também é capaz de encontrar o texto “Ana Luísa”, mesmo que ele não possua um número 6.\nSegundo, o metacharacter + representa 1 ocorrência como mínimo e infinitas ocorrências como máximo. Por consequência, o metacharacter + expressa: “tente encontrar esse caractere pelo menos uma vez!”. Como exemplo, a expressão \"Isa+\" é capaz de encontrar os textos “Isadora”, “Isaac Newton” e “Isaaaaaa3210”. Mas não é capaz de encontrar o texto “Isótopo”, pois esse texto não possui pelo menos um “a” logo após os caracteres “Is”.\nTerceiro, o metacharacter ? representa 0 repetições como mínimo e 1 repetição como máximo. Isto é, o metacharacter ? busca tornar um caractere completamente opcional. Em outras palavras, ao conectarmos um caractere ou uma sub expressão ao metacharacter ? estamos dizendo algo como: “se esse caractere for encontrado, ótimo! Se não, sem problemas!”. Como exemplo, a expressão \"dr?a\" busca encontrar uma letra “d” imediatamente seguida pelos caracteres “ra”. Mas pelo fato de termos incluído o metacharacter ? logo à frente da letra “r”, tornamos essa letra opcional. Por isso, a expressão \"dr?a\" é capaz de encontrar textos como “engendrar”, “dragão” ou “dramin”, assim como os textos “Adaga” e “reciprocidade”.\nQuarto, o metacharacter {} representa a forma geral de um quantificador. Pois ele nos permite especificar exatamente quais as quantidades mínima e máxima que desejamos para um determinado caractere. Basta preencher o par de chaves com essas duas quantidades, separadas por uma vírgula ({min, max}). Por exemplo, a expressão \"31[0-9]{4,5}\" é capaz de encontrar um código do IBGE referente a um município do estado de Minas Gerais (os dígitos 31 representam o código do estado de MG). Esses códigos do IBGE possuem uma versão curta, que pode variar de 2 a 4 dígitos, entretanto, suas versões mais comumente utilizadas são as de 6 e de 7 dígitos. Como exemplo, os códigos 310620 e 3106200 se referem ao município de Belo Horizonte. Com isso, ao estabelecermos 4 e 5 dígitos como os limites do intervalo representado pela sub expressão [0-9]{4,5}, somos capazes de detectar códigos como 310620 e 3106200, e ao mesmo tempo, descartar códigos como 31062, que possui menos de 4 dígitos após os dígitos 31.\nAlém disso, vale destacar que o objetivo de qualquer metacharacter do tipo quantificador, não é o de determinar o número de vezes que um caractere pode aparecer ao longo do texto, mas sim, o número de vezes que um caractere pode ocorrer em sequência. Por exemplo, a expressão \"(25){2,3}\" busca detectar um número arbitrário de 25’s. Assim sendo, essa expressão é capaz de detectar valores como 25, 252, e 2525, da mesma maneira que o texto “Estive na 25 de Março no último dia 25”.\nPorém, muitas pessoas interpretam que os dois 25’s presentes no texto “Estive na 25 de Março no último dia 25” são detectados pela expressão \"(25){2,3}\", quando na verdade, apenas o primeiro 25 é localizado. Pois o segundo 25 no texto, se encontra a mais de 20 caracteres a frente do primeiro 25. Logo, ao utilizarmos um metacharacter do tipo quantificador, estamos geralmente preocupados com a possibilidade de o mesmo caractere aparecer múltiplas vezes em sequência (um atrás do outro).\nVoltando à expressão \"R\\\\$[0-9]\", com tudo o que descrevi nos parágrafos anteriores, nós podemos adicionar um + logo após [0-9]. Dessa maneira, estamos desejando encontrar pelo menos um número qualquer entre 0 e 9, logo após o símbolo monetário R$. Com isso, temos a expressão \"R\\\\$[0-9]+\", que é capaz de encontrar tanto “R$3” quanto “R$3050”.\nNo entanto, ainda temos a possibilidade de encontrarmos um valor monetário que inclui centavos. Ou seja, podemos encontrar um número que seja seguido por uma vírgula e dois outros dígitos que definem os centavos. Por isso, podemos ainda acrescentar a parte \",[0-9][0-9]\" para captar essa possível parte de nosso valor monetário.\n\nvec &lt;- c(\"8730\", \"R$21\", \"R$3120,50\", \"R$43026\", \"R$45,10\")\nteste &lt;- str_detect(vec, \"R\\\\$[0-9]+,[0-9][0-9]\")\nvec[teste]\n\n[1] \"R$3120,50\" \"R$45,10\"  \n\n\nPorém, repare ainda, que ao adicionarmos a seção \",[0-9][0-9]\", a nossa expressão regular não é mais capaz de detectar valores que não possuem uma parte para os centavos, como R$21 e R$43026. É por essa razão, que eu contorno essa seção por parênteses, e adiciono o metacharacter ? logo em seguida. Pois dessa forma, essa seção passa a ser opcional. Ou seja, a parte dos centavos deixa de ser obrigatória.\n\nvec &lt;- c(\"8730\", \"R$21\", \"R$3120,50\", \"R$43026\", \"R$45,10\")\nteste &lt;- str_detect(vec, \"R\\\\$[0-9]+(,[0-9][0-9])?\")\nvec[teste]\n\n[1] \"R$21\"      \"R$3120,50\" \"R$43026\"   \"R$45,10\"  \n\n\n\n10.8.8.1 Conclusão e algumas dicas extras\nRecapitulando o que vimos até aqui, temos que os números de ocorrências representados por cada metacharacter do tipo “quantificador” são:\n\n?: 0 ou 1 ocorrência.\n+: 1 ou mais ocorrências.\n*: 0 ou mais ocorrências.\n{min, max}: entre min e max ocorrências.\n\nPara além do que ainda não foi comentado nessa seção, você pode utilizar novamente o metacharacter {}, para especificar um número específico de ocorrências que você deseja para um caractere, ou então, definir apenas o número mínimo ou o número máximo de repetições. Com isso, temos que:\n\n{n}: exatamente n ocorrências.\n{min,}: pelo menos min ocorrências.\n{,max}: até max ocorrências.\n\n\n\n\n10.8.9 Determinando os limites de uma palavra\nComo estabelecemos anteriormente, expressões regulares não tem a capacidade de diferenciar palavras, e muito menos, de identificar os seus limites. Por essa razão, para termos garantia de que vamos encontrar uma palavra específica no resultado de uma expressão regular, precisamos estabelecer limites para a pesquisa.\nNa seção sobre Âncoras (anchors), utilizamos os metacharacters do tipo âncora (^ e $) para estipularmos os limites da palavra a ser pesquisada. Porém, esses metacharacters não foram criados para esse objetivo. Essa afirmação fica clara, ao retornarmos ao exemplo utilizado na seção supracitada.\nNaquela ocasião, estávamos tentando encontrar todos os textos contidos no vetor text, que possuíssem a palavra “emissão”. Entretanto, ao utilizarmos a expressão \"^emissão$\", fomos capazes de encontrar apenas o primeiro elemento de text. Sendo que, de acordo com o nosso objetivo, também desejamos localizar o quarto, quinto e sexto elementos de text. Pois eles também possuem a palavra “emissão” em alguma instância.\n\ntext &lt;- c(\n  \"emissão\",\n  \"A Ford Brasil executou recentemente uma demissão em massa\",\n  \"remissão\",\n  \"Para mais, a emissão de CO2 cresceu no Brasil\",\n  \"emissão de S02 faz parte do processo\",\n  \"A firma foi processada por tal emissão\"\n)\n\nteste &lt;- str_detect(text, \"^emissão$\")\ntext[teste]\n\n[1] \"emissão\"\n\n\nPor isso, precisamos de uma nova estratégia para estipularmos esses limites. Lembre-se que uma expressão regular, nada mais é, do que uma descrição concisa de uma sequência específica de caracteres. Logo, precisamos encontrar alguma forma de descrevermos os caracteres que podem representar os limites de uma palavra.\nTodavia, para isso, nós precisamos primeiro identificar o que é o limite de uma palavra. Ou redefinindo a questão, o que exatamente separa uma palavra das demais? Com algum tempo de reflexão, você talvez chegue a conclusão de que o que separa uma palavra da outra, são espaços em branco, ou então, símbolos de pontuação, como um ponto final, ou uma vírgula.\nPortanto, precisamos incluir em ambos os lados da palavra “emissão” alguma expressão que possa descrever especificamente esses caracteres, como a expressão \"(\\\\s|[!.,?])\". Repare que o par de parênteses nessa expressão, busca apenas limitar o alcance do metacharacter |, que está separando duas alternativas, ou duas sub expressões (\\\\s e [!.,?]) que podem descrever os caracteres de nosso interesse. Lembre-se que o termo \\\\s representa o comando \\s, que é um atalho para uma classe de caracteres que busca localizar qualquer tipo de espaço em branco.\n\nteste &lt;- str_detect(text, \"(\\\\s|[!.,?])emissão(\\\\s|[!.,?])\")\ntext[teste]\n\n[1] \"Para mais, a emissão de CO2 cresceu no Brasil\"\n\n\nContudo, perceba acima, que o resultado de nossa pesquisa continua incorreta. Há algum outro detalhe que estamos esquecendo de incluir em nossa expressão. Pois dessa vez, apenas o quarto elemento de text foi retornado. Isso ocorre, porque estamos ignorando a possibilidade da palavra de nosso interesse, ser a responsável por iniciar ou terminar uma linha do texto. Logo, precisamos acrescentar os metacharacters ^ e $, em nossa descrição dos limites de uma palavra. Com isso, temos as expressões (^|\\\\s|[!.,?]) e ($|\\\\s|[!.,?]).\n\nteste &lt;- str_detect(text, \"(^|\\\\s|[!.,?])emissão($|\\\\s|[!.,?])\")\ntext[teste]\n\n[1] \"emissão\"                                      \n[2] \"Para mais, a emissão de CO2 cresceu no Brasil\"\n[3] \"emissão de S02 faz parte do processo\"         \n[4] \"A firma foi processada por tal emissão\"       \n\n\nAgora sim, fomos capazes de encontrar todos os textos presentes em text que possuem a palavra “emissão”.\n\n10.8.9.1 Conclusão e algumas dicas extras\nPara pesquisarmos por palavras específicas em uma expressão regular, nós precisamos incluir uma descrição dos caracteres que podem representar os limites físicos de uma palavra. Os limites de uma palavra geralmente assumem no formato de:\n\nUm espaço em branco (descrito por [ ] ou por \\\\s).\nPontuações (vírgulas, ponto final, etc.; descrito por [!.,?]).\nInício ou o fim de uma linha (descrito por ^ e $).\n\nVale ainda destacar, o fato de que o R nos oferece um atalho para indicarmos o limite de uma palavra, que se trata do comando \\b, ou como deve ser escrito no R, \\\\b. Consequentemente, se você desejasse encontrar, por exemplo, a palavra “camisa”, você poderia utilizar a expressão \"\\\\bcamisa\\\\b\".\n\n\n\n10.8.10 Agrupamentos e backreferencing\nEm vários estilos de expressões regulares, parênteses são capazes de “lembrar” o texto encontrado pela sub expressão que eles encapsulam (FRIEDL, 2006, pp. 21). Em expressões regulares, esse mecanismo é comumente denominado de backreferencing.\nEm resumo, ao contornarmos uma sub expressão com um par de parênteses, nós estamos formando um “grupo”, e qualquer que seja o pedaço de texto encontrado especificamente por esse grupo, nós somos capazes de reutilizar esse texto dentro da mesma expressão que o localizou, por meio de suas referências numéricas, como \\\\1, \\\\2, \\\\3, e assim por diante. Entenda que essas referências numéricas, nada mais são do que índices de cada par de parênteses, ou de cada grupo presente em sua expressão regular. Logo, o índice \\\\1 se refere ao texto localizado pela sub expressão do primeiro par de parênteses. Já o índice \\\\2, se refere ao texto descrito pela sub expressão do segundo par de parênteses. E assim segue.\nO exemplo clássico desse tipo de operação, está na localização de letras ou palavras repetidas, em uma determinada cadeia de texto. Por exemplo, a expressão abaixo (\"(..)\\\\1\"), citada por (WICKHAM; GROLEMUND, 2017, pp. 206), busca encontrar dentro do vetor fruit, alguma palavra que possua um par de letras repetido em sequência. Por isso, palavras como “banana” e “coconut” são encontradas por essa expressão.\n\nteste &lt;- str_detect(fruit, \"(..)\\\\1\")\nfruit[teste]\n\n[1] \"banana\"      \"coconut\"     \"cucumber\"    \"jujube\"      \"papaya\"     \n[6] \"salal berry\"\n\n\nPortanto, dentro da expressão \"(..)\\\\1\", o índice \\\\1 está fazendo alusão ao par de caracteres encontrados pela sub expressão \"(..)\". Entretanto, é importante que você tenha cuidado aqui. Pois o índice \\\\1 não corresponde à expressão regular \"(..)\". Ou seja, a expressão \"(..)\\\\1\" não é equivalente à expressão \"(..)(..)\". Perceba que caso essas expressões fossem iguais, estaríamos simplesmente pesquisando por uma sequência de 4 caracteres quaisquer. Logo, não apenas a correspondência detectada pela expressão seria “banana”, mas também, palavras como “raspberry” e “pomegranate” estariam inclusas no resultado (o que não ocorre acima).\n\n\n\n\n\nComo o mecanismo de pesquisa funciona quando utilizamos backreferencing\n\n\n\n\nPor isso, utilizamos o índice \\\\1 quando desejamos encontrar o mesmo pedaço de texto, ou a mesma sequência de caracteres encontrada pelo grupo a que se refere. Com isso, backreferencing se torna um mecanismo útil quando ainda não conhecemos o texto repetido a ser encontrado, ou quando sabemos que esse texto pode variar violentamente ao longo do texto. Por exemplo, suponha que exista em nosso texto, três casos de palavras repetidas (“que que”, “da da” e “ele ele”). Para encontrar esses casos, você talvez tentaria a expressão \"\\\\bque que\\\\b|\\\\bda da\\\\b|\\\\bele ele\\\\b\". Porém, seria muito desgastante escrever uma alternativa para cada variação.\nPor esse motivo, poderíamos resumir esses casos com o uso de backreferencing. Um exemplo de expressão seria \"\\\\b(.+) \\\\1\\\\b\". Dessa forma, a expressão \"(.+)\" busca encontrar uma sequência qualquer de caracteres, e o índice \\\\1 tenta encontrar essa mesma sequência de caracteres logo após um espaço em branco.\nAlém desses pontos, repare que utilizamos o atalho \\\\b (que apresentamos ao final da seção anterior) para definirmos os limites de palavras, ao longo de várias dessas expressões. Se você está querendo descobrir palavras repetidas em seus textos, você com certeza deseja definir esses limites de palavras. Pois caso você não o faça, as repetições de uma sequência específica de caracteres, pelas quais você estaria pesquisando, poderiam ocorrer em qualquer lugar e invadir o espaço de outras palavras.\n\n\n\n\n\nA importância de se incluir os limites de palavras em pesquisas que utilizam backreferencing\n\n\n\n\nIsso significa, que a expressão \"(que) \\\\1\" seria capaz de encontrar o texto “A imagem de Nakaque queima em meu corpo”, ou o texto “É claro que quero!”. Ampliando esse exemplo para uma expressão mais geral, poderíamos rapidamente realizar que a expressão \"(.+) \\\\1\" seria capaz de encontrar textos como “Sutil ilustração”, assim como “fez-se engendrado”. Dessa forma, o atalho \\\\b impõe limites a nossa pesquisa, que evitam esse tipo de inconveniência.\n\n\n10.8.11 Mais sobre padrões\nMesmo estando presente em diversos programas e linguagens, as expressões regulares possuem certa variabilidade, ou apresentam diferentes “gostos” ou “estilos” em cada uma dessas plataformas.\nDito de outra forma, as linguagens JavaScript, Python e R, oferecem um mecanismo próprio de expressões regulares, porém, a forma como esse mecanismo é implementado e quais são as funcionalidades que ele oferece em cada linguagem, pode variar.\nPortanto, existem alguns padrões diferentes estabelecidos de expressões regulares. Apesar disso, a maior parte dos programas e linguagens de programação utilizam o padrão mais popular e completo de todos, que é o padrão criado pela linguagem Perl. Todas as linguagens acima oferecem pacotes e módulos que te permitem utilizar esse padrão.\nContudo, por padrão, as funções da família grep() adotam um padrão diferente de expressões regulares estendidas (extended regular expressions), chamado de POSIX 1003.2, o qual é equivalente ao estilo oferecido pelo programa egrep. Entretanto, essas funções também permitem o uso de expressões regulares no estilo adotado pela linguagem Perl. Basta configurar o seu argumento perl para TRUE.\nPor outro lado, as funções do pacote stringr utilizam as bibliotecas em C do projeto ICU (International Components for Unicode), que oferecem um estilo de expressões regulares muito próximo do padrão da linguagem Perl. Para mais detalhes sobre essa biblioteca, além de uma lista bem útil de todos os metacharacters disponíveis, você pode consultar o site do projeto.",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulação e transformação de *strings* com `stringr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/10-strings.html#substituindo-partes-de-um-texto-com-str_replace",
    "href": "Capítulos/10-strings.html#substituindo-partes-de-um-texto-com-str_replace",
    "title": "10  Manipulação e transformação de strings com stringr",
    "section": "10.9 Substituindo partes de um texto com str_replace()",
    "text": "10.9 Substituindo partes de um texto com str_replace()\nA função str_replace() e sua variante str_replace_all(), lhe permite aplicar uma expressão regular sobre o seu texto, e substituir a área encontrada (ou áreas encontradas) por um novo valor de seu interesse. Por exemplo, se eu possuo o conjunto de palavras abaixo, e desejo substituir qualquer vogal por um underline, eu precisaria do seguinte comando.\n\npalavras &lt;- c(\"arquivo\", \"estante\", \"livro\", \"estiagem\",\n              \"dinheiro\", \"paz\")\n\npalavras &lt;- str_replace(palavras, \"[aeiou]\", \"_\")\n\npalavras\n\n[1] \"_rquivo\"  \"_stante\"  \"l_vro\"    \"_stiagem\" \"d_nheiro\" \"p_z\"     \n\n\nEntretanto, perceba acima, que apenas a primeira vogal é alterada. Isso não apenas é um comportamento natural da função str_replace(), mas também é um padrão adotado por muitos dos sistemas de expressão regular. Como foi colocado por (FRIEDL, 2006, pp. 148): “any match that begins earlier (leftmost) in the string is always preferred over any plausible match that begins later”. Com isso, o autor quis destacar que o ato de parar a pesquisa na primeira correspondência encontrada, faz parte dos princípios de muitas expressões regulares.\nPorém, em muitos momentos, haverá a necessidade de sobrepor esse comportamento, de forma que a sua expressão possa encontrar todas as correspondências presentes em uma string. Por esse motivo, o pacote stringr oferece diversas funções variantes que terminam com o padrão *_all(). Essas funções buscam justamente solucionar esse problema e, por isso, aplicam a expressão regular sobre todo o texto, com o objetivo de encontrar o maior número possível de correspondências.\nPortanto, ao empregarmos a variante str_replace_all(), desejamos substituir todas as correspondências encontradas por uma expressão regular em cada string, por um novo valor textual. Veja que o exemplo abaixo é praticamente idêntico ao anterior, apenas a função str_replace() foi alterada para str_replace_all().\n\npalavras &lt;- str_replace_all(palavras, \"[aeiou]\", \"_\")\n\npalavras\n\n[1] \"_rq__v_\"  \"_st_nt_\"  \"l_vr_\"    \"_st__g_m\" \"d_nh__r_\" \"p_z\"     \n\n\nComo um outro exemplo, poderíamos simular o trabalho executado pela função str_trim(), com as funções str_replace() e str_replace_all(). O comando str_replace(vec, \"^( )+\", \"\") estaria procurando por qualquer linha que se inicia por uma quantidade \\(y\\) (sendo \\(y &gt; 0\\)) de espaços em branco, e substituindo esses espaços por nada (\"\"). Dessa maneira, este comando equivale à str_trim(vec, side = \"left). Já o comando str_replace_all(vec, \"^( )+|( )+$\", \"\"), buscaria qualquer linha que se inicia ou termina por uma quantidade x de espaços em branco, e em seguida, substituiria esses espaços por nada. Sendo assim, esse comando equivale à str_trim(vec, side = \"both\").\n\nvec &lt;- c(\n  \"  Russo é a língua oficial da Rússia   \",\n  \"   Japão se encontra na Ásia\",\n  \"Português nunca foi tão difícil!   \",\n  \"  224,90 \"\n)\n\nstr_replace(vec, \"^( )+\", \"\")\n\n[1] \"Russo é a língua oficial da Rússia   \"\n[2] \"Japão se encontra na Ásia\"            \n[3] \"Português nunca foi tão difícil!   \"  \n[4] \"224,90 \"                              \n\nstr_replace_all(vec, \"^( )+|( )+$\", \"\")\n\n[1] \"Russo é a língua oficial da Rússia\" \"Japão se encontra na Ásia\"         \n[3] \"Português nunca foi tão difícil!\"   \"224,90\"                            \n\n\nPara mais, backreferencing se torna uma ferramenta extremamente útil em conjunto com str_replace(). Por exemplo, suponha que você tenha se esquecido de adicionar o símbolo da moeda brasileira em cada valor numérico. Com a expressão regular \"([0-9]+(,[0-9]+)?)\" podemos encontrar esses valores numéricos. Repare que toda a expressão está contornada por parênteses, logo, todo o número é salvo para o índice \\\\1. Dessa maneira, basta antecedermos esse índice pelo símbolo que desejamos inserir (\"R$\\\\1\").\n\nvec &lt;- c(\"O litro de leite custa 3,50\", \"O ingresso foi caro. Mais de 500 reais!\", \n         \"230015\")\n\nstr_replace(vec, \"([0-9]+(,[0-9]+)?)\", \"R$\\\\1\")\n\n[1] \"O litro de leite custa R$3,50\"            \n[2] \"O ingresso foi caro. Mais de R$500 reais!\"\n[3] \"R$230015\"",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulação e transformação de *strings* com `stringr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/10-strings.html#dividindo-strings-com-str_split",
    "href": "Capítulos/10-strings.html#dividindo-strings-com-str_split",
    "title": "10  Manipulação e transformação de strings com stringr",
    "section": "10.10 Dividindo strings com str_split()",
    "text": "10.10 Dividindo strings com str_split()\nVocê também pode utilizar uma expressão regular para detectar “pontos de quebra” em uma cadeia de texto e, em seguida, quebrar essa cadeia nesses pontos determinados. Repare no exemplo abaixo, que a função str_split() nos retorna como resultado, uma lista de vetores, onde cada elemento dessa lista, contém os “pedaços” de cada elemento do vetor original (vec). Logo, se você está aplicando str_split() sobre um vetor com 34 elementos, você terá uma lista com 34 elementos em seu produto final.\n\nvec &lt;- c(\n  \"1 : 2 : 3 : 4 : 5 : 6 : 7\",\n  \"Faria, Pedro Duarte : 1290321_1\",\n  \"Objeto não localizado : 10_0x341167\",\n  \"A732 : B3 : 24 : C1 : 90 : 89 : QUA : ABD : AQZ29 : C11 : 01ER\"\n)\n\nstr_split(vec, \" : \")\n\n[[1]]\n[1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\"\n\n[[2]]\n[1] \"Faria, Pedro Duarte\" \"1290321_1\"          \n\n[[3]]\n[1] \"Objeto não localizado\" \"10_0x341167\"          \n\n[[4]]\n [1] \"A732\"  \"B3\"    \"24\"    \"C1\"    \"90\"    \"89\"    \"QUA\"   \"ABD\"   \"AQZ29\"\n[10] \"C11\"   \"01ER\" \n\n\nContudo, a depender do que você planeja fazer em seguida, pode ser difícil trabalhar com uma lista. Por isso, a função str_split() nos oferece o argumento simplify, no qual podemos requisitar a função que simplifique o resultado para uma matriz.\n\nstr_split(vec, \" : \", simplify = TRUE)\n\n     [,1]                    [,2]          [,3] [,4] [,5] [,6] [,7]  [,8] \n[1,] \"1\"                     \"2\"           \"3\"  \"4\"  \"5\"  \"6\"  \"7\"   \"\"   \n[2,] \"Faria, Pedro Duarte\"   \"1290321_1\"   \"\"   \"\"   \"\"   \"\"   \"\"    \"\"   \n[3,] \"Objeto não localizado\" \"10_0x341167\" \"\"   \"\"   \"\"   \"\"   \"\"    \"\"   \n[4,] \"A732\"                  \"B3\"          \"24\" \"C1\" \"90\" \"89\" \"QUA\" \"ABD\"\n     [,9]    [,10] [,11] \n[1,] \"\"      \"\"    \"\"    \n[2,] \"\"      \"\"    \"\"    \n[3,] \"\"      \"\"    \"\"    \n[4,] \"AQZ29\" \"C11\" \"01ER\"",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulação e transformação de *strings* com `stringr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/10-strings.html#extraindo-apenas-a-correspondência-de-sua-expressão-regular-com-str_extract",
    "href": "Capítulos/10-strings.html#extraindo-apenas-a-correspondência-de-sua-expressão-regular-com-str_extract",
    "title": "10  Manipulação e transformação de strings com stringr",
    "section": "10.11 Extraindo apenas a correspondência de sua expressão regular com str_extract()",
    "text": "10.11 Extraindo apenas a correspondência de sua expressão regular com str_extract()\nAssim como substituir suas correspondências por novos valores, você também tem a capacidade de extrair essas correspondências isoladamente, por meio da função str_extract(). Essa funcionalidade se torna extremamente importante quando não apenas a estrutura de cada elemento de seu vetor difere, mas também, quando a posição de seu alvo ao longo da cadeia de texto varia. Essas características tornam impossível a extração de nosso alvo com a função str_sub() (que apresentamos anteriormente), que se baseia diretamente na posição dos caracteres ao longo do texto.\nPor isso, a melhor alternativa para superarmos esse empecilho, é empregar uma expressão regular que possa detectar os nossos alvos e, com isso, extraí-los por meio da função str_extract(). Como exemplo, podemos extrair todos os anos presentes em cada elemento do vetor per, através do seguinte comando:\n\nper &lt;- c(\"Janeiro_2020\", \"Visitei Pará de Minas em Fevereiro de 2019\",\n         \"2020 foi um ano terrível\", \"O Brasil era a 11° economia do mundo em 2005\")\n\nstr_extract(per, \"\\\\d{4}\")\n\n[1] \"2020\" \"2019\" \"2020\" \"2005\"\n\n\nOu melhor, podemos colocar o texto original e a parte extraída em uma tabela:\n\ntibble(\n  text = per,\n  ano = str_extract(per, \"\\\\d{4}\")\n)\n\n# A tibble: 4 × 2\n  text                                         ano  \n  &lt;chr&gt;                                        &lt;chr&gt;\n1 Janeiro_2020                                 2020 \n2 Visitei Pará de Minas em Fevereiro de 2019   2019 \n3 2020 foi um ano terrível                     2020 \n4 O Brasil era a 11° economia do mundo em 2005 2005 \n\n\nAssim como str_replace(), str_extract() é capaz de extrair apenas a primeira correspondência encontrada por sua expressão regular. Por esse motivo, você irá precisar de sua variante, str_extract_all(), em todas as ocasiões em que você tiver mais de um alvo a ser extraído em cada texto. Por exemplo, podemos extrair o valor de cada medida presente em medidas, por meio da expressão \"([0-9]+)([.][0-9]+)?\".\n\n### Largura X Altura X Profundidade (Peso, Classe)\nmedidas &lt;- c(\n  \"8.15 m X 2.23 m X 4.5 m (240 Kg, B)\",\n  \"1.14 m X 3.1 m X 0.9 m (15 Kg, A)\",\n  \"4.98 m X 9.2 m X 5.25 m (120 Kg, A)\",\n  \"3.14 m X 3.89 m X 3.41 m (86 Kg, C)\"\n)\n\ntab &lt;- str_extract_all(\n  medidas,\n  \"([0-9]+)([.][0-9]+)?\",\n  simplify = TRUE\n)\n\ncolnames(tab) &lt;- c(\n  \"Largura\", \"Altura\", \"Profundidade\", \"Peso\"\n)\n\ntab\n\n     Largura Altura Profundidade Peso \n[1,] \"8.15\"  \"2.23\" \"4.5\"        \"240\"\n[2,] \"1.14\"  \"3.1\"  \"0.9\"        \"15\" \n[3,] \"4.98\"  \"9.2\"  \"5.25\"       \"120\"\n[4,] \"3.14\"  \"3.89\" \"3.41\"       \"86\" \n\n\n\n\n\n\nFRIEDL, J. E. F. Mastering Regular Expressions. 3. ed. Sebastopol, CA: O’Reilly Media, Inc., 2006.\n\n\nHARALAMBOUS, Y. Fonts & Encodings. Sebastopol, CA: O’Reilly Media, Inc., 2007.\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulação e transformação de *strings* com `stringr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/11-factors.html",
    "href": "Capítulos/11-factors.html",
    "title": "11  Introduzindo fatores (factor’s) com forcats",
    "section": "",
    "text": "11.1 Introdução e pré-requisitos\nNo capítulo de Fundamentos da Linguagem R, introduzimos os 4 tipos básicos de dados disponíveis no R, sendo eles: integer; double; character; e logical. Entretanto, também destacamos que outros tipos de dados “mais complexos” estão presentes na linguagem R, e, que eles serão tão importantes quanto os tipos básicos em suas análises.\nOs exemplos mais importantes desses tipos são os fatores (factor) e as variáveis de tempo, isto é, datas e horários (Date ou POSIXct). Neste capítulo, vamos focar a discussão no tipo factor, e, no próximo capítulo, discutiremos os tipos referentes às variáveis de tempo.\nParte dos exemplos deste capítulo, envolvem o uso de funções do pacote forcats, portanto, não se esqueça de instalar esse pacote (com o comando install.packages()), e, logo depois, chamar pelo pacote para a sua sessão (com o comando library()). O pacote forcats está incluso no pacote tidyverse, e, por isso, o tidyverse representa um caminho alternativo para você acessar as funções deste pacote.\nlibrary(forcats)\n## Ou\nlibrary(tidyverse)",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzindo fatores (*factor*'s) com `forcats`</span>"
    ]
  },
  {
    "objectID": "Capítulos/11-factors.html#o-que-são-fatores",
    "href": "Capítulos/11-factors.html#o-que-são-fatores",
    "title": "11  Introduzindo fatores (factor’s) com forcats",
    "section": "11.2 O que são fatores ?",
    "text": "11.2 O que são fatores ?\nUm fator (ou factor) é um tipo de dado do R desenvolvido para o trabalho com variáveis categóricas, ou variáveis qualitativas. Ou seja, o tipo de dado factor lhe permite armazenar características e qualidades que um indivíduo carrega, ou de outra forma, qual a “categoria” ou grupo em que cada indivíduo de sua tabela se encaixa.\nO sexo e a cor de pele são dois exemplos clássicos de variáveis qualitativas, pois elas identificam uma característica física do indivíduo. Características essas que determinam se o indivíduo pertence ou não a um grupo específico de pessoas (mulheres pardas, homens brancos, etc.). A faixa etária é um outro exemplo muito comum, sendo uma variável que busca separar indivíduos em vários grupos de acordo com as suas idades.\nEntretanto, para além de características e categorias, também podemos identificar uma variável categórica, ao percebermos se essa variável pode (ou deve) assumir um conjunto muito específico e muito bem definido de valores (TEAM, 2020, pp. 8). Por exemplo, uma variável que apresente o sexo de uma pessoa pode assumir apenas dois valores diferentes (Homem ou Mulher; Masculino ou Feminino; H ou M; ou alguma outra variação desses valores). Pode haver ainda, a necessidade de incluir um terceiro valor para casos especiais, como “Indefinido”, mas em geral, o sexo assume apenas os dois valores supracitados1. Como um outro exemplo, uma variável que guarda o mês do ano ao qual os dados de sua tabela se referem pode assumir apenas doze valores diferentes (janeiro, fevereiro, março, …, novembro, dezembro), logo, essa também é uma variável categórica sob essa perspectiva.",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzindo fatores (*factor*'s) com `forcats`</span>"
    ]
  },
  {
    "objectID": "Capítulos/11-factors.html#como-construir-um-fator",
    "href": "Capítulos/11-factors.html#como-construir-um-fator",
    "title": "11  Introduzindo fatores (factor’s) com forcats",
    "section": "11.3 Como construir um fator",
    "text": "11.3 Como construir um fator\nSuponha que você tenha questionado o sexo de várias pessoas, e anotado as suas respostas no vetor abaixo (entrevista):\n\nentrevista &lt;- c(\"Mulher\", \"Homem\", \"Homem\", \"Mulher\", \"Mum\")\n\nSe você deseja transformar esse vetor acima (que no momento é um vetor do tipo character) em um vetor do tipo factor, você deve primeiro pensar sobre o atributo levels que será utilizado neste vetor. Ou seja, todo objeto do tipo factor no R possui um atributo chamado levels, que representa o conjunto de valores que a variável em questão pode assumir. Como estamos anotando o sexo de algumas pessoas entrevistadas, sabemos que essa variável pode assumir apenas dois valores diferentes. Eu crio o vetor abaixo (niveis_sexo) com o objetivo de guardar essas informações.\n\nniveis_sexo &lt;- c(\"Homem\", \"Mulher\")\n\nAgora que temos o vetor com a informação original (entrevista) e um vetor com os níveis, ou, os valores permitidos para essa variável (niveis_sexo), podemos criar o nosso fator através da função factor().\n\nvec_fator &lt;- factor(entrevista, levels = niveis_sexo)\nvec_fator\n\n[1] Mulher Homem  Homem  Mulher &lt;NA&gt;  \nLevels: Homem Mulher\n\n\nPerceba acima, que ao chamarmos pelo novo fator criado, os níveis da variável (atributo levels) são mostrados logo abaixo dos valores armazenados. Repare também, que todos os valores presentes no vetor original (entrevista) e que estejam fora dos níveis da variável (niveis_sexo) são silenciosamente convertidos para valores NA. Isto é, qualquer valor que esteja minimamente divergente dos valores presentes em levels, ou que contenha algum erro ortográfico, será convertido para um valor NA.\nVocê sempre pode acessar os níveis (isto é, o atributo levels) de um fator por meio da função levels(). Basta aplicá-la diretamente sobre o fator, que um vetor contendo esses níveis será retornado para você.\n\nlevels(vec_fator)\n\n[1] \"Homem\"  \"Mulher\"\n\n\nVale destacar, que para o R, um vetor do tipo factor, é na verdade, um vetor do tipo integer que carrega uma classe factor, e que possui um atributo chamado levels. Esse é um dos principais motivos pelos quais os tipos factor, Date e POSIXct são caracterizados como tipos “mais complexos” da linguagem R. Pois esses tipos são construídos a partir dos quatro tipos básicos, mas eles também acumulam novas características ou propriedades que não estão presentes nesses tipos básicos.\nNo caso do tipo factor, ele é construído a partir do tipo integer devido a forma como o R guarda os valores presentes em um vetor do tipo factor (TEAM, 2020, p. 8). Por exemplo, os valores “Homem” e “Mulher” do vetor vec_fator acima, são guardados pelo R como valores 1 e 2, e são posteriormente traduzidos como valores “Homem” e “Mulher” quando chamamos pelo vetor vec_fator. Tudo isso ocorre, devido às propriedades e atributos que um vetor do tipo factor carrega, e que o diferenciam de um vetor do tipo integer.\n\ntypeof(vec_fator)\n\n[1] \"integer\"\n\nclass(vec_fator)\n\n[1] \"factor\"\n\nattributes(vec_fator)\n\n$levels\n[1] \"Homem\"  \"Mulher\"\n\n$class\n[1] \"factor\"",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzindo fatores (*factor*'s) com `forcats`</span>"
    ]
  },
  {
    "objectID": "Capítulos/11-factors.html#porque-utilizar-fatores-se-eu-posso-armazenar-como-texto",
    "href": "Capítulos/11-factors.html#porque-utilizar-fatores-se-eu-posso-armazenar-como-texto",
    "title": "11  Introduzindo fatores (factor’s) com forcats",
    "section": "11.4 Porque utilizar fatores se eu posso armazenar como texto ?",
    "text": "11.4 Porque utilizar fatores se eu posso armazenar como texto ?\nVocê provavelmente está se perguntando qual a necessidade verdadeira dos fatores, levando em conta que você pode utilizar o tipo character para armazenar os dados de um variável qualitativa. (WICKHAM; GROLEMUND, 2017, pp. 224) nos concede um ótimo exemplo de como um fator pode fazer toda a diferença.\nPor exemplo, suponha que você possua o vetor abaixo contendo alguns meses do ano. Em geral, há dois problemas no uso de um vetor do tipo character para guardar essas informações.\n\nvec &lt;- c(\"Mar\", \"Fev\", \"Jan\", \"Set\", \"Out\", \"Abr\")\n\nPrimeiro, você não está prevenido contra possíveis erros ortográficos. Isso pode ser um problema de pouca importância caso esses dados estejam sendo gerados por uma máquina ou programa, mas ele se torna um problema sério caso você esteja anotando esses valores na mão, ou esteja constantemente corrigindo-os de alguma maneira que seja suscetível ao erro. Logo, se algum mês for incorretamente gravado, nenhum erro ou medida cautelar será acionada pelo R para corrigir esse problema.\nSegundo, quando essas informações estão sendo guardadas pelo tipo character, o sistema de ordenação utilizado pelo R (ordenação alfabética) é de pouca utilidade. Como você pode ver abaixo, o R acabou colocando o mês de abril antes dos meses de fevereiro e janeiro.\n\nsort(vec)\n\n[1] \"Abr\" \"Fev\" \"Jan\" \"Mar\" \"Out\" \"Set\"\n\n\nO uso do tipo factor consegue resolver ambos desses problemas. Pois você já sabe que qualquer valor disposto em vec, que possua algum erro ortográfico em comparação com os meses dispostos no atributo levels do fator será automaticamente convertido para um valor NA. Além disso, ao ordenar um objeto do tipo factor, o R sempre vai utilizar como referência, a ordem na qual os valores estão apresentados no atributo levels.\nComo o vetor vec guarda alguns meses do ano, o vetor meses abaixo, representa o atributo levels do fator a ser criado a partir de vec. Lembre-se que, a ordem na qual os meses estão dispostos no atributo levels, afeta diretamente a maneira como o R ordena o fator. Logo, a ordem em que você fornece os valores em meses, será a ordem utilizada pelo R ao ordenar os valores de vec_fator.\n\nmeses &lt;- c(\"Jan\", \"Fev\", \"Mar\", \"Abr\", \"Mai\", \"Jun\",\n           \"Jul\", \"Ago\", \"Set\", \"Out\", \"Nov\", \"Dez\")\n\nvec_fator &lt;- factor(vec, levels = meses)\nvec_fator\n\n[1] Mar Fev Jan Set Out Abr\nLevels: Jan Fev Mar Abr Mai Jun Jul Ago Set Out Nov Dez\n\nsort(vec_fator)\n\n[1] Jan Fev Mar Abr Set Out\nLevels: Jan Fev Mar Abr Mai Jun Jul Ago Set Out Nov Dez",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzindo fatores (*factor*'s) com `forcats`</span>"
    ]
  },
  {
    "objectID": "Capítulos/11-factors.html#não-construir-o-atributo-levels-é-contraintuitivo",
    "href": "Capítulos/11-factors.html#não-construir-o-atributo-levels-é-contraintuitivo",
    "title": "11  Introduzindo fatores (factor’s) com forcats",
    "section": "11.5 Não construir o atributo levels é contraintuitivo",
    "text": "11.5 Não construir o atributo levels é contraintuitivo\nApesar de ser o ideal, você não precisa obrigatoriamente construir o atributo levels ao formar um fator. Pois você tem a opção de delegar esse trabalho para a própria função factor(), ao aplicá-la diretamente sobre o seu vetor de interesse.\nPorém, ao escolher esse caminho, factor() vai extrair todos os valores únicos de seu vetor, e posicioná-los em ordem alfabética no atributo levels. Ou seja, supondo que o seu vetor de interesse se chame x, é como se o atributo levels de seu fator, equivalesse ao resultado dos comandos: unique(x) %&gt;% sort(); ou de outra forma: sort(unique(x)). Veja o exemplo abaixo:\n\nv_letras &lt;- c(\"e\", \"a\", \"b\", \"c\", \"a\", \"b\", \"d\")\nf &lt;- factor(v_letras)\nf\n\n[1] e a b c a b d\nLevels: a b c d e\n\nsort(f)\n\n[1] a a b b c d e\nLevels: a b c d e\n\n\nPerceba acima, que tal comportamento de factor() torna o uso de fatores, algo inútil ou desnecessário. Pois a ordenação de seu fator será idêntica à ordenação alfabética utilizada sobre um vetor do tipo character. Lembre-se que para a ordenação de um fator, é utilizada a ordem na qual os valores são apresentados em levels(). Tal ponto pode ser inferido pelo exemplo abaixo, em que a ordenação produzida sobre os valores de v_letras é a mesma (em comparação com o resultado acima) quando ela se encontra no tipo character.\n\nv_letras &lt;- c(\"e\", \"a\", \"b\", \"c\", \"a\", \"b\", \"d\")\ntypeof(v_letras)\n\n[1] \"character\"\n\nsort(v_letras)\n\n[1] \"a\" \"a\" \"b\" \"b\" \"c\" \"d\" \"e\"",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzindo fatores (*factor*'s) com `forcats`</span>"
    ]
  },
  {
    "objectID": "Capítulos/11-factors.html#alterando-a-ordem-dos-níveis-de-um-fator",
    "href": "Capítulos/11-factors.html#alterando-a-ordem-dos-níveis-de-um-fator",
    "title": "11  Introduzindo fatores (factor’s) com forcats",
    "section": "11.6 Alterando a ordem dos níveis de um fator",
    "text": "11.6 Alterando a ordem dos níveis de um fator\nPortanto, o sistema de ordenação é um dos principais recursos do tipo factor no R, e tal sistema está diretamente conectado com o seu atributo levels. Por isso, uma das principais atividades com fatores está na reordenação e do atributo levels, ou em sua reatribuição.\n\n11.6.1 A maneira mais simples e direta\nA forma mais “simples” de alterarmos esse atributo é redefinindo-o por completo através da função levels(). Repare no exemplo abaixo, que apenas a letra “a” foi reposicionada no atributo.\n\nlevels(f) &lt;- c(\"b\", \"c\", \"d\", \"e\", \"a\")\nsort(f)\n\n[1] b b c c d e a\nLevels: b c d e a\n\n\nTal operação poderia ser realizada de diversas formas. Por exemplo, caso o seu fator possua um número muito grande de níveis, ao invés de reescrevê-los na mão, talvez seja mais rápido utilizar técnicas de subsetting para reordenar os níveis da maneira desejada.\n\n## Criando um fator com muitos níveis\nf &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nlevels(f) &lt;- c(\n  \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\",\n  \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\",\n  \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\",\n  \"v\", \"w\", \"x\", \"y\", \"z\"\n)\n\n## Selecionando os níveis atuais\n## e reordenando-os com subsetting\nniveis_atuais &lt;- levels(f)\nn_niveis &lt;- length(niveis_atuais)\nnovos_niveis &lt;- niveis_atuais[c(4:2, 5:n_niveis, 1)]\n\n## Redefinindo os níveis do fator\nlevels(f) &lt;- novos_niveis\nf\n\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\nattr(,\"levels\")\n [1] \"d\" \"c\" \"b\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\"\n[20] \"u\" \"v\" \"w\" \"x\" \"y\" \"z\" \"a\"\n\n\n\n\n11.6.2 Maneiras alternativas que podem fazer a diferença\nO pacote forcats oferece várias funções voltadas especificamente para o trabalho com fatores no R. Dentre essas funções, temos a fct_infreq(), que lhe permite reordenar o atributo levels de acordo com a frequência em que cada nível aparece no vetor (do nível mais frequente para o menos frequente).\n\nv_letras &lt;- c(\"e\", \"d\", \"d\", \"c\", \"a\", \"a\", \"a\", \"c\",\n              \"b\", \"d\", \"d\", \"e\", \"d\", \"a\", \"d\", \"c\")\nf &lt;- factor(v_letras)\nfct_infreq(f)\n\n [1] e d d c a a a c b d d e d a d c\nLevels: d a c e b\n\n\nAlém disso, você também pode estar interessado em ordenar os níveis de um fator, de acordo com a ordem da primeira aparição de cada nível. Para isso, nós podemos utilizar a função fct_inorder(). Perceba pelo resultado do exemplo abaixo, que as letras “e”, “d” e “c” antecedem as letras “a” e “b” no atributo levels do fator gerado, pois essas letras aparecem primeiro no vetor original.\n\nfct_inorder(f)\n\n [1] e d d c a a a c b d d e d a d c\nLevels: e d c a b\n\n\nPara mais, haverá momentos em que você deseja ordenar os níveis de seu fator, de acordo com uma segunda variável. Essa situação ocorre principalmente quando o seu fator está incluso em um data.frame, junto de várias outras variáveis de seu interesse. Para tal ação, temos a função fct_reorder(), que lhe permite fornecer uma segunda variável na qual a ordenação do atributo levels será baseada.\nComo exemplo, suponha que você possua a seguinte tabela contendo receitas mensais de algumas lojas:\n\nunidades &lt;- c(\"Savassi\", \"Centro\", \"Gameleira\", \"Pampulha\")\nset.seed(3)\ntab &lt;- tibble(\n  ano = 2021,\n  mes = rep(1:12, each = 4),\n  unidade = rep(unidades, times = 12),\n  receita = rnorm(48, 17000, 4800)\n)\ntab &lt;- arrange(tab, mes, unidade)\ntab\n\n# A tibble: 48 × 4\n    ano   mes unidade   receita\n  &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;\n1  2021     1 Centro     15596.\n2  2021     1 Gameleira  18242.\n3  2021     1 Pampulha   11470.\n4  2021     1 Savassi    12383.\n5  2021     2 Centro     17145.\n# ℹ 43 more rows\n\n\nNo exemplo abaixo, ao transformarmos a variável unidade em um fator, os níveis da variável são organizados em ordem alfabética, como era esperado.\n\ntab$unidade &lt;- factor(tab$unidade)\ntab$unidade\n\n [1] Centro    Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha \n [8] Savassi   Centro    Gameleira Pampulha  Savassi   Centro    Gameleira\n[15] Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi   Centro   \n[22] Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi  \n[29] Centro    Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha \n[36] Savassi   Centro    Gameleira Pampulha  Savassi   Centro    Gameleira\n[43] Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi  \nLevels: Centro Gameleira Pampulha Savassi\n\n\nA função fct_reorder() vai sempre ordenar o seu fator de acordo com um sumário, ou alguma estatística descritiva da segunda variável. Por isso, você deve se perguntar qual estatística descritiva você deseja utilizar sobre a segunda variável em questão. Como exemplo, você talvez queira ordenar os níveis de unidade, de acordo com a receita média mensal de cada loja.\nLogo, desejamos aplicar uma função de média sobre a variável receita ao longo de cada nível do fator unidade. Por isso, eu forneço a função mean() ao argumento .fun de fct_reorder(). Como podemos ver abaixo, as unidades do Centro e da Savassi possuem receitas médias menores do que unidades da Pampulha e da Gameleira, pois essas unidades se encontram nas primeiras posições do atributo levels do fator resultante de fct_reorder(). Ou seja, a função fct_reorder() utiliza, por padrão, uma ordem crescente no atributo levels. Caso você deseje inverter esse comportamento, basta configurar o argumento .desc da função para TRUE.\n\n## Utilize: fct_reorder(unidade, receita, .fun = mean, .desc = TRUE)\n## para utilizar uma ordenação crescente no atributo levels\ntab &lt;- tab %&gt;% \n  mutate(\n    unidade = fct_reorder(unidade, receita, .fun = mean)\n  )\n\ntab$unidade\n\n [1] Centro    Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha \n [8] Savassi   Centro    Gameleira Pampulha  Savassi   Centro    Gameleira\n[15] Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi   Centro   \n[22] Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi  \n[29] Centro    Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha \n[36] Savassi   Centro    Gameleira Pampulha  Savassi   Centro    Gameleira\n[43] Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi  \nLevels: Centro Savassi Pampulha Gameleira",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzindo fatores (*factor*'s) com `forcats`</span>"
    ]
  },
  {
    "objectID": "Capítulos/11-factors.html#reordenando-fatores-em-gráficos",
    "href": "Capítulos/11-factors.html#reordenando-fatores-em-gráficos",
    "title": "11  Introduzindo fatores (factor’s) com forcats",
    "section": "11.7 Reordenando fatores em gráficos",
    "text": "11.7 Reordenando fatores em gráficos\nA ordem na qual apresentamos certas informações pode mudar drasticamente não apenas as características físicas e visuais de seu gráfico, mas também, pode afetar e muito a clareza ou a ênfase em certas informações que são cruciais em nosso gráfico. Por essa razão, reordenar variáveis categóricas em seu gráfico pode ser fundamental. Veja o primeiro exemplo abaixo, dado por (WICKHAM; GROLEMUND, 2017, pp. 228).\nDentre as funções que mostramos na seção passada, a função fct_reorder() é talvez a mais útil delas em gráficos. Por exemplo, no gráfico abaixo, temos certa dificuldade em comparar e, principalmente, classificar os vários tempos médios gastos dentro de cada grupo religioso.\n\nrelig &lt;- gss_cat %&gt;%\n  group_by(relig) %&gt;%\n  summarize(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nrelig %&gt;% \n  ggplot() + \n  geom_point(aes(tvhours, relig))\n\n\n\n\n\n\n\n\nTal problema, pode ser rapidamente resolvido ao aplicarmos a função fct_reorder() sobre a variável no eixo y, para que ela seja reordenada de acordo com os valores da variável do eixo x do gráfico. Perceba abaixo, que agora temos uma facilidade muito maior em comparar e classificar os vários tempos médios gastos em cada grupo religioso. Com essa nova ordenação, podemos rapidamente identificar que as pessoas que não sabem (“Don’t know”) a sua religião (ou que são ateus), são aquelas que mais gastam seu tempo em frente a uma televisão.\n\nrelig %&gt;% \n  ggplot() + \n  geom_point(\n    aes(tvhours, fct_reorder(relig, tvhours))\n  )\n\n\n\n\n\n\n\n\nComo um outro exemplo, pode haver certas variáveis que não necessitam de uma reordenação acentuada. Além disso, tais variáveis podem possuir uma ordem própria, que não depende de uma segunda variável. Ou seja, essas variáveis podem possuir uma “ordem natural”. Essa característica, torna o uso de fct_reorder() inadequado (lembre-se que fct_reorder() busca reordenar um fator de acordo com os valores de uma segunda variável).\nPor exemplo, se você olhar para o gráfico abaixo, você poderá perceber que temos uma variável de faixa etária no eixo y, e que apenas a faixa de “Menos de 10” está incorretamente posicionada no eixo. Pelo fato das faixas etárias possuírem uma “ordem natural”, isto é, as faixas “mais altas” são aquelas referentes às idades mais elevadas, enquanto as faixas “mais baixas” são aquelas referentes às idades “mais baixas”, não faz sentido reordenarmos essa variável de acordo com os valores de uma segunda variável.\n\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\narquivo &lt;- \"Curso-R/master/Dados/datasus.csv\"\ndatasus &lt;- read_csv2(paste0(github, arquivo))\n\ntotais &lt;- datasus %&gt;% \n  group_by(`Faixa etaria`) %&gt;% \n  summarise(\n    Total = sum(Contagem)\n  )\n\n\ntotais %&gt;% \n  ggplot() +\n  geom_col(\n    aes(y = `Faixa etaria`, x = Total)\n  )\n\n\n\n\n\n\n\n\nPortanto, a faixa de “Menos de 10” é a única faixa a ser reposicionada, e podemos realizar tal ação com a função fct_relevel(). Repare no exemplo abaixo, que após o ajuste, a faixa “Menos de 10” foi realocada para a posição mais inferior do eixo.\n\ntotais %&gt;% \n  mutate(\n    `Faixa etaria` = fct_relevel(`Faixa etaria`, \"Menos de 10\")\n  ) %&gt;% \n  ggplot() +\n  geom_col(\n    aes(y = `Faixa etaria`, x = Total)\n  )\n\n\n\n\n\n\n\n\nAlém dessas opções, a função fct_infreq() é muito útil para gráficos de barras do ggplot, que incluem por padrão um cálculo de frequência. Em outras palavras, ao lembrarmos que fct_infreq() busca reordenar um fator de acordo com a frequência em que os seus níveis aparecem em seus dados, se torna muito natural aliarmos essa função a um gráfico de barras do ggplot.\nPor exemplo, se gerarmos um gráfico de barras a partir de cada cor de pele presente em nossa tabela datasus, temos o seguinte resultado:\n\ndatasus %&gt;% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor)\n  )\n\n\n\n\n\n\n\n\nAgora, com o uso de fct_infreq() podemos reposicionar essas barras em um sentido mais lógico, como está demonstrado abaixo:\n\ndatasus %&gt;% \n  ggplot() +\n  geom_bar(\n    aes(x = fct_infreq(Cor))\n  )",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzindo fatores (*factor*'s) com `forcats`</span>"
    ]
  },
  {
    "objectID": "Capítulos/11-factors.html#modificando-os-níveis-de-um-fator",
    "href": "Capítulos/11-factors.html#modificando-os-níveis-de-um-fator",
    "title": "11  Introduzindo fatores (factor’s) com forcats",
    "section": "11.8 Modificando os níveis de um fator",
    "text": "11.8 Modificando os níveis de um fator\nAté o momento, demos bastante foco sobre a ordenação dos valores presentes no atributo levels. Justamente pelo fato de que essa característica define uma das principais vantagens do tipo factor no R, que é a de modificar a forma como a linguagem ordena os valores presentes em um vetor. Porém, ainda não discutimos o que ocorre quando nós deliberadamente alteramos um dos valores presentes no atributo levels.\nPor exemplo, suponha que eu possua o fator abaixo. Nesse caso, o fator f possui quatro níveis, sendo eles: a, b, c, e d.\n\nvec &lt;- c(\"a\", \"c\", \"c\", \"d\", \"b\", \"a\", \"b\")\nf &lt;- factor(vec, levels = c(\"a\", \"b\", \"c\", \"d\"))\nf\n\n[1] a c c d b a b\nLevels: a b c d\n\n\nAgora, o que ocorre se eu tentar modificar o primeiro nível (a) desse fator? De maneira elegante e surpreendente, o R irá substituir todos os valores a presentes no fator, pelo novo valor definido, como está demonstrado abaixo:\n\nlevels(f) &lt;- c(\"m\", \"b\", \"c\", \"d\")\nf\n\n[1] m c c d b m b\nLevels: m b c d\n\n\nAssim como nas seções anteriores, o pacote forcats também oferece algumas funções muito úteis para esse procedimento. Veja o exemplo abaixo, em que eu utilizo a função fct_recode() para reconfigurar todos os níveis (ou valores) presentes coluna Cor em nossa tabela datasus.\n\ndatasus %&gt;% \n  mutate(\n    Cor = fct_recode(\n      Cor,\n      \"Carmim\" = \"Parda\",\n      \"Azul\" = \"Amarela\",\n      \"Bronze\" = \"Branca\",\n      \"Roxo\" = \"Indígena\"\n    )\n  )\n\n# A tibble: 1,836 × 6\n  `Faixa etaria` Genero    Cor    `Nome UF` UF    Contagem\n  &lt;chr&gt;          &lt;chr&gt;     &lt;fct&gt;  &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;\n1 10 a 14        Feminino  Carmim Acre      AC           4\n2 10 a 14        Masculino Carmim Acre      AC           4\n3 15 a 19        Feminino  Bronze Acre      AC           2\n4 15 a 19        Feminino  Carmim Acre      AC           4\n5 15 a 19        Masculino Bronze Acre      AC           6\n# ℹ 1,831 more rows\n\n\nCaso você precise unir diversos níveis em um só, ou, em outras palavras, se você precisa agregar vários níveis, a função fct_collapse() é uma melhor escolha. Pois ela lhe permite fornecer um vetor contendo todos os níveis antigos a serem agregados em um só. Veja o exemplo abaixo, em que eu agrego diversas faixas etárias, gerando assim, uma descrição etária menos detalhada:\n\ndatasus %&gt;% \n  mutate(\n    `Faixa etaria` = fct_collapse(\n      `Faixa etaria`,\n      \"Menos de 19 anos\" = c(\"Menos de 10\", \"10 a 14\", \"15 a 19\"),\n      \"Entre 20 e 64 anos\" = c(\"20 a 24\", \"25 a 29\", \"30 a 34\",\n                               \"35 a 39\", \"40 a 44\", \"45 a 49\",\n                               \"50 a 54\", \"55 a 59\", \"60 a 64\"),\n      \"Acima de 64 anos\" = c(\"65 a 69\", \"Mais de 70\")\n    )\n  )\n\n# A tibble: 1,836 × 6\n  `Faixa etaria`   Genero    Cor    `Nome UF` UF    Contagem\n  &lt;fct&gt;            &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;\n1 Menos de 19 anos Feminino  Parda  Acre      AC           4\n2 Menos de 19 anos Masculino Parda  Acre      AC           4\n3 Menos de 19 anos Feminino  Branca Acre      AC           2\n4 Menos de 19 anos Feminino  Parda  Acre      AC           4\n5 Menos de 19 anos Masculino Branca Acre      AC           6\n# ℹ 1,831 more rows\n\n\n\n\n\n\nTEAM, R. C. R Language Definition. Version 4.0.3 ed. [s.l.] R Foundation, 2020.\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzindo fatores (*factor*'s) com `forcats`</span>"
    ]
  },
  {
    "objectID": "Capítulos/11-factors.html#footnotes",
    "href": "Capítulos/11-factors.html#footnotes",
    "title": "11  Introduzindo fatores (factor’s) com forcats",
    "section": "",
    "text": "Pode haver certa confusão entre sexo e gênero aqui. O sexo se refere às características físicas e biológicas do corpo, e essas características podem identificar uma pessoa como Homem ou Mulher. Já o gênero, está muito mais relacionado à cultura e a forma como um indivíduo se identifica como ser. Logo, se nossa variável identificasse o gênero de uma pessoa, haveria muito mais possibilidades do que a simples divisão entre Homem e Mulher.↩︎",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzindo fatores (*factor*'s) com `forcats`</span>"
    ]
  },
  {
    "objectID": "Capítulos/12-variaveis-tempo.html",
    "href": "Capítulos/12-variaveis-tempo.html",
    "title": "12  Introdução à variáveis de tempo com lubridate",
    "section": "",
    "text": "12.1 Introdução e pré-requisitos\nVariáveis de tempo são aquelas que guardam informações que se encontram em alguma unidade de tempo. Exemplos são: datas (i.e. 20 de março de 2020), ou horários - que preferencialmente são acompanhados por uma data (i.e. 11:45 da manhã do dia 12 de fevereiro de 2001; ou, 12/02/2001 11:45:00), ou ainda, a duração (ou o tempo) de algum evento (12 segundos, 12 dias, 2 semanas, 1 mês e meio, etc.).\nTais variáveis podem ser interpretadas no R por meio de quatro tipos de dados diferentes, sendo eles: Date, POSIXlt, POSIXct e difftime. Logo, neste capítulo, vamos focar nesses quatro tipos de dados, e, introduzir várias ferramentas e operações comumente aplicadas sobre eles. Parte dessas ferramentas advém do pacote lubridate e, portanto, para acompanhar os exemplos deste capítulo, você deve (após instalar esse pacote em sua máquina) chamar por esse pacote em sua sessão, através do comando library().\nlibrary(lubridate)",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introdução à variáveis de tempo com `lubridate`</span>"
    ]
  },
  {
    "objectID": "Capítulos/12-variaveis-tempo.html#o-pacote-lubridate",
    "href": "Capítulos/12-variaveis-tempo.html#o-pacote-lubridate",
    "title": "12  Introdução à variáveis de tempo com lubridate",
    "section": "12.2 O pacote lubridate",
    "text": "12.2 O pacote lubridate\nComo é bem descrito por RIPLEY; HORNIK (2001) e GROTHENDIECK; PETZOLDT (2004), desde sua versão 1.9, o R oferece “de fábrica” um excelente suporte para variáveis de tempo. Suas funções são capazes de lidar muito bem com diferenças entre fusos horários, além de incluírem anos bissextos e horários de verão. Porém, mesmo com esse potencial, essas funções (as.Date(), as.POSIXct(), strptime(), dentre outras) tendem a aplicar definições muito formais, tornando-as assim, pouca intuitivas para muitos usuários.\nPor esse motivo, o pacote lubridate tem tido muito sucesso ao longo da comunidade, ao prover funções que realizam grande parte do trabalho irritante com essas funções. Ou seja, no fundo, várias das funções do pacote lubridate são apenas wrappers, isto é, são construídas a partir das funções do pacote básico do R. Significa que o pacote lubridate foi criado, em grande parte, com o intuito de facilitar o nosso trabalho com as ferramentas que o R já oferece, ao invés de remodelá-las por completo.\nPortanto, ao longo deste capítulo, você irá aprender primeiro sobre as funções do pacote lubridate, e, em seguida, as funções básicas do R são apresentadas para aqueles que desejam conhecer mais a fundo tal sistema. Dessa forma, nós estaremos apresentando primeiro, o atalho, e, em seguida, o caminho completo.",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introdução à variáveis de tempo com `lubridate`</span>"
    ]
  },
  {
    "objectID": "Capítulos/12-variaveis-tempo.html#datas-com-o-tipo-date",
    "href": "Capítulos/12-variaveis-tempo.html#datas-com-o-tipo-date",
    "title": "12  Introdução à variáveis de tempo com lubridate",
    "section": "12.3 Datas com o tipo Date",
    "text": "12.3 Datas com o tipo Date\nNo R, datas são normalmente interpretadas através do tipo de dado Date. Temos 3 métodos principais de se criar uma data no R (existem outros métodos menos intuitivos1), os quais estão resumidos na Figura 12.1 abaixo, e que são apresentados a seguir: 1) a partir de strings (um vetor do tipo character); 2) a partir de cada componente da data (dia, mês e ano); e 3) a partir de números.\n\n\n\n\n\n\n\n\nFigura 12.1: Principais métodos para se criar datas no R\n\n\n\n\n\nDentre as funções dos pacotes básicos do R, a função as.Date() é a principal função responsável por criar vetores do tipo Date. Todavia, ao longo dessa seção, estaremos focados nas funções do pacote lubridate, em especial, a função as_date(). De qualquer forma, saiba que, no fim das contas, as funções desse pacote vão utilizar a função as.Date() para criar o vetor contendo as suas datas. As funções as_date() e as.Date() são muito semelhantes entre si, logo, grande parte do conhecimento mostrado em as_date(), pode ser diretamente aplicado em as.Date().\nAo longo das próximas seções, você pode rapidamente perceber que a formação de dados do tipo Date (assim como dos tipos POSIXct e POSIXlt) no R, envolve o ato de coerção de vetores que se encontram em outros tipos (como character ou double) para o tipo Date. Em outras palavras, não é possível criarmos diretamente um vetor do tipo Date. O motivo para tal prática, pode ser atribuído às diversas maneiras em que uma mesma data (além das outras variáveis de tempo) pode ser escrita, ou representada. Por essa diversidade, o R busca oferecer flexibilidade aos seus usuários, através de diferentes métodos de coerção. A Figura 12.1, resume os principais métodos que vamos aprender ao longo dessa seção, além de algumas características importantes que envolvem o tipo Date.\n\n12.3.1 A partir de strings\nComo exemplo inicial, podemos fornecer à função as_date() (do pacote lubridate), a data 01 de abril de 2020 como um string. Repare abaixo, que o resultado final da operação é um vetor do tipo Date (e não do tipo character).\n\nd &lt;- as_date(\"2020-04-01\")\nd\n\n[1] \"2020-04-01\"\n\nclass(d)\n\n[1] \"Date\"\n\n\nEntretanto, você talvez tenha achado estranho o formato em que a data foi escrita na função as_date(). Pois no Brasil, datas são normalmente escritas no padrão “dia/mês/ano” (ex: 01/04/2020), e não “ano-mês-dia”. Este é o formato estipulado pelo padrão internacional ISO-8601, que é o padrão adotado pelo R. Ou seja, no R, datas são manipuladas, estocadas, fornecidas e apresentadas no formato “ano-mês-dia”.\nVocê irá rapidamente perceber que, muitos países podem escrever uma mesma data de maneiras muito diferentes. Por exemplo, nos EUA, datas são usualmente escritas no formato “mês-dia-ano” (ex: 02-18-2021), mas também aparecem muitas vezes em sua forma extensa (ex: February 18, 2021). Em algumas regiões da Espanha, datas são escritas no formato “ano/dia/mês” (ex: 2020/15/08). Também não é incomum encontrarmos em países nórdicos (Suécia, Finlândia, Dinamarca), datas escritas com o uso de pontos separando cada componente (ex: 2020.08.15).\nToda essa variedade só torna o nosso trabalho mais complicado, especialmente se nós não sabemos qual a origem, ou, o padrão adotado por essas datas. E não há nada que você possa fazer a respeito, a não ser, identificar por conta própria o padrão adotado e ajustar a função empregada de acordo com esse padrão.\n\n\n12.3.2 O que devo fazer se minhas datas se encontram em um formato diferente?\nPortanto, caso você possua um conjunto de datas como strings (ou seja, em um vetor do tipo character), e, essas datas estejam em um formato diferente do estipulado pela ISO-8601, você tem 2 opções rápidas para transportar corretamente essas datas para o tipo Date.\n\n\n\n\n\nCódigos que representam cada componente de uma data\n\n\n\n\nPrimeiro, todas as funções no R que lidam com variáveis de tempo, geralmente oferecem um argumento format, no qual você pode definir o formato, ou o padrão adotado por suas datas. Logo, você precisa apenas definir o argumento format em as_date(), ou em qualquer outra função que você esteja utilizando para essa coerção.\nSegundo, você também pode utilizar as funções rápidas do pacote lubridate, ymd(), dmy(), dym() e mdy(), que já possuem uma ordem implícita, ou um format padrão. Dessa maneira, você economiza certo tempo, ao não ter que se preocupar com o argumento format nessas funções.\nPor exemplo, suponha que você possua um conjunto de datas escritas no Brasil, guardadas no vetor datas, e que você deseja converter esse vetor (que se encontra no momento, no tipo character) para o tipo Date. Como os componentes da data estão na ordem “dia \\(\\rightarrow\\) mês \\(\\rightarrow\\) ano”, eu utilizo a função dmy() para ler essas datas.\n\ndatas &lt;- c(\"15/03/2020\", \"16/03/2020\", \"18/03/2020\", \"24/03/2020\")\ndmy(datas)\n\n[1] \"2020-03-15\" \"2020-03-16\" \"2020-03-18\" \"2020-03-24\"\n\n\nIsso significa que, a ordem na qual as letras “d”, “m” e “y” aparecem no nome da função, representa a ordem adotada pelo argumento format dessa função. Em outras palavras, a letra “d” simboliza o “dia”; a letra “m” por sua vez, o “mês”; e a letra “y”, o “ano”, ou, em inglês, “year”. Ou seja, a função dmy() espera como input, datas cujos componentes estejam na ordem “dia \\(\\rightarrow\\) mês \\(\\rightarrow\\) ano” (ou “d \\(\\rightarrow\\) m \\(\\rightarrow\\) y”). Já a função ymd(), tem como expectativa, datas cujos componentes estejam na ordem “ano \\(\\rightarrow\\) mês \\(\\rightarrow\\) dia” (ou “y \\(\\rightarrow\\) m \\(\\rightarrow\\) d”).\nPortanto, as funções rápidas dmy(), ymd() e suas irmãs, possuem implicitamente uma ordem esperada para os componentes de suas datas. Para mais, essas funções identificam automaticamente qualquer caractere que não seja um dígito, e os trata como os delimitadores que separam cada componente da data. Logo, não importa se cada componente está sendo separado por um hífen (-), ponto (.), cifrão ($) ou barra inclinada (/), essas funções serão capazes de detectar esses caracteres e ignorá-los durante a conversão.\nComo já foi descrito acima, a segunda alternativa seria definirmos explicitamente o argumento format em as_date(). Neste argumento, você deve fornecer uma pequena definição2 que descreve o padrão no qual a sua data se encontra. Para construir tal definição, você irá utilizar um conjunto de códigos, que são formados pelo símbolo de porcentagem acompanhado de uma letra específica. Cada um desses códigos, podem representar um dos três componentes de uma data (dia, mês e ano). A Figura 12.2 apresenta um resumo desses códigos.\n\n\n\n\n\n\n\n\nFigura 12.2: Códigos que representam cada componente de uma data\n\n\n\n\n\nTendo os códigos acima, se uma data no Brasil é escrita no formato “dia/mês/ano”, uma descrição que representa tal padrão é \"%d/%m/%Y\". Como um outro exemplo, se temos as datas \"2021, 30-12\" e \"97,10,January\", podemos utilizar respectivamente os valores \"%Y, %d-%m\" e \"%y,%d,%B\" para descrever os padrões adotados por cada uma. Veja os exemplos abaixo:\n\ndatas &lt;- c(\"15/03/2020\", \"16/03/2020\", \"18/03/2020\", \"24/03/2020\")\nas_date(datas, format = \"%d/%m/%Y\")\n\n[1] \"2020-03-15\" \"2020-03-16\" \"2020-03-18\" \"2020-03-24\"\n\nas_date(\"2021, 30-12\", format = \"%Y, %d-%m\")\n\n[1] \"2021-12-30\"\n\nas_date(\"97,10,January\", format = \"%y,%d,%B\")\n\nWarning: 1 failed to parse.\n\n\n[1] NA\n\nas_date(\"12-30-1997\", format = \"%m-%d-%Y\")\n\n[1] \"1997-12-30\"\n\n\nUm detalhe importante é que os códigos %b e %B são capazes de representar apenas os nomes dos meses em inglês (ex: april, december, october). Por isso, se as suas datas possuem os nomes dos meses, em qualquer outra língua que não seja o inglês, você terá que, obrigatoriamente, traduzir esses nomes para o inglês, ou convertê-los para sua versão numérica (março = 03; abril = 04; maio = 05; e assim por diante).\n\n\n12.3.3 A partir de cada componente\nTambém é muito comum, termos cada um dos componentes separados em uma coluna específica de nossa tabela. Como exemplo, temos abaixo a tabela registros, onde o ano, mês e dia estão separados em uma determinada coluna da tabela.\nPara unirmos esses componentes em uma data, nós podemos utilizar a função make_date(). Por meio dessa função, você precisa apenas conectar os argumentos year, month e day, aos nomes das colunas que contém o ano, mês e dia (respectivamente), de cada observação da tabela, como demonstrado abaixo.\n\nregistros &lt;- tibble(\n  valor = c(5.50, 4.25, 1.32, 24.10, 12.50),\n  dia = c(5, 6, 8, 12, 15),\n  mes = c(4, 4, 4, 4, 4),\n  ano = c(2021, 2021, 2021, 2021, 2021)\n)\n\nregistros &lt;- mutate(\n  registros,\n  data = make_date(year = ano, month = mes, day = dia)\n)\n\nregistros\n\n# A tibble: 5 × 5\n  valor   dia   mes   ano data      \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;    \n1  5.5      5     4  2021 2021-04-05\n2  4.25     6     4  2021 2021-04-06\n3  1.32     8     4  2021 2021-04-08\n4 24.1     12     4  2021 2021-04-12\n5 12.5     15     4  2021 2021-04-15\n\n\nAlém disso, é importante frisar que, os seus componentes não precisam necessariamente estar dentro de um data.frame. Dito de outra forma, você também pode fornecer cada componente de sua data como um vetor. Veja o exemplo abaixo:\n\ndias &lt;- c(1, 4, 12, 15, 7)\nmes &lt;- c(1, 1, 2, 2, 2)\nano &lt;- c(2020, 2020, 2020, 2020, 2021)\n\nmake_date(year = ano, month = mes, day = dias)\n\n[1] \"2020-01-01\" \"2020-01-04\" \"2020-02-12\" \"2020-02-15\" \"2021-02-07\"\n\n\n\n\n12.3.4 A partir de números\nPara mais, o R também nos permite criar uma data a partir de um número. Por exemplo, eu posso criar a data \"2020-04-01\" (01 de abril de 2020) através do número 18353. Repare abaixo, que ao invés de um vetor do tipo double contendo o número inicial (18353), a operação me retorna um vetor do tipo Date, contendo a data supracitada.\n\nd &lt;- as_date(18353)\nd\n\n[1] \"2020-04-01\"\n\nclass(d)\n\n[1] \"Date\"\n\n\nQuando você fornece um vetor numérico à função as_date(), todos os números contidos neste vetor são tratados como o número de dias desde a data \"1970-01-01\", ou, 01 de janeiro de 1970. Em outras palavras, o R utiliza uma “escala de dias”, e a data \"1970-01-01\" representa a origem, ou o ponto zero dessa escala (para representar dias anteriores a essa data, utilizamos números negativos). Nós denominamos essa data, como a data de origem.\nPortanto, o número 18353 nos retorna a data \"2020-04-01\", pelo fato de que este dia está a 18353 dias de distância da data \"1970-01-01\". Caso você ainda sinta certa confusão, visite a seção Como as variáveis de tempo são interpretadas pelo R ?, que busca prover uma descrição mais formal e mais detalhada dos conceitos de data de origem e escala de tempo.\n\n\n12.3.5 Fique atento aos tipos de dados empregados!\nVale a pena destacar que, apesar de serem apresentadas a você como strings, dados do tipo Date são guardados e interpretados de uma maneira completamente diferente dos dados do tipo character. Ou seja, quando valores do tipo Date aparecem em seu console, eles sempre aparecem contornados por aspas duplas, como se fossem dados do tipo character. E não há qualquer informação aparente no console, que te indique qual dos dois tipos (Date ou character) está sendo empregado sobre esses valores.\nPor isso, é muito importante que você esteja atento à forma como o R está interpretando os seus dados. Use e abuse de funções e de testes lógicos que possam lhe assegurar que os seus dados estão sendo interpretados da maneira esperada! Tendo essas considerações em mente, a forma mais rápida de identificarmos se um vetor é do tipo character, ou do tipo Date, é descobrirmos a sua classe, por meio da função class(). Repare no exemplo abaixo, que o primeiro valor pertence ao tipo character, enquanto o segundo, está sendo interpretado pelo tipo Date.\n\ntexto &lt;- \"2020-08-01\"\ndata &lt;- as.Date(\"2020-08-01\")\nclass(texto)\n\n[1] \"character\"\n\nclass(data)\n\n[1] \"Date\"\n\n### Um teste lógico para o tipo Date\nclass(texto) == \"Date\"\n\n[1] FALSE\n\nclass(data) == \"Date\"\n\n[1] TRUE\n\n\nPor outro lado, caso as suas datas estejam dentro de um tibble, tal problemática perde um pouco de sua importância. Pois como descrevemos na seção tibble’s como uma alternativa moderna aos data.frame’s, quando um tibble aparece em seu console, ele sempre disponibiliza uma pequena descrição logo abaixo do nome de cada coluna, indicando o tipo de dado contido nela. Portanto, no exemplo abaixo, podemos rapidamente identificar pela descrição &lt;date&gt;, que os dados presentes na coluna data pertencem ao tipo de dado Date.\n\nlibrary(tibble)\n\ntibble(\n  data = dmy(c(\"20/05/2020\", \"21/05/2020\", \"22/05/2020\", \"23/05/2020\"))\n)\n\n# A tibble: 4 × 1\n  data      \n  &lt;date&gt;    \n1 2020-05-20\n2 2020-05-21\n3 2020-05-22\n4 2020-05-23",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introdução à variáveis de tempo com `lubridate`</span>"
    ]
  },
  {
    "objectID": "Capítulos/12-variaveis-tempo.html#datas-horários-e-fusos-horários-com-os-tipos-posixct-e-posixlt",
    "href": "Capítulos/12-variaveis-tempo.html#datas-horários-e-fusos-horários-com-os-tipos-posixct-e-posixlt",
    "title": "12  Introdução à variáveis de tempo com lubridate",
    "section": "12.4 Datas, horários e fusos horários com os tipos POSIXct e POSIXlt",
    "text": "12.4 Datas, horários e fusos horários com os tipos POSIXct e POSIXlt\nEm várias ocasiões, empresas, agentes e governos, precisam registrar o instante de ocorrência de algum episódio com um alto nível de precisão. Com isso, eu quero dizer que em certas situações, precisamos não apenas da data, mas também do horário e do fuso horário em que certo evento ocorre. Para isso, o R nos oferece os tipos POSIXct e POSIXlt, que são capazes de guardar não apenas datas, mas também horários além de fusos horários.\n\n\n\n\n\nComo um ponto no tempo é definido nos tipos POSIXct e POSIXlt\n\n\n\n\nNo fundo, o R utiliza as funções as.POSIXct() e as.POSIXlt() para criar um objeto dos tipos POSIXct e POSIXlt, respectivamente. Portanto, mesmo que as ferramentas apresentadas nessa seção pertençam (em sua maioria) ao pacote lubridate, saiba que no fundo, as funções as.POSIXct() e as.POSIXlt() são empregadas para criar o seu vetor do tipo POSIXct e POSIXlt.\nDentro da comunidade de R, vários usuários costumam se referir aos tipos POSIXct e POSIXlt, em uma forma mais intuitiva. Sendo o termo date-time, o mais utilizado para tal referência. Portanto, date-time é um sinônimo (ou uma gíria) utilizado para se referir à “espécie” de dado (isto é, uma data acompanhada de um horário e de um fuso horário) armazenado pelos tipos POSIXct e POSIXlt.\nPor isso, ao longo dessa seção, quando estivermos descrevendo características gerais que se aplicam a ambos os tipos, vamos utilizar o termo date-time como um sinônimo aos tipos POSIXct e POSIXlt. Por outro lado, quando estivermos descrevendo características específicas de cada um, vamos utilizar o nome do tipo correspondente.\n\n12.4.1 Criando vetores do tipo date-time\nPara criarmos um vetor contendo dados do tipo date-time, podemos utilizar exatamente os mesmos métodos empregados no tipo Date, com pequenas modificações. Isto é, podemos criar um vetor dos tipos POSIXct e POSIXlt: 1) a partir de strings; 2) a partir de números; e 3) a partir de cada componente deste date-time. Um resumo de tais métodos, além de algumas observações quanto ao tipo date-time, são apresentados na Figura 12.3.\nPara realizar cada um desses métodos, o pacote lubridate nos oferece a função as_datetime(). Todavia, vale apontar que essa função sempre gera um vetor do tipo POSIXct como resultado. Por isso, se você deseja converter o seu objeto para o tipo POSIXlt, aplique a função as.POSIXlt() sobre o resultado de as_datetime().\n\n\n\n\n\n\n\n\nFigura 12.3: Principais métodos para se criar dados do tipo date-time no R\n\n\n\n\n\n\n\n12.4.2 A partir de strings\nAssim como descrevemos durante as seções do tipo Date, o R segue as regras definidas no padrão internacional ISO-8601 para armazenar e interpretar suas variáveis de tempo. Esse padrão delimita que, dados do tipo date-time devem ser escritos no formato “ano-mês-dia hora:minuto:segundo”. A Figura 12.4, provê uma representação visual de tal formato.\n\n\n\n\n\n\n\n\nFigura 12.4: Formato padrão no R para dados do tipo date-time\n\n\n\n\n\nMais abaixo, temos um exemplo em que um objeto chamado dt é criado, com o objetivo de guardar o seguinte ponto no tempo: 10 horas, 40 minutos e 35 segundos do dia 01 de janeiro de 2020. Repare nesse exemplo, que nós não incluímos na string inicial qualquer informação a respeito do fuso horário utilizado. Mesmo assim, a função as_datetime() automaticamente configurou o horário com o fuso UTC, que corresponde à Coordinated Universal Time. Portanto, sempre que você não definir explicitamente um fuso horário, a função as_datetime() vai utilizar o fuso horário UTC.\nPara mais, isso demonstra que não é necessário incluirmos o fuso horário utilizado, diretamente na string a ser fornecido. Pois tal informação é definida separadamente no argumento tz da função.\n\ndt &lt;- as_datetime(\"2020-01-01 10:40:35\")\ndt\n\n[1] \"2020-01-01 10:40:35 UTC\"\n\n\nIsso não significa que, as strings não devem ou não podem conter qualquer informação a respeito do fuso horário. Mas significa que essas informações serão, por padrão, ignoradas pela função, que vai utilizar o fuso UTC para qualquer input. Veja o exemplo abaixo, em que dois fusos horários diferentes são testados, e o mesmo resultado é gerado em ambos.\n\nas_datetime(\"2020-01-01 10:40:35 Portugal\")\n\n[1] \"2020-01-01 10:40:35 UTC\"\n\nas_datetime(\"2020-01-01 10:40:35 America/Sao_Paulo\")\n\n[1] \"2020-01-01 10:40:35 UTC\"\n\n\nPortanto, a maneira correta de definir o fuso horário a ser empregado, é por meio do argumento tz, como demonstrado abaixo:\n\nas_datetime(\"2020-01-01 10:40:35\", tz = \"Portugal\")\n\n[1] \"2020-01-01 10:40:35 WET\"\n\nas_datetime(\"2020-01-01 10:40:35\", tz = \"America/Sao_Paulo\")\n\n[1] \"2020-01-01 10:40:35 -03\"\n\n\nFusos horários são usualmente fornecidos ao argumento tz por meio de um código (e.g. \"WET\", \"UTC\", \"ROK\", \"CET\", etc.), ou por meio de uma referência de região ou cidade específica (e.g. \"Europe/Paris\", \"Pacific/Auckland\", \"America/Toronto\", etc.). Para consultar a lista completa de valores reconhecidos pelo R, execute a função OlsonNames() em seu console.\nDito de outra forma, valores como \"ROK\" (abreviação para Republic of Korea), \"CET\" (Central European Time), \"America/Sao_Paulo\" (cidade de São Paulo) e \"Pacific/Auckland\" (cidade de Auckland), são aceitos pelo argumento tz, porque eles estão inclusos no resultado da função OlsonNames(). Em contraste, valores como \"São Paulo\", \"WST\", e \"+11\", não são aceitos pelo argumento tz, pois não estão presentes em OlsonNames().\n\nas_datetime(\"2020-01-01 10:34:12\", tz = \"CET\")\n\n[1] \"2020-01-01 10:34:12 CET\"\n\nas_datetime(\"2020-01-01 10:34:12\", tz = \"ROK\")\n\n[1] \"2020-01-01 10:34:12 KST\"\n\nas_datetime(\"2020-01-01 10:34:12\", tz = \"Pacific/Auckland\")\n\n[1] \"2020-01-01 10:34:12 NZDT\"\n\n\n\n### Quando incluímos um fuso horário desconhecido\n### pelo R, a seguinte mensagem de erro aparece:\nas_datetime(\"2020-01-01 10:34:12\", tz = \"WST\")\n\n\nError in C_force_tz(time, tz = tzone, roll) : \n  CCTZ: Unrecognized output timezone: \"WST\"\n\n\n\n12.4.3 O que devo fazer se meus dados se encontram em um formato diferente?\nDa mesma maneira que uma mesma data pode ser escrita de várias formas, horários também podem assumir formatos diferentes. Sendo que, diferentemente das datas, algumas partes de um horário (hora, minuto e segundo) podem ser ignoradas, a depender da precisão de tempo necessária. De qualquer modo, em casos como este, as soluções a serem empregadas são exatamente as mesmas que descrevemos na seção O que devo fazer se minhas datas se encontram em um formato diferente?, que são:\n\nUtilizar os códigos oferecidos pelo R no argumento format da função.\nOu utilizar as funções rápidas do pacote lubridate (dmy_h(), dmy_hm(), dmy_hms(), etc.) que possuem uma ordem implícita para cada componente.\n\n\n\n\n\n\n\n\n\nFigura 12.5: Códigos que podem representar cada componente de um dado do tipo date-time\n\n\n\n\n\nA Figura 12.5 apresenta os principais códigos oferecidos pelo R para cada componente de um dado do tipo date-time. Porém, há vários outros códigos, os quais são menos comuns e, que por isso, foram omitidos dessa tabela. Você pode encontrar uma lista completa desses códigos, ao consultar a documentação interna da função strptime(), com o comando ?strptime.\nPelas informações dispostas na Figura 12.5, sabemos que o formato delineado pelo padrão ISO-8601, isto é, “ano-mês-dia hora:minuto:segundo”, pode ser descrito pelo padrão \"%Y-%m-%d %H:%M:%S\", ou, de forma mais sucinta, \"%F %T\". Como exemplo, repare abaixo que ambas as descrições geram os mesmos resultados, quando aplicadas sobre os valores presentes no vetor pontos:\n\npontos &lt;- c(\"2018-06-15 08:11:05\", \"2018-07-22 21:09:05\")\nas_datetime(pontos, format = \"%Y-%m-%d %H:%M:%S\")\n\n[1] \"2018-06-15 08:11:05 UTC\" \"2018-07-22 21:09:05 UTC\"\n\n### Ou de forma análoga\nas_datetime(pontos, format = \"%F %T\")\n\n[1] \"2018-06-15 08:11:05 UTC\" \"2018-07-22 21:09:05 UTC\"\n\n\nNo caso do Brasil, valores do tipo date-time costumam se apresentar no formato “dia/mês/ano hora:minuto:segundo”. Logo, uma descrição capaz de representar tal formato é \"%d/%m/%Y %H:%M:%S\", ou então, uma alternativa mais curta é \"%d/%m/%Y %T\".\n\npontos_br &lt;- c(\"15/06/2018 08:11:05\", \"22/07/2018 21:09:05\")\nas_datetime(pontos_br, format = \"%d/%m/%Y %H:%M:%S\")\n\n[1] \"2018-06-15 08:11:05 UTC\" \"2018-07-22 21:09:05 UTC\"\n\n### Ou de forma análoga\nas_datetime(pontos_br, format = \"%d/%m/%Y %T\")\n\n[1] \"2018-06-15 08:11:05 UTC\" \"2018-07-22 21:09:05 UTC\"\n\n\nVale ressaltar que, em todos os exemplos mostrados até agora, todos os componentes de um date-time foram fornecidos nas strings utilizadas como input. Dito de outra forma, em nenhum exemplo mostrado até o momento, os segundos, os minutos ou as horas estavam ausentes das strings utilizadas como input. Esse cenário perfeito nem sempre ocorre, e isso não necessariamente é um problema sério. Pois, em alguns processos, a empresa nem sempre precisa de uma precisão muito alta em seus registros de tempo.\nPor exemplo, uma indústria de aço não recebe matérias primas a cada segundo. Muitas vezes, a firma encomenda um grande estoque de materiais, combustíveis e minérios ao final de cada mês. Por esse motivo, a firma talvez precise registrar apenas as horas e minutos do dia, em que cada entrega (ou carregamento de matéria-prima) chegou a sua sede, em um determinado mês.\nTendo isso em mente, se eu possuo a string abaixo, contendo o valor \"2020-04-15 10:30\", eu poderia utilizar a descrição \"%F %H:%M\" para descrever o formato em que esse valor se encontra. Contudo, uma alternativa eficiente e intuitiva, é utilizar a função ymd_hm(). Perceba pelo resultado abaixo, que ao não possuirmos um determinado componente de um dado do tipo date-time, esse componente faltante é preenchido por zeros.\n\ndt &lt;- \"2020-04-15 10:30\"\nas_datetime(dt, format = \"%F %H:%M\")\n\n[1] \"2020-04-15 10:30:00 UTC\"\n\nymd_hm(dt)\n\n[1] \"2020-04-15 10:30:00 UTC\"\n\n\nDo mesmo modo que descrevemos anteriormente, funções rápidas como ymd_hm() possuem uma ordem para cada componente que está implícita no nome dessa função. A novidade em relação às funções ymd(), dmy() e suas irmãs, é que essas funções focadas em dados do tipo date-time, incluem três novas letras que se referem a hora (h), minuto (m) e segundo (s). Portanto, sabemos pelo nome da função, que ymd_hm() espera um input onde os componentes se apresentam na ordem “ano \\(\\rightarrow\\) mês \\(\\rightarrow\\) dia \\(\\rightarrow\\) hora \\(\\rightarrow\\) minuto”.\nPor isso, a função dmy_hms() é uma alternativa ideal para ler dados do tipo date-time que foram escritos segundo o padrão brasileiro. Pois essa função espera como input, um dado em que os componentes seguem a ordem “dia \\(\\rightarrow\\) mês \\(\\rightarrow\\) ano \\(\\rightarrow\\) hora \\(\\rightarrow\\) minuto \\(\\rightarrow\\) segundo”. Veja o exemplo abaixo:\n\ndts &lt;- c(\"12/10/1998 19:19:32\", \"12/10/1998 22:15:09\")\nsem_segundo &lt;- c(\"12/10/1998 19:19\", \"12/10/1998 22:15\")\nsem_minuto_e_segundo &lt;- c(\"12/10/1998 19\", \"12/10/1998 22\")\n\ndmy_hms(dts)\n\n[1] \"1998-10-12 19:19:32 UTC\" \"1998-10-12 22:15:09 UTC\"\n\ndmy_hm(sem_segundo)\n\n[1] \"1998-10-12 19:19:00 UTC\" \"1998-10-12 22:15:00 UTC\"\n\ndmy_h(sem_minuto_e_segundo)\n\n[1] \"1998-10-12 19:00:00 UTC\" \"1998-10-12 22:00:00 UTC\"\n\n\nPara além dos códigos mais tradicionais, a parte inferior da Figura 12.5 descreve alguns códigos menos comuns, como o código %z. Esse código em específico, é capaz de identificar um ajuste (em horas e minutos) presente na string de input, e adicioná-lo ao fuso horário aplicado sobre o resultado da função. Porém, como veremos mais à frente, lidar com fusos horários não é algo muito simples, e para piorar, o cálculo aritmético por trás da adição de um ajuste com o código %z, é no mínimo, peculiar.\nPortanto, o uso de ajustes representados pelo código %z, é algo mais complicado do que uma simples adição3. Sendo que, o cálculo aritmético aplicado por tal código, está demonstrado em detalhes na seção Quando fusos horários diferentes geram uma grande confusão. Por esses motivos, o código %z é algo difícil de se trabalhar, especialmente levando-se em conta que: em certas situações, o código %z gera resultados diferentes entre as funções as_datetime() e as.POSIXct().\nTal diferença, se baseia puramente no fato de que a função as_datetime() escolhe, por padrão, o fuso horário UTC, enquanto a função as.POSIXct(), tende a escolher o fuso horário padrão de seu sistema operacional (o qual não necessariamente é o fuso horário UTC). Como exemplo, temos abaixo um vetor chamado dt, que contém o instante: 8 horas do dia 01 de janeiro de 2020. Ademais, podemos identificar um ajuste negativo (ou “para trás”) de 3 horas (-0300), ao final da string. Perceba abaixo, que ambas as funções nos retornam horários diferentes. Esse problema vale certa reflexão sua, porque essa diferença existe? Como ela ocorre? Vamos dar as respostas para essas perguntas mais a frente. Até lá, pense um pouco sobre esses resultados.\n\ndt &lt;- \"2020-01-01 08:00:00 -0300\"\nstrptime(dt, format = \"%F %T %z\")\n\n[1] \"2020-01-01 08:00:00\"\n\nas_datetime(dt, format = \"%F %T %z\")\n\n[1] \"2020-01-01 11:00:00 UTC\"\n\n\nComo uma dica, repare como os resultados mudam quando adicionamos uma hora ao ajuste, gerando assim, um desvio negativo de 2 horas (-0200).\n\ndt &lt;- \"2020-01-01 08:00:00 -0200\"\nstrptime(dt, format = \"%F %T %z\")\n\n[1] \"2020-01-01 07:00:00\"\n\nas_datetime(dt, format = \"%F %T %z\")\n\n[1] \"2020-01-01 10:00:00 UTC\"\n\n\n\n\n12.4.4 A partir de cada componente\nCaso você possua, separadamente, cada um dos itens que compõe um dado do tipo date-time (dia, mês, ano, hora, minuto e segundo), você pode utilizar a função make_datetime() para uni-los em um único vetor do tipo date-time. Por exemplo, suponha que você possua um data.frame parecido com a tabela tab abaixo.\n\ntab &lt;- tibble(\n  ano = 2020,\n  mês = 5,\n  dia = c(15, 16, 16, 18, 19),\n  hora = c(9, 11, 12, 8, 14),\n  minuto = c(7, 23, 19, 15, 30),\n  segundo = c(34, 11, 5, 17, 49)\n)\n\ntab \n\n# A tibble: 5 × 6\n    ano   mês   dia  hora minuto segundo\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1  2020     5    15     9      7      34\n2  2020     5    16    11     23      11\n3  2020     5    16    12     19       5\n4  2020     5    18     8     15      17\n5  2020     5    19    14     30      49\n\n\nEm relação à função make_date(), a função make_datetime() introduz três novos argumentos, sendo eles: hour, min e sec, que se referem às horas, os minutos e os segundos, respectivamente.\n\ntab &lt;- mutate(\n  tab,\n  date_time = make_datetime(\n    year = ano, month = mês, day = dia,\n    hour = hora, min = minuto, sec = segundo\n  )\n)\n\ntab\n\n# A tibble: 5 × 7\n    ano   mês   dia  hora minuto segundo date_time          \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dttm&gt;             \n1  2020     5    15     9      7      34 2020-05-15 09:07:34\n2  2020     5    16    11     23      11 2020-05-16 11:23:11\n3  2020     5    16    12     19       5 2020-05-16 12:19:05\n4  2020     5    18     8     15      17 2020-05-18 08:15:17\n5  2020     5    19    14     30      49 2020-05-19 14:30:49\n\n\n\n\n12.4.5 A partir de números\nAssim como ocorre no tipo Date, dados do tipo date-time também podem ser criados a partir de números. O mecanismo de conversão é muito semelhante ao que mostramos com o tipo Date. Porém, ao invés de representar o número de dias desde uma data de origem, ao ser convertido para os tipos POSIXct e POSIXlt, o número que estamos tentando converter, será interpretado como o número de segundos desde a meia-noite de 01 de janeiro de 1970 (de outra forma, 1970-01-01 00:00:00).\nPor isso, podemos chegar ao instante “08 horas do dia 01 de janeiro de 2005”, ao convertermos o número 1.104.566.400 (que representa aproximadamente 1,104 bilhões de segundos) para o tipo date-time. Em outras palavras, 08 horas do dia 01 de janeiro de 2005 está a 1.104.566.400 segundos de distância da meia-noite do dia 01 de janeiro de 1970.\n\nas_datetime(1104566400)\n\n[1] \"2005-01-01 08:00:00 UTC\"\n\n\nPara mais detalhes sobre os conceitos de ponto de origem e escala temporal (que são essenciais para se compreender corretamente essa conversão entre números e instantes no tempo), consulte a seção Como as variáveis de tempo são interpretadas pelo R ?.\n\n\n12.4.6 Novamente, fique atento aos tipos empregados!\nAssim como ocorre com o tipo Date, dados do tipo POSIXct e POSIXlt também aparecem em seu console, contornados por aspas duplas e, novamente, não há qualquer informação aparente, que nos informe se os dados em questão se encontram no tipo character ou em algum dos tipos date-time. Da mesma forma que descrevemos no tipo Date, uma maneira simples e prática de identificar se um objeto pertence ao tipo POSIXct ou POSIXlt, é olhar para a classe desse objeto, com a função class(). Entretanto, de maneira diferente do tipo Date, que continha apenas um valor para a sua classe, repare abaixo que, objetos dos tipos POSIXct e POSIXlt sempre possuem um segundo valor para a sua classe (POSIXt).\n\nv_POSIXct &lt;- as.POSIXct(\"2020-01-01 10:40:35\")\nv_POSIXlt &lt;- as.POSIXlt(\"2020-01-01 10:40:35\")\n\nclass(v_POSIXct)\n\n[1] \"POSIXct\" \"POSIXt\" \n\nclass(v_POSIXlt)\n\n[1] \"POSIXlt\" \"POSIXt\" \n\n\nPor esse detalhe, quando você estiver criando o seu teste lógico, utilize o operador %in%, ao invés do operador ==.\n\n### Para identificar se o objeto é do\n### tipo POSIXct, utilize:\n\"POSIXct\" %in% class(v_POSIXct)\n\n[1] TRUE\n\n### Já para o tipo POSIXlt, utilize:\n\"POSIXlt\" %in% class(v_POSIXlt)\n\n[1] TRUE\n\n\nUm outro método útil de identificarmos se um objeto pertence aos tipos POSIXct e POSIXlt, é através da função inherits(), como está demonstrado abaixo:\n\ninherits(v_POSIXct, \"POSIXct\")\n\n[1] TRUE\n\ninherits(v_POSIXlt, \"POSIXlt\")\n\n[1] TRUE",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introdução à variáveis de tempo com `lubridate`</span>"
    ]
  },
  {
    "objectID": "Capítulos/12-variaveis-tempo.html#diferenças-entre-posixct-e-posixlt",
    "href": "Capítulos/12-variaveis-tempo.html#diferenças-entre-posixct-e-posixlt",
    "title": "12  Introdução à variáveis de tempo com lubridate",
    "section": "12.5 Diferenças entre POSIXct e POSIXlt",
    "text": "12.5 Diferenças entre POSIXct e POSIXlt\nAté o momento, nós não descrevemos quais são as características que diferem os tipos POSIXct e POSIXlt um do outro. Em resumo, os valores do tipo POSIXct são guardados dentro de em um vetor e, os valores do tipo POSIXlt, em uma lista nomeada contendo vários vetores que guardam cada componente desses valores.\nEm mais detalhes, quando utilizamos o tipo POSIXct, o R vai apenas construir um vetor contendo os nossos dados do tipo date-time. Apesar desses valores serem apresentados a nós, no formato “ano-mês-dia hora:minuto:segundo”, em uma camada mais profunda, o R vai armazená-los como o número de segundos desde o instante 1970-01-01 00:00:00 (meia-noite de 01 de janeiro de 1970). Por outro lado, quando empregamos o tipo POSIXlt, o R vai construir uma lista nomeada contendo vários vetores, onde cada um desses vetores possui um componente específico (dia, mês, ano, hora, etc.) de seu dado do tipo date-time. A Figura 12.6, fornece uma representação visual dessa diferença.\n\n\n\n\n\n\n\n\nFigura 12.6: Representação visual das estruturas formadas pelos tipos POSIXct e POSIXlt\n\n\n\n\n\nPara mais detalhes, você pode conferir a documentação interna desses tipos, com ?POSIXct ou ?POSIXlt. Para mais, vale destacar que, dados que se encontram em qualquer um desses dois tipos, são apresentados da mesma maneira a nós. Em outras palavras, quando aparecem em seu console do R, os dados do tipo POSIXct e POSIXlt sempre aparecem como um vetor cotendo valores no formato “ano-mês-dia hora:minuto:segundo”.\n\nv_POSIXct &lt;- as.POSIXct(\"2020-01-01 10:40:35\")\nv_POSIXlt &lt;- as.POSIXlt(\"2020-01-01 10:40:35\")\n\nprint(v_POSIXct)\n\n[1] \"2020-01-01 10:40:35 -03\"\n\nprint(v_POSIXlt)\n\n[1] \"2020-01-01 10:40:35 -03\"\n\n\nPorém, como eu descrevi acima, a forma como esses dados estão estruturados dentro do objeto é completamente diferente. Por exemplo, eu posso extrair os segundos (35) do valor (ou valores) em questão, ao acessar o item de nome sec da lista que compõe o objeto v_POSIXlt. Da mesma forma, caso eu precise extrair o dia (01) de cada data presente no objeto v_POSIXlt, basta acessar o item de nome mday dessa lista.\n\nv_POSIXlt$sec\n\n[1] 35\n\nv_POSIXlt$mday\n\n[1] 1\n\n\nNa hipótese de, realizarmos a mesma tarefa com um valor do tipo POSIXct, sem que ele seja convertido para o tipo POSIXlt, a nossa melhor opção seria implantarmos um string subsetting, com as funções que já vimos no capítulo Manipulação e transformação de strings com stringr.\n\nlibrary(stringr)\ncomo_texto &lt;- as.character(v_POSIXct)\n\n### Por exemplo, para extrair os segundos faríamos:\nas.integer(str_sub(como_texto, 18, 19))\n\n[1] 35\n\n### Para extrair o dia:\nas.integer(str_sub(como_texto, 9, 10))\n\n[1] 1\n\n### Para extrair o ano:\nas.integer(str_sub(como_texto, 1, 4))\n\n[1] 2020\n\n\nPortanto, podemos dizer que o tipo POSIXlt provê um formato mais próximo da maneira como nós, seres humanos, pensamos sobre um valor do tipo date-time. Ou seja, diversos componentes (dia, mês, ano, hora, etc.) que, em conjunto, formam um dado do tipo date-time, mas que ainda representam unidades ou informações diferentes. Todavia, o tipo POSIXct fornece uma estrutura muito mais ideal para o uso em data.frame’s e, em geral, operações e cálculos aritméticos. Dito de outra forma, seja em uma coluna de um data.frame ou em qualquer outra estrutura, é mais fácil trabalhar no R com dados do tipo date-time, quando eles se encontram no tipo POSIXct.\nVocê também pode encarar a escolha entre esses dois tipos da seguinte maneira: se você deseja extrair um componente específico de cada data (dia, mês, ano, hora, etc.), você pode transformar os seus valores para o tipo POSIXlt, com a função as.POSIXlt() e, em seguida, extrair o item da lista resultante que contém o componente desejado; caso você não tenha pretensões de extrair algum componente, sempre utilize o tipo POSIXct. Pois esse tipo provê um formato mais natural para diversas operações e cálculos aritméticos que você venha a realizar sobre os seus valores.",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introdução à variáveis de tempo com `lubridate`</span>"
    ]
  },
  {
    "objectID": "Capítulos/12-variaveis-tempo.html#extraindo-os-componentes-de-uma-variável-de-tempo",
    "href": "Capítulos/12-variaveis-tempo.html#extraindo-os-componentes-de-uma-variável-de-tempo",
    "title": "12  Introdução à variáveis de tempo com lubridate",
    "section": "12.6 Extraindo os componentes de uma variável de tempo",
    "text": "12.6 Extraindo os componentes de uma variável de tempo\nVocê já sabe que, nós podemos extrair cada componente de maneira simples e intuitiva, ao transformarmos os dados em questão para o tipo POSIXlt, e utilizar os itens da lista resultante para chegarmos ao componente desejado. Porém, também vamos mostrar nessa seção, algumas funções rápidas presentes no pacote lubridate, que tornam esse processo de extração ainda mais simples.\nPrimeiro, essas funções rápidas e as partes extraídas por cada uma delas, são:\n\nday(), dia do mês (1-31).\nmonth(), mês do ano (1-12).\nyear(), ano (número de 4 dígitos).\nhour(), hora do dia (0-23).\nminute(), minutos (0-59).\nsecond(), segundos (0-61).\n\nTendo essas funções em mente, se nós desejamos extrair apenas as horas de cada valor presente no vetor dt abaixo, nós podemos simplesmente aplicar a função hour() sobre este vetor. De modo análogo, se desejamos calcular o dia do mês correspondente a cada valor, nós podemos utilizar a função day():\n\ndt &lt;- c(\"21/02/2020 10:22:53\", \"01/11/2019 20:13:01\", \"19/07/2018 15:24:20\")\ndt &lt;- dmy_hms(dt)\n\nhour(dt)\n\n[1] 10 20 15\n\nminute(dt)\n\n[1] 22 13 24\n\nday(dt)\n\n[1] 21  1 19\n\n\nEssas funções rápidas são particularmente úteis, quando desejamos extrair os componentes de alguma coluna de um data.frame’s. Como exemplo, podemos visitar novamente a tabela transf que vimos ao longo do capítulo 4, e extrair os componentes de cada valor presente em sua coluna Data.\n\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo &lt;- \"transf_reform.csv\"\n\nlibrary(readr)\ntransf &lt;- read_csv2(paste0(github, pasta, arquivo))\n\ntransf &lt;- transf %&gt;% \n  select(-Descricao) %&gt;% \n  mutate(\n    hora = hour(Data),\n    minuto = minute(Data),\n    segundo = second(Data)\n  )\n\n\ntransf\n\n# A tibble: 20,006 × 8\n  Data                Usuario  Valor TransferID Pais      hora minuto segundo\n  &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;  &lt;int&gt;   &lt;dbl&gt;\n1 2018-12-06 22:19:19 Eduardo   599.  116241629 Alemanha    22     19      19\n2 2018-12-06 22:10:34 Júlio    4611.  115586504 Alemanha    22     10      34\n3 2018-12-06 21:59:50 Nathália 4418.  115079280 Alemanha    21     59      50\n4 2018-12-06 21:54:13 Júlio    2740.  114972398 Alemanha    21     54      13\n5 2018-12-06 21:41:27 Ana      1408.  116262934 Alemanha    21     41      27\n# ℹ 20,001 more rows\n\n\nPara mais, o vetor dt, assim como a coluna Data da tabela transf, que utilizamos nos exemplos anteriores, são vetores do tipo POSIXct. Contudo, as funções mostradas acima, funcionam exatamente da mesma forma com valores do tipo Date. Ou seja, o processo é o mesmo, basta aplicar a função que extrai o componente no qual você está interessado sobre o seu vetor do tipo Date.\n\nv_Date &lt;- c(\"21/02/2020\", \"01/11/2019\", \"19/07/2018\")\nv_Date &lt;- dmy(v_Date)\n\nday(v_Date)\n\n[1] 21  1 19\n\nmonth(v_Date)\n\n[1]  2 11  7\n\nyear(v_Date)\n\n[1] 2020 2019 2018\n\n\nEm outras palavras, isso é a mesma coisa que dizer: “um vetor do tipo Date pode ser convertido diretamente para o tipo POSIXlt e, com isso, podemos extrair os componentes que compõe cada data presente nesse vetor”. Tal fato está exposto no exemplo abaixo:\n\nv_Date &lt;- c(\"21/02/2020\", \"01/11/2019\", \"19/07/2018\")\nv_Date &lt;- as.POSIXlt(dmy(v_Date))\n\nv_Date$mday\n\n[1] 21  1 19\n\n\nComo definimos na seção anterior, um objeto do tipo POSIXlt é na realidade, uma lista nomeada, e, você pode descobrir quais são os nomes de cada item dessa lista, ao acessar o atributo names desse objeto, com a função attr(), como demonstrado abaixo. Dessa maneira, o nome \"hour\" me indica que há um item chamado hour nessa lista, e, ao acessar esse item com o comando v_POSIXlt$hour, eu posso identificar o que se encontra dentro desse item. Você pode encontrar mais detalhes sobre cada item dessa lista, ao ler a documentação interna do tipo POSIXlt, com o comando ?POSIXlt.\n\nattr(v_POSIXlt, \"names\")\n\n [1] \"sec\"    \"min\"    \"hour\"   \"mday\"   \"mon\"    \"year\"   \"wday\"   \"yday\"  \n [9] \"isdst\"  \"zone\"   \"gmtoff\"",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introdução à variáveis de tempo com `lubridate`</span>"
    ]
  },
  {
    "objectID": "Capítulos/12-variaveis-tempo.html#fusos-horários",
    "href": "Capítulos/12-variaveis-tempo.html#fusos-horários",
    "title": "12  Introdução à variáveis de tempo com lubridate",
    "section": "12.7 Fusos horários",
    "text": "12.7 Fusos horários\n\n12.7.1 Como identificar o fuso horário associado a um valor do tipo date-time\nÉ importante destacar que, todo dado do tipo POSIXct ou POSIXlt estará sempre ligado a algum fuso-horário de referência, mesmo que esse fuso não esteja evidente à primeira vista. Há duas maneiras principais de se identificar o fuso utilizado: primeiro, veja se alguma informação aparece ao lado do horário presente em seu valor do tipo date-time; segundo, veja a informação armazenada no atributo tzone de seu objeto. A partir desses métodos de conferência, existem três possibilidades para a identificação desse fuso, as quais estão resumidas na Figura 12.7.\n\n\n\n\n\n\n\n\nFigura 12.7: Métodos para se identificar o fuso horário empregado em dados do tipo POSIXct e POSIXlt\n\n\n\n\n\nPortanto, busque primeiro, reconhecer se alguma informação aparece à direita do horário. Se não há alguma informação nesse local, verifique o atributo tzone desse objeto. Quando utilizamos as funções dos pacotes básicos do R para criar o nosso objeto, e não definimos algum fuso horário específico no argumento tz, o atributo tzone do objeto resultante estará quase sempre vazio. Em casos como esse, o R vai automaticamente utilizar o fuso horário de seu sistema operacional, que pode ser identificado pelo resultado da função Sys.timezone(). Perceba abaixo, que o sistema operacional do meu computador, utiliza o horário de São Paulo, que é equivalente ao fuso horário de Brasília.\n\nSys.timezone()\n\n[1] \"America/Sao_Paulo\"\n\n\nEsse fuso horário (de Brasília) se encontra a 3 desvios negativos do fuso horário UTC (vamos explicar mais a frente o que isso significa). Por esse motivo que, no exemplo abaixo, um -03 aparece ao final do valor de vec. Em outras palavras, essa informação (-03) está nos dizendo que o fuso horário empregado sobre o valor de vec, é o fuso horário que se encontra a 3 desvios negativos do fuso horário UTC, que pelos motivos apresentados acima, é o fuso horário de Brasília, ou, o fuso horário padrão do sistema operacional de meu computador.\n\nvec &lt;- as.POSIXct(\"2020-01-01 10:34:12\")\nattr(vec, \"tzone\")\n\n[1] \"\"\n\nvec\n\n[1] \"2020-01-01 10:34:12 -03\"\n\n\nEm outras situações, o fuso horário presente à direita do horário será informado em seu código padrão. Veja o exemplo abaixo, em que utilizamos o fuso horário de Paris (França). Como resultado, o atributo tzone é preenchido pelo valor \"Europe/Paris\". Mas quando o valor de vec é desenhado em nosso console, o código CET é posicionado à direita do horário. Esse código se refere à Central European Time (ou “Tempo da Europa Central”), que é o fuso horário usufruído por diversos países europeus, incluindo a França.\n\nvec &lt;- as_datetime(\"2020-01-01 10:34:12\", tz = \"Europe/Paris\")\nattr(vec, \"tzone\")\n\n[1] \"Europe/Paris\"\n\nvec\n\n[1] \"2020-01-01 10:34:12 CET\"\n\n\nSendo assim, você pode aplicar dois métodos diferentes sobre um valor do tipo POSIXct ou POSIXlt, para se identificar o fuso horário de referência. Para mais, compreenda que ao longo desses métodos, o fuso horário aplicado pode se apresentar em 3 formatos diferentes: por meio de um código (como CET, para Central European Time, ou UTC, para Coordinated Universal Time); por meio de uma região, ou uma cidade específica (como America/Sao_Paulo, ou Europe/Paris); ou então, por um desvio positivo ou negativo em relação ao fuso horário UTC (como -03, +05, ou +11).\n\n\n12.7.2 Zonas horárias e o Coordinated Universal Time (UTC) como horário internacional\nO planeta Terra é divido em 24 zonas horárias, que são apresentadas na Figura 12.8. No centro, se encontra a zona horária de número 0, que é a zona em que se encontra o famoso Meridiano de Greenwhich, que por convenção, é o meridiano que divide a terra ao meio, ou, em outras palavras, que separa formalmente o oriente do ocidente. Cada zona horária, representa um fuso horário diferente, e, por isso, podemos dizer que há 24 fusos horários diferentes ao redor do mundo.\n\n\n\n\n\n\n\n\nFigura 12.8: As diferentes zonas horárias presentes no planeta Terra\n\n\n\n\n\nMesmo que cada zona horária seja determinada geograficamente, cada país ou cada nação tem o direito político de decidir qual a zona horária a qual ele pertence. Por esse motivo, mesmo que países como Argélia, Espanha e França estejam geograficamente sobre a zona horária de número 0, por decisão política própria, tais países foram inclusos na zona horária de número +1.\nA zona horária de número 0, é a zona horária em que é calculado e utilizado o horário internacional, que é comumente denominado de Coordinated Universal Time (UTC), ou, Tempo Universal Coordenado. Sendo que todos os fusos horários utilizados ao redor do mundo, são calculados a partir do horário UTC. Dito de outra forma, UTC é o nome do fuso horário utilizado na zona horária de número 0, (isto é, a zona em que se encontra o Meridiano de Greenwhich) e tal horário, é a base para determinarmos todos os outros horários empregados no mundo.\nSendo assim, o UTC é oficialmente o horário universal ou internacional utilizado no mundo. No passado, o sistema UTC era formalmente chamado de Tempo Médio de Greenwhich, ou, Greenwhich Mean Time (GMT), o qual sofreu alterações metodológicas importantes, que o transformaram no sistema UTC que conhecemos e utilizamos hoje. Por isso, caso você encontre algum horário acompanhado da sigla GMT, saiba que ele está se referindo ao “antigo UTC”.\n\n\n12.7.3 Fusos horários como desvios do horário UTC\nÉ muito importante destacar que, o UTC é o horário internacional, não no sentido de que ele é o horário utilizado fora dos limites de qualquer país, mas sim, no sentido de que todos os outros fusos horários utilizados no planeta, são calculados a partir dele.\nEm resumo, o fuso horário aplicado em uma determinada zona horária, apresenta 1 hora de diferença em relação aos fusos horários empregados em suas zonas vizinhas. Tal efeito é de certa forma, uma consequência do fato da Terra levar aproximadamente 24 horas para dar a volta completa em torno de seu próprio eixo (esse movimento é chamado de rotação da Terra). Por esse motivo, cada uma das 24 zonas horárias possui 15 graus de longitude (ou de “largura”). Pois a cada 15 graus que a Terra rotaciona, 1 hora se passa em nosso horário.\nEssa afirmação pode ser posta matematicamente. Ao partirmos do princípio de que a Terra é uma esfera perfeita, sabemos que o planeta possui 360 graus de circunferência. Levando-se em conta que o planeta demora 24 horas para rotacionar-se em torno de seu próprio eixo, temos que \\(360 / 24 = 15\\) graus por hora. Por essa razão que, cada zona horária, ou, cada fuso horário apresenta 1 hora de diferença em relação aos seus vizinhos.\nCom isso, podemos interpretar fusos horários como desvios de \\(x\\) horas em relação ao horário UTC (ou a zona horária de número 0). Ao analisarmos um determinado fuso horário, é muito importante identificarmos o lado do Meridiano de Greenwhich (à esquerda ou à direita) no qual esse fuso se encontra, pois, tal informação determinará se o desvio de \\(x\\) horas (em relação ao horário UTC) é negativo (à esquerda) ou positivo (à direita). Se o desvio for negativo, significa que o desvio deve ser subtraído do horário internacional (ou seja, o horário do país em questão, está atrasado em relação ao horário UTC). Por outro lado, se o desvio for positivo, significa que esse desvio deve ser acrescido ao horário internacional (o país está com horário adiantado).\nPortanto, um fuso horário é calculado a partir de um desvio de \\(x\\) horas em relação ao horário UTC. Para sabermos o número \\(x\\) de horas a serem descontadas (ou adicionadas) do horário UTC, temos que saber a distância da zona horária em análise da zona horária de número 0. Por exemplo, ao voltarmos para a Figura 12.8, podemos identificar que a Finlândia está inclusa na zona horária de número +2 e, por estar a duas zonas horárias de distância da zona horária de número 0, sabemos que o horário empregado na Finlândia possui um desvio positivo de 2 horas em relação ao horário UTC. Isso significa que a Finlândia está 2 horas adiantada em relação ao horário internacional.\nComo um outro exemplo, o Brasil participa de 4 zonas horárias diferentes (de números -2, -3, -4 e -5). Logo, o Brasil possui 4 fusos horários diferentes ao longo de suas regiões, sendo o fuso horário de Brasília o mais comum dentre eles. A zona horária que representa o fuso horário de Brasília, é a zona de número -3. Isso significa que o horário de Brasília está a 3 desvios negativos do horário UTC, ou, dito de outra forma, o horário de Brasília é equivalente ao horário internacional subtraído de 3 horas (ou atrasado em 3 horas). Tal relação está exposta pela Figura 12.9.\n\n\n\n\n\n\n\n\nFigura 12.9: O Brasil possui quatro fusos horários diferentes\n\n\n\n\n\n\n\n12.7.4 Quando fusos horários diferentes geram uma grande confusão\nUma das principais características do pacote lubridate é a de que suas funções tentam utilizar o fuso horário UTC em todo lugar. Por isso, em todas as ocasiões em que não definirmos explicitamente um fuso horário a ser empregado no argumento tz de as_datetime(), ou de dmy_hms(), o valor resultante dessas funções vai utilizar o fuso UTC.\nNo entanto, as funções dos pacotes básicos do R adotam um protocolo diferente. Ao não definirmos um fuso horário no argumento tz das funções as.POSIXct() e strptime(), o fuso horário padrão do sistema operacional será automaticamente empregado sobre o resultado. No caso do Brasil, enfrentamos 4 fusos horários diferentes. Logo, a depender de onde você se encontra no país, você talvez tenha resultados diferentes dos que são apresentados a seguir. Mas o raciocínio permanece o mesmo, independentemente de onde você se encontra no planeta.\nNa prática, essa diferença entre padrões só impacta em seus resultados, caso você esteja trabalhando com diversos fusos horários ao mesmo tempo, ou, se você deseja aplicar alguma operação que lida diretamente com o fuso horário de um dado do tipo date-time. Um exemplo de operação que lida diretamente com o fuso de referência dos dados e, que, portanto, possui diferentes resultados entre as_datetime() e as.POSIXct(), é o uso do código %z em format, para incluir um desvio (em horas e minutos) sobre o fuso horário a ser aplicado sobre o resultado final.\nNa seção O que devo fazer se meus dados se encontram em um formato diferente?, demos um exemplo prático que demonstra esse efeito, que nasce da diferença entre os fusos horários padrões adotados pelas funções. Nesse exemplo possuíamos um vetor chamado dt, contendo o instante: 8 horas do dia 01 de janeiro de 2020. O objetivo principal desse exemplo era demonstrar que, se não definirmos algum fuso horário no argumento tz, as funções as_datetime() e as.POSIXct() nos trazem resultados diferentes, quando aplicadas sobre os mesmos valores do tipo date-time. Tal exemplo está reproduzido abaixo:\n\ndt &lt;- \"2020-01-01 08:00:00 -0300\"\nas.POSIXct(dt, format = \"%F %T %z\")\n\n[1] \"2020-01-01 08:00:00 -03\"\n\nas_datetime(dt, format = \"%F %T %z\")\n\n[1] \"2020-01-01 11:00:00 UTC\"\n\n\nLembre-se que o valor -0300 presente ao final da string armazenada em dt, representa um desvio negativo de 3 horas que será interpretado pelo código %z. Para mais, lembre-se que o valor -03 presente ao final do resultado de as.POSIXct() representa apenas o fuso horário empregado nesse resultado e, portanto, não possui qualquer relação com o desvio de -0300 do código %z.\nPrimeiro, ao observarmos o resultado de as.POSIXct(), percebemos que o desvio de 3 horas (-0300) não gerou alterações no horário (8 horas em ponto) contido em dt. Entretanto, nós também podemos observar abaixo, que a função as_datetime() “adicionou” esse desvio ao valor presente em dt, gerando assim, um horário adiantado em 3 horas. A lógica por trás desses resultados, começa a ficar mais clara, a medida em que alteramos o valor do desvio, como demonstrado abaixo.\n\ndt &lt;- \"2020-01-01 08:00:00 -0200\"\nas.POSIXct(dt, format = \"%F %T %z\")\n\n[1] \"2020-01-01 07:00:00 -03\"\n\nas_datetime(dt, format = \"%F %T %z\")\n\n[1] \"2020-01-01 10:00:00 UTC\"\n\n\nComo um outro exemplo, podemos alterar o sinal do desvio. Porém, ao contrário do que você provavelmente está pensando, mesmo um desvio positivo acaba sendo subtraído do horário. Dessa vez, as.POSIXct() subtraiu 5 horas do horário original de dt, enquanto em as_datetime(), a redução foi de apenas 2 horas.\n\ndt &lt;- \"2020-01-01 08:00:00 +0200\"\nas.POSIXct(dt, format = \"%F %T %z\")\n\n[1] \"2020-01-01 03:00:00 -03\"\n\nas_datetime(dt, format = \"%F %T %z\")\n\n[1] \"2020-01-01 06:00:00 UTC\"\n\n\nA medida em que testamos diferentes valores para esse desvio, podemos perceber que a adição do desvio representado pelo código %z segue a fórmula:\n\\[\nH = h - [(d \\times -1) + z]\n\\]\nSendo que, as variáveis presentes nessa equação são:\n\n\\(H\\): hora presente no resultado final da função.\n\\(h\\): hora inicial, ou, em outras palavras, a hora que está presente na string de input.\n\\(d\\): número de desvios (em relação ao fuso UTC) que representa o fuso horário empregado no resultado final da função.\n\\(z\\): o valor do desvio presente na string de input, e que é representado pelo código %z.\n\nDesse modo, ao olharmos para a string armazenado em dt, identificamos que o valor de \\(h\\) nessa equação, corresponde a 8 horas. Como nós não alteramos o horário presente nessa string em nenhum dos exemplos anteriores, o valor de \\(h\\) esteve sempre fixo. O que estava variando de um exemplo para o outro, era o valor de \\(z\\) e o valor de \\(d\\).\nA valor da variável \\(d\\) depende apenas de qual o fuso horário adotado pela função que estamos utilizando. Quando utilizamos a função as_datetime(), o valor de \\(d\\) será igual a zero, pois essa função sempre tenta adotar o fuso horário UTC em seus resultados. Contudo, quando utilizamos as funções dos pacotes básicos do R, o valor de \\(d\\) vai depender de qual é o fuso horário padrão de seu sistema operacional. No meu caso, o valor de \\(d\\) em meu computador (quando a função as.POSIXct() ou strptime() é empregada) é igual a -3 (que é o desvio que representa o fuso horário de Brasília).\nTendo essas informações em mente, podemos concluir que a diferença entre os resultados das funções as.POSIXct() e as_datetime() se deve apenas à divergência entre os fusos horários adotados por cada função, o que impacta diretamente no valor da variável \\(d\\) para cada função. Em outras palavras, se \\(H_{lubr}\\) e \\(H_{base}\\) são as horas calculadas por as_datetime() e as.POSIXct(), e, se \\(d_{lubr}\\) e \\(d_{base}\\) são os desvios que representam os fusos horários adotados por cada função, respectivamente, podemos expor essa diferença de forma matemática:\n\\[\nH_{lubr} = 8 - [(d_{lubr} \\times -1) + z] = 8+d_{lubr}-z\n\\]\n\\[\nH_{base} = 8 - [(d_{base} \\times -1) + z] = 8+d_{base}-z\n\\]\n\\[\nH_{base} - H_{lubr} = 8+d_{base}-z - (8+d_{lubr}-z)\n\\]\n\\[\nH_{base} - H_{lubr} = d_{base} - d_{lubr}\n\\]\nCom essas equações, podemos rapidamente identificar que se ambas as funções aplicarem o mesmo fuso horário, as variáveis \\(d_{lubr}\\) e \\(d_{base}\\) serão iguais e, consequentemente, essa diferença entre \\(H_{base}\\) e \\(H_{lubr}\\) desaparece. Como exemplo, perceba abaixo que ambas as funções retornam o mesmo resultado, ao escolhermos um fuso horário específico no argumento tz de cada função, como por exemplo, o horário de Toronto (Canadá).\n\ndt &lt;- \"2020-01-01 08:00:00 +0200\"\n### Quando ambas as funções utilizam o mesmo fuso horário\n### a inserção do código %z gera o mesmo resultado\nas.POSIXct(dt, format = \"%F %T %z\", tz = \"America/Toronto\")\n\n[1] \"2020-01-01 01:00:00 EST\"\n\nas_datetime(dt, format = \"%F %T %z\", tz = \"America/Toronto\")\n\n[1] \"2020-01-01 01:00:00 EST\"\n\n\nPortanto, fique atento a possíveis diferenças entre os horários que resultam de funções que, em tese, deveriam ser “equivalentes” e, que portanto, deveriam gerar os mesmos resultados. Essa seção, buscou demonstrar que tal diferença pode nascer da divergência entre os fusos horários adotados por cada função. Caso você encontre uma diferença dessa natureza, busque pela documentação interna de cada função, e procure entender como essas funções trabalham com o fuso horário.\n\n\n12.7.5 Interpretando um mesmo ponto no tempo em diferentes fusos horários\nVamos construir mentalmente duas pessoas. Cláudio mora e trabalha no Rio de Janeiro, e tem feito alguns projetos internacionais na área de marketing. Um de seus principais parceiros é Ryuichi, um grande empresário do Japão. Suponha que Cláudio e Ryuichi tenham marcado uma reunião entre eles, às 9hrs da manhã no horário do Japão (isto é, no horário local para o Ryuichi). Qual será o horário da reunião no Brasil? Ou seja, que horas Cláudio deve ligar o seu computador e acessar a sala de reunião para conversar com Ryuichi?\nPodemos rapidamente responder a essa questão, com a função with_tz(). Precisamos primeiro, criar um objeto que guarde o horário de 9hrs segundo o fuso horário do Japão e, em seguida, pedimos à função, que nos mostre esse mesmo instante segundo o horário de São Paulo. Como você pode ver abaixo, Cláudio teria que entrar na reunião às 21hrs do dia anterior ao dia marcado por Ryuichi.\n\nhorario_japao &lt;- ymd_hm(\"2020-01-01 09:00\", tz = \"Japan\")\nwith_tz(horario_japao, \"America/Sao_Paulo\")\n\n[1] \"2019-12-31 21:00:00 -03\"\n\n\nPortanto, o horário do Japão está 12 horas adiantado em relação ao horário utilizado por Cláudio. Isso significa que, poderíamos chegar ao mesmo resultado mostrado pela função with_tz(), ao subtrairmos 12 horas do valor presente horario_japao. Lembre-se que, valores do tipo POSIXct são armazenados em segundos, logo, para subtrairmos as 12 horas, precisamos multiplicar essas 12 horas com os 60 minutos (de cada hora) e com os 60 segundos (de cada minuto).\n\nhorario_japao - (12 * 60 * 60)\n\n[1] \"2019-12-31 21:00:00 JST\"\n\n\nNo entanto, ao invés de adicionar ou subtrair segundos, no fundo, o que a função with_tz() faz, é retornar o mesmo objeto contendo um atributo tzone diferente. Em outras palavras, podemos ainda chegar ao mesmo resultado de with_tz(), ao alterarmos o valor do atributo tzone em horario_japao para o fuso horário de Cláudio, como demonstrado abaixo.\n\nhorario_brasil &lt;- horario_japao\nattr(horario_brasil, \"tzone\") &lt;- \"America/Sao_Paulo\"\nhorario_brasil\n\n[1] \"2019-12-31 21:00:00 -03\"\n\n\nPor isso, fique atento aos seus dados do tipo POSIXct e POSIXlt. Na hipótese desses dados se alterarem repentinamente, sem alguma explicação clara, pode ser que alguma operação que você realizou tenha alterado o valor conectado ao atributo tzone desses dados e, com isso, provocado esse efeito.",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introdução à variáveis de tempo com `lubridate`</span>"
    ]
  },
  {
    "objectID": "Capítulos/12-variaveis-tempo.html#calculando-intervalos-com-o-tipo-difftime",
    "href": "Capítulos/12-variaveis-tempo.html#calculando-intervalos-com-o-tipo-difftime",
    "title": "12  Introdução à variáveis de tempo com lubridate",
    "section": "12.8 Calculando intervalos com o tipo difftime",
    "text": "12.8 Calculando intervalos com o tipo difftime\nO R oferece de forma nativa, um outro tipo de variável de tempo que é útil para calcularmos intervalos ou diferenças entre dois pontos no tempo. Esse tipo é comumente chamado de difftime, e é representado principalmente pela função difftime().\nO tipo difftime é na verdade, um tipo de dado muito simples. Em resumo, um dado do tipo difftime é um dado do tipo double, acompanhado de um atributo chamado units, que guarda a unidade na qual o valor double se encontra. Porém, o papel que esse tipo busca cumprir não é nada simples.\nPor exemplo, vamos supor dois horários em um mesmo dia, como 09 horas e 16 horas. A diferença entre esses dois pontos é de 7 horas. Tudo que o tipo difftime faz é, armazenar a unidade “horas” no atributo units que está conectado ao número 7. Dito de outra forma, um dos papéis que o tipo difftime cumpre é manter o controle das unidades de tempo empregadas em valores que representam um intervalo de tempo (ou a duração de algum evento).\n\ndt1 &lt;- ymd_h(\"2020-01-01 09\")\ndt2 &lt;- ymd_h(\"2020-01-01 16\")\n\ndifftime(dt2, dt1)\n\nTime difference of 7 hours\n\n\nDevido a esse controle, o tipo difftime é capaz de eficientemente calcular o intervalo de tempo, entre valores que se encontram em unidades de tempo diferentes. Por exemplo, qual a diferença entre 14 horas e 14000 segundos? Ao convertermos esses números para valores do tipo difftime, o R se torna capaz de identificar as unidades de cada um. Dessa forma, o R pode reconhecer qual a maneira ideal de converter ambos os valores para a mesma unidade, e com isso, calcular corretamente a diferença entre os dois.\n\nhoras &lt;- as.difftime(14, units = \"hours\")\nsegundos &lt;- as.difftime(14000, units = \"secs\")\n\nhoras - segundos\n\nTime difference of 36400 secs\n\n\nAlém disso, a função difftime() lhe permite escolher a unidade que você deseja para o resultado. Logo, se você deseja saber quantas semanas estão entre as datas 14 de março de 2020 e 01 de janeiro de 2020, você pode rapidamente calcular esse valor da seguinte maneira:\n\njaneiro &lt;- ymd(\"2020-01-01\")\nmarco &lt;- ymd(\"2020-03-14\")\n\ndifftime(marco, janeiro, units = \"weeks\")\n\nTime difference of 10.42857 weeks\n\n\nCaso você não precise de um nível de precisão muito elevado, você aplicar funções como round(), ceiling() e floor() sobre o resultado de difftime(). Por exemplo, a parte decimal do valor que calculamos acima (10,42857 semanas) é de pouco valor para nós. Digo, quanto é 0,42857 ou 42,857% de uma semana? Por essa questão, seria interessante aplicarmos a função floor() sobre este resultado, para sabermos qual o número de semanas completas que existem entre as datas de marco e janeiro.\n\nfloor(difftime(marco, janeiro, units = \"weeks\"))\n\nTime difference of 10 weeks",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introdução à variáveis de tempo com `lubridate`</span>"
    ]
  },
  {
    "objectID": "Capítulos/12-variaveis-tempo.html#sec:interp_var_tempo",
    "href": "Capítulos/12-variaveis-tempo.html#sec:interp_var_tempo",
    "title": "12  Introdução à variáveis de tempo com lubridate",
    "section": "12.9 Como as variáveis de tempo são interpretadas pelo R ?",
    "text": "12.9 Como as variáveis de tempo são interpretadas pelo R ?\nEm resumo, qualquer informação que represente uma data (ex: 20/12/2020) é geralmente interpretada pelo R por meio do tipo Date; já datas que são acompanhadas de algum horário (ex: 20/12/2020 10:32:41) são assimiladas pelo R através dos tipos POSIXlt e POSIXct (PENG, 2015); e, por último, quando temos a duração de algum evento, ou principalmente, a diferença de tempo entre duas datas (ex: a diferença entre 12 de março e 15 de março é de três dias, ou, 72 horas, ou, 4.320 minutos, ou, 259.200 segundos), temos a opção de empregarmos o tipo difftime sobre essas informações (mas nem sempre isso é necessário).\nNo fundo, qualquer dado que for interpretado pelos tipos Date, POSIXlt, POSIXct, ou difftime, é armazenado pelo R como um número real, isto é, um dado do tipo double. Ou seja, da mesma forma em que descrevemos (no capítulo anterior) o tipo factor como um “parente” do tipo básico integer, os tipos Date, POSIXlt, POSIXct e difftime são na realidade, parentes do tipo básico double, ou, dito de outra forma, são construídos a partir dele. E o que diferencia esses tipos do tipo básico double, são as suas classes e atributos.\nAssim sendo, em termos técnicos, podemos dizer que um dado que se encontra no tipo Date, POSIXlt, POSIXct, ou difftime, é na verdade, um dado do tipo double que possui classe Date, POSIXlt, POSIXct, ou difftime, respectivamente. Para mais, um objeto que se encontra no tipo POSIXlt ou POSIXct, inclui um atributo chamado tzone. Já um objeto do tipo difftime, possui um atributo chamado units. Dito de outra forma, os tipos Date, POSIXlt, POSIXct e difftime são armazenados por meio do tipo double, mas apresentam diferentes classes e atributos que os diferenciam uns dos outros.\nIsso significa que, por exemplo, para testarmos corretamente se um objeto do R se encontra no tipo Date, nós devemos aplicar um teste lógico parecido com o teste abaixo. Ambos os vetores (double_vec e date_vec) conseguem passar (isto é, adquirem um valor TRUE) na primeira parte do teste (is.double(x)), pois ambos os vetores são do tipo double. Entretanto, apenas o vetor date_vec é capaz de passar também na segunda parte do teste (class(x) == \"Date\"), pois apenas date_vec possui classe Date.\n\ndouble_vec &lt;- c(0.5, 1.2, 1.5, 2.4)\ndate_vec &lt;- as.Date(c(\"2020-09-10\", \"2020-09-11\", \"2020-09-12\"))\n\nis.double(double_vec) & class(double_vec) == \"Date\"\n\n[1] FALSE\n\nis.double(date_vec) & class(date_vec) == \"Date\"\n\n[1] TRUE\n\n\nUma segunda forma mais direta de realizarmos esse teste é através da função inherits(), que é capaz de identificar se um objeto específico do R “herda”, ou apresenta as características específicas de um tipo em questão.\n\ninherits(double_vec, \"Date\")\n\n[1] FALSE\n\ninherits(date_vec, \"Date\")\n\n[1] TRUE\n\n\n\n12.9.1 Escala de tempo e o conceito de data de origem\nPara que essa característica fique clara, veja o exemplo abaixo. Primeiro, eu guardo a data 10 de março de 2020 no objeto d. Ao questionarmos o R sobre o tipo de dado e classe utilizados pelo objeto d, vemos que ele é um vetor do tipo double com classe Date. Em seguida, eu aplico a função unclass() sobre o objeto d, para que o R me mostre exatamente como essa data está sendo armazenada.\nRepare abaixo, que o R está guardando a data 2020-03-10 (quer dizer, 10 de março de 2020) como o número 18331. Agora, você provavelmente está se questionando: o que esse número 18331 significa? Como ele é traduzido para a data 10 de março de 2020? Essas questões são respondidas pelo conceito de data de origem.\n\n## O objeto d guarda a data\n## 10 de março de 2020\nd &lt;- as.Date(\"2020-03-10\")\ntypeof(d)\n\n[1] \"double\"\n\nclass(d)\n\n[1] \"Date\"\n\nunclass(d)\n\n[1] 18331\n\n\nEste número, pelo qual o R guarda a data 2020-03-10, representa o número de dias decorridos desde a data de origem até a data 2020-03-10. Digo, 18331 dias se passaram desde a data de origem até atingirmos o dia 10 de março de 2020. Portanto, a data de origem representa o “marco zero”, ou o ponto zero da escala de tempo, e podemos descobrir qual é essa “data de origem” utilizada pelo R, ao subtrairmos da data armazenada o número que a representa.\nPor exemplo, se o número 18331 representa a data 2020-03-10, ao subtrairmos esse número dessa data, o R acaba nos retornando a data 1970-01-01. Portanto, o “dia zero” segundo a perspectiva do R, é o dia 01 de janeiro de 1970. Isso significa que, todos os seus dados no R que estiverem sendo interpretadas pelo tipo Date, vão ser (obrigatoriamente) armazenados pelo R como o número de dias entre a data de origem do R (o dia 01 de janeiro de 1970) e as suas datas em questão.\n\nas.Date(\"2020-03-10\") - 18331\n\n[1] \"1970-01-01\"\n\n\nEssa característica é muito importante, e não é particular ao R. Diversas linguagens de programação, e programas comuns (como o Excel) implementam variáveis de tempo desta mesma maneira4. Logo, no R, qualquer informação que descreva um ponto específico do tempo é armazenada como um número, e, tal número representa (de certa maneira) uma “medida de distância” entre o ponto zero da escala de tempo e o ponto do tempo com o qual você está trabalhando.\nTendo isso em mente, qual é o número que representa a data 10 de janeiro de 1970 no R? Se você compreendeu os conceitos apresentados nessa seção, você certamente respondeu que esse valor é o número 9. Pois partindo do dia 01 de janeiro de 1970 até o dia 10 de janeiro, temos 9 dias de diferença.\n\nd &lt;- as.Date(\"1970-01-10\")\nunclass(d)\n\n[1] 9\n\n\nMas e as datas anteriores ao dia 01 de janeiro de 1970? Como o R representa essas datas? Mesmo nessa situação, o R não muda o seu comportamento. Contudo, como essas datas se encontram atrás do “ponto zero” na escala do tempo utilizada, o R vai representar essas datas com números negativos. Por exemplo, o dia 30 de dezembro de 1969 é representado por meio do número -2. Pois essa data se encontra a 2 dias atrás do dia 01 de janeiro de 1970.\n\nd &lt;- as.Date(\"1969-12-30\")\nunclass(d)\n\n[1] -2\n\n\nPortanto, quanto você aplica uma ordenação sobre um vetor do tipo Date, POSIXlt, POSIXct ou difftime, ao invés de o R comparar o dia, mês e ano de cada data, ele vai utilizar os números que representam cada ponto no tempo presente nesse vetor para calcular essa ordenação. Em outras palavras, esses valores são ordenados de acordo com as suas distâncias em relação à data de origem utilizada pelo R.\n\n\n12.9.2 A unidade ou a escala de tempo muda com o tipo de dado\nNós sabemos que o tipo Date é armazenado como o número de dias em relação à data de origem. Porém, um choque ocorre quando tentamos transportar isso para os tipos POSIXlt e POSIXct. Pois qualquer dado que for interpretado por algum desses dois tipos, vai ser armazenado como os segundos em relação ao ponto de origem.\nOu seja, a teoria continua a mesma; a sua informação continua sendo armazenada como um número, que representa uma “medida de distância” até o “ponto zero” da escala de tempo. Entretanto, a unidade utilizada nessa escala de tempo muda de acordo com o tipo de dado que você emprega. Logo, quando estamos discutindo o tipo Date, o R recorre à uma escala de tempo em dias. Mas quando estamos nos referindo aos tipos POSIXlt e POSIXct, essa mesma escala de tempo é interpretada em segundos.\n\n\n\n\n\nRepresentação visual da escala de tempo utilizada por cada tipo de dado\n\n\n\n\nPara mais, a data de origem é a mesma em ambas as escalas (01 de janeiro de 1970). Todavia, como os tipos POSIXlt e POSIXct são capazes de guardar horários, esses tipos vão utilizar um ponto específico dessa data de origem como referência. Isto é, ao invés de utilizar o dia 01 de janeiro de 1970 como um todo, os tipos POSIXlt e POSIXct empregam um ponto, ou, um horário específico desse dia como o ponto zero de sua escala de tempo. E esse horário é, de certa forma, o ponto zero desse dia, ou, de outra forma, a meia noite desse dia no fuso horário UTC. Logo, o ponto de origem na escala da qual os tipos POSIXlt e POSIXct usufruem é o horário 00:00:00 do dia 01 de janeiro de 1970, especificamente no fuso horário UTC.\nCom isso, se o dia 2020-03-10 está a 18331 dias de distância do dia 1970-01-01, a quantos segundos o horário 14:30 desse mesmo dia (2020-03-10 14:30:00) está de distância do ponto zero da escala (1970-01-01 00:00:00)? Para descobrirmos a resposta, podemos aplicar o mesmo método que utilizamos com o tipo Date, por meio da função unclass(). Vemos abaixo, que tal horário é interpretado pelo R como o segundo 1583850600. Em outras palavras, esse horário está aproximadamente a 1,583 bilhão de segundos de distância do ponto zero da escala.\n\nhr &lt;- as.POSIXct(\"2020-03-10 14:30:00\", tz = \"UTC\")\nunclass(hr)\n\n[1] 1583850600\nattr(,\"tzone\")\n[1] \"UTC\"\n\n\n\n\n\n\nGROTHENDIECK, G.; PETZOLDT, T. Date and Time Classes in R. R News, v. 4, n. 1, p. 29–31, 2004.\n\n\nPENG, R. D. R Programming for Data Science. [s.l.] Leanpub, 2015.\n\n\nRIPLEY, B. D.; HORNIK, K. Date-Time Classes. R News, v. 1, n. 2, p. 8–11, 2001.",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introdução à variáveis de tempo com `lubridate`</span>"
    ]
  },
  {
    "objectID": "Capítulos/12-variaveis-tempo.html#footnotes",
    "href": "Capítulos/12-variaveis-tempo.html#footnotes",
    "title": "12  Introdução à variáveis de tempo com lubridate",
    "section": "",
    "text": "Em resumo, datas podem ser criadas a partir de todos os outros tipos que vimos até o momento (character, double, integer, logical, e factor). Para mais detalhes, consulte ?as.Date e ?Date.↩︎\nhttps://www.stat.berkeley.edu/~s133/dates.html↩︎\nSe é algo não muito comum, e ainda, complicado de se entender, então porque falar sobre o código %z? Pelo simples fato de que ele demonstra de forma eficiente, como o uso de fusos horários podem contribuir para a confusão de muitos usuários.↩︎\nPortanto, diversos programas e linguagens utilizam números para representar pontos em uma “escala de tempo”. Porém, o que tende a divergir e muito entre esses diversos sistemas é a data de origem utilizada (GROTHENDIECK; PETZOLDT, 2004). O Excel por exemplo, utiliza o dia 01 de janeiro de 1900 como o ponto zero de sua escala de tempo, enquanto o SPSS, utiliza o dia de início do calendário gregoriano (14 de outubro de 1582).↩︎",
    "crumbs": [
      "Ferramentas para tipos específicos de dados",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introdução à variáveis de tempo com `lubridate`</span>"
    ]
  },
  {
    "objectID": "Capítulos/13-controle-fluxo.html",
    "href": "Capítulos/13-controle-fluxo.html",
    "title": "13  Controle condicional de fluxo",
    "section": "",
    "text": "13.1 Introdução\nHaverá momentos em que você precisa tomar decisões em seu programa. A estrutura no R que te permite construir essas decisões, são os controles condicionais de fluxo. Nesse capítulo vamos rapidamente descrever o que são controles de fluxo, e focar logo em seguida, nos controles condicionais de fluxo. Apesar deles serem mais conhecidos por outros nomes, basicamente todas as linguagens de programação existentes oferecem tais controles e, por isso, eles fazem parte da base de praticamente todos os programas em uso no mundo.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Controle condicional de fluxo</span>"
    ]
  },
  {
    "objectID": "Capítulos/13-controle-fluxo.html#o-que-são-controles-de-fluxo",
    "href": "Capítulos/13-controle-fluxo.html#o-que-são-controles-de-fluxo",
    "title": "13  Controle condicional de fluxo",
    "section": "13.2 O que são controles de fluxo ?",
    "text": "13.2 O que são controles de fluxo ?\nEm ciência da computação, controle de fluxo (ou control flow) é a ordem na qual expressões (ou comandos) são avaliados em uma dada linguagem ou programa. Mas esse termo também é utilizado para se referir à estruturas que são capazes de alterar essa “ordem de avaliação” dos comandos executados por uma dada linguagem/programa. Nesse capítulo vamos descrever uma dessas estruturas que estão disponíveis na linguagem R.\nNo R, expressões são avaliadas de maneira sequencial (um comando atrás do outro). Mas a linguagem também nos oferece algumas estruturas que alteram a forma como essas expressões podem ser avaliadas. Tais estruturas são chamadas de “elementos de controle de fluxo” nos manuais internos da linguagem (TEAM, 2020), porém, elas são mais conhecidas dentro da comunidade de R (e da comunidade de programação em geral) por um conjunto de termos (loops, if/else statements, exception handling, dentre outros).\nEstes “elementos de controle de fluxo” são estruturas especiais criadas a partir de palavras-chave (funções também se encaixam nessa categoria), e que utilizam um par de chaves ({}) para delimitar o conjunto de comandos sobre o qual essa estrutura vai atuar. Ao contornarmos esses comandos com um par de chaves, formamos o “corpo” (ou o body) dessa estrutura. Logo abaixo, temos uma lista dos “elementos de controle de fluxo” presentes no R. Para além dos elementos listados abaixo, temos algumas outras palavras-chave que ocorrem dentro dessas estruturas, e que também alteram a forma como o fluxo de comandos ocorre, como as palavras-chave next e break, as quais podem ser utilizadas dentro de algum loop.\n\n### if statement\nif ( cond ) {\n  expr\n}\n\n### if else statement\nif ( cond ) {\n  expr1\n} else {\n  expr2\n}\n\n### while loop\nwhile ( cond ) {\n  expr\n}\n\n### repeat loop\nrepeat {\n  expr\n}\n\n### for loop\nfor ( var in list ) {\n  expr\n}\n\nMuitas linguagens de programação oferecem ao menos 3 categorias principais de controles de fluxo, sendo elas: 1) controles condicionais, ou, controles de escolha (if/else statements); 2) controles de iteração (loops); 3) controles de exceções (exception handling). No R, todas essas categorias estão presentes. Entretanto, os controles de exceções estão disponíveis através de funções (como try() e tryCatch()), enquanto os demais tipos de controles são empregados através das estruturas especiais que mencionamos, que são formadas por palavras-chave (como if, for, while, etc.). O foco deste capítulo são os controles de escolha. Por isso, os controles de iteração e de exceções serão descritos em capítulos posteriores.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Controle condicional de fluxo</span>"
    ]
  },
  {
    "objectID": "Capítulos/13-controle-fluxo.html#o-que-são-controles-condicionais-de-fluxo",
    "href": "Capítulos/13-controle-fluxo.html#o-que-são-controles-condicionais-de-fluxo",
    "title": "13  Controle condicional de fluxo",
    "section": "13.3 O que são controles condicionais de fluxo ?",
    "text": "13.3 O que são controles condicionais de fluxo ?\nUm controle condicional de fluxo (ou controle de escolha) lhe permite executar ou ignorar um determinado bloco de comandos com base em uma condição lógica. Dito de outra forma, um controle de escolha vai utilizar o resultado de um teste lógico, para decidir sobre executar ou não um determinado bloco de comandos. Muitos programadores e profissionais da ciência da computação em geral, conhecem os controles condicionais de fluxo pelo termo “branching”.\nNós utilizamos esse tipo de controle de fluxo, toda vez que encontramos uma bifurcação em nosso programa, e precisamos decidir sobre qual dos dois caminhos seguir. Por exemplo, suponha que eu tenha uma variável x em minha sessão, e que eu gostaria que o R me mostrasse no console, uma mensagem para o caso do valor dessa variável ser maior que 10, e, uma outra mensagem para o caso desse valor ser menor que 10. Tal mecanismo de mensagens poderia ser implementado da seguinte forma:\n\nx &lt;- 5\n\nif (x &gt; 10) {\n  print(\"x é maior que 10!\")\n} else {\n  print(\"x é menor que 10!\")\n}\n\n[1] \"x é menor que 10!\"\n\n\nUm controle de escolha é sempre iniciado pela palavra-chave if, e pode ou não incluir uma palavra-chave else em seguida. Sendo assim, após a palavra if, devemos abrir um par de parênteses, e incluir dentro deles, algum teste lógico (ou um objeto que contenha um valor lógico). Depois, abrimos um par de chaves, e incluímos dentro delas, os comandos a serem executados caso o resultado do teste lógico seja TRUE (no exemplo acima, esse comando é print(\"x é maior que 10!\")). Se você deseja que um outro conjunto de comandos sejam executados, para a hipótese do teste lógico retornar o valor FALSE, basta adicionar a palavra-chave else e abrir um novo par de chaves e incluir esse outro conjunto de comandos (no exemplo acima, esse outro comando é print(\"x é menor que 10!\")) dentro delas.\nTendo isso em mente, e observando o resultado dos comandos acima, podemos concluir que o resultado do teste lógico x &gt; 10 foi igual a FALSE, e que por isso, o R ignorou completamente o comando armazenado no primeiro par de chaves, e executou o comando definido no segundo par de chaves que está conectada pela palavra-chave else.\nPortanto, olhando agora para o template abaixo, quando o R encontrar em seu script esse tipo de estrutura iniciada pela palavra if, ele vai primeiro, avaliar o resultado da condição lógica descrita em condicao. Caso o resultado desse teste seja TRUE, o R vai executar os comandos presentes no primeiro par de chaves. Mas caso o resultado desse teste seja FALSE, o R vai ignorar os comandos presentes no primeiro par de chaves, e também, vai verificar se você adicionou uma palavra else após esse primeiro par de chaves. Caso você tenha adicionado essa palavra, o R vai executar os comandos inseridos no par de chaves que está logo após essa palavra else. Vale destacar que, o resultado de condicao deve ser um único valor lógico (TRUE ou FALSE). Caso o resultado de condicao seja um vetor de valores lógicos, if vai utilizar apenas o primeiro valor desse vetor para realizar suas escolhas (GROLEMUND, 2014).\n\nif(condicao){\n  # se `condicao` for verdadeira\n  # execute esses comandos\n} else {\n  # se `condicao` não for verdadeira\n  # execute esses comandos\n}\n\nDescrevendo ainda de outra maneira, e utilizando o template abaixo, se o resultado de condicao for TRUE, o R vai executar os comandos descritos na área comandos1, e vai ignorar completamente os comandos descritos na área comandos2. Por outro lado, se o resultado de condicao for FALSE, o contrário ocorre, logo, o R ignora os comandos descritos em comandos1 e executa os comandos descritos em comandos2. Dessa forma, um if statement é uma maneira de dizermos para o R realizar uma tarefa específica para um caso específico. Em português, um if statement pode ser traduzido como “Caso isso seja verdadeiro, faça isso, caso contrário, faça aquilo” (GROLEMUND, 2014).\n\nif(condicao){\n  # comandos1\n} else {\n  # comandos2\n}\n\nVocê pode incluir em cada área (comandos1 e comandos2) quantas linhas de comandos forem necessárias. Porém, pelo fato de um teste lógico produzir apenas dois valores possíveis (TRUE e FALSE), com 1 combinação de if e else, você é capaz de construir apenas dois blocos de comandos, ou duas possibilidades de execução. Caso você queira adicionar mais blocos possíveis de serem executados, formando uma espécie de “árvore de possibilidades”, você precisa adicionar um novo if após o else, como no exemplo abaixo:\n\ny &lt;- 4\n\nif(y == 1){\n  print(\"y é igual a 1\")\n} else if(y == 2){\n  print(\"y é igual a 2\")\n} else if(y == 3){\n  print(\"y é igual a 3\")\n} else if(y == 4){\n  print(\"y é igual a 4\")\n} else {\n  print(\"Não sei o que y é\")\n}\n\n[1] \"y é igual a 4\"\n\ny &lt;- \"a\"\n\nif(y == 1){\n  print(\"y é igual a 1\")\n} else if(y == 2){\n  print(\"y é igual a 2\")\n} else if(y == 3){\n  print(\"y é igual a 3\")\n} else if(y == 4){\n  print(\"y é igual a 4\")\n} else {\n  print(\"Não sei o que y é\")\n}\n\n[1] \"Não sei o que y é\"\n\n\nContudo, quando você possui mais de duas possibilidades, como no exemplo acima, o seu código geralmente fica mais organizado e legível, quando você utiliza vários if’s individuais para cada caso, como demonstrado abaixo:\n\ny &lt;- \"a\"\n\nif(y == 1){\n  print(\"y é igual a 1\")\n} \n\nif(y == 2){\n  print(\"y é igual a 2\")\n} \n\nif(y == 3){\n  print(\"y é igual a 3\")\n} \n\nif(y == 4){\n  print(\"y é igual a 4\")\n} \n\nPerceba que, quando você não utiliza a palavra-chave else, o R vai executar uma ação se, e somente se o resultado do teste lógico descrito em if for TRUE. Pois sem a palavra-chave else, você basicamente não deu ao R, nenhuma ação a ser executada para o caso do teste lógico resultar em FALSE. Por isso que no exemplo acima, nenhuma das mensagens com print() foram executadas. Pois os testes lógicos de todos os if’s acima, resultaram em FALSE.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Controle condicional de fluxo</span>"
    ]
  },
  {
    "objectID": "Capítulos/13-controle-fluxo.html#a-função-switch-como-uma-alternativa-interessante",
    "href": "Capítulos/13-controle-fluxo.html#a-função-switch-como-uma-alternativa-interessante",
    "title": "13  Controle condicional de fluxo",
    "section": "13.4 A função switch() como uma alternativa interessante",
    "text": "13.4 A função switch() como uma alternativa interessante\nNo R, temos uma função que executa um controle de fluxo semelhante ao realizado por if e else, que é a função switch(). Porém, ao invés de utilizar o resultado de um teste lógico, essa função utiliza uma string ou um índice numérico para selecionar e executar um dos blocos de comandos listados.\nPor exemplo, logo abaixo, eu forneço à função switch() o objeto y, o qual contém a string \"fruit\". Ao receber esse valor, switch() começa a procurar por alguma opção listada cujo o nome seja igual a essa string. Ao se deparar com fruit = \"banana\", switch() pega a expressão guardada nessa opção (nesse caso, a string \"banana\") e a executa. Já no segundo bloco, o objeto y agora guarda a string \"meat\", e assim, a função switch() procura novamente por uma opção listada que possua esse nome. Porém, ela não encontra nenhuma opção com o nome meat, e, por isso, ela acaba executando a expressão “geral” (a qual não está conectada a nenhum “nome” específico).\n\ny &lt;- \"fruit\"\nswitch(y, fruit = \"banana\", vegetable = \"broccoli\", \"Neither\")\n\n[1] \"banana\"\n\ny &lt;- \"meat\"\nswitch(y, fruit = \"banana\", vegetable = \"broccoli\", \"Neither\")\n\n[1] \"Neither\"\n\n\nPortanto, quando fornecemos uma string à switch(), a função procura por uma opção listada que possua um nome igual a essa string. Caso switch() encontre essa opção, a função vai executar a expressão que foi dada a essa opção. Vale destacar que essa expressão pode ser qualquer coisa, uma constante, uma função ou uma expressão que cria um novo objeto (nome_objeto &lt;- valor).\n\ny &lt;- \"média\"\nswitch(y, média = mean(1:10), soma = sum(1:10), \"Não encontrei a função\")\n\n[1] 5.5\n\ny &lt;- \"soma\"\nswitch(y, média = mean(1:10), soma = sum(1:10), \"Não encontrei a função\")\n\n[1] 55\n\ny &lt;- \"divisão\"\nswitch(y, média = mean(1:10), soma = sum(1:10), \"Não encontrei a função\")\n\n[1] \"Não encontrei a função\"\n\n\nUma outra forma de selecionar a expressão a ser executada em switch() é fonecer o índice númerico que representa essa expressão. Ou seja, se eu quero executar a primeira expressão listada, eu forneço o número 1, se eu quero executar a segunda expressão listada, eu forneço o número 2, e assim por diante.\n\ny &lt;- 2\nswitch(y, mean(1:10), sum(1:10), \"Não encontrei a função\")\n\n[1] 55",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Controle condicional de fluxo</span>"
    ]
  },
  {
    "objectID": "Capítulos/13-controle-fluxo.html#em-certas-ocasiões-é-melhor-evitar-uma-árvore-de-ifs-através-de-subsetting",
    "href": "Capítulos/13-controle-fluxo.html#em-certas-ocasiões-é-melhor-evitar-uma-árvore-de-ifs-através-de-subsetting",
    "title": "13  Controle condicional de fluxo",
    "section": "13.5 Em certas ocasiões, é melhor evitar uma árvore de if’s através de subsetting",
    "text": "13.5 Em certas ocasiões, é melhor evitar uma árvore de if’s através de subsetting\nNós utilizamos um controle de escolha para escolher que caminho perseguir em uma determinada parte de nosso programa. Entretanto, muitos usuários podem acabar utilizando if statements de uma forma não produtiva, ou ineficiente. Tenha atenção com isso. Se você está utilizando vários if/else em seu código, você provavelmente consegue refatorar esses comandos, em um formato mais claro e eficiente.\nIsso se torna um ponto ainda mais crítico quando você está tentando lidar com várias possibilidades diferentes. Pois, apesar dos controles de escolha do R serem bastante rápidos, quando temos uma árvore muito grande de if’s, várias verificações lógicas precisam ser avaliadas e, com isso, ineficiências podem surgir em seu programa de maneira desnecessária. Uma das conclusões fundamentais de GROLEMUND (2014) na Parte 3 de sua obra, é que podemos quase sempre evitar esse efeito danoso, ao substituirmos nossa árvore de if’s por um sistema que utiliza subsetting sobre algum objeto de consulta que contém todas as possibilidades.\nPor exemplo, suponha que você esteja construindo um programa que simula uma máquina caça-níquel. Quando você aciona a máquina, três símbolos são sorteados, dentre as opções “D” (diamante), “C” (cereja), “B” (banana), “G” (ouro). Caso os três símbolos seja iguais entre si, você ganha um prêmio, com base em que símbolos são esses. Suponha que 3 diamantes geram R$1000 de prêmio, enquanto 3 cerejas, 3 bananas e 3 ouros levam a prêmios de R$200, R$100 e R$600, respectivamente.\nPortanto, nesse programa, temos um comando que sorteia o resultado da máquina caça-níquel, e uma outra parte, que decide qual o valor do premio com base nesse resultado sorteado. Esse é provavelmente o caso mais típico de uso indevido de um if/else statements, em que você está tentando determinar o valor correto de uma variável (no caso abaixo, premio) que pode assumir diferentes valores a depender de uma ou de várias condições lógicas.\n\n### Sorteando os símbolos:\nresultado &lt;- paste(sample(c(\"D\", \"C\", \"B\", \"G\"), 3), collapse = \"\")\nresultado\n\n[1] \"GDB\"\n\npremio &lt;- 0\n\nif(resultado == \"DDD\"){\n  premio &lt;- 1000\n}\n\nif(resultado == \"CCC\"){\n  premio &lt;- 200\n}\n\nif(resultado == \"BBB\"){\n  premio &lt;- 100\n}\n\nif(resultado == \"GGG\"){\n  premio &lt;- 600\n}\n\n### Vendo qual foi o prêmio da rodada:\nprint(premio)\n\n[1] 0\n\n\nUm método muito mais eficiente de se resolver um problema como esse, seria criarmos um vetor de consulta (ou lookup vector) com os valores de cada prêmio. Para criar um vetor como esse, nós armazenamos os prêmios em um vetor comum, e utilizamos a função names() para nomearmos cada um desses valores com o respectivo resultado que o representa. Dessa forma, ao sortearmos o resultado do caça-níquel, utilizamos esse resultado como uma key dentro da função de subsetting ([). No exemplo abaixo, estamos fazendo isso com o comando premios[resultado]. Assim, o R vai procurar por um prêmio dentro do vetor premios que contém o mesmo nome que essa key.\n\npremios &lt;- c(1000, 200, 100, 600)\nnames(premios) &lt;- c(\"DDD\", \"CCC\", \"BBB\", \"GGG\")\nprint(premios)\n\n DDD  CCC  BBB  GGG \n1000  200  100  600 \n\n### Sorteando o resultado\nresultado &lt;- paste(sample(c(\"D\", \"C\", \"B\", \"G\"), 3), collapse = \"\")\nprint(resultado)\n\n[1] \"DCG\"\n\n### Calculando o prêmio\npremio &lt;- sum(0, premios[resultado], na.rm = TRUE)\nprint(premio)\n\n[1] 0\n\n\nAssim como em que qualquer outra linguagem, você pode reescrever uma sentença de várias formas diferentes, sem afetar o seu significado. Porém, quando estamos tratando de linguagens de programação, certos padrões de escrita tendem a ser mais claros e eficientes do que outros. O padrão de escrita mostrado acima, em que estamos tentando determinar o valor correto de uma variável, pode ser quase sempre resumido por essa estratégia em que criamos um objeto de consulta contendo todas as possibilidades, e utilizamos a função de subsetting ([) para selecionarmos a possibilidade correta.\nEntenda que, esse “valor correto” pode ser qualquer coisa (um character, um double, uma função, o nome de um arquivo, etc.) que o R te permite definir. Como exemplo, suponha que você receba múltiplos valores numéricos individuais, e que esses valores numéricos são acompanhados de um rótulo. Esse rótulo faz referência a um indicador específico.\nVamos supor que temos apenas 3 indicadores diferentes: nota média de atendimento (identificado pelo rótulo \"nma\"), tempo médio de atendimento (identificado pelo rótulo \"tma\") e índice de conclusão de tickets (identificado pelo rótulo \"ict\"). Cada um desses 3 indicadores utilizam uma unidade diferente, ou, em outras palavras, eles são apresentados em formatos diferentes. Por exemplo, o indicador tma é um indicador de tempo, logo, ele pode ser apresentado no formato HH:MM:SS. Por outro lado, o indicador ict é uma proporção de quantos tickets foram concluídos, logo, ele seria apresentado como uma porcentagem VV,VV%.\nPortanto, a depender do rótulo associado ao valor numérico que eu recebo, eu preciso formatar esse valor numérico de uma determinada maneira. Poderíamos organizar essas diferentes maneiras de se apresentar um determinado indicador em diferentes funções de “formatos”. Tais funções estão representadas abaixo. Todas elas esperam receber como input, um valor numérico qualquer, e elas produzem como output, uma representação em texto desse valor numérico no formato ideal para o indicador a que esse valor se refere.\n\nformat_percent &lt;- function(x){\n  rn &lt;- round(as.double(x) * 100, 2)\n  rn &lt;- format(rn, decimal.mark = \",\", big.mark = \".\")\n  paste0(rn, \"%\", collapse = \"\")\n}\n\nformat_double &lt;- function(x){\n  rn &lt;- as.double(x)\n  rn &lt;- round(rn, 2)\n  rn &lt;- format(rn, decimal.mark = \",\", big.mark = \".\")\n  return(rn)\n}\n\nformat_hour &lt;- function(x){\n  n &lt;- as.double(x)\n  H &lt;- as.integer( abs(n) / 3600 )\n  M &lt;- as.integer( (abs(n) / 60) - (H * 60) )\n  S &lt;- as.integer( abs(n) - (M * 60) - (H * 3600) )\n  H &lt;- ifelse(H &lt; 10, paste0(\"0\", as.character(H), collapse = \"\"), as.character(H))\n  M &lt;- ifelse(M &lt; 10, paste0(\"0\", as.character(M), collapse = \"\"), as.character(M))\n  S &lt;- ifelse(S &lt; 10, paste0(\"0\", as.character(S), collapse = \"\"), as.character(S))\n  hour &lt;- paste0(H, ':', M, ':', S, collapse = \"\")\n  return(hour)\n}\n\nCom essas funções em mãos, você poderia construir uma árvore de if’s que decidiria qual dessas funções aplicar sobre um determinado valor a depender do rótulo que o acompanha. Logo abaixo, temos um exemplo deste raciocínio:\n\nvalor &lt;- 560.258812\nnames(valor) &lt;- \"tma\"\n\nif(names(valor) == \"ict\"){\n  format_percent(valor)\n} else \nif(names(valor) == \"tma\"){\n  format_hour(valor)\n} else\nif(names(valor) == \"nma\"){\n  format_double(valor)\n}\n\n[1] \"00:09:20\"\n\n\nEntretanto, podemos facilmente refatorar esses comandos utilizando subsetting. Dessa forma, podemos armazenar as diferentes funções de formato dentro de uma lista e, em seguida, utilizarmos o rótulo que acompanha o valor em questão como uma key para acessarmos a função de formato correta dentro da lista de consulta (funcoes_formato), como está demonstrado abaixo:\n\nfuncoes_formato &lt;- list(\n  \"nma\" = format_double,\n  \"ict\" = format_percent,\n  \"tma\" = format_hour\n)\n\nvalor &lt;- 560.258812\nnames(valor) &lt;- \"tma\"\n\nformat_fun &lt;- funcoes_formato[[names(valor)]]\n\nformat_fun(valor)\n\n[1] \"00:09:20\"\n\n\nUma outra alternativa, seria utilizarmos a função switch() para reorganizarmos esse código:\n\nvalor &lt;- 560.258812\nnames(valor) &lt;- \"tma\"\n\nind &lt;- names(valor)\n\nformat_fun &lt;- switch(\n  ind,\n  \"nma\" = format_double,\n  \"ict\" = format_percent,\n  \"tma\" = format_hour\n)\n\nformat_fun(valor)\n\n[1] \"00:09:20\"\n\n\n\n\n\n\nGROLEMUND, G. Hands-On Programming with R. Sebastopol, CA: O’Reilly Media, Inc., 2014.\n\n\nTEAM, R. C. R Language Definition. Version 4.0.3 ed. [s.l.] R Foundation, 2020.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Controle condicional de fluxo</span>"
    ]
  },
  {
    "objectID": "Capítulos/05-funcoes-loops.html",
    "href": "Capítulos/05-funcoes-loops.html",
    "title": "14  Funções",
    "section": "",
    "text": "14.1 Introdução\nCada pessoa possui necessidades diferentes em seu trabalho, e a grande vantagem de se utilizar uma linguagem de programação para executar esse trabalho, é que ela lhe fornece as ferramentas para que você mesmo possa expandi-la para satisfazer os seus próprios objetivos. E a base para tal expansão está na construção de funções.\nNo início, você pode ter bastante dificuldade de construir a função que você deseja. Há vários pontos que tornam esse processo difícil. Usuários que ainda não absorveram as principais características da linguagem apresentadas no capítulo de Fundamentos da Linguagem R, podem ter muita dificuldade em identificar a origem de erros comuns em suas funções. Para mais, quando você executa uma determinada função, ela processa todas as suas tarefas em um ambiente diferente do seu. Isto significa que você não vê na maior parte do tempo, quais são os resultados que essa função está gerando, ou que objetos ela está criando, e tal situação nebulosa pode confundir muitos usuários.\nApesar dessas dificuldades, a capacidade de construir as suas próprias funções, amplia e muito os seus horizontes, ao permitir que você se aproprie da linguagem. Isto é, através de funções você é capaz de personalizar a linguagem R para que ela resolva especificamente os seus problemas, da maneira exata que você deseja que eles sejam resolvidos. Em outras palavras, apesar da linguagem R já lhe fornecer as principais ferramentas, ela também permite que você construa as suas próprias ferramentas para resolver problemas mais complexos ou mais específicos.\nDe certa forma, todos que realizam algum trabalho sério com o R, estão muito provavelmente expandindo a linguagem o tempo todo (CHAMBERS, 2016, p. 3). Por isso, neste capítulo, vamos mostrar os primeiros passos para que você possa começar a montar as suas próprias funções. Vamos fornecer algumas dicas de como enfrentar erros, além de descrever as melhores formas de se organizar essas funções, para que você não se perca no meio do processo.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/05-funcoes-loops.html#em-que-momento-você-deve-construir-uma-função",
    "href": "Capítulos/05-funcoes-loops.html#em-que-momento-você-deve-construir-uma-função",
    "title": "14  Funções",
    "section": "14.2 Em que momento você deve construir uma função ?",
    "text": "14.2 Em que momento você deve construir uma função ?\nUm bom guia é: se você copiar e colar um mesmo conjunto de comandos mais de 2 vezes, construa uma função para esses comandos! (WICKHAM; GROLEMUND, 2017). Muitos usuários e programadores em geral conhecem essa regra como o princípio DRY - do not repeat yourself! (“não repita você mesmo!”). Portanto, se você utiliza constantemente um mesmo conjunto de comandos em vários contextos diferentes, talvez esta seja a hora de você construir uma função no R que executa esses comandos.\nComo exemplo, suponha que eu tenho um data.frame chamado tab. Dentro dele, encontramos 4 colunas numéricas (v1, v2, v3 e v4). Perceba que, após criar essa tabela com a função data.frame(), eu tenho um bloco de 4 linhas de comandos. Com um pouco de atenção, você talvez perceba que esses comandos estão apenas normalizando cada uma dessas 4 colunas, segundo um índice \\(Z\\) de uma distribuição normal.\nEntretanto, talvez a primeira coisa que você de fato reparou nesse bloco de comandos, é que eles são um pouco difíceis de se ler. Agora, se você realmente prestar atenção neles, você provavelmente pode identificar um erro de digitação, mais especificamente, na linha de comandos que está normalizando a coluna v3. Perceba que eu me esqueci de ajustar a coluna dentro da função mean(), para a coluna v3. Por causa desse erro, os valores da coluna v3 serão normalizados segundo a média dos valores da coluna v2.\n\ntab &lt;- data.frame(\n  v1 = runif(10),\n  v2 = runif(10),\n  v3 = runif(10),\n  v4 = runif(10)\n)\n\n\ntab$v1 &lt;- (tab$v1 - mean(tab$v1, na.rm = TRUE)) / sd(tab$v1, na.rm = TRUE)\ntab$v2 &lt;- (tab$v2 - mean(tab$v2, na.rm = TRUE)) / sd(tab$v2, na.rm = TRUE)\ntab$v3 &lt;- (tab$v3 - mean(tab$v2, na.rm = TRUE)) / sd(tab$v3, na.rm = TRUE)\ntab$v4 &lt;- (tab$v4 - mean(tab$v4, na.rm = TRUE)) / sd(tab$v4, na.rm = TRUE)\n\nIsso é um erro extremamente comum quando começamos a copiar e colar muito um mesmo pedaço de código. Tal erro, ocorre principalmente porque os nossos olhos tendem a focar muito de sua atenção no que é muito diferente do que está ao redor, e não no que é muito parecido entre si. Consequentemente, quando temos muita repetição em um determinado bloco de comandos, ler e compreender esses comandos se torna uma atividade mais difícil e que exige muito mais de sua atenção.\nAo criarmos uma função que justamente executa esses comandos, evitamos esses erros de digitação que são extremamente comuns e que podem ser extremamente danosos. Imagine se alguma pessoa dependesse diretamente dos valores dessa coluna v3 para executar o seu trabalho. Por exemplo, se algum gerente faz suas decisões de negócio com base nessa coluna v3, ele estaria baseando suas decisões em valores errados! Caso você não detectasse esse erro a tempo, antes de enviar os dados para esse gerente, você poderia muito bem perder o seu emprego!\nPara mais, perceba que no exemplo acima, eu repeti o mesmo conjunto de comandos 4 vezes, e por causa disso, se eu precisasse alterar alguma coisa nesses comandos (e.g. para utilizar colunas diferentes, ou normalizar as colunas segundo uma fórmula de cálculo diferente, etc.), eu teria que fazer alterações em 4 lugares diferentes.\nPor outro lado, quando você guarda esses comandos dentro de uma função, você precisa aplicar essas modificações em um único local. Pois ao alterarmos a definição da função, as mudanças são automaticamente refletidas sobre todos os locais onde você emprega essa função. Consequentemente, agrupar os seus comandos em funções, torna a manutenção de seu script mais simples e fácil.\n\n14.2.1 Um exemplo inicial de função\nComo exemplo inicial, vamos criar uma função para o bloco de comandos mostrados na seção anterior. Primeiro, vamos analisar os comandos que estão sendo utilizados, para saber o que essa função vai executar, e que argumentos ela vai precisar. Reproduzi logo abaixo uma parte dos comandos utilizados. Agora, pergunte-se que argumentos essa função precisaria para executar esses comandos abaixo? Ou em outras palavras, quais inputs essa função vai utilizar?\n\n(tab$v1 - mean(tab$v1, na.rm = TRUE)) / sd(tab$v1, na.rm = TRUE)\n\nPara definir os inputs de uma função, é muito útil observarmos as várias repetições dos comandos que queremos incluir nessa função, e identificarmos o que está mudando entre cada repetição. Se você voltar às 4 repetições desses comandos que mostramos na seção passada, você pode perceber que a única coisa que está mudando entre cada linha de código, são as colunas utilizadas (v1, v2, v3 ou v4). Portanto, podemos concluir que nossa função precisa de 1 único argumento, que seria a coluna a ser normalizada.\nTendo isso em mente, poderíamos reescrever a expressão acima com o argumento x de nossa função. Por escolha própria, determinei que o nome desse argumento seria x. Mas a realidade, é que você pode dar o nome que quiser para os argumentos de sua função (poderíamos muito bem dar a ele o nome de coluna por exemplo). Pois esses argumentos são apenas “apelidos” que damos aos inputs de uma função.\n\n(x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n\nAgora, contornamos essa expressão por um par de chaves{}, e posicionamos antes desse par de chaves, a palavra-chave function, seguida de nosso argumento x dentro de um par de parênteses. Com isso, temos a definição completa de nossa função.\n\nfunction(x){\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\nPorém, nós precisamos salvar essa definição em algum lugar. Portanto, salve o resultado dessa estrutura em um novo objeto. Dessa forma, temos agora uma nova função chamada normalizar(), que executa a expressão que definimos acima.\n\nnormalizar &lt;- function(x){\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\nCom essa nova função, podemos reescrever o bloco de comandos que mostramos na seção passada, da maneira apresentada abaixo. Ainda temos certa repetição nos comandos, mas agora, temos um bloco muito mais simples e fácil de se compreender. Para eliminar completamente a repetição envolvida nesses comandos, poderíamos adicionar um loop com a função normalizar(), ou, utilizar uma das funções disponíveis no pacote purrr. Porém, veremos essas técnicas mais à frente, por enquanto, continuaremos focando nos poderes e características que emergem das funções.\n\ntab$v1 &lt;- normalizar(tab$v1)\ntab$v2 &lt;- normalizar(tab$v2)\ntab$v3 &lt;- normalizar(tab$v3)\ntab$v4 &lt;- normalizar(tab$v4)",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/05-funcoes-loops.html#sec:o_que_uma_funcao_faz",
    "href": "Capítulos/05-funcoes-loops.html#sec:o_que_uma_funcao_faz",
    "title": "14  Funções",
    "section": "14.3 O que uma função faz ?",
    "text": "14.3 O que uma função faz ?\nO que uma função faz não é algo muito distante do que você já normalmente faz em sua sessão do R, enviando manualmente cada um de seus comandos do R para dentro do console. Porém, quando você armazena os seus comandos dentro de funções, replicar esses comandos para outras áreas, amostras e indivíduos, se torna algo muito mais fácil e prático. É essa capacidade de expandir o seu trabalho com facilidade, que torna uma função algo muito poderoso.\n\n“Writing functions in R is not separate from issuing commands interactively, but grows from using, and reusing, such commands” (CHAMBERS, 2008, p. 37).\n\nEm resumo, uma função lhe permite reutilizar um certo conjunto de comandos, além de parametrizar a sua execução. Por exemplo, se você possui um bloco de comandos de, digamos, 20 linhas, ao inserir esse bloco de comandos dentro de uma função, você se torna capaz de executar essas 20 linhas de código através de 1 único comando. Por consequência, você não tem mais o trabalho de enviar individualmente cada uma das 20 linhas para o console.\nPara mais, uma função lhe permite que você defina argumentos (ou parâmetros, ou inputs). Através desses argumentos, você é capaz de modificar a forma como essas 20 linhas de código operam e, consequentemente, alterar o resultado que elas produzem.\nTendo esses pontos em mente, você geralmente utiliza uma função, quando você deseja aplicar os mesmos comandos (ou a mesma “funcionalidade”) sobre vários inputs diferentes. Essa característica se torna extremamente importante a partir do momento em que você precisa expandir o seu trabalho para um número maior de locais.\nPor exemplo, suponha que você aplique hoje, os comandos x, y e z sobre 1 única tabela para calcular um determinado indicador. Agora, suponha que amanhã você tenha que calcular o mesmo indicador, só que para um conjunto de 1000 tabelas diferentes. Como você enfrentaria esse desafio? Você copiaria 1000 vezes os comandos x, y e z em seu script para cada uma dessas 1000 tabelas? Uma solução muito mais eficiente para esse problema, seria criarmos uma função que aplica os comandos x, y e z sobre um determinado input, e pedirmos ao R que aplique essa função sobre essas 1000 tabelas por nós.\n\n\n\n\n\n\n\n\nFigura 14.1: Os componentes de uma função",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/05-funcoes-loops.html#os-passos-e-componentes-necessários-para-se-criar-uma-função",
    "href": "Capítulos/05-funcoes-loops.html#os-passos-e-componentes-necessários-para-se-criar-uma-função",
    "title": "14  Funções",
    "section": "14.4 Os passos e componentes necessários para se criar uma função",
    "text": "14.4 Os passos e componentes necessários para se criar uma função\nSegundo WICKHAM; GROLEMUND (2017), a criação de uma nova função no R envolve a realização de 3 passos:\n\nescolha um nome para a sua nova função.\ndefina os argumentos que essa nova função vai precisar, e quais deles são obrigatórios ou opcionais.\ninsira dentro do corpo da função, todos os comandos que você deseja que ela execute.\n\nEstes 3 passos refletem exatamente a estrutura de uma função no R, a qual é formada por 3 componentes diferentes, que são: 1) o nome da função; 2) os argumentos da função; e 3) o corpo, ou o body da função. Para uma compreensão mais visual de cada um desses 3 componentes, eu delimitei cada um deles na Figura 14.1. Nessa figura, utilizo como exemplo, uma função chamada somar, que simplesmente soma os dois argumentos fornecidos a ela, e nos retorna o resultado dessa soma.\nPortanto, toda função que você cria no R deve possuir esses três componentes. Para criarmos a definição de uma função no R (que representa a área laranja escura na Figura 14.1), nós sempre iniciamos pela palavra-chave function. Ou seja, quando você digita essa palavra-chave, o R entende que você está prestes a construir a definição de uma função, ao descrever os seus argumentos e o seu corpo.\n\n14.4.1 Um exemplo: identificando anos bissextos\nVamos supor que, você possua uma necessidade bem específica, que é a de identificar se um determinado ano é um ano bissexto. Você estudou a definição de um ano bissexto, tentou aplicar essa definição dentro do R, e conseguiu construir o teste lógico abaixo, que realiza os testes necessários. Lembre-se que um ano bissexto é um ano que: 1) é múltiplo de 4; e 2) não é múltiplo de 100, a menos que ele seja múltiplo de 400. Repare que, estamos utilizando abaixo o operador %%, o qual nos retorna o resto da divisão. Portanto, se o resto da divisão entre um determinado ano e um número x for igual a zero, sabemos que esse ano é múltiplo de x. Caso esse resto seja diferente de zero, sabemos que esse ano não é múltiplo de x.\n\n## Testando se o ano de 2008 é bissexto ou não\n(2008 %% 4 == 0) & ((2008 %% 100 != 0) | (2008 %% 400 == 0))\n\n[1] TRUE\n\n\nPortanto, se você precisa identificar múltiplos anos como anos bissextos ou não bissextos, você talvez comece a copiar e colar o código que você criou acima para cada ano que você deseja testar, formando algo como:\n\n# Para o ano de 2009\n(2009 %% 4 == 0) & ((2009 %% 100 != 0) | (2009 %% 400 == 0))\n\n[1] FALSE\n\n# Para o ano de 2010\n(2010 %% 4 == 0) & ((2010 %% 100 != 0) | (2010 %% 400 == 0))\n\n[1] FALSE\n\n# Para o ano de 2011\n(2011 %% 4 == 0) & ((2011 %% 100 != 0) | (2011 %% 400 == 0))\n\n[1] FALSE\n\n# Para o ano de 2012\n(2012 %% 4 == 0) & ((2012 %% 100 != 0) | (2012 %% 400 == 0))\n\n[1] TRUE\n\n\nSe você for esperto o suficiente, vai acabar percebendo que o teste lógico que você criou acima é capaz de lidar com um vetor de anos a serem testados.\n\nanos &lt;- 2008:2016\n\nresultado &lt;- (anos %% 4 == 0) & ((anos %% 100 != 0) | (anos %% 400 == 0))\nnames(resultado) &lt;- anos\n\nprint(resultado)\n\n 2008  2009  2010  2011  2012  2013  2014  2015  2016 \n TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE \n\n\nNada mal, mas porque não incorporamos esse teste dentro de uma função? Primeiro, precisamos escolher um nome para essa função. Para o nosso exemplo, algo como é_ano_bissexto é suficiente. Ou se preferir, em inglês, is_leap_year. Porém, se você puder, é sempre interessante retirar os acentos de nomes de seus objetos e funções, para evitar possíveis problemas de encoding. Dessa forma, e_ano_bissexto é um nome melhor.\nAgora que definimos o nome da função, começamos a construir a sua definição. Lembre-se que a definição de uma função sempre se inicia pela palavra-chave function, seguida por um par de parênteses (onde serão definidos os argumentos) e por um par de chaves (onde será definido o corpo).\n\ne_ano_bissexto &lt;- function(){\n  # Corpo da função\n}\n\nA segunda etapa do processo, é definir quais os inputs que essa função precisa. Como essa é uma função que busca identificar se um determinado ano é bissexto ou não, essa função precisa receber um ano sobre o qual ela possa aplicar os seus testes. Esse ano é certamente um input obrigatório, pois caso essa função não receba esse ano, ela vai aplicar os seus testes sobre o quê especificamente?\nPortanto, determinamos que essa função precisa ter 1 argumento obrigatório, que é o ano a ser testado. Por minha escolha, dei o nome de ano a esse argumento, mas ele poderia se chamar x, y, ou qualquer outro nome de sua preferência. Lembre-se que argumentos são como apelidos, eles apenas determinam em que parte do corpo da função será empregado os valores que você fornece a estes argumentos.\n\ne_ano_bissexto &lt;- function(ano){\n  # Corpo da função\n}\n\nNo estado atual da nossa função e_ano_bissexto, ela possui um argumento chamado ano, mas essa função não calcula absolutamente nada, ela nem sequer chega a aplicar algum cálculo sobre o valor que fornecemos a esse argumento ano. Essa é a situação atual, pois o corpo (ou o body) dessa função está vazio. Desse modo, o comando abaixo realiza sim uma chamada à função e_ano_bissexto com o valor de 2020 para o argumento ano, porém, a função em si, simplesmente não realiza cálculo nenhum ou nos retorna algum resultado.\n\ne_ano_bissexto(2020)\n\nNULL\n\n\nSendo assim, é hora de preenchermos o corpo dessa função. Lembre-se que, o corpo de uma função deve conter os comandos que você deseja que essa função execute por você. Nós sabemos que a função e_ano_bissexto() deve testar se um ano é bissexto, logo, devemos incluir nesse corpo, os comandos necessários para aplicar esse teste lógico, considerando o argumento ano que definimos na etapa anterior.\n\ne_ano_bissexto &lt;- function(ano){\n  (ano %% 4 == 0) & ((ano %% 100 != 0) | (ano %% 400 == 0))\n}\n\nEnfim, temos a nossa função e_ano_bissexto() funcionando da forma como desejamos:\n\ne_ano_bissexto(2100) # FALSE pois é múltiplo de 100 mas não de 400\n\n[1] FALSE\n\ne_ano_bissexto(2020) # TRUE pois é múltiplo de 4\n\n[1] TRUE\n\ne_ano_bissexto(2012:2016) # TRUE para 2012 e 2016\n\n[1]  TRUE FALSE FALSE FALSE  TRUE",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/05-funcoes-loops.html#funções-são-para-humanos-e-para-computadores",
    "href": "Capítulos/05-funcoes-loops.html#funções-são-para-humanos-e-para-computadores",
    "title": "14  Funções",
    "section": "14.5 Funções são para humanos e para computadores",
    "text": "14.5 Funções são para humanos e para computadores\nO título dessa seção foi retirado diretamente da obra de WICKHAM; GROLEMUND (2017). Com essa frase, WICKHAM; GROLEMUND (2017) buscam destacar a importância do grau de legibilidade e da documentação de uma função. Ou seja, sempre que você cria uma função, é fundamental que você escolha nomes claros para cada parte dessa função e que você documente o máximo de detalhes sobre ela.\nDessa forma, quando você voltar a essa função um ano depois desde a data em que você a criou, você terá muito mais facilidade de ler, compreender e relembrar o que essa função faz e o quais são os aspectos mais importantes sobre ela. Essa questão se torna ainda mais importante quando você está colaborando com outras pessoas, pois elas precisam ler e compreender o seu código, para que elas possam discutir e trazer as suas contribuições ao trabalho que vocês estão realizando.\nVamos começar pelo nome de sua função. Diferentes estilos de nomes são utilizados hoje no mundo da programação. O importante não é qual desses estilos você adota, mas sim, que você adote um e que você permaneça com ele. Ou seja, veja qual estilo te agrada mais e seja feliz com ele. O objetivo disso é tornar o seu código consistente, de forma que ele sempre esteja utilizando o mesmo estilo. Pois caso contrário, se o seu código utiliza muitos estilos diferentes ao mesmo tempo, sempre que você estiver lendo o seu código, você precisa trocar o tempo todo o seu modo de leitura, e isso exige certo esforço e concentração.\nComo um guia, os principais estilos utilizados hoje no R são: 1) o UpperCamel; 2) o camelCase ; 3) o snake_case; e 4) o dot.case, que é o padrão utilizado pelo próprio R na maioria de suas funções de seus pacotes básicos. Exemplos de funções que utilizam o padrão dot.case são data.frame(), list.files() e is.na().\nPode ser particularmente difícil de se definir um nome curto, e que ainda assim, traga significado para a sua função. De qualquer forma, não é pecado nenhum utilizar nomes grandes em suas funções, desde que eles entreguem o objetivo da função de forma clara. Como um guia, os nomes de funções geralmente devem ser verbos (por exemplo, bind_rows() ou “unir linhas”), e os nomes de seus argumentos, um substantivo (WICKHAM; GROLEMUND, 2017). Entretando, há ocasiões em que é melhor utilizar um substantivo para nomear uma função, especialmente se ela está computando um valor que é muito conhecido por algum substantivo específico (por exemplo, a média - mean(), ou os coeficientes de uma regressão - coef()).\nA medida em que você vai construindo múltiplas funções em um mesmo script, é útil dividirmos esse script em seções, e adicionar comentários à função que explicam como cada parte dela funciona. Nós já vimos essa funcionalidade anteriormente, na seção Scripts, mas é útil relembrarmos aqui.\nPara além de descrever como a função funciona, também é importante que você utilize os comentários para descrever o que os inputs de sua função devem ser (e.g. “o argumento df aceita um data.frame que contenha uma coluna chamada valor”), ou, o que eles definitivamente não podem ser (e.g. “os argumentos A e B não podem ser vetores de comprimentos diferentes!”). Como exemplo, a função normalizar() funciona apenas para vetores de comprimento maior do que 1.\n\n## A função normalizar() busca \"normalizar\" um determinado vetor\n## ou coluna, segundo o índice Z de uma distribuição normal.\n## OBS: argumento x deve ser um vetor de comprimento maior que 1.\n\nnormalizar &lt;- function(x){\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/05-funcoes-loops.html#construindo-argumentos-e-resultados-de-uma-função",
    "href": "Capítulos/05-funcoes-loops.html#construindo-argumentos-e-resultados-de-uma-função",
    "title": "14  Funções",
    "section": "14.6 Construindo argumentos e resultados de uma função",
    "text": "14.6 Construindo argumentos e resultados de uma função\n\n14.6.1 Podemos ter argumentos obrigatórios e/ou opcionais\nQuando você define um argumento de uma função, você pode torná-lo um argumento obrigatório ou opcional. Se uma função possui um argumento obrigatório, você não consegue executar essa função sem definir algum valor para esse argumento. Por exemplo, vamos voltar à função somar() que mostramos na Figura 14.1. Essa função possui dois argumentos (x e y). Caso eu defina um valor para o argumento x, mas não defina um valor para o argumento y, um erro será retornado.\n\nsomar &lt;- function(x, y){\n  resultado &lt;- x + y\n  return(resultado)\n}\n\nTal erro ocorre, pois o argumento y (assim como o argumento x) é um argumento obrigatório da função somar(). Um argumento se torna obrigatório, na medida em que você não estabelece um valor padrão (ou “default”) para ele, na definição de sua função.\n\nsomar(x = 56)\n\nError in somar(x = 56) : argument \"y\" is missing, with no default\nPara estabelecer um valor padrão para um argumento de uma função, basta que você iguale esse argumento a este valor padrão na definição dessa função (mais especificamente, dentro dos parênteses onde são definidos os argumentos da função). Como exemplo, se eu quisesse que o argumento y da função somar() tivesse o valor padrão de 10, eu deveria recriar a função da seguinte forma:\n\nsomar &lt;- function(x, y = 10){\n  resultado &lt;- x + y\n  return(resultado)\n}\n\nDessa forma, eu posso chamar novamente a função definindo apenas o argumento x, e dessa vez, nenhum erro aparece. Pois agora, o argumento y se tornou um argumento opcional, dado que ele já possui um valor padrão. Por causa disso, toda vez que eu executar essa função, ela sempre vai realizar os seus cálculos considerando o valor de 10 para o argumento y.\n\nsomar(x = 56)\n\n[1] 66\n\nsomar(x = 32)\n\n[1] 42\n\n\nAgora, não é porque um certo argumento possui um valor padrão, que você não pode sobrescrever esse valor durante uma chamada. Como exemplo, se eu quisesse somar os números 56 e 43, ao invés de 56 e 10 (o valor padrão do argumento y), eu poderia executar o seguinte comando:\n\nsomar(x = 56, y = 43)\n\n[1] 99\n\n\nIsso quer dizer que, você pode estabelecer um valor padrão para um determinado argumento, mas você não é capaz de determinar um valor único, obrigatório e irreversível para esse argumento na lista de argumentos da função. A única possibilidade de você limitar o valor de um determinado argumento, é você criar validações e bloqueios dentro do corpo de sua função que obrigam o usuário a fornecer um valor específico a este argumento.\nPor exemplo, se quiséssemos limitar o argumento y ao valor 10, poderíamos fazer isso da forma mostrada abaixo. Tal método utiliza a função stop() dentro de um controle condicional de fluxo, construído pela palavra-chave if.\n\nsomar &lt;- function(x, y = 10){\n  if(y != 10){\n    stop(\"O valor do argumento y precisa ser igual a 10.\")\n  }\n  resultado &lt;- x + y\n  return(resultado)\n}\n\n\nsomar(x = 56, y = 43)\n\nError in somar(x = 56, y = 43) : O valor do argumento y precisa ser igual a 10.\nPor outro lado, um outro método bastante simples de limitarmos o valor de y, seria simplesmente retirarmos ele da lista de argumentos, de modo que ele seja definido dentro do corpo da função. Dessa forma, estamos retirando a possibilidade do usuário definir um valor para a variável y. Agora, toda vez que executarmos a função somar, ela sempre vai criar um novo objeto chamado y contendo o valor 10.\n\nsomar &lt;- function(x){\n  y &lt;- 10\n  resultado &lt;- x + y\n  return(resultado)\n}\n\nsomar(x = 56)\n\n[1] 66\n\n\nVale ressaltar que, o valor padrão de um determinado argumento pode ser qualquer coisa que a linguagem R te permite definir. Pode ser, por exemplo, uma constante (e.g., y = 10), uma lista (e.g., y = list(\"add\", \"remove\", \"mult\")), uma outra função (e.g., y = sum ou y = mean), ou um vetor (e.g., y = c(0.25, 0.5, 0.75)).\nComparado à linguagem Python, a linguagem R te dá total liberdade para posicionar os seus argumentos dentro da lista de argumentos de sua função. Em outras palavras, os argumentos opcionais de sua função podem estar em qualquer posição da lista de argumentos. Por causa disso, podemos definir um valor padrão para o argumento x e, ainda assim, mantê-lo como o primeiro argumento da função.\n\nsomar &lt;- function(x = 10, y){\n  resultado &lt;- x + y\n  return(resultado)\n}\n\nsomar(y = 20)\n\n[1] 30\n\n\nIsso não é possível de ser feito na linguagem Python, pois ela te obriga a posicionar os seus argumentos opcionais como os últimos argumentos de sua função. Consequentemente, se tentássemos reproduzir a versão acima de somar(), em Python, teríamos o seguinte resultado:\n\ndef somar(y, x = 10):\n  resultado = x + y\n  return resultado\n\nsomar(y = 20)\n\n30\n\n\n\n\n14.6.2 Algumas dicas sobre argument matching\nQuando um argumento de sua função possui um conjunto pequeno e bem definido de valores possíveis, pode ser interessante empregar um argument matching sobre este argumento. Essa técnica é utilizada principalmente em argumentos que podem assumir um valor em texto (uma string), como \"center\", \"secs\" ou \"auto\", e se baseia na função match.arg() que pertence aos pacotes básicos do R, ou ainda, na função arg_match() que advém do pacote rlang e que realiza exatamente o mesmo trabalho1.\nUm exemplo de função que utiliza essa técnica é a função format(), ou, de maneira mais precisa, o seu argumento justify. Em resumo, o argumento justify de format() pode assumir apenas 4 valores: \"left\", \"right\", \"centre\" ou \"none\". A função match.arg() é responsável por conferir se o usuário selecionou um desses 4 valores neste argumento justify. Caso você forneça qualquer valor que não esteja dentre esses 4 valores, a função vai levantar um erro, obrigando você a corrigir o seu input.\n\ntexto &lt;- \"Hoje, fui acampar.\nMas tive que voltar para casa.\"\n\nformat(texto, justify = \"mx\")\n\nError in match.arg(justify) : 'arg' deve ser um dentre \"left\", \"right\", \"centre\", \"none\"\nComo exemplo, suponha que você tenha desenvolvido uma função que constrói um pequeno resumo pessoal (uma espécie de cartão de visita) para qualquer pessoa que trabalhe em sua empresa. Suponha também que, existem apenas 4 tipos de cargo possíveis nessa empresa: estagiário, analista, gerente e CEO. Agora, como você pode limitar o argumento cargo da função abaixo para essas 4 possibilidades?\n\nconstruir_perfil &lt;- function(nome, cargo, \n                             telefone,endereco,\n                             empresa = \"Take Blip\"){\n  \n  prof &lt;- paste(cargo, empresa, sep = \" em \")\n  top &lt;- paste(nome, telefone, sep = \" | \")\n  perfil &lt;- paste(top, endereco, prof, sep = \"\\n\")\n  \n  writeLines(perfil)\n}\n\nconstruir_perfil(\n  \"Pedro Duarte\", \"Analista\",\n  \"+55 31 98888-8888\",\n  \"Belo Horizonte - MG\"\n)\n\nPedro Duarte | +55 31 98888-8888\nBelo Horizonte - MG\nAnalista em Take Blip\n\n\nPrimeiro, você deve igualar o argumento cargo a um vetor contendo essas 4 possibilidades e, em seguida, incluir a função match.arg() dentro do corpo da função. Dito de outra forma, você deve igualar o seu argumento a um vetor contendo o conjunto de possibilidades, de modo que este vetor se torna o valor padrão desse argumento, e, depois, dentro do corpo de sua função, você aplica a função match.arg() sobre este argumento, e salva o seu resultado em algum objeto.\n\nconstruir_perfil &lt;- function(nome, \n                             cargo = c(\"Estagiário\", \"Analista\", \"Gerente\", \"CEO\"), \n                             telefone, endereco,\n                             empresa = \"Take Blip\"){\n  \n  sel_cargo &lt;- match.arg(cargo)\n  prof &lt;- paste(sel_cargo, empresa, sep = \" em \")\n  top &lt;- paste(nome, telefone, sep = \" | \")\n  perfil &lt;- paste(top, endereco, prof, sep = \"\\n\")\n  \n  writeLines(perfil)\n}\n\nconstruir_perfil(\n  \"Pedro Duarte\", \"Vendedor\",\n  \"+55 31 98888-8888\",\n  \"Belo Horizonte - MG\"\n)\n\nError in match.arg(cargo) : 'arg' deve ser um dentre \"Estagiário\", \"Analista\",\n\"Gerente\", \"CEO\"\n\n\n14.6.3 Dot-dot-dot (...), o argumento mágico\nNo R, temos um tipo especial de argumento, representado por três pontos (...). Esse argumento é comumente chamado por dot-dot-dot dentro da comunidade (TEAM, 2020; WICKHAM; GROLEMUND, 2017), e ele funciona de forma semelhante ao *args e **kwargs do Python. Diversas funções utilizam esse argumento especial, como por exemplo, todas as funções do pacote dplyr que vimos no capítulo 4, como mutate(), summarise(), select(), arrange(), bind_rows(), across(), etc.\n\ndplyr::mutate\n\nfunction (.data, ...) \n{\n    UseMethod(\"mutate\")\n}\n&lt;bytecode: 0x605355277820&gt;\n&lt;environment: namespace:dplyr&gt;\n\ndplyr::arrange\n\nfunction (.data, ..., .by_group = FALSE) \n{\n    UseMethod(\"arrange\")\n}\n&lt;bytecode: 0x6053551af350&gt;\n&lt;environment: namespace:dplyr&gt;\n\n\nEste argumento permite que a sua função aceite um número arbitrário de argumentos. Em outras palavras, nós geralmente utilizamos esse argumento especial em uma função, quando nós não sabemos de antemão, todos os inputs dessa função. Por exemplo, o primeiro argumento da função sum() é o dot-dot-dot. Por causa disso, essa função é capaz de receber 2, 10, 100, ou 1000 inputs diferentes.\n\nsum\n\nfunction (..., na.rm = FALSE)  .Primitive(\"sum\")\n\nsum(3, 5)\n\n[1] 8\n\nsum(\n  1, 2, 3, 4, 5,\n  6, 7, 8, 9, 10\n)\n\n[1] 55\n\n\nUm exemplo de uso bastante comum deste argumento especial, é o transporte de argumentos para outras funções. Por exemplo, eu posso criar uma função chamada apply_agg(), que busca aplicar alguma função agregadora sobre um vetor numérico. Perceba abaixo, que a cada execução da função apply_agg() eu estou modificando a função agregadora utilizada (mean(), table() e quantile()).\nPor serem funções diferentes, elas possuem argumentos diferentes, e isso cria um problema sério caso eu queira definir um de seus argumentos durante a chamada à função apply_agg(). A solução para isso, está no uso do dot-dot-dot. Com ele, a função apply_agg() passa a aceitar um número qualquer de argumentos. Dessa forma, eu posso repassar à apply_agg() todos os argumentos que desejo utilizar na função agregadora. Em outras palavras, apply_agg() vai repassar todos esses argumentos arbitrários à função que eu conectei ao argumento fun.\n\napply_agg &lt;- function(x, fun, ...){\n  fun(x, ...)\n}\n\nvec &lt;- c(1.25, 1.25, 7.8, 5.3, 9.1, NA)\n\napply_agg(vec, mean, na.rm = TRUE)\n\n[1] 4.94\n\napply_agg(vec, table, useNA = \"no\")\n\nx\n1.25  5.3  7.8  9.1 \n   2    1    1    1 \n\napply_agg(\n  vec, \n  quantile,\n  probs = c(0.25, 0.75),\n  na.rm = TRUE,\n  names = FALSE\n)\n\n[1] 1.25 7.80\n\n\nQuando você utiliza o argumento dot-dot-dot em sua função, todo valor que você fornecer a essa função durante a sua chamada, e que não estiver conectado a algum argumento formal, será conectado ao argumento dot-dot-dot (TEAM, 2020). De forma mais clara, se a função mean() só possui um argumento formal (isto é, um argumento que possui um nome definido), apenas o primeiro argumento é conectado a esse argumento formal, enquanto todos os outros argumentos que eu fornecer à função vão ser associados ao argumento dot-dot-dot. No exemplo abaixo, apenas vec é conectado à um argumento formal (x), enquanto os valores na.rm = TRUE e trim = 0.1 são associados ao argumento dot-dot-dot (...).\n\nmean\n\nfunction (x, ...) \nUseMethod(\"mean\")\n&lt;bytecode: 0x605352adc8a8&gt;\n&lt;environment: namespace:base&gt;\n\nmean(vec, na.rm = TRUE, trim = 0.1)\n\n[1] 4.94\n\n\n\n\n14.6.4 Como definir o resultado de sua função\nGeralmente é de nosso desejo que uma função retorne algum resultado. Para que isso aconteça, é importante que você defina dentro do corpo de sua função o que ela deve retornar. Há duas maneiras principais de se definir esse resultado: 1) utilizando a palavra-chave return(); ou 2) ao final de sua função, executar algum comando que retorne por padrão algum resultado.\nA palavra-chave return() é uma função especial que deve ser utilizada somente dentro do corpo de funções, ou dentro do corpo de outras construções parecidas como controles de fluxo (if/else statements e loops). Tudo que a função return() faz é retornar uma cópia do objeto sobre o qual ela foi aplicada e, em seguida, parar a execução da função que a executou.\nComo exemplo, o último comando executado pela função somar() é return(resultado). Sendo assim, quando somar() executar esse comando, return() nos retorna o objeto resultado, e automaticamente encerra a execução da função que a executou (nesse caso, a função somar()). Como essa função return() sempre finaliza a execução da função que chamou por ela, você geralmente inclui essa função return() ao final do corpo de sua função.\n\nsomar &lt;- function(x, y){\n  resultado &lt;- x + y\n  return(resultado)\n}\n\nMas existem funções que utilizam a função return() em diversos pontos de seu corpo. Como um exemplo mais extremo, observe a função fizz_buzz() abaixo, que possui 4 comandos return() diferentes em seu corpo. Essa função é uma representação do jogo popular “FizzBuzz”, o qual é muito comum em países de língua inglesa. A ideia do jogo, são duas pessoas contando de 1 até algum número limite, de maneira alternada. Porém, se a pessoa está prestes a contar um número múltiplo de 3, ao invés de dizer o número em si, ela deve dizer a palavra “Fizz”, caso seja um número múltiplo de 5, ela deve dizer a palavra “Buzz”, e se esse número for múltiplo de ambos (de 3 e de 5), ela deve falar “FizzBuzz”. Portanto, se fôssemos seguir o jogo, e contar de 1 até 16, a contagem seria: “1, 2, Fizz, 4, Buzz, Fizz, 7, 8, Fizz, Buzz, 11, Fizz, 13, 14, FizzBuzz, 16”.\nDa maneira como ela está desenvolvida abaixo, a função fizz_buzz() aceita um número qualquer em seu argumento x. Primeiro, a função vai conferir se esse número é múltiplo de 3 e de 5. Caso o número seja múltiplo de 3 e de 5, ela vai executar o comando return(\"FizzBuzz\"). Isso significa que return() vai terminar a execução de fizz_buzz() e retornar o texto \"FizzBuzz\" como resultado. Porém, se o número não for múltiplo de 3 e de 5, a função vai ignorar o comando return(\"FizzBuzz\"), e prosseguir com sua execução. Depois, a função confere se x é múltiplo de 3, e caso seja, o comando return(\"Fizz\") é executado, caso não, a função novamente ignora esse comando, e prossegue com sua execução. Depois, a função confere se x é múltiplo de 5, caso seja, ela avalia o comando return(\"Buzz\"), caso contrário, ela novamente prossegue com sua execução. Por último, a função executa o comando return(as.character(x)), encerrando enfim, sua execução.\n\nfizz_buzz &lt;- function(x){\n  if(x %% 3 == 0 & x %% 5 == 0){\n    return(\"FizzBuzz\")\n  }\n  \n  if(x %% 3 == 0){\n    return(\"Fizz\")\n  }\n  \n  if(x %% 5 == 0){\n    return(\"Buzz\")\n  }\n  \n  return(as.character(x))\n}\n\n\nfizz_buzz(2)\n\n[1] \"2\"\n\nfizz_buzz(3)\n\n[1] \"Fizz\"\n\nfizz_buzz(5)\n\n[1] \"Buzz\"\n\nfizz_buzz(11)\n\n[1] \"11\"\n\nfizz_buzz(15)\n\n[1] \"FizzBuzz\"\n\n\nPor outro lado, quando nós não incluímos algum return() dentro do corpo da função, ela sempre nos retorna o resultado da última expressão que ela executou. Por exemplo, eu poderia reescrever a função somar() da forma apresentada abaixo. Dessa maneira, quando executarmos essa função, ela vai nos retornar o resultado da última e única expressão avaliada por ela (x + y).\n\nsomar &lt;- function(x, y){\n  x + y\n}\n\nsomar(5, 10)\n\n[1] 15\n\n\nUm outro exemplo seria a função construir_perfil() que apresentamos na seção passada. Perceba que o corpo da função termina com o comando writeLines(perfil). Consequentemente, o resultado apresentado pela função construir_perfil() é o resultado dessa expressão writeLines(perfil).\nUma outra forma comum de se retornar um resultado em uma função, é escrever o nome do objeto que você deseja retornar ao final do corpo da função. Com essa noção em mente, poderíamos reescrever novamente a função somar() da maneira abaixo. Como o último comando executado pela função somar() é uma chamada ao objeto soma, a função vai nos retornar o conteúdo desse objeto como resultado.\n\nsomar &lt;- function(x, y){\n  soma &lt;- x + y\n  soma\n}\n\nsomar(5, 10)\n\n[1] 15\n\n\nTodavia, um tipo de expressão que foge desse escopo, são expressões que criam novos objetos (nome_objeto &lt;- valor). Em outras palavras, se o corpo de sua função terminar em uma expressão desse tipo, nada será retornado. Veja o exemplo abaixo:\n\nsomar &lt;- function(x, y){\n  soma &lt;- x + y\n}\n\nsomar(5, 10)\n\n\n\n14.6.5 Uma função não precisa necessariamente retornar algum resultado\nCaso você não defina explicitamente o que a sua função deve retornar, ela nunca vai retornar algum resultado para você. Vale ressaltar que, uma função não precisa necessariamente ter algum retorno, para que ela possa funcionar e executar os comandos descritos em seu corpo.\nAlgumas funções foram especificamente desenvolvidas de forma a não retornarem algum resultado visível para o seu usuário. Ao invés de calcularem um “resultado”, funções desse tipo, geralmente são funções que foram desenvolvidas com o intuito de produzir “efeitos colaterais” em sua sessão, ou, de outra maneira, são funções que buscam afetar outros objetos, environments e/ou configurações de sua sessão.\nDiversas funções do pacote knitr funcionam dessa maneira. Um exemplo é a função render_latex() que está reproduzida abaixo. Perceba abaixo, que a função não possui ao final, algum return() ou o nome de algum objeto. Na realidade, o último comando executado no corpo de render_latex() é uma chamada a uma outra função chamada set(), que está armazenada em um objeto chamado knit_hooks.\n\nrender_latex &lt;- function() {\n  opts_chunk$set(out.width = '\\\\maxwidth', dev = 'pdf')\n  opts_knit$set(out.format = 'latex')\n  h &lt;- opts_knit$get('header')\n  if (!nzchar(h['framed'])) set_header(framed = .header.framed)\n  if (!nzchar(h['highlight'])) set_header(highlight = .header.hi.tex)\n  knit_hooks$set(hooks_latex())\n}\n\nAo observamos mais atentamente o que essa função set() faz, podemos perceber que ao final, essa função executa o comando invisible(NULL). A função invisible() é parecida com a função return(), no sentido de que ela simplesmente retorna para o usuário, uma cópia do objeto sobre o qual ela foi aplicada. No caso abaixo, invisible() está retornando uma cópia do valor NULL. Entretanto, essa cópia é na verdade uma cópia “invisível” do objeto. Dessa maneira, a função de fato retorna essa cópia como resultado, mas não mostra ele de forma visível para o seu usuário.\n\nknitr::knit_hooks$set\n\nfunction (...) \n{\n    set2(resolve(...))\n}\n&lt;bytecode: 0x605351c740c0&gt;\n&lt;environment: 0x605351c85a68&gt;\n\n\nPor essas características, se eu executar essa função em meu console, nada acontece, ou melhor, nada aparentemente acontece, pois a função está sim executando os comandos descritos em seu corpo, ela só não está retornando algo visível para nós.\n\nlibrary(knitr)\nrender_latex()\n\n\n\n14.6.6 Como retornar múltiplos resultados\nPor padrão, uma função sempre retorna o resultado da última expressão executada por ela. Mas e se você precisasse que essa função retornasse os resultados de múltiplas expressões calculadas por ela de uma vez só? Dito de outra forma, suponha que você tenha vários objetos definidos dentro do corpo de sua função, e que você deseja acessar o conteúdo desses objetos em sua sessão. Como você faria isso?\nComo exemplo, vamos supor que você possua uma função parecida com a função aggs() abaixo. Essa função aceita dois números como input, e calcula a soma, a divisão, o produto e a potência entre eles. Como faríamos para acessar os resultados de todas essas operações de uma vez só?\nO método mais simples e direto de retornarmos todos esses resultados, seria, armazenarmos esses diferentes resultados em uma lista e, em seguida, pedir à função que nos retorne essa lista como resultado. Lembre-se que, você pode guardar o que você quiser dentro de uma lista. Repare no exemplo abaixo, que eu salvo os resultados de todas as operações individualmente e, depois, eu guardo todos esses resultados em uma lista e, por último, peço que a função me retorne essa lista com a função return().\n\naggs &lt;- function(x, y){\n  soma &lt;- x + y\n  div &lt;- x / y\n  prod &lt;- x * y\n  pot &lt;- x ^ y\n  \n  lista &lt;- list(soma, div, prod, pot)\n  names(lista) &lt;- c(\n    \"soma\", \"divisão\",\n    \"produto\", \"potência\"\n  )\n  return(lista)\n}\n\n\naggs(15, 5)\n\n$soma\n[1] 20\n\n$divisão\n[1] 3\n\n$produto\n[1] 75\n\n$potência\n[1] 759375",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/05-funcoes-loops.html#implementando-verificações-e-bloqueios-em-sua-função",
    "href": "Capítulos/05-funcoes-loops.html#implementando-verificações-e-bloqueios-em-sua-função",
    "title": "14  Funções",
    "section": "14.7 Implementando verificações e bloqueios em sua função",
    "text": "14.7 Implementando verificações e bloqueios em sua função\n\n14.7.1 Exit early as possible\nUm programa (ou script) do R é, em geral, construído a partir de um conjunto de funções. Essas funções coletam e utilizam vários inputs para produzirem um output. Contudo, para que uma função execute a tarefa para a qual ela foi desenvolvida, e da maneira correta, essa função precisa muitas vezes que certas condições sejam satisfeitas.\nCom a frase exit early as possible (ou, “saia o mais rápido possível”) estou destacando a importância de conferirmos se essas condições são satisfeitas, e, caso seja necessário, pararmos o mais rápido possível a execução de uma função. Com isso em mente, essa frase poderia ser comparada com “primeiro de tudo, confirme que suas condições foram satisfeitas”, ou ainda, “se algo estiver errado, pare imediatamente!”.\nPortanto, em qualquer função que você venha a desenvolver no R, é sempre uma boa ideia iniciar essa função com um conjunto de conferências sobre os seus inputs. Se os inputs fornecidos à essa função, tiverem todas as características e atributos que você espera que eles tenham, você possui uma maior confiança de que a sua função vai funcionar da maneira correta. Porém, se algum desses inputs não satisfizerem alguma dessas condições, a sua função pode não ser capaz de lidar com esse input da forma esperada. Por essa razão, talvez seja melhor pararmos a execução, e avisarmos ao usuário de que o input que ele forneceu não é adequado para essa função.\nAlgumas funções que apresentamos até aqui, seguem esse princípio. Um exemplo é a função readxl::read_excel(). Como descrevemos no capítulo Importando e exportando dados com readr, readxl e haven, utilizamos essa função para ler planilhas do Excel (.xlsx ou .xls).\nLogo abaixo, temos o body dessa função, ou em outras palavras, todos os comandos que ela executa. Perceba abaixo que, a primeira coisa que essa função read_excel() faz é executar duas outras funções (check_format() e check_file()).\n\nbody(readxl::read_excel)\n\n{\n    path &lt;- check_file(path)\n    format &lt;- check_format(path)\n    read_excel_(path = path, sheet = sheet, range = range, col_names = col_names, \n        col_types = col_types, na = na, trim_ws = trim_ws, skip = skip, \n        n_max = n_max, guess_max = guess_max, progress = progress, \n        .name_repair = .name_repair, format = format)\n}\n\n\nEssas duas funções são responsáveis pelas conferências necessárias sobre o principal input da função (que é o argumento path). Ao observarmos o body de check_file(), podemos perceber que a função realiza duas conferências principais: 1) primeiro, ela se certifica que o caminho fornecido à read_excel() é uma string (com a função readxl:::is_string()), ou, em outras palavras, um valor do tipo character; 2) segundo, a função se certifica que o caminho fornecido à read_excel() é válido, isto é, se o arquivo descrito nesse caminho existe de fato em meu computador (com a função file.exists()).\n\nbody(readxl:::check_file)\n\n{\n    if (!is_string(path)) {\n        stop(\"`path` must be a string\", call. = FALSE)\n    }\n    if (!file.exists(path)) {\n        stop(\"`path` does not exist: \", sQuote(path), call. = FALSE)\n    }\n    path\n}\n\n\nPor que essas conferências são necessárias? Primeiro, porque caminhos até arquivos e diretórios devem ser fornecidos como strings no R, assim como em diversas outras linguagens de programação. Segundo, porque eu posso muito bem entregar à função, um caminho imaginário, ou seja, um caminho que não existe em meu computador. O que read_excel() deveria fazer nesse caso? Se o caminho não existe, será que ela deveria sequer tentar encontrar e ler o arquivo descrito nesse caminho? Provavelmente, o melhor a se fazer nesse caso seria simplesmente interrompermos a execução de read_excel(), e avisarmos ao usuário que o caminho dado não existe no computador em questão.\nEste é exatamente o papel que a função readxl:::check_file() cumpre. Perceba acima que essa função utiliza um if statement para executar a função stop(), a depender do resultado de !file.exists(path). Dessa forma, se a expressão !file_exists(path) retornar FALSE, significa que o arquivo descrito no input path existe em meu computador e, por isso, a função ignora completamente o comando stop() que está dentro do if statement. Porém, se a expressão !file.exists(path) retornar TRUE, o if statement vai executar o comando stop(), e toda a execução de read_excel() é interrompida com uma mensagem de erro, a qual avisa o usuário que o arquivo descrito em path não existe.\nA função readxl:::check_format() realiza um trabalho parecido. Em resumo, essa função utiliza readxl:::excel_format() para determinar se o arquivo descrito em path é de fato uma planilha do Excel, isto é, se o arquivo possui extensão .xslx ou .xls. Para isso, a função confere com a expressão is.na(format), se a função readxl:::excel_format() conseguiu determinar o formato do arquivo. Caso não tenha, é muito provável que o arquivo descrito em path não é uma planilha do Excel e, por esse motivo, a função executa o comando stop() que está dentro do if statement.\n\nbody(readxl:::check_format)\n\n{\n    format &lt;- excel_format(path)\n    if (is.na(format)) {\n        stop(\"Can't establish that the input is either xls or xlsx.\", \n            call. = FALSE)\n    }\n    format\n}\n\n\nPortanto, sempre que você estiver desenvolvendo uma função (ou o seu script como um todo), reflita se há alguma condição que precisa ser satisfeita para que a sua função (ou o seu script) funcione de maneira adequada. Por exemplo, vamos voltar novamente à função somar(). Existe alguma condição que precisa ser satisfeita, para que essa função funcione como esperado? Como essa função busca somar dois números, você pode rapidamente chegar à conclusão de que ambos os inputs da função (x e y) devem ser valores numéricos. Logo, seria interessante incluirmos dentro dela um sistema de bloqueio que nos avise caso essa condição não se sustente, como está demonstrado abaixo:\n\nsomar &lt;- function(x, y){\n  \n  if(!is.numeric(x) | !is.numeric(y)){\n    stop(\"Um dos inputs (`x` ou `y`) não é um valor numérico!\")\n  }\n  \n  resultado &lt;- x + y\n  return(resultado)\n}\n\nsomar(5, \"15\")\n\nError in somar(5, \"15\"): Um dos inputs (`x` ou `y`) não é um valor numérico!\n\n\n14.7.2 A função stop()\nQuando queremos criar um sistema de bloqueio em nossa função, nós quase sempre recorremos à função stop() dentro de algum if statement. Como o próprio nome da função dá a entender, stop() encerra a execução da função que a executa, e retorna uma mensagem de erro. Você geralmente define essa mensagem de erro, através de uma string contendo a mensagem desejada.\n\nstop(\"Teste\")\n\nError: Teste\nÉ importante que você seja claro e objetivo nesta mensagem de erro, pois ela deve explicar brevemente (ou fornecer uma dica) para o usuário, sobre o que ele fez de errado com sua função. Muitas vezes, é útil explicar nessa mensagem, o porquê de sua função ter decidido executar o stop(). No exemplo abaixo, o if statement vai executar o stop() somente se o objeto x não for um valor numérico, logo, é natural que o stop() nos retorne uma mensagem dizendo explicitamente que o objeto x deveria ser um valor numérico.\n\nx &lt;- \"5\"\n\nif(!is.numeric(x)){\n  stop(\"O objeto `x` não é um valor numérico!\")\n}\n\nError: O objeto `x` não é um valor numérico!",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/05-funcoes-loops.html#algumas-dicas-sobre-como-construir-a-sua-função",
    "href": "Capítulos/05-funcoes-loops.html#algumas-dicas-sobre-como-construir-a-sua-função",
    "title": "14  Funções",
    "section": "14.8 Algumas dicas sobre como construir a sua função",
    "text": "14.8 Algumas dicas sobre como construir a sua função\n\n14.8.1 Construa sua função aos poucos\nNão se apresse! Muitas vezes, você precisa inserir vários comandos dentro do corpo de sua função, para que ela cumpra o papel desejado. Cada um desses comandos pode ser uma fonte de erros ou de bugs. Por isso, o ideal é que você construa a sua função de forma incremental. Ou seja, adicione um comando, e teste a função. Se tudo der certo como planejado, adicione o próximo comando, e teste novamente a função. E assim por diante, até que você tenha adicionado todos os comandos necessários.\nPor exemplo, suponha que seu objetivo fosse construir uma função que fosse capaz de reordenar as colunas de um data.frame qualquer, segundo uma ordenação alfabética (reordenar_colunas()). Qual seria o primeiro passo que essa função precisa cumprir? Primeiro, para aplicarmos uma ordenação alfabética precisamos saber os nomes das colunas do data.frame em questão. Podemos fazer isso com a função colnames():\n\ndf_teste &lt;- data.frame(\n  Produto = c(\"Leite\", \"Leite\", \"Arroz\", \"Feijão\"),\n  Preço = c(3.15, 3.15, 18.25, 6.92),\n  ID = c(1200, 1200, 1655, 1987),\n  Estoque = c(500, 500, 1250, 900)\n)\n\nreordenar_colunas &lt;- function(df){\n  cols &lt;- colnames(df)\n  return(cols)\n}\n\nreordenar_colunas(df_teste)\n\n[1] \"Produto\" \"Preço\"   \"ID\"      \"Estoque\"\n\n\nEm seguida, podemos reordenar os nomes dessas colunas segundo uma ordenação alfabética. Podemos realizar esse passo, ao aplicarmos a função sort() sobre os nomes dessas colunas. Adiciono um novo comando ao corpo da função, e aplico ela novamente para conferir se está tudo funcionando:\n\nreordenar_colunas &lt;- function(df){\n  cols &lt;- colnames(df)\n  cols &lt;- sort(cols)\n  return(cols)\n}\n\nreordenar_colunas(df_teste)\n\n[1] \"Estoque\" \"ID\"      \"Preço\"   \"Produto\"\n\n\nPor último, podemos utilizar esse vetor com os nomes das colunas já ordenados, para reordenarmos o data.frame em questão, através de subsetting:\n\nreordenar_colunas &lt;- function(df){\n  cols &lt;- colnames(df)\n  cols &lt;- sort(cols)\n  df_reordenado &lt;- df[cols]\n  \n  return(df_reordenado)\n}\n\nreordenar_colunas(df_teste)\n\n  Estoque   ID Preço Produto\n1     500 1200  3.15   Leite\n2     500 1200  3.15   Leite\n3    1250 1655 18.25   Arroz\n4     900 1987  6.92  Feijão\n\n\nCom um primeiro protótipo da função funcionando, podemos pensar em melhorias para essa função. Por exemplo, podemos dar maior flexibilidade à função, ao permitir que reordenar_colunas() reordene as colunas segundo uma ordem crescente ou decrescente. Para isso, podemos adicionar um argumento crescente à função, e utilizar esse argumento para determinar se uma ordem crescente ou decrescente será aplicada por sort().\n\nreordenar_colunas &lt;- function(df, crescente = TRUE){\n  cols &lt;- colnames(df)\n  cols &lt;- sort(cols, decreasing = !crescente)\n  df_reordenado &lt;- df[cols]\n  \n  return(df_reordenado)\n}\n\nreordenar_colunas(df_teste, crescente = FALSE)\n\n  Produto Preço   ID Estoque\n1   Leite  3.15 1200     500\n2   Leite  3.15 1200     500\n3   Arroz 18.25 1655    1250\n4  Feijão  6.92 1987     900\n\n\n\n\n14.8.2 Comece por um caso pequeno\nSe o seu objetivo é, por exemplo, aplicar um modelo sobre 1000 bases de dados diferentes, comece tentando criar uma função que aplique esse modelo para apenas 1 dessas 1000 bases. Em outras palavras, é melhor ter primeiro uma barraca de pé e estável, do que tentar construir um castelo logo de cara!\nTentar lidar ao mesmo tempo com todas as dimensões do problema, como as especificações do modelo, o manuseio das bases, e a questão da expansão (ou de como aplicar o modelo) para as demais 999 tabelas, é um tiro no pé. O melhor que você pode fazer, é lidar com uma dimensão de cada vez. Ao isolarmos uma dessas 1000 bases, e utilizarmos ela como uma massa de teste, podemos nos concentrar em uma das dimensões, e adiarmos as demais até que elas precisem de fato ser resolvidas.\n\n\n14.8.3 Se você possui um grande objetivo, divida ele em pequenos passos\nSe você deseja construir uma função que cumpre um grande objetivo, é essencial que você quebre esse grande objetivo em vários pequenos passos. Ao dividir o seu grande objetivo em pequenos passos, você terá mais facilidade de implementar funções que cumprem cada um desses pequenos passos. Aos poucos, você vai construindo várias funções, que juntas, completam o seu grande objetivo.\n\n\n14.8.4 Quando puder, aproveite e suba no ombro de gigantes!\nEm certas ocasiões, o melhor conselho que nós podemos dar sobre como construir a sua função é: “não construa sua função!”, ou “não perca o seu tempo tentando reinventar a roda”. Antes de construir qualquer função, é interessante que você faça uma rápida busca pelo Google, atrás de alguma função que já cumpra o trabalho que você deseja realizar. Por exemplo, e se você precisasse ler uma planilha de Excel? Porque eu deveria criar, do zero, uma nova função que lê esse tipo de arquivo, se eu posso me aproveitar de uma função já existente (readxl::read_excel()) ?\nPortanto, a lição é: sempre que puder, se aproveite de funções já prontas! Suba nos ombros de quem já fez o trabalho duro por você! Se essa função já possui tudo o que você precisa, você economiza muito de seu tempo e avança mais rapidamente para o seu objetivo principal. Não há pecado nenhum em nos aproveitarmos de coisas já prontas para economizarmos muito de nosso tempo e esforço.\nContudo, existem duas situações em que, pode ser necessário que você crie uma função do zero, mesmo que já existam algumas alternativas prontas. Uma dessas situações, é quando você enfrenta um problema de performance. Ou seja, a alternativa já existente no R é muito lenta, e você conhece formas mais rápidas e eficientes de se realizar o mesmo cálculo. A outra situação, é quando a alternativa existente aplica um metodologia que apresenta algum conflito com o objetivo que você deseja atingir. Por exemplo, se uma função já existente estima uma regressão linear através do método OLS (Ordinary Least Squares), mas você precisa que essa regressão seja estimada pelo método ML (Maximum Likelihood).",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/05-funcoes-loops.html#funções-anônimas",
    "href": "Capítulos/05-funcoes-loops.html#funções-anônimas",
    "title": "14  Funções",
    "section": "14.9 Funções anônimas",
    "text": "14.9 Funções anônimas\nLembre-se que, nós normalmente acessamos e aplicamos uma função no R, através do nome do objeto onde armazenamos a sua definição. Porém, você não precisa necessariamente salvar a sua definição em um objeto, para que você seja capaz de utilizar uma função. Tendo apenas a definição dessa função em mãos, o que na Figura 14.1 representa toda a área verde escura, você já possui todos os métodos que descrevem como essa função funciona e de quais inputs ela precisa.\nEntretanto, justamente pelo fato de você possuir apenas a definição dessa função, você é incapaz de utilizá-la através do modo tradicional, pois você não consegue se referir a essa definição através de um nome. Por esse motivo, quando temos apenas a definição de uma função, nós normalmente a denominamos de “função anônima”, ou “anonymous function”. Ou seja, ela se torna uma função sem “nome”.\nCriar funções anônimas é uma prática muito comum no R quando estamos utilizando um certo conjunto de funções. Principalmente pela economia de digitação, pois não temos mais o trabalho de criarmos um objeto para armazenarmos essa definição. Normalmente, utilizamos essas funções anônimas em argumentos de outras funções, e existem uma infinidade de funções no R que aceitam outras funções em seus argumentos. Ou seja, muitas funções utilizam como input, uma outra função. Exemplos desses tipos de funções são do.call(), lapply() e purrr::map().\nPor conseguinte, se você possui apenas a definição de uma função (e não um objeto que contenha essa definição), e deseja aplicar essa definição sobre um conjunto de inputs, você precisa fornecer essa função anônima a uma outra função que possa aplicar essa definição por você. Como um exemplo, eu poderia rapidamente criar uma função anônima equivalente à somar mostrada na Figura 14.1, e aplicá-la sobre um conjunto de inputs através da função do.call(), como demonstrado abaixo:\n\ndo.call(\n  function(x, y) x + y,\n  list(x = 15, y = 88)\n)\n\n[1] 103",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/05-funcoes-loops.html#sec:oque_e_uma_funcao_R",
    "href": "Capítulos/05-funcoes-loops.html#sec:oque_e_uma_funcao_R",
    "title": "14  Funções",
    "section": "14.10 O que é uma função no R ?",
    "text": "14.10 O que é uma função no R ?\nPara responder essa pergunta, quero destacar dois princípios fundamentais sobre a linguagem R apresentados na obra de CHAMBERS (2016):\n\nTudo que existe no R, são objetos.\nTudo que acontece no R, são chamadas a funções.\n\nNós já comentamos sobre o primeiro princípio no capítulo de Fundamentos da Linguagem R, mas vale a pena destacá-lo mais uma vez. Portanto, assim como os demais objetos que você cria em sua sessão, todas as funções existentes no R também são objetos. Você talvez tenha percebido isso, ao criarmos a função normalizar() na seção anterior.\nPortanto, nós criamos funções no R ao salvarmos sua definição em um objeto através do operador de assignment (&lt;-), e acessamos posteriormente suas funcionalidades ao utilizar o objeto no qual essa função foi salva. O nome da função corresponde ao nome do objeto no qual está salvo a definição dessa função. Assim como os demais objetos disponíveis na linguagem, toda função possui uma classe e um tipo associados a ela. Por padrão, funções pertencem ao tipo closure e possuem a classe function. Tais características estão demonstradas abaixo, em que estou utilizando a função rnorm() como exemplo.\n\ntypeof(rnorm)\n\n[1] \"closure\"\n\nclass(rnorm)\n\n[1] \"function\"\n\n\nContudo, de maneira oposta a diversos tipos de objetos no R, os operadores de subsetting ([ e [[) não funcionam sobre funções. Tal fato está diretamente relacionado ao erro \"object of type 'closure' is not subsettable\", o qual é um erro bem comum, tão comum que foi o título principal de uma palestra de Jenny Bryan na rstudio::conf20202. Você pode facilmente reproduzir esse erro, ao aplicar um operador de subsetting sobre um objeto do tipo closure, isto é, sobre uma função qualquer.\n\nrnorm[1]\n\nError in rnorm[1] : object of type 'closure' is not subsettable\nNa visão do R, toda função possui 3 componentes principais, sendo eles: 1) os argumentos (arguments), ou os inputs da função; 2) o seu body, ou o corpo da função; 3) e o environment dessa função (TEAM, 2020; WICKHAM, 2015). Vamos explicar em mais detalhes o que é um environment, por enquanto, apenas saiba que toda função possui um environment associado a ela. Você pode acessar os argumentos, o corpo e o environment associados a uma determinada função, através das funções formals(), body() e environment() respectivamente. Por padrão, a função formals() nos retorna uma lista, onde cada elemento dessa lista corresponde a um argumento da função. Os argumentos que já possuem um valor padrão, já vem preenchidos nessa lista com este valor padrão. Já os argumentos que não possuem um valor padrão, aparecem nesta lista preenchidos com um valor NULL.\n\n## Os arguemntos da função rnorm():\nformals(rnorm)\n\n$n\n\n\n$mean\n[1] 0\n\n$sd\n[1] 1\n\n## O corpo da função rnorm():\nbody(rnorm)\n\n.Call(C_rnorm, n, mean, sd)\n\n## O environment associado à função rnorm():\nenvironment(rnorm)\n\n&lt;environment: namespace:stats&gt;\n\n\nEnquanto os argumentos e corpo de uma função são especificados de maneira explícita quando você cria essa função, o environment associado à função é determinado de forma implícita, com base em onde você define essa função (WICKHAM, 2015). Para além dessas características, você pode visualizar a definição completa de uma função, ao chamar pelo objeto onde essa função foi salva. Como exemplo, para visualizarmos todos os 3 componentes (argumentos, body e environment) da função rnorm(), basta chamarmos no console pelo objeto rnorm:\n\nrnorm\n\nfunction (n, mean = 0, sd = 1) \n.Call(C_rnorm, n, mean, sd)\n&lt;bytecode: 0x60535de7b248&gt;\n&lt;environment: namespace:stats&gt;\n\n\nPorém, temos um tipo de função especial que representa a única exceção a essa regra de que toda função no R possui 3 componentes. Esse tipo são as funções primitivas (Primitive), as quais são as funções que não possuem nenhum código em R escrito dentro delas. Essas funções, utilizam dentro delas a função .Primitive() para acessar rotinas escritas na linguagem C. Grande parte dessas funções primitivas são encontradas dentro do pacote base da linguagem, sendo um exemplo de função primitiva, a função sum(). Perceba abaixo que, dentro de sum(), temos apenas uma chamada à função .Primitive(), que procura por uma função chamada sum definida dentro das rotinas escritas em C.\n\nsum\n\nfunction (..., na.rm = FALSE)  .Primitive(\"sum\")\n\nformals(sum)\n\nNULL\n\nbody(sum)\n\nNULL\n\nenvironment(sum)\n\nNULL\n\n\nTais funções primitivas inclusive possuem um tipo associado a elas diferente das demais (builtin), apesar de ainda possuírem a classe function.\n\ntypeof(sum)\n\n[1] \"builtin\"\n\nclass(sum)\n\n[1] \"function\"\n\n\nProsseguindo, de acordo com o segundo princípio apresentado por CHAMBERS (2016), em qualquer operação que você realiza no R, por mais simples que ela pareça, você está realizando por trás múltiplas chamadas à várias funções diferentes. Com este princípio, CHAMBERS (2016) busca principalmente destacar a característica “funcional” da linguagem R. Logo, apesar de ser uma linguagem baseada em objetos (isto é, uma linguagem que utiliza o paradigma OOP - object-oriented programming), o R também herdou algumas características do paradigma FP - functional programming. E por essa característica, autores como CHAMBERS (2016) preferem caracterizar a linguagem R como uma “Functional, object-based language” (ou uma “linguagem funcional baseada em objetos”).\nEm resumo, três características principais de functional programming estão presentes no R. Primeiro, toda expressão escrita no R pode ser reescrita em sua forma “funcional”. Por exemplo, quando escrevemos expressões como (1 + 2), ou, z[1] &lt;- x[1] + y[1], estamos indiretamente utilizando as funções &lt;-, [&lt;-, (, [ e +. Como resultado, podemos reescrever essas expressões de uma forma mais functional-based, como se estivéssemos aplicando funções sobre os objetos envolvidos nessas expressões, como está apresentado abaixo. Portanto, mesmo que uma expressão no R não possua ou apresente de uma forma explícita alguma função, você certamente está executando alguma função nessa expressão, mesmo que de forma indireta.\n\n# Reescrevendo a expressão: z &lt;- 10\n`&lt;-`(z, 10)\n# Reescrevendo a expressão: 1 + 2\n`+`(1, 2)\n# Reescrevendo a expressão: z + (y * (x ^ 0.5))\n`+`( z, `(`( `*`(y, `(`( `^`(x, 0.5) ))))\n# Reescrevendo a expressão: z[1] &lt;- x[1] + y[1]\n`&lt;-`(z, `[&lt;-`(z, 1, x[1] + y[1]))\n# Ou ainda:\n`&lt;-`(z, `[&lt;-`(z, 1, `+`( `[`(x, 1), `[`(y, 1) )))\n\nSegundo, todo código no R pode ser representado através de uma árvore de chamadas a funções (ou tree of function calls). Na Figura 14.2, temos essa representação para a expressão x &lt;- y + 2. Perceba que, inicialmente é realizado uma chamada à função &lt;- contendo dois argumentos. O primeiro argumento corresponde ao objeto x, e o segundo, a uma nova chamada à uma função. Nessa segunda chamada, é executada a função + com dois outros argumentos, sendo eles o objeto y e a constante 2.\n\n\n\n\n\n\n\n\nFigura 14.2: Representando uma expressão do R em uma árvore de chamadas a funções - Exemplo 1\n\n\n\n\n\nPortanto, todo comando no R é executado como uma sequência de function calls, e pode ser representado através dessa relação sequencial. Como um outro exemplo, poderíamos desenhar novamente essa árvore de function calls de forma a representar a expressão x - mean(x) / sd(x). Como temos um número maior de funções envolvidas nessa expressão, a árvore que a representa é mais profunda, mas o raciocínio permanece o mesmo.\n\n\n\n\n\n\n\n\nFigura 14.3: Representando uma expressão do R em uma árvore de chamadas a funções - Exemplo 2\n\n\n\n\n\nTerceiro, toda função executa as suas tarefas em um environment diferente do seu, ou, em outras palavras, em um contexto separado dos demais. Isto significa que, quando chamamos por uma função do R, é criado um novo contexto (ou um novo envirnoment) em sua sessão, e essa função executa as suas tarefas dentro desse contexto separado, onde um objeto é criado para cada um dos argumentos da função, e os valores desses objetos correspondem aos valores que fornecemos aos argumentos na chamada à função. O resultado final da execução dessa função, é o valor gerado ao executarmos os comandos que formam o corpo (ou o body) da função, neste environment separado (CHAMBERS, 2016, p. 52).\nIsso garante maior confiança e reprodutibilidade dos resultados gerados por essa função, pois eles podem ser gerados de forma independente dos demais contextos (CHAMBERS, 2016). Portanto, mesmo que eu esteja redefinindo um objeto chamado x dentro de minha função, e que eu já possua um objeto chamado x salvo em minha sessão (ou em meu global environment), quando eu executar essa função, ela vai criar um objeto x em um ambiente separado do meu, e, por isso, a função não vai afetar de forma alguma os objetos salvos em minha sessão.\n\nx &lt;- 1\nprint(x)\n\n[1] 1\n\nf &lt;- function(){\n  x &lt;- 1000\n}\n\n# Executei a função:\nf()\n\n# O resultado abaixo continua sendo 1, ao invés de 1000\nprint(x)\n\n[1] 1\n\n\nLogo, esta terceira característica do R, representa uma concepção mais flexível do paradigma FP. Pois normalmente, a execução de uma função no R não afeta de forma alguma os objetos salvos em meu ambiente principal de trabalho, mas se eu quiser, eu posso permitir que os objetos salvos em meu ambiente afetem o resultado gerado por uma função, principalmente se eu utilizo um de meus objetos dentro do body dessa função. Como um exemplo, suponha que eu tenha a função dobrar() abaixo. Repare abaixo que, essa função não possui nenhum argumento (ou nenhum input) definido.\nPortanto, como essa função está gerando o resultado abaixo de 200 ? Assim como em qualquer outra função, o R vai começar a executar os comandos descritos no body dessa função. Ao analisar a expressão x * 2, o R percebe que ele precisa de um objeto chamado x para executar essa expressão. Consequentemente, o R inicia um processo de busca, em que ele procura por um objeto chamado x ao longo de todos os contextos ativos em minha sessão. Assim que ele chega ao meu ambiente, ele percebe que eu defini logo antes da função, um objeto chamado x e, por isso, ele utiliza o valor armazenado neste objeto no body da função dobrar().\n\nx &lt;- 100\n\ndobrar &lt;- function(){\n  x * 2\n}\n\ndobrar()\n\n[1] 200\n\n\nCaso eu elimine, ou altere esse objeto x salvo em minha sessão de alguma maneira, eu posso alterar diretamente o resultado gerado pela função dobrar().\n\n# Alterando o objeto x salvo em meu ambiente\nx &lt;- 500\n\ndobrar()\n\n[1] 1000\n\n\nOutras linguagens que adotam o paradigma FP de maneira mais fiel, em geral, abraçam esse conceito de independência de contextos de forma mais rígida. Por isso, o R nos traz o que tem de melhor do paradigma FP (que é a maior confiança e reprodutibilidade dos resultados), mas ao mesmo tempo, não tenta ser muito restritivo sobre o que um usuário é capaz de fazer com os contextos que ele cria dentro da linguagem.\nConcluindo, funções no R são objetos e, por isso, nós criamos uma nova função ao salvarmos sua definição em um novo objeto, e utilizamos essa função, através do nome do objeto no qual a sua definição foi armazenada. Para além disso, funções representam a base de como a linguagem R funciona, pois, a forma como essas funções se comportam e realizam as suas tarefas, determina diretamente os resultados que a linguagem gera.\n\n\n\n\nCHAMBERS, J. M. Software for Data Analysis: Programming with R. New York, NY: Springer, 2008.\n\n\nCHAMBERS, J. M. Extending R. Boca Raton, FL: CRC Press, 2016.\n\n\nTEAM, R. C. R Language Definition. Version 4.0.3 ed. [s.l.] R Foundation, 2020.\n\n\nWICKHAM, H. Advanced R. 2. ed. Boca Raton, Florida: CRC Press, 2015.\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/05-funcoes-loops.html#footnotes",
    "href": "Capítulos/05-funcoes-loops.html#footnotes",
    "title": "14  Funções",
    "section": "",
    "text": "A principal diferença entre match.arg() e rlang::arg_match(), é que rlang::arg_match() não permite matches parciais. Ou seja, se dentre os valores possíveis de um argumento x temos o valor \"center\", e eu forneço o valor \"cent\" a este argumento durante a chamada da função, rlang::arg_match() vai me retornar um erro, enquanto match.arg() vai tentar encontrar um texto parecido com \"cent\" dentre as possibilidades.↩︎\nhttps://www.youtube.com/watch?v=vgYS-F8opgE&ab_channel=RStudio↩︎",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/17-loops.html",
    "href": "Capítulos/17-loops.html",
    "title": "15  Loops",
    "section": "",
    "text": "15.1 Introdução\nOs loop’s são uma outra categoria de controles de fluxo que praticamente toda linguagem de programação oferece. Portanto, eles impactam a ordem em que certos comandos são avaliados pelo R. Sendo mais preciso, um loop te permite executar múltiplas vezes um mesmo conjunto de comandos, criando assim, um “espaço de repetição” no fluxo de execução de seu programa.\nLoop’s são particularmente úteis, quando desejamos replicar uma mesma função (ou um mesmo conjunto de comandos) sobre vários inputs diferentes. Loop’s também são parte essencial quando desejamos trabalhar com listas (list), seja caminhando por ela (isto é, visitando cada um de seus elementos), ou modificando-a de uma forma simples e automatizada.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Loops*</span>"
    ]
  },
  {
    "objectID": "Capítulos/17-loops.html#o-que-são-loops",
    "href": "Capítulos/17-loops.html#o-que-são-loops",
    "title": "15  Loops",
    "section": "15.2 O que são loops ?",
    "text": "15.2 O que são loops ?\nUm loop te permite executar repetidas vezes um mesmo conjunto de comandos, e, assim como ocorre em outras linguagens, nós temos diferentes “tipos” de loops no R. Mais especificamente, a linguagem oferece três tipos explícitos de loop que são: 1) for loop; 2) while loop; 3) repeat loop. Além disso, a linguagem também oferece as palavras-chave next e break, que oferecem maior controle sobre a execução de loops (TEAM, 2020a). Também temos tipos implícitos de loop oferecidos pela família de funções apply (apply(), tapply(), sapply(), vapply(), e lapply()). Entretanto, vamos focar por enquanto neste capítulo nos tipos explícitos de loop.\nA diferença entre cada tipo de loop, está apenas em como eles determinam o número de repetições que eles vão executar, ou em como eles decidem parar essa repetição. O tipo mais simples de todos é provavelmente o while loop, que em resumo, vai repetir um certo conjunto de comandos, enquanto uma certa condição lógica resultar em TRUE. Por outro lado, o tipo mais genérico de todos é o for loop, que vai repetir os comandos de acordo com um “índice de repetição”. E o tipo menos comum de todos é o repeat loop, que vai repetir o conjunto de comandos indefinidamente, até que uma condição de break seja executada.\nO exemplo mais simples de um loop, provavelmente seria um for loop que simplesmente nos mostra o valor que o seu iterador assume a cada repetição. Tal exemplo está reproduzido abaixo. Perceba que a cada repetição do for loop, ele está executando o comando print(i). Descrevendo de outra forma, a cada repetição do for loop, a função print() é executada, a qual procura por um objeto chamado i, e nos retorna como resultado, o conteúdo desse objeto. No exemplo abaixo, esse objeto i é o “iterador” do for loop. Esse iterador é um objeto que guarda o índice de repetição do loop.\n\nfor(i in 1:5){\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Loops*</span>"
    ]
  },
  {
    "objectID": "Capítulos/17-loops.html#descrevendo-um-for-loop",
    "href": "Capítulos/17-loops.html#descrevendo-um-for-loop",
    "title": "15  Loops",
    "section": "15.3 Descrevendo um for loop",
    "text": "15.3 Descrevendo um for loop\nUm for loop é sempre iniciado pela palavra-chave for, seguido por um par de parênteses, onde é feita a “definição do loop”, e, depois, por um par de chaves, onde é incluído o “corpo do loop”, ou o conjunto de comandos que vão ser executados em cada repetição. Portanto, todo for loop possui esses dois componentes: definição e corpo. Todo while loop também possui essas duas partes, contudo, um repeat loop possui apenas o corpo. Para uma noção mais clara, eu delimitei cada componente na Figura 15.1.\n\n\n\n\n\n\n\n\nFigura 15.1: Componentes de um for loop\n\n\n\n\n\n\n15.3.1 Definição\nA definição de um for loop é formada dentro de um par de parênteses, logo após a palavra-chave for. Dentro desse par de parênteses, temos três itens diferentes: 1) um iterador, ou, um “índice de iteração”; 2) a palavra-chave in; e 3) um objeto qualquer (geralmente um vetor). Essa definição deve sempre conter esses três itens.\nUm iterador é um objeto (ou uma variável) que será reservado para conter o índice do loop. Em outras palavras, o iterador é um objeto criado pelo for loop, que será responsável por armazenar o índice de repetição do loop. A cada repetição, o iterador de um for loop vai assumir um valor diferente. Mais especificamente, ele vai armazenar um elemento diferente do objeto que você forneceu após a palavra-chave in.\nOu seja, esse objeto (ou o “terceiro item” da definição) que você forneceu determina o conjunto de valores que o iterador vai assumir ao longo da execução do for loop. Por exemplo, se eu forneço o vetor 1:5, significa que o iterador vai assumir os valores 1, 2, 3, 4 e 5 ao longo da execução do loop. Mas se eu forneço o vetor c(\"Ana\", \"Eduardo\", \"Márcia\"), então esse iterador vai assumir os valores \"Ana\", \"Eduardo\" e \"Márcia\" a medida em que o loop realiza suas repetições.\nPortanto, na 1° repetição do loop, o iterador vai conter o 1° elemento do objeto que você forneceu após a palavra-chave in, já na 2° repetição, o iterador vai conter o 2° elemento, e assim por diante. O que será cada um desses elementos, vai depender do objeto que você forneceu e da estrutura de dados que ele utiliza. Perceba no exemplo abaixo, que o iterador i assume o valor \"a\" na 1° repetição do loop, depois, o valor \"b\" na 2° repetição, e depois, o valor \"c\" na 3° e última repetição do loop.\n\nletras &lt;- c(\"a\", \"b\", \"c\")\n\nfor(i in letras){\n  print(i)\n}\n\n[1] \"a\"\n[1] \"b\"\n[1] \"c\"\n\n\nRepare também pelo exemplo acima, que o tamanho (ou o número de elementos) do objeto que você forneceu, determina o número de repetições que o for loop vai executar. Desse modo, se um while loop utiliza uma condição lógica para determinar o número de iterações a serem executadas, um for loop se baseia apenas no número de elementos presentes no objeto que você estabeleceu na definição do loop. Logo, se você utiliza, por exemplo, um data.frame de 5 colunas, o for loop vai repetir os comandos 5 vezes, mas se você utiliza uma lista de 30 elementos, então o for loop vai iterar 30 vezes sobre os comandos definidos em seu corpo.\nAinda observando o exemplo acima, ao invés de fornecermos um vetor de character’s, é mais comum fornecermos um vetor contendo uma sequência de integer’s, utilizando o operador : (como 1:10) ou funções de sequência como seq_along() e seq_len(). Dessa forma, o iterador se comporta como um índice numérico, que representa o número da repetição em que o loop se encontra. Dito de outra forma, se o meu loop está na 1° repetição, o iterador vai conter o valor 1, se o loop está na 2° repetição, o iterador passa a conter o valor 2, e assim por diante.\nPortanto, eu poderia muito bem reescrever o loop anterior, utilizando dessa vez um índice numérico para acessar os elementos do vetor letras. Repare abaixo, que estou utilizando o índice numérico do iterador em conjunto com subsetting, para acessar cada elemento do vetor letras.\n\nfor(i in seq_along(letras)){\n  print(letras[i])\n}\n\n[1] \"a\"\n[1] \"b\"\n[1] \"c\"\n\n\nPerceba também no exemplo acima, que estou aplicando a função seq_along() sobre o vetor letras. Tudo que essa função faz, é me retornar uma sequência de 1 até o número de elementos contidos no objeto em que apliquei ela. Logo, o resultado de seq_along() no caso acima, é um vetor contendo uma sequência de 1 a 3. Isso também significa que, eu poderia muito bem substituir essa expressão seq_along(letras) por 1:3, ou, c(1, 2, 3), ou, 1:length(letras).\nA função seq_len() é irmã de seq_along(). Essa função gera uma sequência de 1 até o número que você oferecer à função. Ou seja, a expressão seq_len(3) é equivalente a 1:3, e seq_len(100), à 1:100, e assim por diante. Tendo isso em mente, poderíamos reescrever o loop acima da seguinte maneira:\n\nfor(i in seq_len(length(letras))){\n  print(letras[i])\n}\n\n[1] \"a\"\n[1] \"b\"\n[1] \"c\"\n\n\nCaso o resultado da expressão length(letras) fosse igual a zero, as funções seq_along() e seq_len() nos retornaria um vetor do tipo integer de comprimento zero. Dessa forma, o for loop não é executado pelo R. Ou seja, como o vetor em questão estaria vazio, o iterador do for loop não teria nenhum elemento para iterar sobre.\nUma expressão como 1:length(x) funciona perfeitamente bem quando o vetor x possui comprimento maior que 1. Todavia, quando esse vetor possui comprimento zero, a expressão 1:length(x) acaba nos retornando 1:0 (isto é, o vetor c(1, 0)) como resultado, ao invés de um vetor vazio. Um detalhe como esse, pode causar erros no mínimo medonhos e de difícil rastreabilidade quando utilizamos esse vetor em um for loop. Ao evidenciar essa diferença, quero destacar que as funções seq_along() e seq_len() são métodos mais seguros e apropriados de se criar essas sequências a serem utilizadas pelo iterador de um for loop.\nPara mais, vale destacar que, o objeto definido após a palavra-chave in pode ser qualquer coisa que a linguagem te permite definir. Geralmente esse objeto é um vetor de índices numéricos, como nos exemplos acima, mas ele poderia muito bem ser uma lista ou um data.frame, ou algo mais de sua preferência. Qualquer que seja a sua escolha, o for loop vai caminhar ao longo desse objeto que você forneceu, elemento por elemento.\nPor uma convenção, programadores em geral, quase sempre utilizam a letra i para representar esse iterador. Especialmente se se esse iterador contém um índice numérico. Mas você tem a liberdade de dar o nome que quiser para o seu iterador. Como exemplo, eu poderia muito bem criar um iterador chamado fruta.\n\nfrutas &lt;- c(\n  \"Banana\", \"Maçã\", \"Pêra\",\n  \"Pêssego\", \"Laranja\"\n)\n\nfor(fruta in frutas){\n  print(fruta)\n}\n\n[1] \"Banana\"\n[1] \"Maçã\"\n[1] \"Pêra\"\n[1] \"Pêssego\"\n[1] \"Laranja\"\n\n\nO iterador é parte essencial de um for loop, pois em geral, utilizamos esse iterador para acessarmos um elemento diferente de algum objeto, ou, para gerarmos um resultado diferente a cada repetição do loop. Veja no exemplo abaixo, que a cada iteração o for loop está somando 10 a um elemento diferente do vetor valores. Consequentemente, o valor armazenado no objeto soma muda a cada repetição do for loop.\n\nvalores &lt;- c(15, 20, 25, 30)\n\nfor(i in valores){\n  soma &lt;- i + 10\n  print(soma)\n}\n\n[1] 25\n[1] 30\n[1] 35\n[1] 40\n\n\nPortanto, geralmente utilizamos o iterador para aplicarmos uma função sobre um input diferente e, com isso, gerar um resultado distinto a cada repetição. Esse input pode ser o próprio índice numérico do iterador (como nos exemplos em que aplicamos a função print() sobre o iterador), ou, então, um elemento (ou parte) de algum objeto (como no exemplo acima, do vetor valores).\nContudo, temos também a opção de não utilizamos o iterador ao longo do corpo do loop. Dessa forma, o loop vai sempre executar os mesmos comandos, que por sua vez, vão utilizar sempre os mesmos inputs e, consequentemente, vão gerar sempre o mesmo resultado a cada repetição.\n\nfor(i in 1:5){\n  soma &lt;- 10 + 15\n  msg &lt;- paste0(\"Essa soma é igual a: \", soma)\n  print(msg)\n}\n\n[1] \"Essa soma é igual a: 25\"\n[1] \"Essa soma é igual a: 25\"\n[1] \"Essa soma é igual a: 25\"\n[1] \"Essa soma é igual a: 25\"\n[1] \"Essa soma é igual a: 25\"\n\n\n\n\n15.3.2 Corpo\nO corpo de um for loop (assim como de qualquer outro tipo de loop) contém o conjunto de comandos que serão executados a cada repetição. Dessa maneira, você deve inserir dentro desse corpo, todos os comandos que você deseja que esse for loop execute por você. Nesse sentido, o corpo de um loop funciona de uma maneira muito parecida com o corpo de uma função.\nComo exemplo, eu posso utilizar um for loop para realizar 5 jogadas de um dado tradicional. Dessa forma, em cada uma das 5 repetições, o for loop executa a função sample() para sortear um número de 1 a 6, e, em seguida, me mostra qual foi o número sorteado através da função print().\n\ndado &lt;- 1:6\n\nfor(i in 1:5){\n  print(sample(dado, 1))  \n}\n\n[1] 5\n[1] 1\n[1] 4\n[1] 4\n[1] 4",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Loops*</span>"
    ]
  },
  {
    "objectID": "Capítulos/17-loops.html#armazenando-os-resultados-de-um-loop.",
    "href": "Capítulos/17-loops.html#armazenando-os-resultados-de-um-loop.",
    "title": "15  Loops",
    "section": "15.4 Armazenando os resultados de um loop.",
    "text": "15.4 Armazenando os resultados de um loop.\nO que acontece dentro de um loop (seja ele um for, while ou repeat loop) permanece dentro desse loop (GROLEMUND, 2014). Isso significa que os resultados gerados ao longo da execução de um loop não são salvos, a menos que você peça explicitamente por isso.\nImagine por exemplo, que você deseja simular 20 jogadas do dado, utilizando um loop como o da seção anterior. Porém você deseja ter os números sorteados em cada jogada, salvos em algum objeto, para que você possa fazer cálculos sobre esses resultados após a execução do loop. Para isso, você precisa utilizar uma expressão de assignment para salvar (em algum objeto) um resultado gerado dentro de seu loop.\nNo exemplo abaixo, eu estou criando um vetor do tipo integer com 20 elementos chamado jogadas. Em seguida, dentro do loop, eu estou usando o operador de assignment (&lt;-) para salvar o resultado de cada jogada em um dos elementos do vetor jogadas. Como resultado, se quisermos utilizar os números sorteados ao longo do loop em algum cálculo posterior, basta utilizarmos o objeto jogadas.\n\njogadas &lt;- vector(\"integer\", length = 20)\nfor(i in 1:20){\n  jogadas[i] &lt;- sample(dado, 1)  \n}\n\njogadas\n\n [1] 6 2 5 1 1 1 4 1 5 5 2 4 3 5 1 6 5 3 3 2\n\n\nPerceba no exemplo acima, que eu reservei o espaço para cada resultado antes do for loop. É muito importante que você crie previamente, um objeto que possa guardar os resultados de seu loop (GROLEMUND, 2014; WICKHAM; GROLEMUND, 2017). Logo, esse objeto precisa ter espaço suficiente para comportar todos os resultados gerados pelo seu loop.\nPor exemplo, se eu possuo um data.frame contendo 4 colunas numéricas, e desejo calcular a média de cada coluna, eu preciso criar algum objeto que possa receber as 4 médias que serão geradas pelo loop. No exemplo abaixo, eu utilizo a função vector() para criar um novo vetor atômico chamado media. Este vetor é do tipo double, e possui 4 elementos. Sendo assim, dentro do corpo do loop, eu salvo os resultados da função mean() dentro de cada elemento do vetor media.\n\ndf &lt;- data.frame(\n  a = rnorm(20),\n  b = rnorm(20),\n  c = rnorm(20),\n  d = rnorm(20)\n)\n\nmedia &lt;- vector(mode = \"double\", length = 4)\nfor(i in 1:4){\n  media[i] &lt;- mean(df[[i]])\n}\n\nmedia\n\n[1]  0.11955837  0.13558123 -0.09504801  0.03715764\n\n\nPor que é muito importante que você reserve o espaço para cada resultado antes do loop? Pois caso contrário, o nosso loop pode ficar muito lento, dado que, para cada resultado gerado, o R precisa reservar um tempo durante a execução, para expandir o objeto em que você está salvando esses resultados (GROLEMUND, 2014).\nEm mais detalhes, se você possui um vetor x de 5 elementos, e adiciona um 6° elemento a ele, para que o vetor “cresça”, o R é obrigado a criar um novo vetor de 6 elementos em um outro endereço de sua memória RAM, e copiar todos os 5 elementos do vetor x para esse novo endereço, e, por fim, adicionar o 6° elemento a este novo vetor criado. Obviamente esse processo é feito de maneira automática, mas com certeza é um processo altamente custoso.\nDentro da comunidade do R, esse problema é mais conhecido pelo termo growing vector problem (ou “problema do vetor crescente”). Caso estivéssemos usando um loop de 2 mil repetições, o R precisaria executar 2 mil vezes o processo descrito no parágrafo anterior, para aumentar um elemento a mais em meu vetor, com o objetivo de guardar o novo resultado gerado em cada uma dessas 2 mil repetições. Por outro lado, se eu já reservo previamente um vetor com 2 mil elementos, o R não precisaria mais executar esse processo, e pode se dedicar apenas na execução do loop.\nComo exemplo, eu realizei um pequeno teste em minha máquina. Em ambos os exemplos abaixo estou realizando o mesmo loop de 10 milhões de repetições. A cada repetição, esse loop salva o valor do iterador em um vetor chamado vec. A diferença entre os dois exemplos, é que no primeiro eu expando o vetor vec a cada repetição e, no segundo, o vetor vec já possui 10 milhões de elementos antes do loop começar. Repare abaixo, que a minha máquina demorou em torno de 3,92 segundos para executar o primeiro exemplo, mas apenas 0,43 segundos para executar o segundo.\n\nsystem.time({\n  vec &lt;- 0\n  for(i in 1:10000000){\n    vec[i] &lt;- i\n  }\n})\n\n## usuário   sistema decorrido \n##    3.47      0.41      3.92\n\nsystem.time({\n  vec &lt;- vector(\"integer\", length = 10000000)\n  for(i in 1:10000000){\n    vec[i] &lt;- i\n  }\n})\n\n## usuário   sistema decorrido \n##    0.40      0.02      0.43\nAlém disso, é muito importante que você crie um vetor associado ao mesmo tipo de dado que o resultado gerado em seu loop. Logo, se o seu loop gera um valor do tipo double em cada repetição, é importante que você crie um vetor do tipo double para armazenar esses resultados. Também é essencial que você saiba o tamanho que esse resultado pode assumir em cada repetição. Em outras palavras, será que a cada repetição de seu loop, um único número é gerado (por exemplo, uma média)? Ou um novo vetor de 5 elementos? Ou um data.frame de tamanho variável?\nA partir do momento que você sabe qual o tipo de resultado que será gerado pelo seu loop, você pode identificar com mais facilidade, qual a melhor estrutura de dado para guardar esses valores. Pergunte-se: será que um vetor atômico consegue guardar esses resultados? Ou uma lista é mais adequada? Lembre-se que vetores atômicos só podem guardar dentro de si, valores que pertencem ao mesmo tipo de dado (double, integer, logical, character, etc.). Além disso, nós não podemos guardar um novo vetor ou um novo data.frame, dentro de cada elemento de um vetor atômico. Logo, se a cada repetição do loop você está gerando um vetor, uma lista ou um data.frame, é melhor que você utilize uma lista para armazenar cada um desses resultados (ao invés de um vetor atômico).\nPara criar uma nova lista de \\(n\\) elementos, você pode utilizar novamente a função vector(). Basta que você configure o argumento mode da função para o valor \"list\". Lembre-se que, para acessar um elemento de uma lista, você precisa utilizar 2 pares de colchetes ao invés de 1 par. No exemplo abaixo, estou utilizando um for loop para realizar um trabalho semelhante à função split(), que é o de dividir (ou separar) as linhas de um data.frame em diferentes elementos de uma lista, de acordo com os valores de uma determinada coluna.\n\nlibrary(dplyr)\n\n\ntab &lt;- data.frame(\n  setor = c(\"B\", \"C\", \"C\", \"A\"),\n  ID = c(\"1154\", \"678\", \"9812\", \"2500\"),\n  valor = round(rnorm(4), 2)\n)\n\nsetores &lt;- c(\"A\", \"B\", \"C\")\nlista_vazia &lt;- vector(\"list\", length = 3)\nnames(lista_vazia) &lt;- setores\n\nfor(setor_id in setores){\n  lista_vazia[[setor_id]] &lt;- filter(tab, setor == setor_id)\n}\n\nlista_vazia\n\n$A\n  setor   ID valor\n1     A 2500  1.51\n\n$B\n  setor   ID valor\n1     B 1154 -0.65\n\n$C\n  setor   ID valor\n1     C  678  1.04\n2     C 9812 -0.39\n\n\n\n15.4.1 Alguns outros padrões de loops\nLoops são ferramenta fundamental para trabalharmos com listas no R. Pois a linguagem não trata as listas da mesma forma que os vetores atômicos. Logo, operações muito simples e corriqueiras, como aplicar uma determinada operação sobre todos os elementos de um vetor, não possuem a mesma solução direta quando lidamos com uma lista. Por exemplo, se eu tentasse multiplicar cada elemento de uma lista por 2, da mesma forma que eu faria para um vetor atômico, um erro é retornado:\n\nlist(1, 2, 3) * 2\n\n## Error in list(1, 2, 3) * 2 : argumento não-numérico para operador binário\nAplicar uma determinada operação/função sobre cada elemento de uma lista é uma atividade bastante comum no R. Porém, para realizarmos esse trabalho, temos que utilizar um loop para navegar sobre cada elemento dessa lista, aplicando a operação/função que desejamos aplicar. Nesse aspecto, uma lista da linguagem R se aproxima muito à uma lista da linguagem Python, que também exige o uso de loops para trabalharmos com cada elemento.\nComo exemplo, para multiplicarmos cada elemento de uma lista por 2, teríamos que construir um loop parecido com este. Nesse exemplo, estou utilizando o iterador do loop para acessar cada elemento da lista, através do comando lista[[i]] e, em seguida, estou multiplicando esse elemento por 2 e, por último, salvo o resultado nesse mesmo elemento da lista.\n\nlista &lt;- list(1, 2, 3)\nfor(i in seq_along(lista)){\n  lista[[i]] &lt;- lista[[i]] * 2 \n}\n\nlista\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 6\n\n\nAlém disso, até o momento, focamos bastante em loops que utilizam vetores contendo uma sequência numérica. Contudo, também é muito comum iterarmos sobre vetores contendo nomes (ou rótulos), com o objetivo de extrairmos ou modificarmos elementos específicos de uma lista, ou, colunas específicas de um data.frame. Por exemplo, imagine que você possua um data.frame parecido com o objeto tab abaixo.\n\ntab &lt;- data.frame(\n  ID = c(\"A\", \"A\", \"B\", \"C\"),\n  c1 = rnorm(4),\n  c2 = rnorm(4),\n  c3 = rnorm(4)\n)\n\nAgora, suponha que você desejasse calcular a média de todas as colunas numéricas dessa tabela. Para isso, você poderia utilizar um código parecido com esse:\n\nmedias &lt;- list(\n  c1 = mean(tab$c1),\n  c2 = mean(tab$c2),\n  c3 = mean(tab$c3)\n)\n\nEntretanto, essa solução se torna rapidamente inviável a medida em que o número de colunas numéricas em seu data.frame aumenta. Logo, uma solução mais interessante, seria primeiro, coletarmos o nome das colunas que são numéricas e, em seguida, utilizar um loop para iterarmos ao longo dessas colunas, calculando a média de cada uma.\nPara coletarmos os nomes das colunas numéricas, poderíamos construir um loop como o demonstrado abaixo. Dessa forma, estamos empregando a função is.numeric() sobre cada coluna de tab, e armazenando o resultado no vetor vec. Ao final do loop, o vetor vec guarda um valor do tipo logical para cada coluna de tab, indicando se essa coluna é numérica ou não. Com isso, podemos utilizar esse vetor vec com subsetting sobre o resultado da função names(), para descobrirmos os nomes das colunas numéricas de tab.\n\nvec &lt;- vector(\"logical\", length = ncol(tab))\nfor(i in seq_along(tab)){\n  vec[i] &lt;- is.numeric(tab[[i]])\n}\n\ncolunas_numericas &lt;- names(tab)[vec]\ncolunas_numericas\n\n[1] \"c1\" \"c2\" \"c3\"\n\n\nCom esses nomes guardados, podemos construir um novo loop que utiliza esses nomes para acessar cada uma dessas colunas numéricas de tab, e aplicar a função mean() sobre cada uma delas. Como resultado, temos um novo vetor chamado medias que contém as médias de cada coluna numérica de tab.\n\nmedias &lt;- vector(\"double\", length = length(colunas_numericas))\nfor(i in seq_along(colunas_numericas)){\n  coluna &lt;- colunas_numericas[i]\n  medias[i] &lt;- mean(tab[[coluna]])\n}\n\nnames(medias) &lt;- colunas_numericas\nmedias\n\n        c1         c2         c3 \n0.82789102 0.40834457 0.01124178 \n\n\nPortanto, no exemplo acima, a coluna ID do objeto tab não foi acessada em momento algum pelo for loop. Pois o nome dessa coluna não está presente no vetor colunas_numericas. Sendo assim, quando estamos trabalhando com estruturas nomeadas (como listas e data.frame’s), podemos utilizar um for loop em conjunto com o nome atribuído a cada elemento dessa estrutura para acessar e modificar elementos específicos do objeto, sem afetarmos os demais elementos do mesmo.\n\n\n15.4.2 Cuidado com o nome de seu iterador\nO iterador é uma variável criada automaticamente pelo for loop. Porém, tome muito cuidado, pois a depender do ambiente em que o for loop for executado, essa variável pode ser criada em seu ambiente global (global environment). Isso significa que, o iterador criado pelo for loop pode acabar sobrescrevendo um objeto que você criou anteriormente em seu ambiente.\nPor isso, mesmo que você tenha liberdade para definir o nome que desejar para o seu iterador, é importante que você tome cuidado para não sobrescrever algum objeto importante durante o seu programa. Apenas para que esse problema fique claro, veja no exemplo abaixo, que eu crio antes do loop, um objeto i que guarda o texto \"Uma anotação importante\". Após o loop, eu verifico o que está armazenado nesse objeto i, e o número 3 é retornado (ao invés da anotação importante).\n\ni &lt;- \"Uma anotação importante\"\n\nfor(i in 1:3){\n  soma &lt;- 15 + 3\n}\n\nprint(i)\n\n[1] 3\n\n\nNo exemplo acima, como o iterador do loop se chamava i, o for loop cria um novo objeto chamado i, o qual sobrescreve o objeto i anterior que guardava a string. Após a execução do loop, este objeto i guarda o número 3, que é o valor que esse iterador assumiu na última repetição do for loop.\nPortanto, o iterador de um for loop, é um objeto criado no ambiente (ou environment) em que esse for loop é chamado. Uma solução inteligente para esse problema gerado pelo for loop, seria executarmos esse loop através de uma função. Pois, como discutimos no capítulo anterior, as funções são executadas em ambientes separados do seu ambiente global. Dessa forma, o iterador do for loop é criado no ambiente em que essa função é executada. Perceba abaixo, que dessa vez, mesmo após executarmos a função contendo o loop, o objeto i ainda contém a anotação importante.\n\ni &lt;- \"Uma anotação importante\"\n\nf &lt;- function(){\n  for(i in 1:3){\n    soma &lt;- 15 + 3\n  }\n}\n\n### Executei a função\nf()\n\n### O valor do objeto i continua o mesmo\nprint(i)\n\n[1] \"Uma anotação importante\"",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Loops*</span>"
    ]
  },
  {
    "objectID": "Capítulos/17-loops.html#descrevendo-um-while-loop",
    "href": "Capítulos/17-loops.html#descrevendo-um-while-loop",
    "title": "15  Loops",
    "section": "15.5 Descrevendo um while loop",
    "text": "15.5 Descrevendo um while loop\nUm while loop é criado a partir da palavra-chave while. Assim como um for loop, um while loop também possui uma definição e um corpo. Sendo que o seu corpo funciona exatamente da mesma forma que em um for loop. Logo, você inclui dentro do corpo de um while loop, os comandos a serem executados em cada iteração.\nPorém, a definição de um while loop é construída de uma forma diferente. Essa definição também é construída dentro de um par de parênteses, logo após a palavra-chave while, contudo, ela possui 1 único item dentro dela, que é a condição lógica responsável por reger (ou coordenar) o loop. No exemplo abaixo, essa condição lógica é i &lt; 5.\nRepare também, que eu crio o objeto i antes do while loop ocorrer. Logo, ao contrário de um for loop, um while loop não utiliza um iterador, ou, em outras palavras, um while loop não cria um objeto durante sua execução, ele apenas confere o resultado da condição lógica i &lt; 5 a cada repetição.\n\ni &lt;- 1\nwhile(i &lt; 5){\n  print(i)\n  i &lt;- i + 1\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n\n\nPortanto, a cada repetição, o while loop confere se o resultado de i &lt; 5 é igual a TRUE, caso seja, os comandos definidos no corpo desse loop são executados. Perceba que, no exemplo acima, o loop nos mostra o conteúdo do objeto i com print() e, em seguida, acrescenta 1 ao valor do objeto i com i &lt;- i + 1. Como esse incremento é executado em toda repetição do loop, em algum momento, o valor de i será maior ou igual a 5 e, consequentemente, o resultado da condição lógica i &lt; 5 não será mais TRUE. No instante em que essa condição retornar FALSE, o while loop vai encerrar sua execução. Esse fluxo de execução está desenhado na Figura 15.2 abaixo.\n\n\n\n\n\n\n\n\nFigura 15.2: Fluxo de execução de um while loop\n\n\n\n\n\nTendo isso em mente, um while loop repete um mesmo conjunto de comandos enquanto uma condição lógica for verdadeira (GROLEMUND, 2014). Agora, tenha cuidado com um while loop, pois se a condição que rege o loop nunca resultar em FALSE, o loop nunca vai encerrar a sua execução. Ou seja, podemos criar um loop infinito.\nSe você decidiu utilizar um while loop (ao invés de um for loop), é razoável pressupormos que os comandos inseridos no corpo deste loop vão decidir se essa condição vai continuar resultando em TRUE ou não. Logo, se o código presente no corpo de seu while loop não possui qualquer relação com a condição lógica que você forneceu na definição do loop, esse loop nunca vai parar de repetir os comandos descritos em seu corpo (GROLEMUND, 2014).\nNo exemplo anterior, o comando i &lt;- i + 1 presente no corpo do loop, gerava um “crescimento” do objeto i a cada iteração e, por causa disso, garantia que em algum momento, a condição i &lt; 5 resultaria em FALSE. Mas o que seria um caso de while loop infinito ? Um exemplo seria um loop que utiliza uma condição formada por constantes, como 1 &lt; 5. Pois 1 sempre será menor que 5, logo, essa condição sempre resultará em TRUE. Um outro exemplo seria o loop abaixo, que utiliza uma condição lógica em torno do objeto x, mas que não possui nenhum comando presente em seu corpo, que altere esse objeto x de alguma forma que possa tornar a condição lógica x == 10 igual a FALSE.\n\nx &lt;- 10\ncontagem &lt;- 1\n### Esse loop é infinito:\nwhile(x == 10){\n  print(contagem)\n  contagem &lt;- contagem + 1\n}\n\nEntenda que, a definição de um while loop pode conter qualquer tipo de condição lógica que você quiser. Você pode inclusive fornecer diretamente um valor do tipo logical a essa definição (apesar de que isso criaria um loop infinito - TRUE, ou, um loop que jamais executaria os comandos de seu corpo - FALSE). De qualquer forma, a condição lógica que você fornecer à definição de um while loop, deve resultar em 1 único valor do tipo logical. Caso essa condição resulte em um vetor de valores do tipo logical, while vai utilizar apenas o primeiro elemento deste vetor para determinar se o loop prossegue ou não com a sua iteração.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Loops*</span>"
    ]
  },
  {
    "objectID": "Capítulos/17-loops.html#descrevendo-um-repeat-loop",
    "href": "Capítulos/17-loops.html#descrevendo-um-repeat-loop",
    "title": "15  Loops",
    "section": "15.6 Descrevendo um repeat loop",
    "text": "15.6 Descrevendo um repeat loop\nUm repeat loop é um loop infinito por definição. Logo, você precisa ter um cuidado em dobro com este tipo de loop. Sendo assim, um repeat loop vai repetir indefinidamente o conjunto de comandos descritos no corpo do loop. Por esse motivo, quando utilizamos um repeat loop, nós geralmente criamos uma condição de break em seu corpo.\nEm resumo, o comando break cria uma ordem que interrompe o loop que o executou. Portanto, break é uma palavra-chave que deve ser utilizada dentro do corpo de qualquer tipo de loop. Com essa palavra-chave, podemos transformar um loop infinito, em um loop finito. Como exemplo, podemos recriar o exemplo básico de loop com um repeat loop dessa forma:\n\ni &lt;- 1\nrepeat{\n  if(i &gt;= 5){\n    break\n  }\n  print(i)\n  i &lt;- i + 1\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n\n\nPerceba acima, que um repeat loop não possui uma definição, apenas o corpo. Em um for loop ou while loop, a definição determina o momento em que a iteração do loop deve ser finalizada. Como um repeat loop é um loop infinito, não faz sentido criarmos uma definição para ele.\nEm vista disso, assim como ocorre em um while loop, você também precisa incluir dentro do corpo de um repeat loop, comandos que possam decidir quando é o momento de parar o loop, dessa vez, utilizando um comando break. No exemplo acima, utilizo um if statement dentro do corpo do loop para fazer essa decisão.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Loops*</span>"
    ]
  },
  {
    "objectID": "Capítulos/17-loops.html#pulando-repetições-com-next",
    "href": "Capítulos/17-loops.html#pulando-repetições-com-next",
    "title": "15  Loops",
    "section": "15.7 Pulando repetições com next",
    "text": "15.7 Pulando repetições com next\nEnquanto break para a execução de um loop, next faz com que o loop vá direto para a próxima iteração. Dito de outra forma, a palavra-chave next no R é equivalente à palavra-chave continue nas linguagens C e Python.\nComo exemplo, o loop abaixo utiliza um if statement com o teste lógico i %% 2 == 0 para verificar se o valor do objeto i é um número par, caso seja, o loop vai executar um comando next para pular os comandos restantes do corpo do loop, e ir direto para a próxima iteração. Em outras palavras, quando o iterador i assume valores pares, como 2 e 4, o loop não chega a executar o comando print(i), pois o comando next já moveu o loop para a próxima repetição.\n\nfor(i in 1:5){\n  if(i %% 2 == 0){\n    next\n  }\n  \n  print(i)\n}\n\n[1] 1\n[1] 3\n[1] 5",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Loops*</span>"
    ]
  },
  {
    "objectID": "Capítulos/17-loops.html#sec:loop_exportando_planilhas_excel",
    "href": "Capítulos/17-loops.html#sec:loop_exportando_planilhas_excel",
    "title": "15  Loops",
    "section": "15.8 Um estudo de caso: exportando múltiplas planilhas de Excel",
    "text": "15.8 Um estudo de caso: exportando múltiplas planilhas de Excel\nO pacote readxl (que introduzimos no capítulo 4) nos oferece a função read_excel(), com a qual podemos ler (ou importar) planilhas do Excel no R. Porém, o pacote não nos oferece uma função capaz de escrever (ou exportar) um data.frame do R para um arquivo de Excel.\n\nApesar do R não oferecer de fábrica uma solução, existem vários outros pacotes disponíveis que trabalham com planilhas de Excel, e que oferecem funções capazes de escrever tal formato de arquivo. Sendo os principais: openxlsx, xlsx e writexl.\nO pacote writexl é o mais recente e simples de todos dessa lista, dado que ele oferece uma única função, chamada write_xlsx(). Entretanto, isso também significa que ele é a opção mais limitada, e não oferece várias funcionalidades importantes (por exemplo, a adição de abas, ou sheets, ao arquivo). Este pacote é uma interface para a biblioteca libxlsxwriter (escrita em C). Por causa disso, writexl é, em geral, o pacote que escreve os menores arquivos (em tamanho) e no menor tempo possível. Tendo isso em mente, se você precisa de uma solução simples e performática, writexl é uma boa escolha.\nPor outro lado, o pacote xlsx já é um pacote antigo, tendo sido uma das primeiras alternativas a surgirem dentro da comunidade de R. Apesar de ser um pacote bastante completo, ele depende de uma biblioteca escrita em Java, e, por causa dessa dependência, é importante que você tenha o Java devidamente instalado e configurado em seu computador, para que você consiga aproveitar de suas funcionalidades. Infelizmente, alguns usuários enfrentam problemas que surgem dessa dependência^[https://www.r-bloggers.com/2021/09/error-java_home-cannot-be-determined-from-the-registry/#:~:text=Approach%201%3A%20error%3A%20JAVA_HOME%20cannot%20be%20determined%20from%20the%20Registry&text=This%20is%20frequently%20due%20to,t%20install%20Java%20at%20all..\nPor último, o pacote openxlsx é, em geral, a solução que oferece um equilíbrio entre os dois mundos: é performática, fácil de se utilizar e não possui dependências externas ao pacote. Por esse motivo, vamos utilizar as funções de openxlsx ao longo dos exemplos mostrados neste estudo de caso.\n\n15.8.1 Descrevendo um contexto comum\nÉ frequente termos vários data.frame’s diferentes que desejamos salvar em arquivos de nosso computador. Até o momento, mostramos no capítulo 4 como podemos salvar esses objetos em arquivos CSV, através de funções como readr::write_delim() e readr::write_csv2(). Mas nessa seção, vamos exportar esses data.frame’s para arquivos de Excel.\nComo exemplo, vamos utilizar novamente a tabela datasus que introduzimos anteriormente no capítulo 8. Lembrando que você pode importar rapidamente essa tabela para a sua sessão com os comandos abaixo. Ou seja, copie e cole os comandos abaixo em seu console, que você já terá acesso a essa tabela.\n\nlibrary(readr)\n\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo &lt;- \"datasus.csv\"\ndatasus &lt;- read_csv2(paste0(github, pasta, arquivo))\n\n\nprint(datasus)\n\n# A tibble: 1,836 × 6\n  `Faixa etaria` Genero    Cor    `Nome UF` UF    Contagem\n  &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;\n1 10 a 14        Feminino  Parda  Acre      AC           4\n2 10 a 14        Masculino Parda  Acre      AC           4\n3 15 a 19        Feminino  Branca Acre      AC           2\n4 15 a 19        Feminino  Parda  Acre      AC           4\n5 15 a 19        Masculino Branca Acre      AC           6\n# ℹ 1,831 more rows\n\n\n\n\n15.8.2 Como exportar uma tabela para um arquivo de Excel\nPara escrevermos uma planilha de Excel (.xlsx) com o pacote openxlsx, temos que seguir basicamente quatro passos: 1) criar um workbook vazio com a função createWorkbook(); 2) adicionar uma nova página a esse workbook, com a função addWorksheet(); 3) escrever os dados do data.frame em questão nessa nova página adicionada ao workbook, com a função writeData(); 3) por último, exportar esse workbook (ou essa planilha) com a função saveWorkbook().\nEm resumo, todas as planilhas de Excel criadas pelo pacote openxlsx são representadas no R através de um “workbook” (em termos mais técnicos, isto é um objeto de classe \"Workbook\"). Portanto, sempre que estamos trabalhando com as funções do pacote openxlsx, seja adicionando dados a essa planilha, ou alterando suas configurações, estamos na realidade, aplicando essas funções sobre o workbook que representa essa planilha de Excel no R.\nTendo isso em mente, você vai acabar percebendo que a grande maioria das funções do pacote openxlsx recebem em seu primeiro argumento, o workbook que armazena a sua planilha. Nos exemplos dessa seção, eu vou sempre armazenar esse workbook em um objeto chamado wb. Para criarmos um workbook, podemos utilizar a função createWorkbook(), como demonstrado abaixo:\n\nlibrary(openxlsx)\n\n## Criando um workbook vazio:\nwb &lt;- createWorkbook()\n\nPorém, essa função createWorkbook() cria a representação de uma planilha completamente vazia. Por isso, precisamos adicionar um novo sheet à essa planilha. Em outras palavras, é como se estivéssemos adicionando à essa planilha, uma nova folha de papel, onde podemos escrever os nossos dados. Para adicionarmos essa nova página (ou sheet), podemos utilizar a função addWorksheet(). Após executarmos essa função no exemplo abaixo, o workbook armazenado no objeto wb passa a conter uma nova página chamada “Dados DATASUS”.\n\n## Adicionando uma nova página (ou sheet) nesse workbook:\naddWorksheet(wb, \"Dados DATASUS\")\n\nApós adicionarmos essa nova página, podemos escrever os nossos dados nela, com a função writeData(). Para utilizar essa função, você fornece o seu workbook no primeiro argumento, o nome da página na qual você deseja escrever esses dados (nesse caso, a página “Dados DATASUS”) no segundo argumento, e os dados em questão a serem escritos no terceiro argumento.\n\n## Escrevendo os dados da tabela datasus\n## nessa nova página:\nwriteData(wb, \"Dados DATASUS\", datasus)\n\nSendo assim, o nosso workbook wb já contém os dados da tabela datasus escritos em uma página chamada “Dados DATASUS”. Por último, precisamos apenas exportar esse workbook para um arquivo de Excel (.xslx). Para isso, podemos utilizar a função saveWorkbook(). Após executar o comando abaixo, um novo arquivo .xlsx chamado \"dados-datasus\" é criado em meu diretório de trabalho, contendo os dados da tabela datasus.\n\n## Por último exportando os dados:\nsaveWorkbook(wb, \"dados-datasus.xlsx\")\n\n\n\n15.8.3 Como salvar múltiplas planilhas de Excel\nAgora que sabemos quais são os passos necessários para salvar uma única planilha, podemos pensar em como podemos salvar múltiplas planilhas diferentes. Como exemplo, vamos dividir a tabela datasus, em várias tabelas menores. Mais especificamente, vamos dividir essa tabela por cada UF (Unidade da Federação). Para isso, podemos utilizar a função split():\n\npor_uf &lt;- split(datasus, ~UF)\n\nAgora, o objeto por_uf é uma lista de 27 elementos. Cada elemento, contém um data.frame com os dados de uma UF específica. Por exemplo, com o comando abaixo, podemos acessar os dados de Minas Gerais (MG).\n\npor_uf[[\"MG\"]]\n\n# A tibble: 89 × 6\n  `Faixa etaria` Genero    Cor    `Nome UF`    UF    Contagem\n  &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;    &lt;dbl&gt;\n1 10 a 14        Feminino  Branca Minas Gerais MG           1\n2 10 a 14        Feminino  Parda  Minas Gerais MG           3\n3 10 a 14        Feminino  Preta  Minas Gerais MG           1\n4 10 a 14        Masculino Branca Minas Gerais MG           3\n5 10 a 14        Masculino Parda  Minas Gerais MG          11\n# ℹ 84 more rows\n\n\nComo podemos exportar uma planilha para cada UF? Para isso, podemos utilizar um for loop sobre o objeto por_uf. O for loop abaixo, vai (a cada repetição) criar um novo objeto wb contendo uma planilha vazia, em seguida, adicionar uma página chamada “Página 1” a essa planilha, depois, escrever os dados de uma UF específica nessa página, e, por último, exportar esses dados para uma planilha com o nome da UF.\nA cada repetição do loop, os dados da UF são selecionados através do comando dados_uf &lt;- por_uf[[uf]]. Após executar o for loop abaixo, você deve ter 27 novas planilhas em seu diretório de trabalho.\n\nufs &lt;- names(por_uf)\n\nfor(uf in ufs){\n  ## Selecionando os dados da UF\n  dados_uf &lt;- por_uf[[uf]]\n  ## Criando o workbook vazio\n  wb &lt;- createWorkbook()\n  ## Adicionando uma página padrão:\n  addWorksheet(wb, \"Página 1\")\n  ## Escrevendo os dados da UF na nova página\n  writeData(wb, \"Página 1\", dados_uf)\n  ## Salvando o workbook em uma planilha\n  saveWorkbook(wb, paste(uf, \".xlsx\", collapse = \"\"))\n}\n\n\n\n15.8.4 Salvando os dados em diferentes páginas de uma mesma planilha\nPortanto, já vimos como podemos salvar uma única planilha, e, também, várias planilhas de uma vez só com um for loop. Porém, podemos ainda salvar os dados de cada UF em páginas separadas de uma mesma planilha do Excel. Ou seja, podemos criar um único arquivo de Excel, contendo 27 páginas. Cada página, contém os dados de uma UF específica.\nPerceba que o problema continua o mesmo: queremos exportar os dados de cada UF para locais separados. Todavia, a forma como estamos separando esses dados se modificou, pois agora, estamos separando por páginas de uma planilha, ao invés de separarmos por planilha. Para executarmos essa tarefa, podemos novamente aplicar um for loop sobre o objeto por_uf.\nPerceba abaixo, que o corpo do loop é quase idêntico ao do exemplo anterior, contendo algumas poucas alterações. Dessa vez, o workbook wb é criado fora do loop, pois queremos salvar todos os dados no mesmo workbook (ou na mesma planilha). Ou seja, nós não queremos redefinir esse workbook a cada repetição do loop, mas sim, adicionar mais conteúdo a ele. Repare também, que a função addWorksheet() também cumpre um papel importante dessa vez, dado que ela é responsável por criar as páginas na planilha para cada UF.\nLogo, a cada repetição do loop abaixo, estamos adicionando uma nova página ao workbook wb com o nome de uma UF, e escrevendo nessa nova página adicionada, os dados da UF correspondente. Após a execução do loop, o workbook wb já contém todas as 27 páginas com os dados de cada UF. Tudo o que precisamos fazer ao final é exportar esse workbook para uma planilha chamada \"dados-datasus\", com a função saveWorkbook().\n\nufs &lt;- names(por_uf)\nwb &lt;- createWorkbook()\n\nfor(uf in ufs){\n  ## Selecionando os dados da UF:\n  dados_uf &lt;- por_uf[[uf]]\n  ## Adicionando uma nova página ao workbook:\n  addWorksheet(wb, uf)\n  ## Escrevendo os dados da UF nessa página:\n  writeData(wb, uf, dados_uf)\n}\n\nsaveWorkbook(wb, \"dados-datasus.xlsx\")",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Loops*</span>"
    ]
  },
  {
    "objectID": "Capítulos/17-loops.html#sobre-código-vetorizado-vectorized-code",
    "href": "Capítulos/17-loops.html#sobre-código-vetorizado-vectorized-code",
    "title": "15  Loops",
    "section": "15.9 Sobre código vetorizado (vectorized code)",
    "text": "15.9 Sobre código vetorizado (vectorized code)\nNa comunidade do R, os loop’s não são particularmente incentivados como em outras linguagens de programação. Programas escritos em linguagens como C, C++ e Python quase sempre utilizam loop’s de forma massiva, algo que nem sempre ocorre em programas escritos em R.\n\n\n\n\n\n\n\n\nFigura 15.3: Como a soma entre dois vetores é executada em diferentes linguagens de programação\n\n\n\n\n\nTal diferença ocorre por dois motivos: 1) R é uma linguagem funcional, logo, quando precisamos utilizar um loop, ao invés de defini-lo explicitamente, nós geralmente aplicamos uma função que constrói esse loop por nós (WICKHAM; GROLEMUND, 2017); 2) para mais, o R é uma linguagem focada em cálculos vetorizados (GROLEMUND, 2014). Isto significa que a linguagem R prefere trabalhar em seus cálculos, com todo o vetor (ou todo o objeto) de uma vez só, ao invés de trabalhar sequencialmente com cada um dos elementos desse objeto de forma individual.\nPor essa característica, programas em R, usualmente se aproveitam de três características: testes lógicos, subsetting e cálculos por elemento, ou element-wise execution (GROLEMUND, 2014). Pois essas características são o que o R faz de melhor.\nUma soma entre dois vetores, é um bom exemplo que demonstra como essa noção de element-wise execution está enraizada na forma como o R realiza os seus cálculos. Para somarmos dois vetores no R, precisamos apenas conectar esses dois vetores pelo operador +. Perceba que isso é algo muito simples e direto.\n\nvetor1 &lt;- 1:5\nvetor2 &lt;- c(10, 20, 30, 40, 50)\n\nvetor1 + vetor2\n\n[1] 11 22 33 44 55\n\n\nContudo, para realizarmos esse mesmo trabalho em outras linguagens, temos um trabalho maior, pois essas outras linguagens operam de uma forma completamente diferente do R. Perceba que nos dois exemplos abaixo, ambas as soluções apresentadas dependem de um for loop. Como um primeiro exemplo, eu poderia reproduzir em C, a soma entre os objetos vetor1 e vetor2 da seguinte forma:\n\nint vetor1[5] = {\n  1,2,3,4,5\n};\n\nint vetor2[5] = {\n  10,20,30,40,50\n};\n\nint soma[5];\n\nfor (int i = 0; i &lt; 5; i++) {\n  soma[i] = vetor1[i] + vetor2[i];\n  printf(\"%d  \", soma[i]);\n}\n\n## 11  22  33  44  55\nComo um segundo exemplo, eu poderia reproduzir essa mesma soma em Python da seguinte maneira:\n\nvetor1 = [1, 2, 3, 4, 5]\nvetor2 = [10, 20, 30, 40, 50]\n\nsoma = []\nfor i in range(len(vetor1)):\n  soma.append(vetor1[i] + vetor2[i])\n  \nprint(soma)\n\n[11, 22, 33, 44, 55]\n\n\nPortanto, enquanto linguagens como Python e C executam seus cálculos em uma perspectiva mais “incremental” (uma operação de cada vez), o R prefere realizar esses mesmos cálculos em uma perspectiva mais “vetorizada”, lidando com todo o objeto de uma vez só. A Figura 15.3 apresenta tal diferença de maneira gráfica.\nGROLEMUND (2014) é provavelmente o autor que melhor destacou essa diferença entre o R e outras linguagens. Como exemplo, GROLEMUND (2014) mostrou a diferença entre duas funções (abs_loop() e abs_vec()) que aceitam um vetor numérico como input, e que retornam um novo vetor contendo os valores absolutos dos números contidos no vetor de input.\nEm outras palavras, ambas as funções são equivalentes à função abs() dos pacotes básicos do R. Porém, elas realizam os seus cálculos de maneiras bastante distintas. A função abs_loop() utiliza um for loop para visitar individualmente cada elemento do vetor de input, e multiplica esse elemento por -1 caso ele seja menor que 0. Logo, abs_loop() adota uma perspectiva semelhante às linguagens C e Python. Por outro lado, abs_vec() se aproveita das características fortes do R, pois ele primeiro utiliza um teste lógico para detectar todos os elementos do vetor que precisam ser ajustados, e, em seguida, multiplica todos esses elementos por -1 de uma vez só.\n\nabs_loop &lt;- function(vec){\n  for(i in seq_along(vec)){\n    if(vec[i] &lt; 0){\n      vec[i] &lt;- vec[i] * -1\n    }\n  }\n  \n  return(vec)\n}\n\n\nabs_vec &lt;- function(vec){\n  negative &lt;- vec &lt; 0\n  vec[negative] &lt;- vec[negative] * -1\n  return(vec)\n}\n\nRealizei um teste rápido em meu computador, aplicando ambas as funções sobre um vetor de 100 milhões de elementos. Os resultados da função abs_loop() são de certa forma impressionantes, pois eles mostram claramente uma grande evolução da linguagem nos últimos anos.\nNa época, GROLEMUND (2014) realizou este mesmo teste com um vetor de 5 milhões de observações, e a função abs_loop() demorou em torno de 16 segundos para sua execução. Porém, hoje, em 2021, utilizando uma instalação do R no Windows, em sua versão 4.1.0, adquirimos praticamente os mesmos 16 segundos sobre um vetor 20 vezes maior que o vetor utilizado por GROLEMUND (2014). Isso mostra uma grande melhoria de performance dos loops construídos pela linguagem nos últimos anos.\n\nsystem.time({\n  abs_loop(rnorm(100000000))\n})\n\n##  usuário   sistema decorrido \n##    15.99      0.29     16.34\n\nsystem.time({\n  abs_vec(rnorm(100000000))\n})\n\n##  usuário   sistema decorrido \n##     9.05      0.45      9.58\nObviamente, parte dessa melhoria se deve ao hardware atual, que provavelmente é mais rápido e moderno que o hardware utilizado na época de GROLEMUND (2014). Mesmo assim, um ganho de performance de 20 vezes não pode ser atribuído apenas ao hardware de um notebook de entrada como o meu, que inclui 8GB de RAM e um processador lançado ao mercado no início de 2017. Parte desses resultados se devem à otimizações da própria linguagem, que foi se aprimorando ao longo dos anos.\nPara fins de comparação, mesmo que eu reproduza exatamente o mesmo teste realizado por GROLEMUND (2014), podemos perceber não apenas o grande ganho de abs_loop(), mas também, de abs_vec(). Nos testes de GROLEMUND (2014), as funções abs_loop() e abs_vec() demoraram 16,018 e 0,52 segundos, respectivamente. Por outro lado, perceba pelos resultados dos testes abaixo (realizados no meu computador), que essas mesmas funções levaram apenas 0,77 e 0,11 segundos. O que realmente impressiona nesses resultados, é como a função abs_loop() se aproximou bastante da performance apresentada por abs_vec().\n\nlong &lt;- rep(c(-1, 1), 5000000)\n\nsystem.time({\n  abs_loop(long)\n})\n\n##  usuário   sistema decorrido \n##     0.76      0.00      0.77\n\nsystem.time({\n  abs_vec(long)\n})\n\n##  usuário   sistema decorrido \n##     0.09      0.02      0.11 \nEste tipo de resultado, demonstra que os loops no R são muito mais rápidos do que a maior parte dos usuários imagina. Essa é uma polêmica antiga na comunidade internacional de R, onde a ideia de que loops no R são lentos e ineficientes acabou sendo difundida em massa. Parte da culpa não reside apenas nos usuários, dado que o próprio manual interno e introdutório da linguagem desincentiva o uso de loops:\n\n\nWarning: for() loops are used in R code much less often than in compiled languages. Code that takes a ‘whole object’ view is likely to be both clearer and faster in R (TEAM, 2020b, pp. 41).\n\n\nUma outra parte da fonte que incentivou o surgimento dessa polêmica, foi o simples fato de que o R é uma linguagem funcional. Portanto, loops explícitos no R são mais incomuns do que em outras linguagens. Por esse motivo, muitos usuários acabaram pressupondo que loops explícitos fossem algo ruim no R.\nO que muitos não percebem, é que mesmo com esses pressupostos, nós ainda utilizamos loops em diversas situações no R. Porém, quando essas situações ocorrem, esse loop geralmente está “escondido” atrás de uma função. Ou seja, ao invés de construirmos um loop explícito, nós utilizamos uma função que constrói, por nós, esse loop de forma implícita. Exemplos disso são as funções lapply() e purrr::map().\nConcluindo, os resultados acima demonstram que a linguagem R oferece sim, loops rápidos e eficientes, que podem produzir uma boa performance. Entretanto, ainda assim, as soluções vetorizadas continuam sendo as mais performáticas, e mesmo com o bom desempenho apresentado, os loops do R não se escalam tão bem quanto os loops de outras linguagens como C e C++.\nPor esse motivo, muitos usuários do R, quando enfrentam um problema mais complexo que exige o uso intensivo de loops, utilizam interfaces (como a API fornecida pelo pacote Rcpp) para reescrever os seus loops em linguagens mais performáticas como C++. O artigo de introdução1 do pacote Rcpp oferece bons exemplos onde isso ocorre, mostrando também como você pode acessar, através do R, funções escritas em C++.\nNa prática, isso significa que, se você deseja adquirir a melhor performance possível no R, tente escrever um código sob uma perspectiva “vetorizada”, que se aproveita das 3 características principais do R (subsetting, testes lógicos e element-wise execution). Entretanto, não tenha medo ou receio de utilizar loops em seu código, pois eles também conseguem entregar uma boa performance.\nContudo, se os loops do R não são rápidos o suficiente para o seu problema, tente utilizar alguma interface para reescrever esses loops em linguagens mais performáticas, como C e C++. O R oferece de fábrica uma API para a linguagem C, que está descrita no capítulo 5 do manual Writing R Extensions2. Mas você também pode utilizar o pacote Rcpp para acessar funções escritas em C++.\n\n\n\n\nGROLEMUND, G. Hands-On Programming with R. Sebastopol, CA: O’Reilly Media, Inc., 2014.\n\n\nTEAM, R. C. R Language Definition. Version 4.0.3 ed. [s.l.] R Foundation, 2020a.\n\n\nTEAM, R. C. An Introduction to R: A Programming Environment for Data Analysis and Graphics. Version 4.0.3 ed. [s.l.] R Foundation, 2020b.\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Loops*</span>"
    ]
  },
  {
    "objectID": "Capítulos/17-loops.html#footnotes",
    "href": "Capítulos/17-loops.html#footnotes",
    "title": "15  Loops",
    "section": "",
    "text": "https://cran.r-project.org/web/packages/Rcpp/vignettes/Rcpp-introduction.pdf↩︎\nhttps://cran.r-project.org/doc/manuals/r-release/R-exts.html#System-and-foreign-language-interfaces↩︎",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Loops*</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html",
    "href": "Capítulos/18-purrr.html",
    "title": "16  Functional programming com purrr",
    "section": "",
    "text": "16.1 Introdução\nNeste capítulo, vamos introduzir um outro pacote do tidyverse, chamado de purrr. Esse pacote provê um conjunto de ferramentas que ampliam as funcionalidades de functional programming do R. Para ter acesso às funções desse pacote, você pode chamar tanto pelo tidyverse quanto pelo purrr diretamente.\nlibrary(tidyverse)\nlibrary(purrr)",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html#loops-implícitos-com-a-família-map",
    "href": "Capítulos/18-purrr.html#loops-implícitos-com-a-família-map",
    "title": "16  Functional programming com purrr",
    "section": "16.2 Loops implícitos com a família map",
    "text": "16.2 Loops implícitos com a família map\nA principal fraqueza de um for loop é que ele foca demasiada atenção sobre os objetos envolvidos na iteração. Isso por um lado é bom, pois você consegue identificar todas as “dependências” de um for loop, mas, por um outro lado, é ruim. Pois na maioria das vezes, é muito mais importante identificarmos a ação, a transformação ou a funcionalidade que está sendo aplicada sobre esses objetos em cada iteração.\nPor exemplo, abaixo temos dois for loops diferentes que aplicam uma determinada operação sobre o objeto tab. O que cada for loop abaixo está fazendo? Qual a diferença entre eles? Após observá-los por um tempo você vai acabar percebendo que a única diferença entre esses dois for loops está na função que está sendo aplicada sobre cada coluna de tab.\n\ntab &lt;- data.frame(\n  x1 = rnorm(10),\n  x2 = rnorm(10),\n  x3 = rnorm(10),\n  x4 = rnorm(10)\n)\n\nvec1 &lt;- vector(\"double\", length = ncol(tab))\nfor(i in seq_along(tab)){\n  vec1[i] &lt;- mean(tab[[i]], na.rm = TRUE)\n}\n\n\nvec2 &lt;- vector(\"double\", length = ncol(tab))\nfor(i in seq_along(tab)){\n  vec2[i] &lt;- median(tab[[i]], na.rm = TRUE)\n}\n\nprint(vec1)\n\n[1]  0.13909983  0.22810043 -0.17061259 -0.01588861\n\nprint(vec2)\n\n[1] 0.000945201 0.214661946 0.094196225 0.044004442\n\n\nÉ esse o problema que a família de funções map busca solucionar, ao nos fornecer um meio de construirmos loops em um formato mais funcional, destacando assim, as transformações e funções que estamos aplicando em cada repetição, ao invés dos objetos envolvidos na iteração. Como exemplo, podemos replicar o mesmo exemplo de for loops acima, utilizando a família de funções map, da seguinte forma:\n\nlibrary(purrr)\nvec1 &lt;- map_dbl(tab, mean, na.rm = TRUE)\nvec2 &lt;- map_dbl(tab, median, na.rm = TRUE)\n\nprint(vec1)\n\n         x1          x2          x3          x4 \n 0.13909983  0.22810043 -0.17061259 -0.01588861 \n\nprint(vec2)\n\n         x1          x2          x3          x4 \n0.000945201 0.214661946 0.094196225 0.044004442 \n\n\nPerceba acima, o quão simples e sucinto é para expressarmos uma operação com a família map. Vamos explicar daqui a pouco, em detalhes como essas funções funcionam. Por enquanto, quero apenas destacar que agora com a função map_dbl(), está muito fácil de identificarmos a diferença entre os dois loops acima. Pois a única coisa que está de fato mudando entre uma linha e outra, é a função aplicada sobre cada coluna de tab, que são as funções mean() e median(). Dessa forma, você pode rapidamente entender que o primeiro loop está calculando a média de cada coluna, enquanto o segundo loop, está calculando a mediana.\n\n16.2.1 A família de funções map()\nPortanto, o pacote purrr nos oferece a família de funções map, a qual possui 7 membros diferentes, sendo eles:\n\nmap(): retorna uma lista.\nmap_dbl(): retorna um vetor atômico do tipo double.\nmap_chr(): retorna um vetor atômico do tipo character.\nmap_int(): retorna um vetor atômico do tipo integer.\nmap_lgl(): retorna um vetor atômico do tipo logical.\nmap_dfr() e map_dfc(): retornam um data.frame.\n\nTodas essas 7 funções possuem os mesmos argumentos e realizam exatamente o mesmo trabalho. A única diferença entre elas, está na estrutura de dado em que o resultado é retornado. Tal estrutura é identificada pelo sufixo presente no nome de cada função. Portanto, todas essas funções map aceitam um objeto como input, e retornam como output, um novo objeto de mesmo comprimento que o objeto de input, e na estrutura identificada pelo sufixo no nome da função (WICKHAM; GROLEMUND, 2017).\n\n\n\n\n\n\n\n\nFigura 16.1: Representação simples da tarefa executada por map_dbl()\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 16.2: Representação mais detalhada da tarefa executada por map_dbl()\n\n\n\n\n\nToda função map possui 3 argumentos principais, sendo eles: 1) .x, que é o objeto sobre o qual map vai iterar, ou, sobre o qual ela vai aplicar o loop; 2) .f, que é a função a ser aplicada sobre cada elemento de .x; e 3) ..., que é a lista de argumentos a serem repassados para a função definida em .f.\nEm resumo, todas as funções map buscam aplicar a função definida em .f sobre cada elemento do objeto .x. Consequentemente, o resultado de toda função map é um novo objeto contendo os resultados da função definida em .f aplicada sobre cada elemento do objeto definido em .x. Tal ação, está representada na Figura 16.1.\nPortanto, no exemplo anterior, em que aplicamos a função map_dbl() sobre o objeto tab, o que map_dbl() fez, foi criar um loop para aplicar as funções mean() e median() sobre cada elemento de tab. Como tab é um data.frame, cada elemento desse objeto corresponde a uma coluna do data.frame. A medida em que as funções mean() e median() foram sendo aplicadas sobre cada coluna de tab, a função map_dbl() foi coletando e armazenando os seus resultados em um vetor atômico do tipo double. Por fim, a função map_dbl() nos retorna como output, este vetor atômico contendo todos os resultados gerados. A Figura 16.2 apresenta esse processo de forma mais detalhada.\n\n\n16.2.2 No fundo, estamos utilizando um for loop\nNo fim das contas, todas as funções map utilizam em algum momento um for loop para aplicar a função .f sobre cada elemento do objeto .x. Um detalhe é que essas funções constroem esse for loop em C, com o objetivo de gerar máxima performance. A título de ilustração, poderíamos reproduzir em R a definição da função map(), da seguinte forma:\n\nmap &lt;- function(.x, .f, ...){\n  resultados &lt;- vector(\"list\", length = length(.x))\n  for(i in seq_along(.x)){\n    resultados[[i]] &lt;- .f(.x[[i]], ...)\n  }\n  \n  return(resultados)\n}\n\nmap(tab, mean, na.rm = TRUE)\n\n[[1]]\n[1] 0.1390998\n\n[[2]]\n[1] 0.2281004\n\n[[3]]\n[1] -0.1706126\n\n[[4]]\n[1] -0.01588861\n\n\nCom essa definição em mente, você também pode rapidamente atribuir as diferenças entre as funções map(), map_dbl(), e todas as demais funções map, à primeira linha dessa definição com a função vector(). Ou seja, a diferença principal entre as funções map() e map_dbl() (ou qualquer outra das funções map) é o tipo de vetor criado pela função vector(). Tal diferença está marcada na Figura 16.3.\nSendo assim, todas as funções map ainda dependem de um for loop para realizar o seu trabalho. Porém, essas funções assumem o trabalho duro de criar esse for loop por você. Como resultado, você economiza parte de seu tempo, e deixa a intenção de seu código mais clara.\n\n\n\n\n\n\n\n\nFigura 16.3: Diferenças entre as definições das funções map\n\n\n\n\n\n\n\n16.2.3 Se não existe uma solução pronta no R, crie a sua própria\nUm dos grandes poderes das funções map, é que elas te ajudam a aplicar as suas ações sobre múltiplos inputs diferentes. Por “suas ações”, quero destacar que, se você não possui uma função já pronta no R que execute a ação que você deseja aplicar sobre cada elemento de seu objeto, você pode muito bem criar uma função personalizada, que aplique exatamente essa ação da forma como você deseja. Replicar depois essa função personalizada para os demais inputs se torna um passo muito simples com as funções map.\nPor exemplo, imagine que você tenha uma lista como o objeto l abaixo, onde cada elemento é uma nova lista que pode conter um número variável de elementos. Agora, imagine que você queira identificar quais elementos dessa lista possuem NA’s. Nesse caso, você pode criar uma função como a tem_na() abaixo, que aceita uma lista como input, e utiliza as funções is.na() e any() para descobrir se algum dos elementos dessa lista contém um valor NA. Em seguida, podemos simplesmente replicar essa função para cada elemento da lista l com a função map_lgl().\n\ntem_na &lt;- function(x){\n  teste &lt;- is.na(x)\n  resultado &lt;- any(teste)\n  return(resultado)\n}\n\nl &lt;- list(\n  list(1, 2, 3, NA),\n  list(24, 12),\n  list(21, NA, 4),\n  list(56, 19, 20, 43)\n)\n\nvec &lt;- map_lgl(l, tem_na)\nvec\n\n[1]  TRUE FALSE  TRUE FALSE\n\n\n\n\n16.2.4 Alguns atalhos úteis das funções map\nExistem alguns atalhos úteis que você pode utilizar ao definir o argumento .f nas funções map. Por exemplo, suponha que você possua uma lista com várias informações referentes a um determinado aluno. Caso você precise coletar as idades de cada aluno em um vetor atômico por exemplo, você poderia fornecer à função map_dbl(), uma função anônima responsável por extrair o item idade de uma lista de input, como demonstrado abaixo.\n\nalunos &lt;- list(\n  Ana = list(idade = 15, altura = 1.67),\n  Bruno = list(idade = 17, altura = 1.75),\n  Amanda = list(idade = 21, altura = 1.88),\n  Eduardo = list(idade = 14, altura = 1.62)\n)\n\nalunos %&gt;% \n  map_dbl(function(x) x$idade)\n\n    Ana   Bruno  Amanda Eduardo \n     15      17      21      14 \n\n\nApesar de bem prático escrevermos uma função anônima dessa forma, podemos utilizar uma notação ainda mais simples. Tal notação consiste em utilizar um til (~) como uma abreviação para a declaração da função anônima, e um ponto final (.) para determinar onde o argumento será posicionado no corpo dessa função anônima. Tendo isso em mente, poderíamos reproduzir o exemplo acima, da seguinte forma:\n\nalunos %&gt;% \n  map_dbl(~.$idade)\n\n    Ana   Bruno  Amanda Eduardo \n     15      17      21      14 \n\n\nPortanto, o til substitui de certa forma a palavra-chave function, e o ponto final representa o argumento da função, ou, o elemento sobre o qual a função será aplicada. Contudo, como esse processo de extrair informações específicas de uma lista é algo muito comum, as funções map também oferecem um outro atalho, que seria o uso de uma string. Logo, se você deseja extrair um item de uma lista presente em cada elemento de um objeto, você pode simplesmente fornecer o nome desse item em uma string à função map.\n\nalunos %&gt;% \n  map_dbl(\"idade\")\n\n    Ana   Bruno  Amanda Eduardo \n     15      17      21      14",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html#um-estudo-de-caso-aplicando-um-modelo-econométrico-sobre-diferentes-países",
    "href": "Capítulos/18-purrr.html#um-estudo-de-caso-aplicando-um-modelo-econométrico-sobre-diferentes-países",
    "title": "16  Functional programming com purrr",
    "section": "16.3 Um estudo de caso: aplicando um modelo econométrico sobre diferentes países",
    "text": "16.3 Um estudo de caso: aplicando um modelo econométrico sobre diferentes países\nNessa seção, vamos reproduzir o famoso exemplo dado por Hadley Wickham em sua palestra “Managing many models with R”. Pois esse exemplo demonstra bem, como as funções map ampliam as nossas capacidades com a linguagem R. Tal exemplo, começa pelo dataset gapminder, disponível através do pacote gapminder. Esse dataset contém dados de expectativa de vida (lifeExp), população (pop) e PIB per capita (gdpPercap) de diversos países do mundo (country), ao longo de vários anos (year).\n\nlibrary(gapminder)\n\n\ngapminder\n\n# A tibble: 1,704 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n# ℹ 1,699 more rows\n\n\nRepare abaixo, que esse dataset contém dados de 142 países diferentes, ao longo de 5 continentes do mundo. Dentre esses vários países, temos uma expectativa de vida estimada que varia de 23,59 até 82,60 anos, e um PIB per capita de 241 até 113.523 dólares.\n\ndplyr::n_distinct(gapminder$country)\n\n[1] 142\n\ndplyr::n_distinct(gapminder$continent)\n\n[1] 5\n\nrange(gapminder$lifeExp)\n\n[1] 23.599 82.603\n\nrange(gapminder$gdpPercap)\n\n[1]    241.1659 113523.1329\n\n\nCom esses dados em mãos, podemos utilizar um modelo econométrico para tentar explicar a expectativa de vida da população de cada país com base no seu PIB per capita. Essa é uma hipótese clássica da literatura econômica, que se baseia na ideia de que um povo vive melhor e por mais tempo, quando ele possui uma maior capacidade de adquirir bens e serviços. Tal modelo econométrico está apresentado abaixo, onde \\(lifeExp_j\\) representa a expectativa de vida estimada para o país \\(j\\), e \\(gdpPercap_j\\), o PIB per capita observado para o mesmo país \\(j\\).\n\\[\nlifeExp_j= \\beta_{0} + \\beta_{1} \\times gdpPercap_j\n\\]\nCaso você nunca tenha visto ou estudado sobre econometria (também conhecida como “análise de regressão linear”), não se preocupe em entender exatamente como o modelo é calculado, ou o que a equação acima representa. Se preocupe apenas em entender os seguintes pontos: 1) a função lm() é uma função presente nos pacotes básicos do R, que é capaz de calcular esse tipo de modelo; 2) precisamos aplicar essa função lm() sobre os dados de cada país, para obtermos os resultados do modelo separados para cada país.\nComo um primeiro exemplo, para aplicarmos esse modelo econométrico sobre os dados de um país em específico, como o Brasil, poderíamos fazer o seguinte:\n\nlibrary(tidyverse)\nbr &lt;- gapminder %&gt;% \n  filter(country == \"Brazil\")\n\nmodelo &lt;- lm(lifeExp ~ gdpPercap, data = br)\nsummary(modelo)\n\n\nCall:\nlm(formula = lifeExp ~ gdpPercap, data = br)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.066 -1.278  0.367  1.335  2.350 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 4.599e+01  1.510e+00   30.46 3.41e-11 ***\ngdpPercap   2.787e-03  2.405e-04   11.59 4.04e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.943 on 10 degrees of freedom\nMultiple R-squared:  0.9307,    Adjusted R-squared:  0.9238 \nF-statistic: 134.4 on 1 and 10 DF,  p-value: 4.045e-07\n\n\nPortanto, no exemplo acima, o objeto modelo contém os resultados do modelo para o Brasil. Pois aplicamos a função lm() especificamente sobre os dados do Brasil. Todavia, caso aplicássemos a função lm() diretamente sobre a tabela gapminder inteira, teríamos na verdade, os resultados do modelo para todo o mundo (sem distinção de países). Pois estamos utilizando os dados de todos os países ao mesmo tempo para calcular o modelo.\n\n### Abaixo temos os resultados do modelo para\n### todo o mundo. Pois aplicamos a função lm() sobre\n### os dados de todos os países de uma vez só.\nmodelo &lt;- lm(lifeExp ~ gdpPercap, data = gapminder)\nsummary(modelo)\n\n\nCall:\nlm(formula = lifeExp ~ gdpPercap, data = gapminder)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-82.754  -7.758   2.176   8.225  18.426 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 5.396e+01  3.150e-01  171.29   &lt;2e-16 ***\ngdpPercap   7.649e-04  2.579e-05   29.66   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.49 on 1702 degrees of freedom\nMultiple R-squared:  0.3407,    Adjusted R-squared:  0.3403 \nF-statistic: 879.6 on 1 and 1702 DF,  p-value: &lt; 2.2e-16\n\n\nAgora, como poderíamos calcular os resultados desse modelo separados para cada um dos 142 países descritos em gapminder? Com a ajuda das funções map, replicar esse modelo para os 142 países, se torna uma tarefa extremamente simples de ser feita.\nPelo fato da função map() aplicar uma determinada função sobre cada elemento de um objeto, podemos utilizar map() para aplicarmos lm() sobre os dados de cada país. Sendo assim, cada elemento do objeto utilizado por map(), deve conter os dados de um país específico. Logo, cada elemento deste objeto seria muito provavelmente um data.frame contendo os dados de um país.\nDito de outra forma, vamos aplicar a função map() sobre uma lista de data.frame’s. Por esse motivo, a função que map() vai aplicar sobre cada elemento dessa lista, deve aceitar como input, um data.frame contendo os dados de um país específico, e gerar como output, os resultados do modelo aplicado sobre esses dados de input. Como primeiro passo, vamos criar essa função.\n\n16.3.1 A função que calcula o modelo econométrico\nPortanto, precisamos criar uma função que aceita um data.frame como input, e que calcula o modelo econométrico sobre os dados desse input. A função aplicar_modelo() abaixo, cumpre justamente esse papel. Tudo que essa função faz é aplicar a função lm() sobre o data.frame de input (argumento x). Perceba também que, independente de qual for o data.frame que fornecermos a essa função, ela vai sempre calcular o mesmo modelo, pois a equação na função lm() sempre será lifeExp ~ gdpPercap.\n\naplicar_modelo &lt;- function(x){\n  lm(lifeExp ~ gdpPercap, data = x)\n}\n\n\n\n16.3.2 Criando uma lista de data.frame’s\nPodemos criar a lista de data.frame’s, contendo os dados de cada país, de diversas formas. Em sua palestra, Hadley Wickham utilizou a função nest(), proveniente do pacote tidyr, para criar essa lista de data.frame’s dentro de uma coluna do data.frame original. Ou seja, Wickham utilizou nest() para criar uma espécie de data.frame de data.frame’s, pois ele queria demonstrar esta poderosa ideia de um nested data.frame. Porém, como uma solução ainda mais simples, também poderíamos utilizar a função split() para dividirmos a tabela gapminder em uma lista, onde cada elemento dessa lista conteria um data.frame com os dados de um país diferente. Ambas as soluções são perfeitamente válidas.\n\n\n16.3.3 Com a função split()\nPrecisamos separar em diferentes elementos, os dados de cada país descrito na tabela gapminder. Para isso, podemos utilizar a função split(). Em resumo, essa função aceita um vetor ou data.frame como input, e divide esse objeto de input em diferentes elementos de uma lista, com base em algum vetor de grupos.\nLogo, podemos pedir à split() que divida a tabela gapminder de acordo com os valores da coluna country. Veja o resultado abaixo:\n\ndados_por_pais &lt;- gapminder %&gt;% split(~country)\ndados_por_pais[[1]]\n\n# A tibble: 12 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n# ℹ 7 more rows\n\n\nPortanto, o objeto dados_por_pais é uma lista, onde cada elemento dessa lista, contém um data.frame com os dados de um país específico. Agora, podemos utilizar a função map() para simplesmente aplicarmos a função aplicar_modelo() sobre cada elemento dessa lista, ou, sobre os dados de cada país. Como resultado, teremos uma nova lista, onde cada elemento dessa lista, contém os resultados do modelo para um determinado país. No exemplo abaixo, estou mostrando os resultados do modelo para o Afeganistão. Curiosamente, o coeficiente estimado pelo modelo foi negativo (-0,00224), indicando assim, que para o Afeganistão, aumentos no PIB per capita reduzem a expectativa de vida estimada da população. Um resultado que contradiz a nossa hipótese inicial.\n\nmodelos &lt;- map(dados_por_pais, aplicar_modelo)\nsummary(modelos[[1]])\n\n\nCall:\nlm(formula = lifeExp ~ gdpPercap, data = x)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.730 -3.880  1.845  3.866  6.734 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 39.27720   12.04623   3.261  0.00857 **\ngdpPercap   -0.00224    0.01488  -0.151  0.88334   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.341 on 10 degrees of freedom\nMultiple R-squared:  0.002261,  Adjusted R-squared:  -0.09751 \nF-statistic: 0.02266 on 1 and 10 DF,  p-value: 0.8833\n\n\nCom a lista modelos, podemos continuar utilizando a função map() para extrair informações específicas desses modelos. Por exemplo, os comandos abaixo utilizam a função glance() do pacote broom para extrair o \\(R^2\\) (coeficiente de determinação) estimado por cada modelo. No exemplo abaixo, estou mostrando os coeficientes dos 10 primeiros países.\n\nr2s &lt;- modelos %&gt;%\n  map(broom::glance) %&gt;%\n  map_dbl(\"r.squared\")\n\nr2s[1:10]\n\nAfghanistan     Albania     Algeria      Angola   Argentina   Australia \n0.002260718 0.700762689 0.818067786 0.090648834 0.691638237 0.973075112 \n    Austria     Bahrain  Bangladesh     Belgium \n0.985977854 0.806033051 0.717947961 0.985551840 \n\n\n\n\n16.3.4 Com a função nest()\nApesar da função split() já nos oferecer uma ótima solução, também podemos muito bem adotar a solução mostrada por Wickham, que utiliza a função nest() para criar um “data.frame de data.frame’s”.\n\n\n\n\n\n\n\n\nFigura 16.4: Transformação executada por nest()\n\n\n\n\n\nNo momento, cada linha da tabela gapminder descreve os dados de um país em um determinado ano. Entretanto, a nossa intenção com essa solução, é transformar a tabela gapminder, de modo que cada linha da tabela contenha todos os dados de um determinado país para todos os anos.\nPodemos realizar essa transformação, ao agruparmos à tabela pela coluna country (com a função group_by()) e, em seguida, aplicarmos a função nest() do pacote tidyr, como demonstrado abaixo:\n\nlibrary(tidyr)\nlibrary(magrittr)\nlibrary(dplyr)\n\n\ndados_por_pais &lt;- gapminder %&gt;%\n  group_by(country, continent) %&gt;% \n  nest()\n\ndados_por_pais\n\n# A tibble: 142 × 3\n# Groups:   country, continent [142]\n  country     continent data             \n  &lt;fct&gt;       &lt;fct&gt;     &lt;list&gt;           \n1 Afghanistan Asia      &lt;tibble [12 × 4]&gt;\n2 Albania     Europe    &lt;tibble [12 × 4]&gt;\n3 Algeria     Africa    &lt;tibble [12 × 4]&gt;\n4 Angola      Africa    &lt;tibble [12 × 4]&gt;\n5 Argentina   Americas  &lt;tibble [12 × 4]&gt;\n# ℹ 137 more rows\n\n\nDessa vez, o objeto dados_por_pais é um data.frame que contém três colunas (country, continent e data). A coluna data é uma lista, e cada elemento dessa lista contém um novo data.frame, que por sua vez, contém todos os dados referentes ao país identificado na coluna country da tabela.\nOu seja, ainda estamos utilizando uma lista de data.frame’s, onde cada data.frame dessa lista contém os dados de um país específico. A diferença agora, é que essa lista está inserida em uma coluna de um data.frame, ao invés de estar em um objeto separado.\nPortanto, a Figura 16.4 apresenta de forma gráfica a transformação executada por nest(). Repare também, que o pacote tidyr nos oferece a função unnest(), com a qual podemos reverter a transformação executada por nest().\nComo exemplo, os dados do Brasil estão na 15° linha da tabela dados_por_pais. Logo, eu posso adquirir todos os dados do Brasil, ao acessar o 15° elemento da coluna data. Perceba abaixo, que um novo data.frame é retornado, que contém todos os dados referentes ao Brasil.\n\ndados_por_pais$data[[15]]\n\n# A tibble: 12 × 4\n   year lifeExp       pop gdpPercap\n  &lt;int&gt;   &lt;dbl&gt;     &lt;int&gt;     &lt;dbl&gt;\n1  1952    50.9  56602560     2109.\n2  1957    53.3  65551171     2487.\n3  1962    55.7  76039390     3337.\n4  1967    57.6  88049823     3430.\n5  1972    59.5 100840058     4986.\n# ℹ 7 more rows\n\n\nAgora, precisamos apenas aplicar a função aplicar_modelo() sobre cada elemento da coluna data. Para isso, podemos utilizar novamente a função map(), dessa vez, dentro da função mutate() que introduzimos no capítulo 4. Dessa maneira, map() vai executar a função aplicar_modelo() para cada elemento da coluna data, e retornar uma lista com os resultados, e a função mutate() vai adicionar essa lista como uma nova coluna do data.frame.\n\nmodelos &lt;- dados_por_pais %&gt;% \n  mutate(\n    resultados = data %&gt;% map(aplicar_modelo)\n  )\n\nmodelos\n\n# A tibble: 142 × 4\n# Groups:   country, continent [142]\n  country     continent data              resultados\n  &lt;fct&gt;       &lt;fct&gt;     &lt;list&gt;            &lt;list&gt;    \n1 Afghanistan Asia      &lt;tibble [12 × 4]&gt; &lt;lm&gt;      \n2 Albania     Europe    &lt;tibble [12 × 4]&gt; &lt;lm&gt;      \n3 Algeria     Africa    &lt;tibble [12 × 4]&gt; &lt;lm&gt;      \n4 Angola      Africa    &lt;tibble [12 × 4]&gt; &lt;lm&gt;      \n5 Argentina   Americas  &lt;tibble [12 × 4]&gt; &lt;lm&gt;      \n# ℹ 137 more rows\n\n\nAgora, cada elemento da coluna resultados contém todos os resultados do modelo para cada país da tabela gapminder. A partir daqui, podemos utilizar novamente as funções map para extrairmos as informações específicas dos modelos. Por exemplo, podemos extrair o beta estimado (\\(\\beta_1\\)) e o coeficiente de determinação de cada país, e adicioná-los como novas colunas da tabela modelos.\n\nmodelos &lt;- modelos %&gt;% \n  mutate(\n    glance = resultados %&gt;% map(broom::glance),\n    tidy = resultados %&gt;% map(broom::tidy),\n    beta_estimado = tidy %&gt;% map_dbl(~.[[\"estimate\"]][2]),\n    r2 = glance %&gt;% map_dbl(\"r.squared\")\n  ) %&gt;% \n  select(-glance, -tidy)\n\nmodelos\n\n# A tibble: 142 × 6\n# Groups:   country, continent [142]\n  country     continent data              resultados beta_estimado      r2\n  &lt;fct&gt;       &lt;fct&gt;     &lt;list&gt;            &lt;list&gt;             &lt;dbl&gt;   &lt;dbl&gt;\n1 Afghanistan Asia      &lt;tibble [12 × 4]&gt; &lt;lm&gt;            -0.00224 0.00226\n2 Albania     Europe    &lt;tibble [12 × 4]&gt; &lt;lm&gt;             0.00444 0.701  \n3 Algeria     Africa    &lt;tibble [12 × 4]&gt; &lt;lm&gt;             0.00714 0.818  \n4 Angola      Africa    &lt;tibble [12 × 4]&gt; &lt;lm&gt;            -0.00103 0.0906 \n5 Argentina   Americas  &lt;tibble [12 × 4]&gt; &lt;lm&gt;             0.00187 0.692  \n# ℹ 137 more rows\n\n\nCom esses resultados em mãos, podemos criar visualizações muito interessantes. Como o gráfico de dispersão abaixo, que apresenta a relação entre o beta estimado e o coeficiente de determinação do modelo. Repare nesse gráfico, que os países da Europa, em geral, possuem um beta estimado baixo, indicando assim, que aumentos no PIB per capita tem baixos impactos na expectativa de vida. Isso provavelmente ocorre, porque esses países já possuem expectativas de vida relativamente altas.\nPor outro lado, perceba também que os países africanos parecem se concentrar nos dois extremos do gráfico, com os maiores e menores betas estimados. Os maiores betas, indicam que aumentos no PIB per capita trazem fortes impactos positivos sobre as expectativas de vida nesses países. Isso provavelmente se deve à vida precária e a baixa expectativa de vida que a população desses países enfrenta, de modo que, uma melhoria mínima pode trazer grandes impactos positivos nas condições de vida dessas populações.\nPara mais, repare que os países africanos que possuem betas estimados negativos também possuem coeficientes de determinação baixos, indicando assim, um baixo poder explicativo do modelo. Isso é um sinal de que o nosso modelo não consegue explicar muito dos dados desses países, e provavelmente, esse baixo poder explicativo gerou um beta estimado negativo, que é algo inesperado para essa relação entre expectativa de vida e renda per capita.\nTalvez, esses países tem características importantes que os outros países não possuem, e que afetam essa relação econômica. Por exemplo, muitos países africanos enfrentam guerras civis recorrentes. Guerras desse tipo geram impactos negativos na expectativa de vida, e as mortes podem gerar quedas na população total do país, o que resultaria em um aumento do PIB per capita (ceteris paribus).\n\nmodelos %&gt;% \n  ggplot() +\n  geom_point(\n    aes(x = r2, y = beta_estimado, color = continent)\n  )",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html#comparando-a-família-map-à-família-apply",
    "href": "Capítulos/18-purrr.html#comparando-a-família-map-à-família-apply",
    "title": "16  Functional programming com purrr",
    "section": "16.4 Comparando a família map à família apply",
    "text": "16.4 Comparando a família map à família apply\nOs pacotes básicos do R, nos oferecem a família apply de funções, a qual desenvolve um papel muito similar às funções map. Os membros dessa família estão listados abaixo:\n\napply (generic apply): retorna diferentes tipos de estrutura a depender de um conjunto de condições.\nlapply (list apply): retorna uma lista.\nsapply (simple apply): tenta simplificar o resultado para uma estrutura mais “simples”, a depender do comprimento de cada resultado gerado por FUN.\nvapply (vector apply): retorna um vetor de mesmo tipo de dado que o vetor definido no argumento FUN.VALUE.\n\nTendo isso em mente, todas essas funções aceitam um objeto (X) e uma função (FUN) em seus dois primeiros argumentos. Essas funções apply vão aplicar a função FUN sobre cada elemento do objeto X fornecido, e retornar como resultado, um novo objeto contendo todos os resultados gerados pela função FUN aplicada sobre cada elemento do objeto X.\nUm dos principais motivos pelos quais a família apply tem perdido espaço para a família map, é pelo fato dessas funções serem menos consistentes, especialmente quanto à estrutura do resultado retornado. Por exemplo, apply() pode retornar um vetor, um array ou uma lista como resultado. Para mais, as condições que determinam qual dessas estruturas é retornada por apply() são levemente confusas. Se estiver curioso, leia a seção Value da documentação interna (?apply).\nA função sapply() também é um outro caso de incosistência, pois essa função altera a estrutura de dados retornada, a depender do comprimento de cada um dos resultados gerados pela função FUN. Isso significa que, a estrutura de dados retornada por sapply() é determinada por um conjunto de resultados aos quais nós não temos acesso enquanto a função não completar a sua execução. Ou seja, nós não somos capazes de prever com antecedência, qual será a estrutura retornada por sapply(). Isso é um problema grave, dado que ele pode gerar bugs em seu script com muita facilidade, caso você não esteja preparado para lidar com literalmente qualquer tipo de resultado possível de sapply().\nSão inconsistências desse tipo, que tornaram as funções map o padrão utilizado pela comunidade na construção de muitos pacotes e funções. Pois as funções map são extremamente consistentes em seus resultados. Por esse mesmo motivo, que as funções lapply() e vapply() são exemplos de funções apply que ainda são muito utilizadas em diversos pacotes e funções existentes na atualidade.\nPois diferente de apply() e sapply(), essas funções são consistentes em seus resultados. A função lapply() é equivalente à função map(), pois ela sempre lhe retorna uma lista como resultado. Já a função vapply() vai sempre retornar um vetor de mesmo tipo de dado que o vetor fornecido ao seu argumento FUN.VALUE. Ou seja, poderíamos reproduzir a função map_dbl() com vapply(), ao fornecermos um vetor do tipo double ao seu argumento FUN.VALUE.\n\nnumeros &lt;- list(\n  c(1.5, 2.5, 3),\n  c(9.8, 1.2),\n  c(1.2, 1.3, 1.5, 1.1)\n)\n\n\nsomas &lt;- vapply(numeros, FUN = sum, FUN.VALUE = double(1))\nprint(somas)\n\n[1]  7.0 11.0  5.1\n\n\nNa verdade, a função vapply() também é capaz de retornar matrizes e arrays. Tudo depende de como você organiza o objeto fornecido ao argumento FUN.VALUE. Isso é um diferencial importante, que nenhuma das funções map são capazes de fazer até o momento.\n\n### Retorna uma matriz\nvapply(numeros, FUN = range, FUN.VALUE = double(2))\n\n     [,1] [,2] [,3]\n[1,]  1.5  1.2  1.1\n[2,]  3.0  9.8  1.5\n\n### Retorna um array\nvapply(numeros, FUN = range, FUN.VALUE = array(double(1), dim = c(1,2,1)))\n\n, , 1, 1\n\n     [,1] [,2]\n[1,]  1.5    3\n\n, , 1, 2\n\n     [,1] [,2]\n[1,]  1.2  9.8\n\n, , 1, 3\n\n     [,1] [,2]\n[1,]  1.1  1.5",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html#identificando-erros-nas-funções-map",
    "href": "Capítulos/18-purrr.html#identificando-erros-nas-funções-map",
    "title": "16  Functional programming com purrr",
    "section": "16.5 Identificando erros nas funções map",
    "text": "16.5 Identificando erros nas funções map\nA cada iteração do loop criado por map, estamos executando a função definida no argumento .f. Isso significa que, em um loop de 10 mil iterações, essa função será chamada 10 mil vezes. Isso é um detalhe importante, pois um erro pode surgir em cada uma dessas 10 mil chamadas. E caso esse erro ocorra, como você faria para identificar a sua fonte? É esse tema que vamos abordar nessa seção.\nVamos utilizar os comandos abaixo como exemplo. Perceba que um erro foi levantado.\n\nvalores &lt;- list(\n  2.5, 5.1, 6.7, 8.9, \"9.1\", 0.2,\n  \"4.4\", \"5.1\", \"7.4\", 3.6, 3.8,\n  4.2, 8.7, 8.8\n)\n\n\nlogaritmos &lt;- valores %&gt;% map_dbl(log)\n\nError in .Primitive(\"log\")(x, base) :\n  non-numeric argument to mathematical function\nA principal dificuldade que temos é identificar onde o erro ocorreu. Isto é, em qual das iterações esse erro ocorreu? Será que ele ocorre logo na primeira iteração do loop? Ou, talvez na última iteração? Ou ainda, ao longo de várias iterações diferentes do loop?\nPara identificar tais pontos, poderíamos ter acesso aos resultados que foram gerados com sucesso, e aos resultados que fracassaram. Para isso, o pacote purrr nos provê a função safely().\nVocê deve aplicar essa função safely() sobre a função .f que você deseja utilizar dentro de map(). Como resultado, safely() gera uma nova versão da função .f, que é capaz de coletar os todos os resultados gerados, mesmo que eles levantem algum erro durante sua execução.\n\nsafe_log &lt;- safely(log)\nsafe_log\n\nfunction (...) \ncapture_error(.f(...), otherwise, quiet)\n&lt;bytecode: 0x63dcbd146788&gt;\n&lt;environment: 0x63dcbd1462f0&gt;\n\n\nO que essa nova versão da função faz, é sempre gerar uma lista com dois elementos (result e error) para cada input. O elemento result vai estar preenchido com o resultado da função caso ele tenha sido gerado com sucesso, enquanto o elemento error, estará vazio. Entretanto, caso algum erro ocorra e o resultado da função não possa ser gerado, o contrário ocorre. Ou seja, o elemento result estará vazio, enquanto o elemento error irá conter o erro que interrompeu a execução.\nNo primeiro exemplo abaixo, o elemento result gerado por safe_log() contém o valor 2.302585, que corresponde ao resultado de log(10). Isso significa que o valor da expressão log(10) pôde ser calculado com sucesso, sem nenhum erro encontrado. Porém, no segundo exemplo abaixo, o elemento result está vazio, enquanto o elemento error contém a mensagem de erro gerada. Logo, o resultado da expressão log(\"a\") não pôde ser calculada com sucesso, pois o erro contido no elemento error foi levantado durante a execução.\n\nsafe_log(10) %&gt;% str()\n\nList of 2\n $ result: num 2.3\n $ error : NULL\n\nsafe_log(\"a\") %&gt;% str()\n\nList of 2\n $ result: NULL\n $ error :List of 2\n  ..$ message: chr \"non-numeric argument to mathematical function\"\n  ..$ call   : language .Primitive(\"log\")(x, base)\n  ..- attr(*, \"class\")= chr [1:3] \"simpleError\" \"error\" \"condition\"\n\n\nAgora, podemos simplesmente fornecer para map() a nova função criada. Repare que dessa vez, eu estou utilizando a função map() ao invés da função map_dbl() para coletar os resultados gerados por safe_log(). Pois a função log() gera um único valor do tipo double para cada input, já a função safe_log(), gera uma lista com dois elementos (result e error) para cada input. Como exemplo, mostro abaixo os resultados para os 3 primeiros elementos. Perceba que nenhum desses elementos levantou algum erro, dado que o elemento error está vazio para todos eles.\n\nlogaritmos &lt;- valores %&gt;% map(safe_log)\nlogaritmos[1:3] %&gt;% \n  str()\n\nList of 3\n $ :List of 2\n  ..$ result: num 0.916\n  ..$ error : NULL\n $ :List of 2\n  ..$ result: num 1.63\n  ..$ error : NULL\n $ :List of 2\n  ..$ result: num 1.9\n  ..$ error : NULL\n\n\nSendo assim, para identificarmos quais elementos de valores são os responsáveis por levantar o erro que vimos anteriormente, podemos navegar por cada elemento de logaritmos, e descobrir em quais deles, o elemento error não está vazio.\n\nerros &lt;- logaritmos %&gt;% map(\"error\")\nerro_nao_vazio &lt;- erros %&gt;% map_lgl(~!is.null(.))\n\nvalores[erro_nao_vazio] %&gt;% \n  str()\n\nList of 4\n $ : chr \"9.1\"\n $ : chr \"4.4\"\n $ : chr \"5.1\"\n $ : chr \"7.4\"\n\n\nRepare acima, que antes de aplicar o teste lógico para saber quais erros estavam vazios, eu precisei extrair primeiro o elemento error de todos os elementos de logaritmos. Como uma alternativa, podemos reorganizar os elementos de logaritmos em duas listas diferentes, uma contendo todos os resultados gerados (result), e outra, contendo todos os erros gerados (error).\nPara isso, basta aplicarmos a função transpose() sobre o objeto logaritmos. Agora, o objeto logaritmos contém dentro dele, uma lista de resultados (result) e uma lista de erros (error).\n\nlogaritmos &lt;- transpose(logaritmos)\nlogaritmos$result[1:3]\n\n[[1]]\n[1] 0.9162907\n\n[[2]]\n[1] 1.629241\n\n[[3]]\n[1] 1.902108\n\nlogaritmos$error[1:3]\n\n[[1]]\nNULL\n\n[[2]]\nNULL\n\n[[3]]\nNULL\n\n\nCom essa estrutura, podemos reproduzir o teste anterior com:\n\nerro_nao_vazio &lt;- map_lgl(logaritmos$error, ~!is.null(.))\n\nvalores[erro_nao_vazio] %&gt;% \n  str()\n\nList of 4\n $ : chr \"9.1\"\n $ : chr \"4.4\"\n $ : chr \"5.1\"\n $ : chr \"7.4\"\n\n\nPortanto, sabemos agora que os elementos \"9.1\", \"4.4\", \"5.1\" e \"7.4\" do objeto valores estão levantando erros quando aplicamos a função log() sobre eles. Com isso, podemos reproduzir o erro ao aplicar a função log() sobre um desses elementos. Dessa forma, podemos analisar caso a caso de forma mais concentrada, e entender o que está gerando o erro.\n\nlog(\"9.1\")\n\nError in log(\"9.1\") : non-numeric argument to mathematical function\nDe qualquer forma, você provavelmente já entendeu qual é o problema. Esses elementos estão sendo interpretados pelo tipo character, ao invés de um tipo numérico como o tipo double. Em outras palavras, a função log() não sabe como calcular o logaritmo de um valor textual (ou uma string), como \"9.1\".\nTendo isso em mente, poderíamos aplicar a função as.double() sobre esses elementos para resolvermos esse problema. Perceba que após realizarmos essa correção, o comando com map_dbl() executa normalmente sem nenhum erro.\n\nvalores[erro_nao_vazio] &lt;- valores[erro_nao_vazio] %&gt;% \n  map(as.double)\n\n### Agora, os comandos abaixo funcionam normalmente\n### sem nenhum erro.\nlogaritmos &lt;- valores %&gt;% map_dbl(log)\nlogaritmos \n\n [1]  0.9162907  1.6292405  1.9021075  2.1860513  2.2082744 -1.6094379\n [7]  1.4816045  1.6292405  2.0014800  1.2809338  1.3350011  1.4350845\n[13]  2.1633230  2.1747517\n\n\nPortanto, a função safely() te oferece um conjunto de informações mais completas sobre cada execução, pois ela te traz exatamente qual foi a mensagem de erro retornada. Porém, em algumas ocasiões, você só quer coletar os resultados gerados.\nPara isso, temos uma outra função irmã mais simplificada, que é a função possibly(). Assim como ocorre com safely(), essa função possibly() recebe uma outra função como input, e retorna como output, uma nova versão da função de input. Assim como ocorre com safely(), a função criada por possibly() vai sempre executar com sucesso, mesmo que um erro seja levantado pela função principal .f.\nPara mais, a função possibly() te permite definir um valor padrão de retorno, caso a execução da função principal .f retorne um erro. Por exemplo, com os comandos abaixo, estou definindo que se a função log() levantar algum erro para um determinado input, ela deve retornar como output o valor NA_real_.\n\nvalores &lt;- list(\n  3.2, 4.4, 5.1, 8.6,\n  \"A\", \"B\", \"C\"\n)\n\nvalores %&gt;% \n  map_dbl(possibly(log, NA_real_))\n\n[1] 1.163151 1.481605 1.629241 2.151762       NA       NA       NA\n\n\nApesar de duas opções bastante úteis, você pode ainda estar interessado em coletar outras informações sobre a execução de cada iteração. Como exemplo, a função quietly() exerce um papel semelhante à safely(), mas, ao invés de coletar erros, essa função busca coletar os resultados, mensagens e avisos gerados em cada iteração, além dos possíveis outputs que são mostrados na tela.\nPerceba no exemplo abaixo, que assim como ocorre com safely() e possibly(), quietly() também nos retorna uma nova versão da função print(). Quando eu aplico essa nova função sobre algum input qualquer, é retornado uma lista com 4 elementos. Como os elementos warnings e messages abaixo estão vazios, isso significa que não houveram avisos ou mensagens acionadas durante a execução da expressão print(8). Para mais, podemos ver através dos itens result e output, o resultado da expressão e, também, qual é o texto apresentado em nosso console quando a expressão print(8) é executada.\n\nquiet_print &lt;- quietly(print)\nquiet_print(8)\n\n$result\n[1] 8\n\n$output\n[1] \"[1] 8\"\n\n$warnings\ncharacter(0)\n\n$messages\ncharacter(0)\n\n\nSendo assim, podemos utilizar a função quietly() em conjunto com map() para coletarmos essas informações sobre a execução de uma função qualquer sobre vários inputs diferentes. Veja no exemplo abaixo, que o segundo input da lista x (-10) gerou um aviso, pois o elemento warnings da segunda lista no resultado não está vazio.\n\nx &lt;- list(5, -10, 15)\nx %&gt;%\n  map(quietly(log)) %&gt;% \n  str()\n\nList of 3\n $ :List of 4\n  ..$ result  : num 1.61\n  ..$ output  : chr \"\"\n  ..$ warnings: chr(0) \n  ..$ messages: chr(0) \n $ :List of 4\n  ..$ result  : num NaN\n  ..$ output  : chr \"\"\n  ..$ warnings: chr \"NaNs produced\"\n  ..$ messages: chr(0) \n $ :List of 4\n  ..$ result  : num 2.71\n  ..$ output  : chr \"\"\n  ..$ warnings: chr(0) \n  ..$ messages: chr(0)",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html#compreendendo-as-funções-map_dfr-e-map_dfc",
    "href": "Capítulos/18-purrr.html#compreendendo-as-funções-map_dfr-e-map_dfc",
    "title": "16  Functional programming com purrr",
    "section": "16.6 Compreendendo as funções map_dfr() e map_dfc()",
    "text": "16.6 Compreendendo as funções map_dfr() e map_dfc()\nNovamente, as funções map_dfc() e map_dfr() realizam exatamente o mesmo trabalho e possuem os mesmos argumentos das demais funções map. Contudo, como você já deve ter pressuposto pelo sufixo df, as funções map_dfc() e map_dfr() retornam como resultado, um data.frame. Porém, essas duas funções constroem esse novo data.frame de maneiras distintas.\nEm primeiro lugar, você pode utilizar as funções map_dfr() e map_dfc(), sempre que um data.frame é gerado a cada iteração do loop criado pela função map. Ou seja, quando aplicamos a função .f sobre um elemento de .x, um data.frame é gerado como resultado. Dito ainda de uma outra forma, a função .f recebe um elemento de .x como input, e gera um novo data.frame como output.\n\n\n\n\n\nmap_dfr() une os data.frame’s gerados, por linha\n\n\n\n\n\n\n\n\n\nmap_dfc() une os data.frame’s gerados, por coluna\n\n\n\n\nPortanto, se você utiliza a função map_df*() sobre um objeto de 50 elementos, é esperado que 50 data.frame’s sejam gerados durante a execução de map_df*(). Após gerar todos esses 50 data.frame’s, a função map_df*() em questão, vai tentar uni-los em um único data.frame. Por fim, a função vai retornar como resultado, esse data.frame único, que contém os resultados de todos os 50 data.frame’s gerados.\nPor isso, a única diferença essencial entre as funções map_dfr() e map_dfc(), está na forma como essas funções vão unir esses 50 data.frame’s gerados. Como você pode observar nas figuras 16.5 e 16.6, map_dfr() une os data.frame’s por linha, enquanto map_dfc(), une por coluna.\nTendo esses pontos em mente, as funções map_dfr() e map_dfc() são particularmente úteis, quando desejamos aplicar uma função sobre cada elemento de um objeto, e armazenar todos os resultados em um data.frame único.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html#sec:demanda_dist_ICMS",
    "href": "Capítulos/18-purrr.html#sec:demanda_dist_ICMS",
    "title": "16  Functional programming com purrr",
    "section": "16.7 Um estudo de caso: uma demanda real sobre a distribuição de ICMS",
    "text": "16.7 Um estudo de caso: uma demanda real sobre a distribuição de ICMS\nNessa seção, vou apresentar um exemplo prático, sobre uma demanda real que chegou até mim em 2020. Na época, eu trabalhava como estagiário na Diretoria de Estatística e Informações da Fundação João Pinheiro (FJP-MG), mais especificamente com uma lei estadual que é tradicionalmente chamada de Lei Robin Hood (Lei 18.030 de 2009 - MG). Essa lei rege a distribuição do ICMS total de Minas Gerais, ao longo dos municípios do estado.\n\n\n\n\n\nLista de arquivos do Excel\n\n\n\n\nEm resumo, o Governo de Minas Gerais, coleta o ICMS (imposto sobre operações relativas à circulação de mercadorias e sobre prestações de serviços de transporte interestadual, intermunicipal e de comunicação) gerado em todo o estado, e ao final de um período, ele redistribui esse valor para os 853 municípios do estado. Cada município, possui um índice de participação, que corresponde à porcentagem do ICMS total ao qual o respectivo município tem direito. Em outras palavras, se o ICMS total gerado no estado em um período foi de 8,5 bilhões de reais, e o município de Belo Horizonte possui um índice de participação equivalente a 0,009, isso significa que ao final do período, 0,9% do ICMS total, ou 76,5 milhões de reais serão transferidos para a prefeitura do município de Belo Horizonte.\nDiversos critérios descritos na lei regem o cálculo deste índice de participação de cada município, sendo alguns deles: Turismo, Esporte, Patrimônio Cultural, População e Receita Própria. Em suma, o índice de participação de cada município, é uma média ponderada dos índices de cada um desses diversos critérios da lei. Você pode encontrar uma descrição completa desses critérios e do cálculo dos índices de participação, no texto original da lei1.\n\n16.7.1 A demanda em si\nA demanda é muito simples, porém, ela é trabalhosa e envolve um volume excessivo de repetição se você optar por utilizar programas como Excel para resolvê-la. Dentre os vários critérios da lei, temos o critério de Meio Ambiente, e o órgão responsável pelo cálculo do índice referente a esse critério, é a SEMAD-MG (Secretaria de Estado de Meio Ambiente e Desenvolvimento Sustentável). Um dia, a SEMAD chegou até nós da Fundação João Pinheiro (FJP), pedindo por todos os valores de ICMS transferidos para cada município, ao longo dos anos de 2018 e 2019, de acordo com o critério do Meio Ambiente da Lei Robin Hood.\nOs funcionários da FJP, calculam e publicam todo mês, os valores transferidos de ICMS separados por cada critério da lei, e para cada município. Ou seja, para o ano de 2019, pense por exemplo, em uma lista de arquivos de Excel parecida com a lista abaixo, onde cada planilha corresponde aos valores de ICMS transferidos em um mês específico do ano.\nDando uma olhada mais de perto, cada uma dessas planilhas do Excel, assumem a estrutura abaixo. Onde cada linha da tabela, representa um município do estado de Minas Gerais, e cada coluna (ou pelo menos, grande parte dessas colunas), representa os valores de ICMS transferidos segundo os índices de um critério específico da lei. Ou seja, a coluna Educação, nos apresenta os valores de ICMS transferidos para cada município do estado, considerando-se o índice que cada um desses municípios adquiriram no critério de Educação, e também, considerando-se a parcela que o critério de Educação representa do total de ICMS distribuído.\n\nlibrary(readxl)\nAbril_2019 &lt;- read_excel(\"./../Dados/planilhas/Abril_2019.xlsx\")\nAbril_2019\n\n# A tibble: 853 × 27\n   IBGE1 IBGE2   SEF Municípios          População População dos 50 + Populoso…¹\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt;                         &lt;dbl&gt;\n1 310010    10     1 ABADIA DOS DOURADOS     8847.                             0\n2 310020    20     2 ABAETÉ                 29470.                             0\n3 310030    30     3 ABRE CAMPO             17087.                             0\n4 310040    40     4 ACAIACA                 5068.                             0\n5 310050    50     5 AÇUCENA                12151.                             0\n# ℹ 848 more rows\n# ℹ abbreviated name: ¹​`População dos 50 + Populosos`\n\n\nPorém, temos dois problemas aqui: 1) A SEMAD precisa apenas dos valores de ICMS transferidos de acordo com o critério de Meio Ambiente, e nada mais; 2) A SEMAD precisa dos valores de ICMS transferidos ao longo de todos os meses dos anos de 2018 e 2019, e se nós temos 12 planilhas por ano, temos que reunir informações de 24 planilhas diferentes para a secretaria.\nPortanto, temos aqui uma típica tarefa extremamente repetitiva e monótona, que ninguém gosta de fazer. Imagine você abrindo na mão, cada uma das 24 planilhas, procurando pela coluna do Meio Ambiente, copiando e colando ela em um novo arquivo contendo apenas os dados de Meio Ambiente, preenchendo colunas de ano e mês para manter a rastreabilidade dos registros, etc. Aqueles com mais experiência no Excel, poderiam argumentar que uma solução mais segura, seria utilizar a plataforma de queries do programa para carregar os dados das 24 planilhas em uma planilha única. Porém, apenas pelo tempo que você levaria para importar cada arquivo e configurar cada querie, seria muito mais rápido se você simplesmente adotasse a estratégia de Crtl+C e Ctrl+V, para transferir todos os dados para uma planilha única.\nAlém disso, tarefas muito repetitivas são, não apenas muito cansativas, mas também, muito error-prone (ou seja, elas elevam muito as suas chances de erros). Esses são dois fatores que podem ser facilmente evitados através do uso de funções e de loop’s no R. Ao construir uma função que define as ações que você deseja aplicar, e um loop que replique essa função para todas as x planilhas, você permite que o seu computador realize o trabalho duro e cansativo por você. Com isso, as suas chances de erro se reduzem muito, e você realiza o mesmo trabalho em menor tempo. Pois os nossos computadores são extremamente rápidos e precisos para realizar todo tipo de cálculo. Afinal, é para isso que eles foram feitos.\n\n\n16.7.2 Planejando os passos\nComo exemplo prático, para formatar os arquivos segundo as necessidades da SEMAD-MG, vou demonstrar as seguintes etapas: 1) importar essas planilhas para o R; 2) adicionar colunas de referência para cada planilha (ano e mês a que os dados se referem); 3) unir todas as planilhas em uma tabela única; 4) selecionar apenas as colunas relevantes para a SEMAD; 5) exportar o resultado para fora do R.\n\n\n16.7.3 Importando as planilhas\nTendo isso em mente, o primeiro passo seria importarmos essas planilhas. Mas, para isso precisamos dos path’s, ou, dos caminhos até esses arquivos. Podemos coletar essa informação, através da função list.files(), a qual pertence aos pacotes básicos do R. Como o próprio nome dá a entender, essa função busca listar os nomes de todos os arquivos contidos em determinada uma pasta. Caso você não defina alguma pasta específica na função (diferente do que fizemos abaixo), list.files() vai listar todos os arquivos presentes no seu diretório de trabalho atual do R.\nNeste exemplo, todas as 12 planilhas já estão separadas dentro de uma pasta de meu computador chamada \"planilhas\". Por isso, forneço abaixo o nome dessa pasta à função list.files(). Como resultado, o objeto caminhos contém o caminho até todas essas planilhas que desejamos importar para dentro do R.\n\ncaminhos &lt;- list.files(\"./../Dados/planilhas/\", full.names = TRUE)\ncaminhos\n\n [1] \"./../Dados/planilhas//Abril_2019.xlsx\"    \n [2] \"./../Dados/planilhas//Agosto_2019.xlsx\"   \n [3] \"./../Dados/planilhas//Dezembro_2019.xlsx\" \n [4] \"./../Dados/planilhas//Fevereiro_2019.xlsx\"\n [5] \"./../Dados/planilhas//Janeiro_2019.xlsx\"  \n [6] \"./../Dados/planilhas//Julho_2019.xlsx\"    \n [7] \"./../Dados/planilhas//Junho_2019.xlsx\"    \n [8] \"./../Dados/planilhas//Maio_2019.xlsx\"     \n [9] \"./../Dados/planilhas//Marco_2019.xlsx\"    \n[10] \"./../Dados/planilhas//Novembro_2019.xlsx\" \n[11] \"./../Dados/planilhas//Outubro_2019.xlsx\"  \n[12] \"./../Dados/planilhas//Setembro_2019.xlsx\" \n\n\nAgora que temos os caminhos até todas essas planilhas, importá-las para dentro do R se torna algo extremamente simples. Podemos simplesmente utilizar a função map() para aplicar uma função (que seja capaz de ler esses arquivos) sobre cada um desses caminhos. Lembre-se que, podemos importar planilhas do Excel para dentro do R, através da função readxl::read_excel() que introduzimos no capítulo 4.\n\nlibrary(readxl)\nlibrary(purrr)\n\nplanilhas &lt;- map(caminhos, read_excel)\nplanilhas[[1]]\n\n# A tibble: 853 × 27\n   IBGE1 IBGE2   SEF Municípios          População População dos 50 + Populoso…¹\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt;                         &lt;dbl&gt;\n1 310010    10     1 ABADIA DOS DOURADOS     8847.                             0\n2 310020    20     2 ABAETÉ                 29470.                             0\n3 310030    30     3 ABRE CAMPO             17087.                             0\n4 310040    40     4 ACAIACA                 5068.                             0\n5 310050    50     5 AÇUCENA                12151.                             0\n# ℹ 848 more rows\n# ℹ abbreviated name: ¹​`População dos 50 + Populosos`\n\n\nAgora, o objeto planilhas é uma lista de 12 elementos. Cada elemento dessa lista, contém um data.frame que corresponde aos dados de uma das 12 planilhas.\n\n\n16.7.4 Conferindo a estrutura dos arquivos\nVamos aproveitar que já importamos as 12 planilhas, para fazermos algumas conferências sobre esses arquivos. Será que todas as planilhas possuem a mesma estrutura (o mesmo número de linhas, as mesmas colunas, os mesmos tipos de dados, etc.) ? Logo abaixo, estamos utilizando a função nrow() para coletarmos os números de linhas de cada tabela, ncol() para o número de colunas, e colnames() para os nomes das colunas. Perceba abaixo, que todas as planilhas possuem o mesmo número de linhas e colunas.\n\nn_linhas &lt;- map_int(planilhas, nrow)\nprint(n_linhas)\n\n [1] 853 853 853 853 853 853 853 853 853 853 853 853\n\nn_colunas &lt;- map_int(planilhas, ncol)\nprint(n_colunas)\n\n [1] 27 27 27 27 27 27 27 27 27 27 27 27\n\n\nPara conferirmos os nomes das colunas temos um pouco mais de trabalho, mas nada que seja muito distante do que foi mostrado até o momento.\n\nnomes_colunas &lt;- map(planilhas, colnames)\nreferencia &lt;- nomes_colunas[[1]]\n\nigual_a_referencia &lt;- vector(\"logical\", length = 12)\nfor(i in seq_along(nomes_colunas)){\n  igual_a_referencia[i] &lt;- all(nomes_colunas[[i]] == referencia)\n}\n\nnames(igual_a_referencia) &lt;- caminhos\nprint(igual_a_referencia)\n\n    ./../Dados/planilhas//Abril_2019.xlsx \n                                     TRUE \n   ./../Dados/planilhas//Agosto_2019.xlsx \n                                     TRUE \n ./../Dados/planilhas//Dezembro_2019.xlsx \n                                    FALSE \n./../Dados/planilhas//Fevereiro_2019.xlsx \n                                     TRUE \n  ./../Dados/planilhas//Janeiro_2019.xlsx \n                                     TRUE \n    ./../Dados/planilhas//Julho_2019.xlsx \n                                     TRUE \n    ./../Dados/planilhas//Junho_2019.xlsx \n                                     TRUE \n     ./../Dados/planilhas//Maio_2019.xlsx \n                                     TRUE \n    ./../Dados/planilhas//Marco_2019.xlsx \n                                     TRUE \n ./../Dados/planilhas//Novembro_2019.xlsx \n                                    FALSE \n  ./../Dados/planilhas//Outubro_2019.xlsx \n                                     TRUE \n ./../Dados/planilhas//Setembro_2019.xlsx \n                                     TRUE \n\n\nPerceba pelo resultado acima, que os arquivos Dezembro_2019.xlsx e Novembro_2019.xlsx possuem alguma divergência no nome de suas colunas. Podemos rapidamente descobrir que colunas são essas com um simples teste lógico e subsetting:\n\n## Coluna diferente no arquivo Dezembro_2019.xlsx\nnomes_colunas[[3]][ !referencia == nomes_colunas[[3]] ]\n\n[1] \"cota minima\"\n\n## Coluna diferente no arquivo Novembro_2019.xlsx\nnomes_colunas[[10]][ !referencia == nomes_colunas[[10]] ]\n\n[1] \"cota minima\"\n\n\nPelos resultados acima, podemos observar que as duas planilhas possuem uma coluna chamada cota minima, a qual não está presente nas demais planilhas. Essa mesma coluna está nomeada como Cota Mínima, nas demais planilhas. Como resultado, caso você estivesse aplicando um loop sobre cada uma das 12 planilhas, e estivesse procurando por uma coluna chamada Cota Mínima em cada uma delas, o R não seria capaz de encontrar essa coluna nos arquivos Dezembro_2019.xlsx e Novembro_2019.xlsx.\nPelo fato de estarmos preocupados com a coluna de Meio Ambiente, essa diferença se torna um pouco irrelevante para nós. Entretanto, caso estivéssemos trabalhando com essa coluna de Cota Mínima em cada planilha, teríamos um grande problema a ser resolvido.\n\n\n16.7.5 Adicionando colunas de referência\nApesar de já termos importado todas as 12 planilhas, temos um grande problema a ser solucionado. Os dados de cada planilha não possuem qualquer coluna ou metadado de referência que indique o período ao qual os dados se referem.\nDito de outra forma, ao olharmos para os dados da primeira planilha, podemos ver os valores monetários de cada município para cada critério. Porém, a que mês esses valores monetários se referem? Dezembro? Janeiro? Março? E de que ano? 2019? ou 2020?\n\nplanilhas[[1]]\n\n# A tibble: 853 × 27\n   IBGE1 IBGE2   SEF Municípios          População População dos 50 + Populoso…¹\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt;                         &lt;dbl&gt;\n1 310010    10     1 ABADIA DOS DOURADOS     8847.                             0\n2 310020    20     2 ABAETÉ                 29470.                             0\n3 310030    30     3 ABRE CAMPO             17087.                             0\n4 310040    40     4 ACAIACA                 5068.                             0\n5 310050    50     5 AÇUCENA                12151.                             0\n# ℹ 848 more rows\n# ℹ abbreviated name: ¹​`População dos 50 + Populosos`\n\n\nSabemos que os dados dessa primeira planilha se referem ao mês de abril de 2019, pois essa informação está incrustada no nome da primeira planilha descrita no objeto caminhos, o qual utilizamos para importar todas as 12 planilhas. Porém, qualquer pessoa que não tenha acesso ao objeto caminhos, não será capaz de identificar tal informação.\nPor isso, seria muito importante adicionarmos colunas de mês e ano em cada uma das 12 planilhas. Para isso, podemos aplicar os comandos abaixo. Pelo fato do mês e do ano de cada planilha estarem definidos nos próprios nomes dos arquivos, os primeiros comandos buscam extrair essas informações a partir do objeto caminhos. Depois disso, utilizamos um for loop para adicionar essas informações a cada uma 12 tabelas.\n\nnomes_arquivos &lt;- basename(caminhos)\n\nmeses &lt;- stringr::str_replace(\n  nomes_arquivos, \"(.*)_(.*)[.]xlsx\", \"\\\\1\"\n)\n\nanos &lt;- stringr::str_replace(\n  nomes_arquivos, \"(.*)_(.*)[.]xlsx\", \"\\\\2\"\n)\n\nanos &lt;- as.integer(anos)\n\n### Um for loop para visitar cada uma das\n### 12 planilhas e adicionar as colunas Ano e Mes:\nfor(i in seq_along(planilhas)){\n  planilhas[[i]] &lt;- planilhas[[i]] %&gt;% \n    mutate(\n      Ano = anos[i],\n      Mes = meses[i]\n    )\n}\n\n### Os dados de Abril de 2019:\nplanilhas[[1]] %&gt;% select(Ano, Mes)\n\n# A tibble: 853 × 2\n    Ano Mes  \n  &lt;int&gt; &lt;chr&gt;\n1  2019 Abril\n2  2019 Abril\n3  2019 Abril\n4  2019 Abril\n5  2019 Abril\n# ℹ 848 more rows\n\n### Os dados de Dezembro de 2019:\nplanilhas[[3]] %&gt;% select(Ano, Mes)\n\n# A tibble: 853 × 2\n    Ano Mes     \n  &lt;int&gt; &lt;chr&gt;   \n1  2019 Dezembro\n2  2019 Dezembro\n3  2019 Dezembro\n4  2019 Dezembro\n5  2019 Dezembro\n# ℹ 848 more rows\n\n\n\n\n16.7.6 Selecionando apenas as colunas relevantes\nAgora que adicionamos as colunas de referência a cada uma das 12 planilhas, podemos nos preocupar em selecionar apenas as colunas relevantes para a SEMAD de cada planilha. Para isso, podemos simplesmente aplicar a função select() que vimos no capítulo 4, sobre cada planilha.\nAqui, podemos nos aproveitar do argumento especial ... da função map(). Lembre-se que map() utiliza esse argumento especial para coletar os argumentos que serão repassados para a função (.f) que estamos aplicando.\n\n\n\n\n\nRelembrando os argumentos de map()\n\n\n\n\nLembre-se também, que os argumentos repassados serão constantes ao longo de todo o loop. Em outras palavras, esses argumentos serão sempre os mesmos em cada chamada da função .f. Logo, quando você digita um comando como map(x, mean, na.rm = TRUE), a função map() vai sempre repassar o argumento na.rm com o valor TRUE em cada chamada à função mean().\nPara compreender como você pode se aproveitar desse argumento, pense em como você aplicaria a função select() sobre apenas 1 das 12 planilhas. Perceba abaixo, que estamos repassando os argumentos Ano, Mes, IBGE1, Municípios e Meio Ambiente à função.\n\nplanilhas[[1]] %&gt;% \n  select(Ano, Mes, IBGE1, Municípios, `Meio Ambiente`)\n\n# A tibble: 853 × 5\n    Ano Mes    IBGE1 Municípios          `Meio Ambiente`\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;                         &lt;dbl&gt;\n1  2019 Abril 310010 ABADIA DOS DOURADOS              0 \n2  2019 Abril 310020 ABAETÉ                           0 \n3  2019 Abril 310030 ABRE CAMPO                   10433.\n4  2019 Abril 310040 ACAIACA                          0 \n5  2019 Abril 310050 AÇUCENA                       7727.\n# ℹ 848 more rows\n\n\nEssas são as colunas que estamos interessados em extrair de cada planilha. Ou seja, queremos sempre repassar esses 5 argumentos à função select(), pois desejamos selecionar sempre essas mesmas colunas de cada planilha. Tendo isso em mente, podemos aplicar o seguinte comando:\n\nplanilhas &lt;- map(\n  planilhas, select,\n  ## Argumentos repassados para select():\n  Ano, Mes, IBGE1, Municípios, `Meio Ambiente`\n)\n\n\n\n16.7.7 Unindo as 12 planilhas em uma só\nTemos agora, uma lista contendo todas as 12 planilhas com apenas as colunas que a SEMAD necessita. Porém, lembre-se que cada planilha, está atualmente separada em um elemento diferente da lista. Nós estabelecemos anteriormente, que o ideal seria reunirmos todas essas 12 tabelas, em uma só.\nPara executarmos esse passo, nós podemos simplesmente aplicar a função bind_rows() (que introduzimos no capítulo 4) sobre a lista planilhas. Se nós temos 12 planilhas diferentes, onde, cada linha de cada planilha representa um dos 853 municípios de Minas Gerais, ao unirmos todas essas tabelas, devemos ter como resultado, uma única tabela contendo 10.236 linhas (\\(853 \\times 12 = 10.236\\)).\n\nresultado &lt;- bind_rows(planilhas)\nresultado\n\n# A tibble: 10,236 × 5\n    Ano Mes    IBGE1 Municípios          `Meio Ambiente`\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;                         &lt;dbl&gt;\n1  2019 Abril 310010 ABADIA DOS DOURADOS              0 \n2  2019 Abril 310020 ABAETÉ                           0 \n3  2019 Abril 310030 ABRE CAMPO                   10433.\n4  2019 Abril 310040 ACAIACA                          0 \n5  2019 Abril 310050 AÇUCENA                       7727.\n# ℹ 10,231 more rows\n\n\nContudo, se você relembrar da função map_dfr() que expomos anteriormente, você pode chegar à conclusão de que poderíamos ter eliminado esse passo, ao utilizarmos essa função map_dfr() para aplicarmos a função select() sobre cada planilha. Pois, como destacamos, a função map_dfr() vai aplicar a função .f sobre cada elemento de .x e, em seguida, vai tentar unir todos os resultados em um único data.frame.\n\n## Todos os resultados já são armazenados\n## em um único data.frame:\nresultado &lt;- map_dfr(\n  planilhas, select,\n  ## Argumentos repassados para select():\n  Ano, Mes, IBGE1, Municípios, `Meio Ambiente`\n)\n\n\n\n16.7.8 Conclusão\nPortanto, uma tarefa que inicialmente seria trabalhosa e extremamente repetitiva em muitos programas comuns (como o Excel), pode ser resolvida no R de maneira fácil e rápida, através do uso das funções map().\nTínhamos como objetivo, reunir os dados presentes em 12 planilhas em uma única tabela, e em seguida, selecionar apenas aquelas colunas que eram de interesse da SEMAD. Se reunirmos todos os comandos que utilizamos no R, temos um script com mais ou menos 30 linhas. Ou seja, com apenas 30 linhas, somos capazes de economizar um tempo e esforço enormes em nosso trabalho.\nA partir daqui, com a tabela única em nossas mãos, nós precisamos apenas exportar essa tabela para fora do R. Algo que pode ser rapidamente realizado através de uma função como a write_csv2(), que introduzimos na seção Exportando dados em arquivos de texto com readr.\n\ncaminhos &lt;- list.files(\"./../Dados/planilhas/\")\nplanilhas &lt;- map(caminhos, planilhas)\n\nnomes_arquivos &lt;- basename(caminhos)\n\nmeses &lt;- stringr::str_replace(\n  nomes_arquivos, \"(.*)_(.*)[.]xlsx\", \"\\\\1\"\n)\n\nanos &lt;- stringr::str_replace(\n  nomes_arquivos, \"(.*)_(.*)[.]xlsx\", \"\\\\2\"\n)\n\nanos &lt;- as.integer(anos)\n\nfor(i in seq_along(planilhas)){\n  planilhas[[i]] &lt;- planilhas[[i]] %&gt;% \n    mutate(\n      Ano = anos[i],\n      Mes = meses[i]\n    )\n}\n\nresultado &lt;- map_dfr(\n  planilhas, select,\n  Ano, Mes, IBGE1, Municípios, `Meio Ambiente`\n)\n\n### Para exportar o resultado:\nreadr::write_csv2(\n  resultado, \"tabela_para_SEMAD.csv\"\n)",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html#iterando-sobre-vários-inputs-simultaneamente",
    "href": "Capítulos/18-purrr.html#iterando-sobre-vários-inputs-simultaneamente",
    "title": "16  Functional programming com purrr",
    "section": "16.8 Iterando sobre vários input’s simultaneamente",
    "text": "16.8 Iterando sobre vários input’s simultaneamente\nA medida em que você vai ganhando familiaridade com a família map de funções, você vai sentir a necessidade de expandir ainda mais as suas funcionalidades. Parte dessa expansão, reside em aplicar o loop implícito sobre um número maior de input’s. Por esse motivo, o pacote purrr também nos oferece as famílias map2 e pmap de funções.\n\n16.8.1 Utilizando dois input’s\nComo o próprio nome dá a entender, a única diferença entre as famílias map e map2, é que as funções map2 recebem 2 objetos (.x e .y) diferentes de input. Ou seja, as funções map2 buscam aplicar a função .f sobre cada elemento de .x e de .y de forma simultânea. Em mais detalhes, cada elemento de .x é repassado como primeiro argumento de .f, enquanto cada elemento de .y é posicionado no segundo argumento de .f.\nVale destacar que o loop (criado pela função map2 em questão) é aplicado de forma paralela sobre os objetos .x e .y. Ou seja, na primeira iteração, serão utilizados os elementos .x[[1]] e .y[[1]], na segunda iteração, os elementos .x[[2]] e .y[[2]], e assim por diante. A Figura 16.5 apresenta tal loop de maneira gráfica:\n\n\n\n\n\n\n\n\nFigura 16.5: Representação da tarefa executada pela função map_dbl()\n\n\n\n\n\nAlém disso, a família map2 também tem um membro para cada estrutura de dado que você deseja retornar. Logo, a função map2() retorna uma lista, map2_chr(), um vetor do tipo character, map2_dfr(), um data.frame, e assim por diante.\nComo exemplo, suponha que você tivesse os dois vetores (x e y) abaixo. Agora, suponha também que você desejasse compilar os menores números possíveis entre esses dois vetores. Ou seja, você deseja encontrar o menor número entre cada elemento de x e y. Você poderia realizar esse trabalho, através das funções map2_int() e min(), como demonstrado abaixo:\n\nx &lt;- c(2L, 6L, 9L)\ny &lt;- c(1L, 7L, 4L)\n\nmap2_int(x, y, min)\n\n[1] 1 6 4\n\n\nÉ importante frisar, que os objetos .x e .y precisam necessariamente ter o mesmo comprimento. Caso você não respeite essa regra, um erro será levantado pela função map2 que você está utilizando.\n\nmap2(1:2, 1:3, sum)\n\n# Error: Mapped vectors must have consistent lengths:\n# * `.x` has length 2\n# * `.y` has length 3\n\n\n16.8.2 Utilizando \\(n\\) input’s\nSe é possível utilizarmos 1 ou 2 input’s diferentes em uma função map, porque não permitirmos também um número arbitrário de input’s ? Esse é exatamente o objetivo que a família pmap de funções busca cumprir.\n\n\n\n\n\n\n\n\nFigura 16.6: Representação da tarefa executada pela função pmap_dbl()\n\n\n\n\n\nAssim como as demais famílias apresentadas até o momento, a família pmap também contém um membro para cada tipo de estrutura de dado que você deseja retornar. Sendo assim, pmap_int() retorna um vetor do tipo integer, enquanto pmap() retorna uma lista, e assim por diante.\nTodavia, enquanto as funções map e map2 podem receber um objeto qualquer em seus primeiros argumentos, uma função pmap recebe necessariamente uma lista (.l) em seu primeiro argumento. Essa lista deve conter todos os input’s sobre os quais você deseja aplicar o loop. Dito de outra forma, cada elemento dessa lista .l corresponde a um input diferente que será utilizado na função .f.\nIsso significa que você deve armazenar todos os input’s (sobre os quais você deseja aplicar a função .f) dentro de uma lista, e, fornecer essa lista à função pmap. Apesar desse detalhe, uma função pmap aplica o loop de forma simultânea sobre todos os input’s (da mesma forma como ocorre com as funções map e map2).\nComo resultado, se você fornece uma lista como list(x, y, z) à função pmap, na primeira iteração serão utilizados os elementos x[[1]], y[[1]] e z[[1]], já na segunda iteração, os elementos x[[2]], y[[2]] e z[[2]], e assim por diante. Esse processo está apresentado na Figura 16.6.\nPerceba também pela Figura 16.6, que os elementos da lista .l são fornecidos como argumentos para a função .f, de acordo com a posição que eles ocupam na lista. Sendo assim, o primeiro elemento da lista .l é fornecido como primeiro argumento de .f, enquanto o segundo elemento, como segundo argumento de .f, e assim por diante.\nA função pmap realiza essa correspondência por posição sempre que você não dá um nome específico para cada elemento da lista. Como exemplo, a função rnorm() possui 3 argumentos (n, mean e sd). Caso eu nomeie os elementos da lista .l de acordo com esses 3 argumentos, eu posso reorganizar esses input’s dentro da lista .l da maneira que eu bem entender. Pois nesse caso, a função pmap em questão, vai conectar cada argumento da função aos nomes dos elementos da lista .l.\nComo exemplo, repare abaixo, que o primeiro elemento da lista args foi corretamente associado ao argumento mean, mesmo que esse argumento não seja o primeiro argumento da função rnorm().\n\nset.seed(1)\nargs &lt;- list(\n  mean = c(15, 50, 500), n = c(2, 3, 5), sd = c(1, 1, 5)\n)\n\npmap(args, rnorm)\n\n[[1]]\n[1] 14.37355 15.18364\n\n[[2]]\n[1] 49.16437 51.59528 50.32951\n\n[[3]]\n[1] 495.8977 502.4371 503.6916 502.8789 498.4731\n\n\nPelo fato de um data.frame ser essencialmente, uma lista nomeada que contém elementos de mesmo comprimento, podemos armazenar tranquilamente os nossos input’s em um data.frame, e fornecê-lo à função pmap.\n\nset.seed(1)\nargs &lt;- data.frame(\n  mean = c(15, 50, 500), \n  n = c(2, 3, 5),\n  sd = c(1, 1, 5)\n)\n\npmap(args, rnorm)\n\n[[1]]\n[1] 14.37355 15.18364\n\n[[2]]\n[1] 49.16437 51.59528 50.32951\n\n[[3]]\n[1] 495.8977 502.4371 503.6916 502.8789 498.4731\n\n\nUm outro detalhe, é que assim como todas as funções map e map2 que vimos até o momento, pmap também possui o argumento especial ... para repassar argumentos específicos para a função .f. Logo, todo argumento que você fornecer após o (ou à direita do) argumento .f, são argumentos que serão sempre repassados à função .f em cada iteração do loop. No exemplo abaixo, estamos repassando os argumentos na.rm = TRUE e names = TRUE em todas as chamadas à função quantile().\n\nargs &lt;- data.frame(\n  probs = c(0.25, 0.5, 0.75)\n)\n\ndists &lt;- list(\n  c(NA, 2.5, 8.1, 3.9),\n  c(42.2, NA, 93.2, 35.1),\n  c(0.9, 27.1, 5.3, NA)\n)\n\nargs$x &lt;- dists\n\n\npmap(args, quantile, na.rm = TRUE, names = TRUE)\n\n[[1]]\n25% \n3.2 \n\n[[2]]\n 50% \n42.2 \n\n[[3]]\n 75% \n16.2",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html#a-família-walk",
    "href": "Capítulos/18-purrr.html#a-família-walk",
    "title": "16  Functional programming com purrr",
    "section": "16.9 A família walk()",
    "text": "16.9 A família walk()\nO pacote purrr, também nos oferece a família walk de funções, a qual é composta por apenas três membros: walk(), walk2() e pwalk(). Em resumo, as funções walk funcionam da mesma maneira que as funções map, contudo, elas não retornam, por padrão, algum resultado para o usuário.\nEm mais detalhes, as funções walk constroem o loop implícito e aplicam a função .f sobre cada elemento dos objetos de input. Porém, essas funções não coletam os resultados gerados pela função .f a cada iteração, até porque, uma função walk tem como pressuposto, que a função .f não retorna nenhum resultado.\nPor esse motivo, você geralmente utiliza a família walk, quando você deseja aplicar o mesmo loop implícito da família map, mas não está preocupado em coletar os resultados gerados. Ou ainda, quando a função .f que você deseja aplicar, não retorna um resultado por padrão, e sim, imprime alguma informação em seu console, ou altera objetos, configurações e environments presentes em sua sessão. No exemplo abaixo, estou aplicando a função print() sobre cada elemento de l.\n\nl &lt;- list(1, 2, 3, 4)\n\nwalk(l, print)\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n\n\nComo você já deve ter inferido, a função walk() aceita um objeto (.x) de input e uma função .f, enquanto a função walk2() aceita dois objetos (.x e .y) de input e uma função .f. Já a função pwalk() aceita uma lista (.l) contendo \\(n\\) objetos de input, além de uma função .f. Assim como as demais funções que vimos ao longo desse capítulo, essas três funções também possuem o argumento especial ..., com o qual podemos repassar argumentos para a função .f em todas as chamadas executadas.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html#agregando-resultados-com-reduce",
    "href": "Capítulos/18-purrr.html#agregando-resultados-com-reduce",
    "title": "16  Functional programming com purrr",
    "section": "16.10 Agregando resultados com reduce()",
    "text": "16.10 Agregando resultados com reduce()\nEm algumas ocasiões, você tem uma lista complexa que você deseja reduzir para uma lista mais simples (WICKHAM; GROLEMUND, 2017). É em momentos como esse, que as funções Reduce() e purrr::reduce() se tornam extremamente úteis. Ambas as funções realizam exatamente o mesmo trabalho. A diferença entre elas, é que a função Reduce() pertence aos pacotes básicos do R, enquanto reduce() advém do pacote purrr.\n\n\n\n\n\n\n\n\nFigura 16.7: Representação da combinação executada por reduce()\n\n\n\n\n\nVocê possivelmente já conhece o termo reduce, especialmente se você já trabalhou com alguma outra linguagem de programação focada no paradigma FP. Mas esse termo também é muito associado ao modelo MapReduce que é comumente utilizado em ferramentas para processamento de BigData.\nEm resumo, reduce() busca combinar todos os elementos de um objeto em um único valor. Ou seja, de certa forma, essa função reduce() calcula uma “agregação” dos elementos de um objeto. Esse processo combinatório de reduce() é uma operação bastante comum em diversos tipos de computação. Por isso, várias linguagens de programação oferecem uma função parecida com reduce(). Um exemplo é o método functools.reduce() da linguagem Python.\nA forma como reduce() conduz essa combinação é na realidade, bastante simples. Considerando um objeto que possua 4 elementos como exemplo, reduce() vai primeiro, aplicar a função .f sobre os elementos 1 e 2, produzindo o resultado r1; em seguida, ela aplica novamente a função .f sobre o resultado anterior (r1) e o elemento 3, produzindo assim, o resultado r2; em seguida, ela aplica a função .f sobre o resultado anterior (r2), e o elemento 4, produzindo assim, o resultado final r3, que contém dentro de si, um resumo de todos os 4 elementos do objeto. Descrevendo de outra forma, o resultado de uma expressão como reduce(1:4, f) seria f(f(f(1, 2), 3), 4). Tal processo de combinação está apresentado de maneira gráfica na Figura 16.7.\nUm dos exemplos mais clássicos de uso da função reduce() ao longo de várias linguagens de programação, seria o cálculo de uma soma vetorizada. Ou seja, através da função reduce() conseguimos reproduzir a mesma funcionalidade da função sum(). No exemplo abaixo, a função reduce() está calculando o valor da expressão (((1+2)+3)+4)+5, que é basicamente o mesmo cálculo de sum(1:5).\n\nreduce(1:5, `+`)\n\n[1] 15\n\n## O mesmo cálculo:\nsum(1:5)\n\n[1] 15\n\n\nCom esse exemplo em mente, podemos expandi-lo com facilidade para as demais operações aritméticas, como multiplicação, potência e divisão:\n\n## Multiplicação:\nreduce(1:5, `*`)\n\n[1] 120\n\n## Divisão:\nreduce(1:5, `/`)\n\n[1] 0.008333333\n\n## Potência:\nreduce(1:5, `^`)\n\n[1] 1\n\n\nUm outro exemplo em que reduce() se torna extremamente útil, seria quando desejamos unir vários data.frame’s através de join’s (os quais apresentamos no capítulo 6). Fica meio chato, escrevermos vários join’s separados para unirmos todas essas tabelas, e a função reduce() oferece uma maneira elegante e eficiente de resumirmos essa operação.\n\ndias &lt;- data.frame(\n  dia = seq.Date(as.Date(\"2021-12-01\"), as.Date(\"2021-12-10\"), by = \"1 day\")\n)\n\nsavassi &lt;- data.frame(\n  dia = c(as.Date(\"2021-12-01\"), as.Date(\"2021-12-03\"), as.Date(\"2021-12-05\")),\n  vendas_savassi = c(1200, 4500, 3400)\n)\n\n\ncentro &lt;- data.frame(\n  dia = c(\n    as.Date(\"2021-12-02\"), as.Date(\"2021-12-03\"), as.Date(\"2021-12-04\"),\n    as.Date(\"2021-12-05\"), as.Date(\"2021-12-07\"), as.Date(\"2021-12-10\")\n  ),\n  vendas_centro = c(2400, 3600, 3100, 1400, 1500, 2700)\n)\n\n\nbarreiro &lt;- data.frame(\n  dia = c(\n    as.Date(\"2021-12-07\"), as.Date(\"2021-12-08\"), as.Date(\"2021-12-09\")\n  ),\n  vendas_barreiro = c(5400, 4500, 8700)\n)\n\n### Unindo todas essas tabelas através de um FULL JOIN:\nreduce(list(dias, savassi, centro, barreiro), full_join, by = \"dia\")\n\n          dia vendas_savassi vendas_centro vendas_barreiro\n1  2021-12-01           1200            NA              NA\n2  2021-12-02             NA          2400              NA\n3  2021-12-03           4500          3600              NA\n4  2021-12-04             NA          3100              NA\n5  2021-12-05           3400          1400              NA\n6  2021-12-06             NA            NA              NA\n7  2021-12-07             NA          1500            5400\n8  2021-12-08             NA            NA            4500\n9  2021-12-09             NA            NA            8700\n10 2021-12-10             NA          2700              NA\n\n\nApesar da praticidade de reduce(), é importante que você conheça muito bem a operação que você está aplicando sobre os elementos. Pois a depender da forma como essa operação é realizada, a direção do processo combinatório realizado por reduce() pode te levar a diferentes resultados.\nComo um primeiro exemplo, quando aplicamos o operador de potenciação (^) sobre o vetor 1:4, o resultado gerado por reduce() é de 1. Pois a função calculou o valor da expressão (((1^2)^3)^4). Ou seja, estamos elevando repetidamente 1 a um determinado número, e 1 elevado a qualquer coisa é sempre igual a 1.\n\nreduce(1:4, `^`)\n\n[1] 1\n\n\nSe invertermos a ordem da combinação (através do argumento .dir), o mesmo resultado é retornado. Pois dessa forma, reduce() está calculando o valor da expressão (1^(2^(3^4))). Ou seja, no fim das contas, ainda estamos elevando 1 a um número gigantesco.\n\nreduce(1:4, `^`, .dir = \"backward\")\n\n[1] 1\n\n\nEntretanto, não se engane por esse caso especial, ou por essa exceção à regra. Pois o resultado da operação de potenciação depende sim da ordem em que os elementos são combinados. Podemos enxergar isso, ao retirarmos o número 1 dessa expressão. Portanto, as expressões ((2^3)^4) e (2^(3^4)), calculadas abaixo por reduce(), geram resultados diferentes, pois elas resultam em \\(8^4\\) e \\(2^{81}\\) (respectivamente).\n\nreduce(2:4, `^`)\n\n[1] 4096\n\nreduce(2:4, `^`, .dir = \"backward\")\n\n[1] 2.417852e+24\n\n\nComo um segundo exemplo, perceba que a estrutura das listas a e b abaixo são diferentes, mesmo que ambas tenham sido construídas com base no mesmo objeto (1:4) e função (list).\n\na &lt;- reduce(1:4, list)\nb &lt;- reduce(1:4, list, .dir = \"backward\")\n\nstr(a)\n\nList of 2\n $ :List of 2\n  ..$ :List of 2\n  .. ..$ : int 1\n  .. ..$ : int 2\n  ..$ : int 3\n $ : int 4\n\nstr(b)\n\nList of 2\n $ : int 1\n $ :List of 2\n  ..$ : int 2\n  ..$ :List of 2\n  .. ..$ : int 3\n  .. ..$ : int 4\n\n\nSendo assim, a depender da função que você está aplicando através de reduce(), você terá que inverter a ordem da combinação através do argumento .dir, para chegar ao resultado que você deseja.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html#acumulando-resultados-com-accumulate",
    "href": "Capítulos/18-purrr.html#acumulando-resultados-com-accumulate",
    "title": "16  Functional programming com purrr",
    "section": "16.11 Acumulando resultados com accumulate()",
    "text": "16.11 Acumulando resultados com accumulate()\nSe podemos combinar os diversos resultados gerados para produzir um único valor, também podemos “acumular” esses resultados, através da função accumulate(). Esse processo é um pouco diferente, pois, ao invés de produzir um único valor, ele acaba produzindo um novo objeto de mesmo comprimento que o objeto de input. Contudo, esse processo ainda herda parte da metodologia combinatória empregada por reduce().\nComo exemplo, quando utilizamos accumulate() para aplicar o operador de soma (+) sobre o vetor 1:4, o resultado é a soma acumulada do vetor. Ou seja, a expressão abaixo é equivalente à expressão cumsum(1:4).\n\naccumulate(1:4, `+`)\n\n[1]  1  3  6 10\n\n\nCom esse exemplo, podemos entender um pouco melhor o que accumulate() faz. Em resumo, accumulate() aplica o mesmo processo combinatório de reduce(), porém, ele armazena cada resultado gerado ao longo do processo. A Figura 16.8 traz uma representação do processo executado por accumulate().\nPerceba nessa figura, que para retornar um novo objeto de mesmo comprimento que o objeto de input, accumulate() precisa gerar um resultado para cada elemento deste objeto. Devido a essa regra, na primeira iteração, accumulate() precisa aplicar a função .f somente sobre o primeiro elemento do objeto de input, para nas próximas iterações, aplicar a função .f em pares.\n\n\n\n\n\n\n\n\nFigura 16.8: Representação da tarefa executada por accumulate()\n\n\n\n\n\nCaso accumulate() não fizesse esse passo na primeira iteração, a função nos retornaria um novo objeto de \\(n-1\\) elementos, para um objeto de input de \\(n\\) elementos. O que desrespeitaria a regra de mesmo comprimento entre o input e output da função.\nDescrevendo ainda de uma outra forma, a expressão accumulate(1:4, f) resulta em um vetor de 4 elementos, onde o primeiro elemento contém o resultado de f(1); o segundo elemento, de f(f(1),2); o terceiro elemento, de f(f(f(1),2),3); e o quarto elemento, de f(f(f(f(1),2),3),4).\nAssim como ocorre em reduce(), accumulate() também possui um argumento .dir que define a direção do processo combinatório. Ao invertermos a ordem desse processo, os 4 elementos do vetor resultante da expressão accumulate(1:4, f) conteriam os resultados das expressões f(f(f(f(4),3),2),1), f(f(f(4),3),2), f(f(4),3) e f(4), respectivamente.\n\naccumulate(1:4, `+`, .dir = \"backward\")\n\n[1] 10  9  7  4\n\n\n\n\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/18-purrr.html#footnotes",
    "href": "Capítulos/18-purrr.html#footnotes",
    "title": "16  Functional programming com purrr",
    "section": "",
    "text": "https://www.almg.gov.br/consulte/legislacao/completa/completa-nova-min.html?tipo=LEI&num=18030&comp=&ano=2009&texto=original↩︎",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>*Functional programming* com `purrr`</span>"
    ]
  },
  {
    "objectID": "Capítulos/15-debugging.html",
    "href": "Capítulos/15-debugging.html",
    "title": "17  Debugging - Resolvendo bugs em suas funções",
    "section": "",
    "text": "17.1 Introduzindo debugging\nEm nosso dia-a-dia, desenvolvemos vários scripts e funções no R, com o objetivo de formar um programa que executa uma tarefa específica. Temos uma sensação de conquista quando conseguimos desenvolver esse programa, e estamos ansiosos para testá-lo pela primeira vez. Criamos a expectativa de que o programa funcione perfeitamente bem, gerando todos os resultados esperados. Porém, no mundo real, quando executamos pela primeira vez o nosso programa, o que ocorre na maioria das vezes são vários erros distintos.\nEssa é uma situação extremamente comum, que ocorre em qualquer linguagem de programação, e que atinge desde os mais novatos até os mais experientes programadores. Quanto mais experiência você possui em uma determinada linguagem, menor tendem a ser as suas taxas de erros. Contudo, essas taxas nunca chegam efetivamente a zero.\nPois é sempre muito fácil de se esquecer de uma vírgula aqui ou ali, de fechar um parêntese ou chave, ou ainda, de se certificar que os seus objetos estejam corretamente definidos. Além desses fatos, computadores são extremamente precisos, e, por esse motivo, conseguem perceber facilmente quando algo está fora do lugar.\nSendo assim, um erro é a forma que seu computador tem de te indicar que há algo de errado em seu programa. Logo, em alguma parte desse programa, você pode não ter sido claro o suficiente com suas intenções, ou ainda, você pode ter tentado fazer algo que não é possível de ser feito.\nO termo debugging se refere ao ato de analisar, identificar e corrigir as fontes desses erros em nossos programas. Já o termo bug é o nome dado à um erro qualquer em seu programa. Logo, o seu programa pode ter um ou vários bugs (ou erros) diferentes. O seu trabalho é analisar cada um desses bugs e corrigi-los. Nas próximas seções vamos descrever algumas estratégias de debugging.\nÉ comum certos bugs estarem relacionados entre si, de modo que, quando você identifica e corrige um deles, todos os demais bugs são automaticamente solucionados. Porém, uma parte considerável dos bugs podem ser independentes entre si. Nessa situação, você é obrigado a identificar e corrigir individualmente cada um deles.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>*Debugging* - Resolvendo *bugs* em suas funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/15-debugging.html#tente-sempre-melhorar-a-organização-de-seu-programa",
    "href": "Capítulos/15-debugging.html#tente-sempre-melhorar-a-organização-de-seu-programa",
    "title": "17  Debugging - Resolvendo bugs em suas funções",
    "section": "17.2 Tente sempre melhorar a organização de seu programa",
    "text": "17.2 Tente sempre melhorar a organização de seu programa\nBugs são sempre muito difíceis de se evitar. Especialmente quando estamos construindo um programa relativamente grande e complexo. Mesmo assim, temos sempre a oportunidade de adotarmos pequenas ações que nos ajudam a identificar e resolver esses bugs no futuro.\nUma dessas ações é sempre se preocupar com a organização de seu programa. Um programa (ou um script) é melhor organizado quando ele é repartido em várias funções pequenas. Cada função pequena executa uma única tarefa e, tenta incluir apenas os comandos mínimos para executar essa tarefa.\nDessa forma, você tem uma chance muito maior de compreender por completo, como o seu programa funciona e, mais importante ainda, você tem uma facilidade muito maior de identificar onde os erros de seu programa estão localizados.\nVamos para um exemplo prático. David Brahm e Greg Snow construíram um pacote no R, chamado sudoku, o qual é capaz de resolver jogos de sudoku. A função playSudoku() é a principal função desse pacote. Você fornece a ela uma matriz contendo os valores iniciais de seu jogo e, como resultado, a função vai resolver esse jogo para você.\nPorém, perceba no exemplo abaixo, que um erro foi retornado ao fornecer o meu jogo à função.\n\nlibrary(sudoku)\n\nplaySudoku(\n  z = matrix(sample(0:9, size = 9, replace = TRUE))\n)\n\nSolving...Error in z[i, j] : subscript out of bounds\nAo pesquisar pelo erro no Google, você pode chegar a um artigo útil do StackOverflow1. Esse artigo descreve que o erro subscript out of bounds ocorre sempre que tentamos acessar um elemento que está fora dos limites de um objeto (em outras palavras, um elemento que não existe nesse objeto). Por exemplo, quando tentamos acessar o 5° elemento de um vetor que possui apenas 4 elementos, ou a 5° coluna de um data.frame que possui apenas 3 colunas, e assim por diante.\nApesar dessa informação ser útil, ainda temos uma questão fundamental para identificar e corrigir esse erro, que é onde ele ocorre. Onde? Em que função? Em que parte específica da função estamos tentando acessar um elemento que está fora dos limites?\nComo primeiro instinto, você talvez tente compreender o código-fonte da função playSudoku() com o comando sudoku::playSudoku. Porém, você vai rapidamente perceber o quão grande é essa função playSudoku(). Temos uma quantidade enorme de comandos sendo executados dentro dela, e, cada um desses vários comandos podem ser a fonte de nosso erro.\nAo traçar o traceback que levou ao erro, como demonstrado abaixo, você pode identificar que o erro na verdade surgiu dentro da função solveSudoku(), que é executada pela função playSudoku().\n\ntraceback()\n\n## 2: solveSudoku(z, print.it = FALSE)\n## 1: sudoku::playSudoku(z = matrix(sample(0:9, size = 9, replace = TRUE)))\nApesar de útil, essa nova informação também não é de grande ajuda. Pois ao observar o código-fonte da função solveSudoku() com o comando sudoku::solveSudoku, você percebe que essa função também é muito grande! Temos novamente várias possibilidades para a fonte de nosso erro.\nVocê já sabe que o nosso erro geralmente ocorre quando estamos tentando acessar um elemento de um objeto, ou seja, quando estamos utilizando subsetting sobre um objeto. Tendo isso em mente, você talvez pense em procurar no código-fonte de solveSudoku(), por todas as partes em que as funções de subsetting ([ e [[) são utilizadas. Pois essas partes são as potenciais fontes do erro.\nContudo, temos uma nova frustração. Pois existem em torno de 35 chamadas diferentes à essas funções no código-fonte de solveSudoku(). Em qual dessas 35 chamadas, o nosso erro ocorre?\nConcluindo, o problema principal destacado aqui, é que as funções playSudoku() e solveSudoku() são muito grandes. Elas tentam abarcar sozinhas uma parte substancial do programa, e, como consequência disso, temos uma dificuldade muito maior de identificarmos as origens de nossos erros. O ideal, seria que cada etapa fosse quebrada em múltiplas funções pequenas.\nPois se um erro surgir dentro de uma função pequena, você tem um conjunto muito menor de comandos para analisar. Em outras palavras, você tem menos possibilidades para a fonte de seu erro.\nPor outro lado, quando os seus erros surgem dentro de uma função muito grande, cada um dos vários e vários comandos que essa função executa são candidatos para a origem do seu erro. Logo, você tem o trabalho de analisar um conjunto muito maior de possibilidades.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>*Debugging* - Resolvendo *bugs* em suas funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/15-debugging.html#uma-boa-estratégia-de-debugging",
    "href": "Capítulos/15-debugging.html#uma-boa-estratégia-de-debugging",
    "title": "17  Debugging - Resolvendo bugs em suas funções",
    "section": "17.3 Uma boa estratégia de debugging",
    "text": "17.3 Uma boa estratégia de debugging\nSegundo WICKHAM (2015a), encontrar a causa raiz de um bug é sempre um processo desafiador. Por isso, ter uma boa estratégia de debugging é sempre uma boa ajuda nesse processo. O autor dita 4 passos essenciais nessa estratégia, que são:\n\nGoogle: sempre que encontrar um erro, tente primeiro pesquisar por ele no Google. Pois outras pessoas podem ter enfrentado esse mesmo erro anteriormente, e, publicado a solução na internet;\nMonte um exemplo reprodutível do erro: para analisar e compreender esse erro, você terá que executar várias vezes o mesmo código que gera esse erro. Para que esse processo seja o mais rápido possível, vale a pena investir um tempo organizando um exemplo mínimo e simples que reproduza esse erro.\nDescubra de onde esse erro está surgindo: compreender e analisar um determinado erro, se torna uma atividade muito mais fácil quando você sabe de onde exatamente esse erro está surgindo;\nConserte o erro e realize testes para confirmar que ele foi solucionado: depois de compreender como o erro acontece, e, aplicar uma solução para esse erro, é importante que você teste novamente o seu código, para se certificar que o erro foi de fato solucionado;",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>*Debugging* - Resolvendo *bugs* em suas funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/15-debugging.html#compreendendo-tracebacks",
    "href": "Capítulos/15-debugging.html#compreendendo-tracebacks",
    "title": "17  Debugging - Resolvendo bugs em suas funções",
    "section": "17.4 Compreendendo tracebacks",
    "text": "17.4 Compreendendo tracebacks\nUm traceback representa a sequência de funções executadas que geraram um determinado erro. Sendo assim, um traceback nos mostra justamente quais foram as funções executadas antes do erro surgir. Essa informação é extremamente útil quando desejamos localizar onde exatamente o erro ocorre.\nComo exemplo, a função infos_compras() exposta abaixo executa dentro dela outras 2 funções chamadas buscar_compras() e extrair_cpfs(). Perceba também que, ao executarmos essa função, um erro é retornado pela expressão compras$info.\n\nlibrary(readr)\nlibrary(dplyr)\nbuscar_compras &lt;- function(){\n  github &lt;- \"https://raw.githubusercontent.com/\"\n  pasta &lt;- \"pedropark99/Curso-R/master/Dados/\"\n  arquivo &lt;- \"compras.txt\"\n  \n  texto &lt;- readr::read_file(paste0(github, pasta, arquivo))\n  texto &lt;- unlist(stringr::str_split(texto, \"\\n\"))\n  return(texto)\n}\n\nextrair_cpfs &lt;- function(texto){\n  pcpf &lt;- \"([0-9]{3}[.][0-9]{3}[.][0-9]{3}[-][0-9]{2})\"\n  cpfs &lt;- gsub(paste0(\"(.*)\", pcpf, \"(.*)\"), \"\\\\2\", texto)\n  return(cpfs)\n}\n\n\ninfos_compras &lt;- function(){\n  compras &lt;- buscar_compras()\n  compras$cpfs &lt;- extrair_cpfs(compras$info)\n  \n  return(compras)\n}\n\n\ninfos_compras()\n\n## Error in compras$info : $ operator is invalid for atomic vectors \nPara identificarmos qual a função onde essa expressão compras$info foi executada, podemos olhar para o traceback desse erro. Para acessarmos esse traceback, precisamos apenas executar a função traceback() como demonstrado abaixo.\n\ntraceback()\n\n## 4: is.factor(x)\n## 3: gsub(paste0(\"(.*)\", pcpf, \"(.*)\"), \"\\\\2\", texto) at #3\n## 2: extrair_cpfs(compras$info) at #3\n## 1: infos_compras()\nComo você pode ver acima, a expressão que levantou o erro (compras$info) foi executada dentro da função is.factor(), que por sua vez, foi executada dentro da função gsub(), e, assim por diante. Portanto, a ordem (ou a sequência) de funções executadas antes que o erro fosse levantado foi infos_compras() \\(\\rightarrow\\) extrair_cpfs() \\(\\rightarrow\\) gsub() \\(\\rightarrow\\) is.factor().\nSe você está trabalhando dentro do RStudio, você também pode acessar o traceback de um erro, ao apertar o botão “Show Traceback”, que aparece à direita de todo erro que surge no console. Esse botão está destacado na Figura 17.1.\n\n\n\n\n\n\n\n\nFigura 17.1: Botão de Traceback do RStudio",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>*Debugging* - Resolvendo *bugs* em suas funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/15-debugging.html#o-método-print-ou-print-debugging",
    "href": "Capítulos/15-debugging.html#o-método-print-ou-print-debugging",
    "title": "17  Debugging - Resolvendo bugs em suas funções",
    "section": "17.5 O método print() ou print debugging",
    "text": "17.5 O método print() ou print debugging\nUma das grandes dificuldades que emergem das funções, é que elas executam as suas tarefas em um ambiente separado do seu. Por causa disso, você não consegue visualizar com facilidade todos os resultados e objetos que estão sendo gerados dentro dessa função. Como consequência, a sua investigação de erros fica comprometida.\nPara solucionar esse problema, vários programadores costumam recorrer ao método print(), ou, como é mais conhecido dentro da comunidade de programação, print debugging.\nCom o traceback que mostramos na seção anterior, nós já descobrimos que o erro surge a partir da função infos_compras(), pois a sequência de funções executadas começa por essa função. Tendo isso em mente, um bom próximo passo seria analisarmos se todas as nossas condições ou pressupostos estão sendo respeitados dentro dessa função. Pois se um erro surgiu dessa função, é provável que ela não soube lidar com algo que está fora dessas condições e pressupostos.\nUma das formas mais simples e eficazes de se realizar essa análise, é imprimir ou mostrar informações em seu console que confirmam que esses pressupostos foram respeitados. Para isso, podemos utilizar funções como print() ou cat().\nPortanto, a técnica print debugging consiste em inserir expressões de print() em partes chaves de seu código. Especialmente dentro de funções e loops, que são as partes em que você possui menor visibilidade. Dessa forma, vamos nos certificando aos poucos, que todos os objetos importantes estão sendo criados, e que eles são interpretados pelos tipos de dados corretos (ou esperados).\nVários tipos de erros surgem porque uma condição lógica não está funcionando da forma como você esperava, ou, porque um objeto importante não foi definido, ou ainda, porque um valor NA surge em uma parte inesperada de seu programa, ou mais, porque você esperava que um objeto fosse associado ao tipo de dado A, quando na verdade, ele acaba sendo associado ao tipo de dado B.\nDois objetos principais (compras e cpfs) são criados dentro da função infos_compras(). Geralmente, estamos sempre interessados em identificar duas informações principais sobre um determinado objeto, que é a sua estrutura e o tipo de dado associado a ele.\nCom o comando print(str(objeto)) podemos identificar essas duas informações de uma vez só. Porém, o resultado de str() pode ser muito grande a depender do objeto, por isso, para visualizar rapidamente a estrutura do objeto, eu costumo olhar apenas os 5 primeiros elementos do objeto, com print(objeto[1:5]), já, para o tipo de dado, eu busco o resultado da função typeof(), com print(typeof(objeto)).\nComo exemplo inicial, vamos inserir esses dois comandos de print dentro do corpo da função infos_compras() para analisarmos o objeto compras mais de perto. Perceba que estou redefinindo (ou recriando) a função infos_compras() para adicionar esses comandos de print dentro dela. Em seguida, executo novamente a função para visualizarmos as novas informações.\n\ninfos_compras &lt;- function(){\n  compras &lt;- buscar_compras()\n  cat(\"Primeiros elementos:\\n\")\n  print(compras[1:5])\n  cat(\"Tipo de dado:\\n\")\n  print(typeof(compras))\n  compras$cpfs &lt;- extrair_cpfs(compras$info)\n  \n  return(compras)\n}\n\ndados &lt;- infos_compras()\n\n## Primeiros elementos:\n## [1] \"\\\"Márcio390.287.917-210akqzS2tk$URMcLOk5Q\\\"\"    \n## [2] \"\\\"Igor944.236.416-254tLo8&S9WtXg05fsdU\\\"\"       \n## [3] \"\\\"Márcio395.304.955-57pfwji9Z4Q6dZxSWZV7#7Z$J\\\"\"\n## [4] \"\\\"Isabela322.900.842-74K5D6b$xAnY&QJ1$XQzE2f\\\"\" \n## [5] \"\\\"Álvaro475.767.740-583WWonElfbisKD1GiIVS\\\"\"    \n## Tipo de dado:\n## [1] \"character\"\n## Error in compras$info : $ operator is invalid for atomic vectors\nO erro permanece, mas agora, mostramos algumas informações relevantes sobre o objeto compras. Perceba que este objeto é um vetor do tipo character. Ao extrair essa informação, você é capaz de compreender o porquê do erro estar acontecendo. Pois o objeto compras é um vetor atômico, e, a mensagem de erro fala bem claramente que o operador $ é invalido para este tipo de objeto.\nTendo identificado o porquê do erro, temos agora a capacidade de solucionar esse erro. Podemos por exemplo, transformar o objeto compras em um data.frame, e incluir o resultado de buscar_compras() em uma coluna chamada info. Pois o operador $ é válido para data.frame’s. Repare abaixo que, após essas alterações, a função infos_compras() foi executada sem erros.\n\ninfos_compras &lt;- function(){\n  compras &lt;- data.frame(\n    info = buscar_compras()\n  )\n  compras$cpfs &lt;- extrair_cpfs(compras$info)\n  \n  return(compras)\n}\n\ndados &lt;- infos_compras()\nhead(dados)\n\n##                                            info           cpfs\n## 1     \"Márcio390.287.917-210akqzS2tk$URMcLOk5Q\" 390.287.917-21\n## 2        \"Igor944.236.416-254tLo8&S9WtXg05fsdU\" 944.236.416-25\n## 3 \"Márcio395.304.955-57pfwji9Z4Q6dZxSWZV7#7Z$J\" 395.304.955-57\n## 4  \"Isabela322.900.842-74K5D6b$xAnY&QJ1$XQzE2f\" 322.900.842-74\n## 5     \"Álvaro475.767.740-583WWonElfbisKD1GiIVS\" 475.767.740-58\n## 6    \"Rafael031.357.966-89bOzZ7#2JBcsd!sWzaeNY\" 031.357.966-89",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>*Debugging* - Resolvendo *bugs* em suas funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/15-debugging.html#modo-debug-do-r",
    "href": "Capítulos/15-debugging.html#modo-debug-do-r",
    "title": "17  Debugging - Resolvendo bugs em suas funções",
    "section": "17.6 Modo debug do R",
    "text": "17.6 Modo debug do R\nNa seção anterior, mostramos algumas informações essenciais sobre os objetos que estavam sendo criados dentro da função infos_compras(), e, com essas informações pudemos identificar e corrigir a fonte do nosso erro. Portanto, debugging é uma atividade puramente de coleta de informações sobre o nosso programa. Quando temos um erro, nós buscamos informações para compreendê-lo, pois só assim vamos saber como corrigi-lo.\nNa seção anterior, utilizamos a função print() para coletarmos essas informações. Mas o próprio R possui um modo especial de execução chamado debug. Neste modo, temos um ambiente onde podemos coletar essas informações de maneira interativa e prática. Com isso, não temos o trabalho de redefinir múltiplas vezes as nossas funções.\nComo exemplo, vamos voltar à nossa função infos_compras(). Repare abaixo que estou redefinindo a função para o seu estado inicial. Portanto, quando eu executo novamente essa função, o erro anterior volta a aparecer.\n\ninfos_compras &lt;- function(){\n  compras &lt;- buscar_compras()\n  compras$cpfs &lt;- extrair_cpfs(compras$info)\n  \n  return(compras)\n}\n\ninfos_compras()\n\n## Error in compras$info : $ operator is invalid for atomic vectors \n\n17.6.1 Inserindo breakpoints em suas funções\nPara utilizar este modo debug do R, você precisa inserir um breakpoint em seu código. Um breakpoint representa o ponto (ou a linha) em seu script, que você deseja parar a execução, e, analisar o estado atual de seu programa. Isto é, o R não possui um botão de “Pare agora!”, por isso, você precisa dizer antes ao R, quando ele deve pausar a execução de seu código.\nPara adicionar um breakpoint você tem três alternativas principais (existem outras menos comuns). Todas elas giram em torno da função browser(). Apesar dos resultados serem basicamente os mesmos, uma dessas alternativas oferece vantagens mais importantes que as outras.\nEssas alternativas são: 1) inserir manualmente a função browser() dentro do body de sua função de interesse; ou 2) utilizar a função debug() para inserir essa chamada à função browser(); ou 3) permitir que o próprio RStudio faça esse trabalho por você.\nA primeira alternativa, consiste em inserir uma chamada à função browser() dentro do body da função que você está investigando. A função browser() advém dos pacotes básicos do R. Tudo que ela faz é criar um breakpoint e acionar o modo debug do R no instante em que ela é avaliada.\n\n\n\n\n\n\n\n\n\n\n\nA questão fundamental aqui é: onde inserir esse breakpoint? Para responder a essa pergunta, você precisa localizar a linha de seu script onde você deseja parar a execução e investigar o estado atual.\nPor exemplo, utilizando a primeira alternativa citada, queremos investigar a função infos_compras(), pois sabemos que o erro surge a partir dessa função. Por isso, vou redefinir essa função, incluindo um comando browser() logo na primeira linha do body da função. Sendo assim, a execução será interrompida logo no início de infos_compras().\n\ninfos_compras &lt;- function(){\n  browser()\n  compras &lt;- buscar_compras()\n  compras$cpfs &lt;- extrair_cpfs(compras$info)\n  \n  return(compras)\n}\n\nJá a segunda alternativa, consiste em aplicar a função debug() sobre a função que você deseja investigar. Ou seja, ao aplicar a função debug() sobre uma outra função, uma chamada à browser() será incluída na primeira linha do body dessa outra função.\nTendo isso em mente, como desejamos parar a execução na função infos_compras(), poderíamos executar o comando debug(infos_compras). Após esse comando, se você executar a função infos_compras(), o modo debug será automaticamente acionado, logo na primeira linha da função2.\n\ninfos_compras &lt;- function(){\n  compras &lt;- buscar_compras()\n  compras$cpfs &lt;- extrair_cpfs(compras$info)\n  \n  return(compras)\n}\n\ndebug(infos_compras)\n\n### Ao executar a função, você entrará automaticamente\n### em modo debug\ninfos_compras()\n\n### Para retornar ao estado inicial da função\n### utilize undebug()\nundebug(infos_compras)\n\nEm contrapartida, a terceira alternativa, consiste em permitir que o próprio RStudio insira esse comando browser() dentro de sua função com apenas um clique em seu script. Obviamente, para utilizar essa terceira alternativa, você precisa estar trabalhando com o R através do RStudio.\nEm resumo, essa terceira alternativa citada consiste em clicar (com o botão esquerdo do mouse) à esquerda do número da linha em que você deseja inserir o breakpoint.\nPortanto, eu procuro pela definição dessa função infos_compras() em meu script aberto no RStudio e, identifico que a primeira linha do body dessa função, está na linha 21 de meu script (como demonstrado na Figura 17.2). Logo, eu clico à esquerda do número 21, e, como resultado, uma bola vermelha aparece ao lado desse número, indicando assim, que um novo breakpoint foi adicionado àquela linha.\n\n\n\n\n\n\n\n\nFigura 17.2: Adicionando breakpoints ao seu script - Parte 1\n\n\n\n\n\nEssa mesma bola vermelha também aparece em sua janela de Environment do RStudio, logo ao lado do nome da função onde esse breakpoint foi inserido.\n\n\n\n\n\n\n\n\nFigura 17.3: Adicionando breakpoints ao seu script - Parte 2\n\n\n\n\n\nVocê também pode adicionar esse mesmo breakpoint, ao acionar o atalho Shift + F9, quando o cursor de seu mouse estiver na linha desejada.\nContudo, caso o objeto da função em questão, ainda não tenha sido criado em sua sessão, o RStudio vai levantar um aviso, dizendo que o breakpoint será adicionado assim que o seu script for executado. Esse aviso está apresentado na Figura 17.4. Perceba que, quando este tipo de situação acontece, a bola vermelha presente em seu script fica oca.\n\n\n\n\n\n\n\n\nFigura 17.4: Breakpoint é adicionado assim que o objeto da função é criado\n\n\n\n\n\nApós esse processo, ao observamos a definição da função infos_compras(), podemos perceber que essa função é agora um objeto de classe \"functionWithTrace\". Apesar da classe ter sido modificada, no fundo, tudo o que o RStudio fez foi inserir um comando browser() dentro do corpo de infos_compras(), mesmo que esse comando não esteja visível à primeira vista.\n\ninfos_compras\n\n## Object with tracing code, class \"functionWithTrace\"\n## Original definition: \n## function(){\n##   compras &lt;- buscar_compras()\n##   compras$cpfs &lt;- extrair_cpfs(compras$info)\n##  \n##   return(compras)\n## }\n##\n## ## (to see the tracing code, look at *body*(object))\nO resultado entre as três alternativas é basicamente o mesmo. Porém, configurar esses breakpoints pelas ferramentas que o RStudio oferece é preferível a utilizar a função debug(), ou, inserir manualmente comandos browser(). Pois é mais simples de se configurar, e, você não corre o risco de se esquecer de retirar os comandos browser() de suas funções, após resolver todos os bugs (WICKHAM, 2015a).\n\n\n17.6.2 Entrando em modo debug\nVocê consegue identificar se o seu R está em modo debug ou não, ao observar o indicador de seu console. Caso ele esteja no formato Browse[n]&gt;, você está no modo debug. Porém, se ele estiver no formato tradicional com o símbolo de “maior que” (&gt;), você está no modo “normal” do R.\nPerceba na Figura 17.5, que, assim que eu executo a função infos_compras(), o indicador de meu console passa do formato &gt; para Browse[n]&gt;, indicando assim, que eu entrei no modo debug. Além disso, perceba também que um conjunto de botões (Next, Continue, Stop, dentre outros) aparece no canto superior do console do RStudio. Esses botões são uma outra forma de você identificar que o seu R está no modo debug.\n\n\n\n\n\n\n\n\nFigura 17.5: Modo debug do R - Parte 1\n\n\n\n\n\nPortanto, quando executamos a função infos_compras(), o R entra automaticamente em modo debug, pelo simples fato de que essa função contém um breakpoint dentro dela. Este modo debug é ligado assim que o R encontra um breakpoint, isto é, no instante em que a função browser() é executada.\nTendo isso em mente, o R realiza a chamada à função infos_compras(). Entretanto, ele paralisa a execução logo na primeira linha descrita no body dessa função. Pois é justo nessa linha que inserimos o breakpoint.\nCaso você esteja dentro do RStudio, se você retornar ao script onde está a definição dessa função, você vai reparar que o RStudio marcou em amarelo essa linha, e adicionou uma seta verde à esquerda. Com isso, o RStudio está te avisando que o seu R está parado especificamente naquela linha, aguardando novas instruções para prosseguir com a execução.\n\n\n\n\n\nModo debug do R - Parte 2\n\n\n\n\nÉ muito importante destacar que, se o R está parado em uma linha específica, isso significa que ele ainda não executou essa linha. Em outras palavras, a função buscar_compras() ainda não foi executada, consequentemente, o objeto compras ainda não foi criado.\nPodemos verificar essa afirmativa, ao procurar pelo objeto compras dentro do modo debug do RStudio. Perceba abaixo, que um erro é retornado, indicando que esse objeto ainda não foi definido.\n\nBrowse[2]&gt; compras\n\n## Error: object 'compras' not found\nRecapitulando, para entrarmos no modo debug do R, precisamos executar uma função que contenha um breakpoint dentro dela. No nosso exemplo, essa função é infos_compras().\nAo avaliarmos essa função infos_compras(), o R paralisa a execução logo na primeira linha do body dessa função. Contudo, mesmo em modo debug, o R continua disponível para executar novos comandos. Ou seja, você consegue criar novos objetos, executar outras funções e imprimir informações no console, da mesma forma que você normalmente faria no modo “normal” do R.\nSendo assim, em modo debug, o R paralisa a execução da função (ou do loop) que contém o breakpoint. Mas o R não fica indisponível, ou, ele não paralisa toda e qualquer outra execução. Dito de outra forma, o modo debug te permite paralisar a execução de uma função e, investigar de forma interativa o seu estado, atrás de algum problema que revele a fonte de seu erro.\nPortanto, o modo debug do R te ajuda a realizar os seguintes passos, que são essenciais em qualquer ato de debugging:\n\nVocê começa a executar o seu script;\nParalisa a execução no ponto em que você suspeita estar a fonte de seu erro;\nComeça a investigar os objetos que estão sendo criados e as ações que estão sendo realizadas nesse ponto;\nDescobre o problema que está ocorrendo naquele ponto;\n\n\n\n17.6.3 Navegando pelo modo debug\nPara navegar pelo modo debug, você pode utilizar os botões que aparecem no canto superior de seu console no RStudio, ou, utilizar um dos comandos curtos de texto que estão descritos abaixo:\n\nn: executar a próxima linha (ou a próxima etapa) da função. Caso você possua um objeto definido chamado n, quando estiver em modo debug, você precisa utilizar o comando print(n) para visualizar o conteúdo desse objeto.\ns: funciona de forma parecida com o comando n, porém, caso a próxima linha da função que você está investigando, contenha uma outra função, o modo debug vai entrar dentro dessa outra função, para que você possa investigar o estado dessa outra função também.\nf: encerra a execução do loop ou função atual.\nc: sai momentaneamente do modo interativo do debug, e, executa todos os próximos passos da função, até que um novo breakpoint seja encontrado. Esse comando é útil, caso você tenha adicionado uma correção para o seu erro, e, deseja confirmar que o problema foi de fato resolvido.\nQ: finaliza o modo debug, encerra a execução da função, e, retorna o R para o seu modo “normal” de execução. Utilize esse comando quando você deseja sair do modo debug do R.\nwhere: mostra a árvore atual de chamadas. Esse comando é, basicamente, o equivalente à função traceback() para o modo debug.\n\nComo destacamos na seção passada, você pode acessar esses mesmos comandos através dos botões que aparecem (quando você entra em modo debug) no canto superior de seu console do RStudio. A Figura 17.6 apresenta justamente a correspondência entre esses comandos em texto e os botões desse painel.\n\n\n\n\n\n\n\n\nFigura 17.6: Relação entre os comandos em texto e os botões do painel de debug do RStudio\n\n\n\n\n\nComo um primeiro exemplo, vamos observar a função f() descrita abaixo. Perceba que essa função executa um loop dentro dela, e, dentro desse loop, temos uma chamada à função browser().\n\nf &lt;- function(){\n  for(i in 1:10){\n    browser()\n  }\n}\n\nDevido ao fato de browser() ser a única função presente no body de f(), os comandos c e n do modo debug são aproximadamente equivalentes. Pois com o comando n, o R vai executar a próxima linha do body da função f(). Porém, como essa próxima etapa é a próxima iteração do loop, a função browser() será executada novamente e, consequentemente, o R entrará novamente em modo debug.\nJá o comando c, vai fazer com que o R saia do modo debug e execute todas as etapas restantes do body da função f(). Todavia, como essas próximas etapas correspondem às próximas iterações do loop, o R vai executar novamente a função browser() e, consequentemente, entrar novamente em modo debug.\nContudo, se inserirmos um novo comando após browser(), os comandos n e c deixam de ser equivalentes. Perceba abaixo, que inserimos a expressão print(i * 10) após a função browser().\n\nf &lt;- function(){\n  for(i in 1:10){\n    browser()\n    print(i * 10)\n  }\n}\n\nCom essa nova definição de f(), quando utilizamos o comando c, a expressão print(i * 10), assim como a próxima iteração do loop, e, consequentemente, o próximo browser(), são todos executados de uma vez só. Perceba na Figura 17.7, pela expressão Called from: f(), que um novo comando browser() é executado a cada novo comando c.\n\n\n\n\n\n\n\n\nFigura 17.7: Comando Continue\n\n\n\n\n\nPor outro lado, quando utilizamos o comando n, o R se move para a próxima linha do body, que é expressão print(i * 10). No segundo comando n, o R executa a expressão print(i * 10) e, se move para a próxima linha, que corresponde ao próximo browser(). Logo, para executarmos o próximo browser(), temos que utilizar três comandos n, como apresentado na Figura 17.8.\n\n\n\n\n\n\n\n\nFigura 17.8: Comando Next\n\n\n\n\n\n\n\n17.6.4 Investigando o estado de sua função\nPortanto, o modo debug do R te permite investigar o ambiente (ou o environment) de sua função, de forma interativa. Em outras palavras, ele te permite analisar os resultados gerados dentro de sua função. Este modo também te permite entrar dentro do ambiente de outras funções que são executadas dentro de sua função (com o botão Step Into, ou, o comando s). Dessa maneira, você também pode investigar os objetos criados e os processos executados dentro dessas funções “secundárias”.\nEu poderia utilizar este modo debug para coletar as mesmas informações que extraímos (sobre o objeto compras) na seção sobre print debugging. Por exemplo, após adicionar um breakpoint à função infos_compras(), eu executo ela para entrar em modo debug. Perceba abaixo (pela expressão debug at), que o R está parado na linha em que o objeto compras é criado.\n\ninfos_compras()\n\n## Called from: eval(expr, p)\n## Browse[1]&gt; n\n## *debug* at #21: compras &lt;- buscar_compras()\nLembre-se que, se o R está parado nessa linha, quer dizer que ele ainda não avaliou essa linha. Por isso, eu utilizo o comando n para executar essa linha, para que o objeto compras seja criado.\n\nBrowse[2]&gt; n\n\n## *debug* at #22: cpfs &lt;- extrair_cpfs(compras$info)\nEm seguida, começo a investigar o objeto compras, visualizando parte de seu conteúdo, e, investigando sua estrutura.\n\nBrowse[2]&gt; compras[1:5]\n\n## [1] \"\\\"Márcio390.287.917-210akqzS2tk$URMcLOk5Q\\\"\"    \n## [2] \"\\\"Igor944.236.416-254tLo8&S9WtXg05fsdU\\\"\"       \n## [3] \"\\\"Márcio395.304.955-57pfwji9Z4Q6dZxSWZV7#7Z$J\\\"\"\n## [4] \"\\\"Isabela322.900.842-74K5D6b$xAnY&QJ1$XQzE2f\\\"\" \n## [5] \"\\\"Álvaro475.767.740-583WWonElfbisKD1GiIVS\\\"\" \n\nBrowse[2]&gt; str(compras)\n\n## chr [1:1150] \"\\\"Márcio390.287.917-210akqzS2tk$URMcLOk5Q\\\"\" ...\nApós coletar todas as informações que preciso para compreender e corrigir o erro, eu posso sair do modo debug, com o comando Q.\n\nBrowse[2]&gt; Q\n### O R retorna para o seu modo \"normal\" de execução",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>*Debugging* - Resolvendo *bugs* em suas funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/15-debugging.html#sempre-teste-o-seu-código",
    "href": "Capítulos/15-debugging.html#sempre-teste-o-seu-código",
    "title": "17  Debugging - Resolvendo bugs em suas funções",
    "section": "17.7 Sempre teste o seu código",
    "text": "17.7 Sempre teste o seu código\nApós compreender e corrigir os erros em suas funções, é importante que você teste novamente todo o seu código. Pois, ao corrigir uma parte de seu código, você pode acidentalmente quebrar uma outra parte dele.\nApesar dessa importância, você pode se perguntar “quando especificamente você deve realizar esses testes”. Temos três respostas corretas para essa pergunta:\n\nSempre!\nO mais cedo possível!\nCom frequência!\n\nProgramadores ou desenvolvedores de software geralmente dividem testes em duas categorias: unity tests e integration tests. Um teste unitário (ou unity test) consiste em testar se uma função isolada funciona da forma esperada. Já um teste integrado (ou integration test) consiste em testar se todas as funções de seu programa funcionam em conjunto, da forma correta.\nExistem métodos formais de se realizar tais tipos de testes no R, especialmente a partir do pacote testthat. Porém, como esse pacote é focado especialmente no público que busca desenvolver novos pacotes para o R, ele está fora do escopo deste livro. Por esse motivo, se você deseja aprender mais sobre esse pacote, a obra de WICKHAM (2015b) é uma boa referência.\n\nApós aplicar as correções necessárias em sua função, execute novamente essa função. Dessa forma, você estará realizando um teste unitário sobre essa função. Confira se essa função retorna o resultado ou erro esperados. Caso tudo ocorra como você previa, é uma boa ideia realizar um teste integrado de seu programa logo em seguida.\nUma forma prática e segura de se realizar esse tipo de teste é reiniciar o seu R (com o atalho Ctrl + Shift + F10) e, em seguida, executar todo o seu script (com o atalho Ctrl + Shift + S). Ao executar todo o seu script, se todas as funções forem executadas normalmente, sem erros, e, todos os objetos esperados forem gerados, isso é um forte sinal de que você possui um programa correto e com bom grau de reprodutibilidade.\n\n\n\n\nWICKHAM, H. Advanced R. 2. ed. Boca Raton, Florida: CRC Press, 2015a.\n\n\nWICKHAM, H. R Packages. Sebastopol, CA: O’Reilly Media, Inc., 2015b.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>*Debugging* - Resolvendo *bugs* em suas funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/15-debugging.html#footnotes",
    "href": "Capítulos/15-debugging.html#footnotes",
    "title": "17  Debugging - Resolvendo bugs em suas funções",
    "section": "",
    "text": "https://stackoverflow.com/questions/15031338/subscript-out-of-bounds-general-definition-and-solution↩︎\nApós aplicar debug() sobre a sua função de interesse, se você deseja retornar para o seu estado inicial de sua função, você pode aplicar undebug() sobre essa função.↩︎",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>*Debugging* - Resolvendo *bugs* em suas funções</span>"
    ]
  },
  {
    "objectID": "Capítulos/16-environments.html",
    "href": "Capítulos/16-environments.html",
    "title": "18  Environments ou ambientes no R",
    "section": "",
    "text": "18.1 Introdução\nTodo objeto existente no R está armazenado em um environment (ou ambiente) específico. Como é destacado por WICKHAM (2015) os environments são a estrutura de dados que sustenta o processo de scoping do R, isto é, as regras de “busca” por objetos da linguagem R.\nCompreender o que é um environment é algo bastante simples. Porém, entender como os vários environments ativos em sua sessão funcionam em conjunto, representa um outro nível de dificuldade. Mesmo assim, environments são estruturas muito importantes para a linguagem R, e que sustentam grande parte das operações realizadas pelos pacotes dplyr e ggplot2.\nAlém disso, environments são parte fundamental da reprodutibilidade dos programas criados pela linguagem R. Pois eles são as estruturas responsáveis por garantir que os diferentes componentes de seu programa sejam únicos e independentes entre si.\nAo longo deste capítulo vamos utilizar algumas funções do pacote rlang. Sendo assim, para que você possa acompanhar alguns dos exemplos a seguir, é necessário que esse pacote esteja instalado em sua máquina.\nlibrary(rlang)",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>*Environments* ou ambientes no R</span>"
    ]
  },
  {
    "objectID": "Capítulos/16-environments.html#sec:environments",
    "href": "Capítulos/16-environments.html#sec:environments",
    "title": "18  Environments ou ambientes no R",
    "section": "18.2 Noções básicas de environments",
    "text": "18.2 Noções básicas de environments\nPara além de uma linguagem que trabalha com objetos, o R é também uma linguagem que trabalha com objetos que estão contidos (ou guardados) em certos environments. Um environment (ou ambiente) no R, é muito parecido com uma lista nomeada. Cada nome presente nessa lista, corresponde ao nome de um objeto que está armazenado nesse respectivo environment.\nSegundo WICKHAM (2015), todo environment carrega algumas propriedades:\n\nTodos os nomes em um environment são únicos (isso garante que dois ou mais objetos de mesmo nome não existam dentro de um mesmo environment);\nOs nomes presentes em um environment não são ordenados;\nTodo environment possui um environment “pai”;\nUm environment é modificado in place (ou seja, ele não é copiado quando ele é modificado).\n\nQuando estamos trabalhando com um determinado objeto, geralmente nos referimos a este objeto através de seu nome, contudo, o nome é apenas parte desta referência, pois objetos existem dentro de um determinado contexto, ou escopo. Portanto, no R, uma referência completa a um determinado objeto, é na verdade, a combinação entre o nome deste objeto e o environment no qual ele está inserido (CHAMBERS, 2016).",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>*Environments* ou ambientes no R</span>"
    ]
  },
  {
    "objectID": "Capítulos/16-environments.html#descobrindo-o-environment-atual",
    "href": "Capítulos/16-environments.html#descobrindo-o-environment-atual",
    "title": "18  Environments ou ambientes no R",
    "section": "18.3 Descobrindo o environment atual",
    "text": "18.3 Descobrindo o environment atual\nIndependentemente de onde você esteja dentro do R, você sempre é capaz de identificar qual é o environment atual através da função environment(). Basta executar essa função, e, o endereço do environment no qual você está será retornado como resultado.\nPerceba abaixo que, ao executar essa função em minha sessão atual do R, o endereço R_GlobalEnv é retornado. Normalmente, environments são identificados através do endereço da memória RAM no qual eles estão localizados. Contudo, esse valor R_GlobalEnv representa um apelido para um environment especial do R, chamado de global environment. Vamos discutir esse environment na próxima seção.\n\nenvironment()\n\n## &lt;environment: R_GlobalEnv&gt;\nEm termos mais técnicos, o que a função environment() faz é retornar o endereço do environment no qual ela é executada. Portanto, o resultado dessa função depende diretamente de onde você a executa.\nLogo, se o comando environment() está sendo executado dentro do body de uma função chamada f, o resultado será o environment de execução dessa função f. Mas, se você executar esse comando diretamente no seu console do R, o resultado será diferente.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>*Environments* ou ambientes no R</span>"
    ]
  },
  {
    "objectID": "Capítulos/16-environments.html#o-environment-global",
    "href": "Capítulos/16-environments.html#o-environment-global",
    "title": "18  Environments ou ambientes no R",
    "section": "18.4 O environment global",
    "text": "18.4 O environment global\nNormalmente, quando digitamos o nome de um determinado objeto, nós não estamos preocupados com o environment no qual este objeto está guardado. Pois o próprio R realiza o trabalho duro de procurar por este objeto ao longo de todos os environments ativos em sua sessão, atrás de um objeto que possua o mesmo nome que você digitou. Tal mecanismo de procura é denominado de scoping ou de lexical scoping (WICKHAM, 2015), e ele geralmente se inicia pelo seu global environment.\nToda vez que você inicia a sua sessão no R, você está trabalhando com um environment especial que chamamos de global environment, ou ambiente global. Logo, todos os objetos que você normalmente cria em sua sessão, são guardados dentro deste global environment.\nVocê pode se referir a esse environment através da função globalenv(). Como exemplo, eu posso usar a função ls() para listar os nomes de todos os objetos que estão disponíveis especificamente neste global environment. Como vimos na seção passada, o endereço desse environment é referenciado como R_GlobalEnv.\n\nglobalenv()\n\n&lt;environment: R_GlobalEnv&gt;\n\n\n\n# Iniciei uma nova sessão no R\n\n# Criei alguns objetos\na &lt;- 1\nb &lt;- 2\n\n# ls() lista todos os objetos criados\n# em meu global environment\nls(envir = globalenv())\n\n## [1] \"a\" \"b\"\nPortanto, um environment é uma espécie de caixa ou um espaço reservado para guardar um certo conjunto de objetos. O seu global environment é um desses environments, onde ficam todos os seus objetos que você normalmente cria em sua sessão. Todavia, sempre existem vários outros environments ativos em sua sessão, e você também pode criar objetos dentro desses outros environments (caso seja de seu desejo).",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>*Environments* ou ambientes no R</span>"
    ]
  },
  {
    "objectID": "Capítulos/16-environments.html#sec:environment_exec",
    "href": "Capítulos/16-environments.html#sec:environment_exec",
    "title": "18  Environments ou ambientes no R",
    "section": "18.5 O environment de execução de uma função",
    "text": "18.5 O environment de execução de uma função\nToda função no R, possui o que nós chamamos de function environment, que corresponde ao environment no qual elas foram criadas. No exemplo abaixo, estamos identificando quais são esses environments para as funções filter() do pacote dplyr, e seq() do pacote base.\n\nrlang::fn_env(dplyr::filter)\n\n&lt;environment: namespace:dplyr&gt;\n\nrlang::fn_env(seq)\n\n&lt;environment: namespace:base&gt;\n\n\nComo um outro exemplo, caso eu crie uma nova função em minha sessão, perceba que o environment a qual ela pertence, se trata justamente do global environment (R_GlobalEnv).\n\nsoma &lt;- function(x, y){\n  return(x + y)\n}\n\nrlang::fn_env(soma)\n\n## &lt;environment: R_GlobalEnv&gt;\nPor outro lado, se eu quiser, por exemplo, criar uma função chamada g dentro de uma outra função chamada h, o function environment de g() será o environment de execução de h(). Pois a função g() foi criada dentro deste environment de h().\n\nh &lt;- function(){\n  g &lt;- function(){\n    print(5)\n  }\n  \n  g_env &lt;- rlang::fn_env(g)\n  return(g_env)\n}\n\nh()\n\n&lt;environment: 0x58cf208da2c0&gt;\n\n\nPortanto, as funções também possuem o que chamamos de environment de execução, que se trata do environment no qual os seus cálculos são executados. Ou seja, sempre que você executa uma função, os cálculos realizados por essa função são feitos em um environment separado de seu global environment.\nComo expomos ao final do capítulo de Funções, quando uma função é executada, um novo environment vazio é criado. Em seguida, um objeto para cada argumento fornecido à função é criado dentro desse novo environment. Por último, todos os comandos presentes no body dessa função são executados dentro desse novo environment (CHAMBERS, 2016, p. 52).\nPor esse motivo, você não consegue visualizar com facilidade, os resultados que são gerados por essa função, pois os seus cálculos estão sendo realizados em um environment diferente do environment no qual você se encontra (global environment).\nEm contrapartida, essa característica garante que uma função não afete os objetos de seu global environment. Isso também permite que uma função do R seja self-contained, de modo que, os seus resultados dependam apenas dos valores de seus argumentos, e não dos objetos de outros environments presentes em sua sessão (CHAMBERS, 2016).\nPara demonstrar esse conceito de environment de execução, estou criando abaixo uma função chamada f_env, que nos retorna justamente o endereço do environment no qual essa função executou a soma entre 4 e 5. Perceba que a cada momento em que eu executo essa função, ela me retorna um endereço diferente.\nLogo, esses environments de execução são temporários (ou efêmeros se preferir), e utilizados uma única vez pela função. Por causa disso, no R, cada execução de uma função é independente uma da outra. A função não sabe absolutamente nada sobre o que aconteceu na última vez em que ela foi avaliada.\n\nf_env &lt;- function(){\n  soma &lt;- 4 + 5\n  env &lt;- environment()\n  return(env)\n}\n\nf_env()\n\n&lt;environment: 0x58cf20e83b40&gt;\n\nf_env()\n\n&lt;environment: 0x58cf20f6b080&gt;\n\n\n\n\n\n\n\n\n\n\n\n\nO exemplo abaixo, demonstra essa ideia de que os environments de execução asseguram que toda função não altere os nossos objetos salvos em nosso global environment. Dentro da função f() mostrada abaixo, estou criando um objeto chamado y com o valor de 100. Porém, mesmo após executar essa função, o objeto y que está salvo em meu global environment continua armazenando o valor 1.\n\n### Crie um objeto y em meu global environment\ny &lt;- 1\nf &lt;- function(){\n  y &lt;- 100\n}\n\n### Executo a função f()\nf()\n### O valor de y continua igual a 1\nprint(y)\n\n[1] 1\n\n\n\n18.5.1 Os environments de pacotes\nPortanto, o trabalho de um environment no R, é o de vincular, ou de associar um conjunto de nomes (os nomes dos objetos), a seus respectivos conjuntos de valores (WICKHAM, 2015, Cáp. 7). Ou seja, um dos principais papéis que um environment desempenha no R, é o de organizar um conjunto de objetos, de forma que o R seja capaz de diferenciar dois ou mais objetos com o mesmo nome.\nUm bom exemplo disso, é a função filter() do pacote dplyr, que vimos no capítulo 4. Pois nós temos dentre os pacotes básicos do R, mais especificamente no pacote stats, uma outra função também chamada filter(). Por isso, sempre que chamamos pelo pacote dplyr através de library(), a seguinte mensagem aparece, nos informando que há um choque entre as duas funções.\n\nlibrary(dplyr)\n\nAttaching package: ‘dplyr’\n\nThe following objects are masked from ‘package:stats’:\n\n    filter, lag\nEssa mensagem está nos informando, que o pacote dplyr possui funções com os mesmos nomes das funções filter() e lag() do pacote stats, e, que por esse motivo, essas funções seriam “escondidas” de forma a evitar conflitos.\nPortanto, após carregarmos o pacote dplyr com library(), as funções filter() e lag() do pacote stats são “escondidas”. Como resultado, se nós chamarmos pela função filter() no console, estaremos utilizando a função do pacote dplyr, e não a função do pacote stats.\n\n\n\n\n\n\n\n\nFigura 18.1: Ambientes de pacotes no R\n\n\n\n\n\nPortanto, essas duas funções filter(), são funções diferentes, que servem para propósitos diferentes. O único fator que permite ao R, diferenciar essas funções uma da outra, é o fato de que elas pertencem a ambientes, ou environments diferentes, como demonstrado na Figura 18.1. Lembre-se que todas as funções estão associadas a um environment específico. Por isso, nós podemos diferenciar as funções filter() e lag() de ambos os pacotes (dplyr e stats), através do nome do environment ao qual essas funções pertencem.\nPacotes do R são um caso especial, pois eles contêm dois environments diferentes que se relacionam entre si. Um é o environment propriamente dito do pacote, que contém os seus respectivos objetos, e um outro comumente chamado de namespace. Essa diferenciação só será útil na prática, quando você estiver desenvolvendo um novo pacote para o R.\nOu seja, não se preocupe em entender agora a diferença entre esses dois espaços. Apenas entenda que, pacotes no R, vão além de simples environments. Também entenda que, os objetos e funções de todo pacote do R estão sempre armazenados no environment deste pacote, o qual é um environment separado de seu global environment.\nTendo isso em mente, quando desejamos utilizar uma função que está em conflito com uma outra função de um outro pacote, nós devemos definir de alguma forma, o environment do pacote no qual o R deve procurar pela função que você está chamando.\nNo caso de pacotes, podemos acessar funções definidas em seus respectivos environments, ao fornecer o nome do pacote que contém essa função, seguido do operador ::, e do nome da função que desejamos utilizar. Veja o exemplo abaixo, em que estamos utilizando a função filter() do pacote stats.\n\nx &lt;- ts(rnorm(100), start = c(1, 1990), end = c(4, 1998), frequency = 12)\n\nstats::filter(x, filter = c(0.5, 0.8, 0.2))\n\n             Jan          Feb          Mar          Apr          May\n166                                                                 \n167 -0.521652457  0.288679545  0.357363761  0.189136199  0.512888717\n168  1.025315929 -0.008626853 -0.805855578  0.473984326 -0.192164343\n169 -0.875673533 -0.078710120 -0.551113642  0.383794104  2.056333336\n170 -0.779275572  0.287376069  1.172226141  1.375027658  0.875187484\n             Jun          Jul          Aug          Sep          Oct\n166                                                               NA\n167  0.883772307  0.502891827  0.566576854  1.016966016 -0.556151454\n168 -1.721288722 -1.231294885 -0.782290006 -0.527011340 -0.182809083\n169  1.540795431  0.663096525  0.023953127 -0.009203929 -0.546564600\n170           NA                                                    \n             Nov          Dec\n166  1.166079935 -0.172345025\n167 -0.790527234  0.525434683\n168  0.011024679 -0.614595715\n169 -1.686797998 -1.558951331\n170",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>*Environments* ou ambientes no R</span>"
    ]
  },
  {
    "objectID": "Capítulos/16-environments.html#acessando-outros-environments",
    "href": "Capítulos/16-environments.html#acessando-outros-environments",
    "title": "18  Environments ou ambientes no R",
    "section": "18.6 Acessando outros environments",
    "text": "18.6 Acessando outros environments\nJá mostramos que você pode acessar o environment atual através da função environment(). Também mostramos que você pode acessar o seu global environment por meio da função globalenv(). Agora, a questão que fica é: como podemos acessar outros environments que estão presentes no caminho de pesquisa do R?\nPor exemplo, como podemos acessar o environment do pacote dplyr? Para isso podemos utilizar as funções as.environment() e rlang::as_environment(). Ambas as funções desempenham basicamente o mesmo trabalho. Utilizando essas funções, podemos acessar o environment do pacote dplyr ao fornecer o nome de seu environment, como demonstrado abaixo.\nPerceba que, se você utilizar a função as.environment() (dos pacotes básicos do R), você precisa fornecer o nome completo do environment. Por se tratar do environment de um pacote, o nome deste pacote precisa ser antecedido por package:. Por outro lado, a função rlang::as_environment() é inteligente o suficiente para pesquisar por um pacote com o nome que você digitou.\n\nas.environment(\"package:dplyr\")\n\n&lt;environment: package:dplyr&gt;\nattr(,\"name\")\n[1] \"package:dplyr\"\nattr(,\"path\")\n[1] \"/home/pedro-dev/R/x86_64-pc-linux-gnu-library/4.4/dplyr\"\n\nrlang::as_environment(\"dplyr\")\n\n&lt;environment: package:dplyr&gt;\nattr(,\"name\")\n[1] \"package:dplyr\"\nattr(,\"path\")\n[1] \"/home/pedro-dev/R/x86_64-pc-linux-gnu-library/4.4/dplyr\"\n\n\nComo um outro exemplo, vamos refletir sobre o objeto LETTERS. Esse objeto está sempre disponível em sua sessão no R. Pois ele pertence ao environment do pacote base (o qual faz parte dos pacotes básicos da linguagem, e, portanto, é sempre carregado para a sua sessão).\nVamos supor que eu crie um novo objeto chamado LETTERS em meu global environment. Como resultado, se eu procurar por este objeto no console do R, o objeto encontrado será este novo objeto salvo em meu global environment. Pois o processo de busca do R geralmente se inicia pelo global environment.\n\n### Este é o objeto LETTERS salvo no\n### *environment* do pacote `base`\nLETTERS\n\n\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n\n\n### Estou criando um novo objeto LETTERS em\n### meu global environment\nLETTERS &lt;- \"a\"\n\n### Agora, se eu procurar por um objeto\n### LETTERS, o R vai encontrar primeiro o objeto \n### salvo em meu global environment\nLETTERS\n\n[1] \"a\"\n\n\nVale destacar que, o objeto LETTERS original, ainda existe dentro do environment do pacote base. A única diferença é que, antes de chegar ao environment do pacote base, o R está encontrando primeiro o objeto LETTERS salvo em meu global environment. Logo, ele retorna esse objeto contendo o valor \"a\", ao invés do objeto original.\nPelo fato de termos dois objetos LETTERS diferentes em nossa sessão, para acessarmos o objeto LETTERS original, precisamos definir o environment no qual o R deve pesquisar por este objeto. Como este objeto LETTERS pertence a um pacote do R, podemos utilizar a mesma estrutura que utilizamos para acessar a função filter() do pacote stats, como demonstrado abaixo.\n\nbase::LETTERS\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n\nContudo, como uma outra alternativa, também podemos utilizar a função get() para especificarmos melhor, qual dos dois objetos desejamos acessar. Pois essa função possui um argumento (envir) onde podemos definir o environment em que o objeto deve ser pesquisado.\nComo exemplo, para acessarmos o objeto LETTERS original, precisamos pesquisar por ele dentro do environment do pacote base. Por isso, eu forneço abaixo, o environment deste pacote ao argumento envir.\n\nget(\"LETTERS\", envir = as.environment(\"package:base\"))\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n\nPortanto, mesmo que eu crie um objeto em minha sessão, ou em outras palavras, um objeto em meu global environment chamado LETTERS, o R ainda é capaz de diferenciar os dois objetos denominados LETTERS, através do environment ao qual eles estão associados. Esta ideia está apresentada de forma visual na Figura 18.2.\n\n\n\n\n\n\n\n\nFigura 18.2: Representação de environments\n\n\n\n\n\nApós criarmos um novo objeto LETTERS, se eu chamar por este objeto no console, o resultado será o valor contido no objeto LETTERS do meu global environment. Isso ocorre, pois o R irá geralmente procura por um objeto primeiro em seu global environment. Depois ele vai procurar por este objeto ao qual você requisitou em outros environments.\nEsse caminho de environments pelo qual o R percorre durante sua procura, é comumente chamado por search path (ou “caminho de busca”). Como vimos acima, podemos utilizar a função get() sempre que desejamos contornar esse caminho padrão seguido pelo R, e, pesquisar por nosso objeto em um environment específico.\nConcluindo, nós geralmente desejamos acessar um environment específico, quando temos dois objetos existentes em nossa sessão que possuem o mesmo nome, porém, são diferentes entre si. Nesse caso, precisamos unir o nome deste objeto, e o environment ao qual ele pertence, para acessarmos o objeto correto.\nCaso esse objeto em questão, pertença a um pacote do R específico, podemos utilizar a estrutura pacote::objeto para acessarmos esse objeto. No entanto, se esse objeto pertence a um outro tipo de environment, podemos utilizar a função get() e seu argumento envir, para definirmos em que environment específico, o objeto deve ser pesquisado.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>*Environments* ou ambientes no R</span>"
    ]
  },
  {
    "objectID": "Capítulos/16-environments.html#o-sistema-de-scoping-do-r",
    "href": "Capítulos/16-environments.html#o-sistema-de-scoping-do-r",
    "title": "18  Environments ou ambientes no R",
    "section": "18.7 O sistema de scoping do R",
    "text": "18.7 O sistema de scoping do R\nSempre que você digita o nome de um objeto, o R inicia um processo de busca ao longo de todos os environments ativos em sua sessão, atrás de um objeto que possua o mesmo nome do que você digitou. Esse processo de busca é chamado de scoping, ou, lexical scoping.\nAntes de explicar como esse mecanismo de busca funciona, precisamos descrever o que é um parent environment. Pois eles determinam qual o caminho que o R vai perseguir durante a sua pesquisa.\n\n18.7.1 Compreendendo parent environments\nTodo environment possui um environment “pai”. Dentro da comunidade, esse tipo de environment é chamado de parent environment. Como exemplo, vamos supor que você crie um novo environment a partir de seu global environment.\nPara criar um novo environment, você pode utilizar as funções rlang::env() e new.env(). Perceba abaixo, que eu não apenas crio esse novo environment chamado env1, mas eu também já adiciono dois novos objetos (a e b) a esse environment. Esses objetos a e b guardam os valores 1 e 2, respectivamente.\n\nenv1 &lt;- rlang::env(a = 1, b = 2)\n\nComo eu não defini explicitamente dentro da função rlang::env(), um parent environment para esse novo environment, a função vai, por padrão, criar esse novo environment a partir do environment atual, isto é, o environment no qual essa função foi chamada. No exemplo acima, esse environment atual é o global environment, porque eu estou executando a função diretamente em meu console do R.\n\n\n\n\n\n\n\n\nFigura 18.3: Apresentando parent environments - Parte 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 18.4: Apresentando parent environments - Parte 2\n\n\n\n\n\nPor esse motivo, o parent environment de env1 é o meu global environment. Eu posso representar essa relação de maneira visual, como na Figura 18.3. Cada retângulo nessa figura é um environment específico. Em todas as figuras a seguir, o environment filho vai estar sempre apontando para o environment pai com uma seta azul.\nComo um outro exemplo, eu posso criar um outro enviroment chamado env2. Porém, dessa vez, esse environment é criado a partir de env1. Ou seja, env1 se torna o parent environment de env2. Repare que eu crio 3 novos objetos (e, d e c) dentro desse novo environment.\n\nenv2 &lt;- rlang::env(env1, c = 3, d = 4, e = 5)\n\nPara descobrir o parent environment de um environment qualquer, você pode utilizar a função parent.env(). Veja no exemplo abaixo que, o resultado do comando parent.env(env2) é justamente o endereço de env1.\n\nparent.env(env2)\n\n&lt;environment: 0x58cf21834df0&gt;\n\nenv1\n\n&lt;environment: 0x58cf21834df0&gt;\n\n\nCaso eu aplique essa função sobre env1, podemos confirmar que o meu global environment é de fato o pai desse environment.\n\nparent.env(env1)\n\n## &lt;environment: R_GlobalEnv&gt;\nSendo assim, podemos atualizar a nossa representação visual da seguinte maneira:\nVale destacar que, a Figura 18.4 acima não mostra um parent environment para o meu global environment, mas isso não significa que esse environment não existe. Eu apenas o omiti acima, para manter a figura simples. Lembre-se sempre que, todo environment possui um parent environment. Como exemplo, perceba abaixo que, o parent environment de meu global environment é (neste momento) o environment do pacote dplyr, que foi o último pacote que eu carreguei para a minha sessão.\n\nparent.env(globalenv())\n\n## &lt;environment: package:dplyr&gt;\n## attr(,\"name\")\n## [1] \"package:dplyr\"\n## attr(,\"path\")\n## [1] \"C:/Users/Pedro/Documents/R/win-library/4.1/dplyr\"\nNos manuais internos do R, o parent environment é muitas vezes chamado de enclosing environment, isto é, o ambiente que “envolve” ou que “contém” os demais environments (TEAM, 2020). Ou seja, de certa forma, o environment env1 envolve ou contém env2 dentro dele, e, o meu global environment contém env1.\n\n\n18.7.2 O environment vazio ou empty environment\nEventualmente, toda sequência de environments termina em um environment vazio (ou empty environment). Em outras palavras, se você começar a subir pela árvore genealógica de seus environments, seguindo parent environment atrás de parent environment, você vai eventualmente chegar a um empty environment. Que é um tipo especial de environment, pois ele é a exceção à regra de que todo environment possui um pai.\nPortanto, um empty environment é identificado pelo apelido R_EmptyEnv e, ele não possui um parent environment. Você pode acessar esse environment através da função emptyenv().\n\nemptyenv()\n\n&lt;environment: R_EmptyEnv&gt;\n\n\nVocê pode comprovar a afirmação do parágrafo acima, ao tentar aplicar a função parent.env() sobre esse environment. Perceba abaixo que um erro é retornado, avisando que esse environment não possui um environment “pai”.\n\nparent.env(emptyenv())\n\n## Error in parent.env(emptyenv()) : the empty *environment* has no parent\nTendo isso em mente, esse environment vazio representa o final de toda sequência de environments. De certa maneira, esse environment é o último parent environment de todos. Assim que o R atinge esse environment, ele encerra o seu processo de pesquisa, pois ele não tem mais para onde ir.\nSe você refletir sobre isso, você pode chegar a conclusão de que, se o R chegar a esse environment vazio durante o seu processo de pesquisa, isso significa que o R não pôde encontrar o objeto que você requisitou. Pois ao chegar a esse environment vazio, o R já vai ter visitado todos os outros environments ativos em sua sessão.\n\n\n18.7.3 O caminho de busca ou search path do R\nPara encontrar o objeto pelo qual você requisitou, o R visita environment por environment, em busca desse objeto, até atingir um empty environment. A lista de environments que o R visita durante esse processo de pesquisa, é chamada de search path (ou, o caminho de pesquisa). Você pode descobrir qual é esse search path, através da função search().\nBasta executar essa função, que um vetor contendo os nomes de todos esses environments será retornado como resultado. Vale destacar que, os nomes desses environments vão estar precisamente na ordem em que eles são visitados, durante este processo de pesquisa.\nPerceba abaixo que, o environment .GlobalEnv (que é um outro apelido para o global environment) é o primeiro da lista. Logo, o seu global environment é o primeiro environment visitado pelo R. Por outro lado, o environment do pacote base é o último environment visitado.\n\nsearch()\n\n## [1]  \".GlobalEnv\"        \"tools:rstudio\"     \"package:stats\"\n## [4]  \"package:graphics\"  \"package:grDevices\" \"package:utils\"\n## [7]  \"package:datasets\"  \"package:methods\"   \"Autoloads\"\n## [10] \"package:base\"\nPortanto, o search path do R sempre segue essa mesma estrutura. Ele sempre se inicia pelo seu global environment, seguido dos environments dos pacotes que estão carregados em sua sessão, que por sua vez, são seguidos pelo environment Autoloads e pelo environment do pacote base.\nO environment Autoloads é basicamente responsável por carregar algumas bases de dados padrão do R. Porém, tais bases são carregadas de maneira lazy (preguiçosa), isto é, essas bases são carregadas para a memória RAM apenas no momento em que você efetivamente requisita por elas.\nJá o environment do pacote base é sempre o último environment dessa lista. Isso significa que, após esse environment, temos um environment vazio que encerra o mecanismo de pesquisa do R, como está demonstrado abaixo.\n\nparent.env(as.environment(\"package:base\"))\n\n&lt;environment: R_EmptyEnv&gt;\n\n\nPodemos representar este caminho de maneira gráfica, como apresentado na Figura 18.5. Perceba que, pelo fato do environment do pacote base ser o último da lista resultante de search(), o seu parent environment é justamente um environment vazio.\n\n\n\n\n\n\n\n\nFigura 18.5: Representação do search path do R\n\n\n\n\n\n\n\n18.7.4 Descrevendo o lexical scoping\nComo descrevemos anteriormente, a linguagem R utiliza um conjunto de regras (chamadas de lexical scoping) para encontrar o valor de seus objetos. Nessa seção, vamos explicar em mais detalhes que regras são essas.\nPrimeiro, o R sempre inicia o seu processo de busca pelo environment em que você chamou por esse objeto. Por exemplo, se você está chamando por esse objeto, diretamente no console do R, então, você está chamando esse objeto a partir de seu global environment, logo, o R começa a sua pesquisa por este environment. Contudo, se você está chamando por esse objeto, dentro do body de uma função, então, o R vai procurar primeiro dentro do environment de execução dessa função.\nSegundo, se o R não encontra o objeto em questão no primeiro environment pesquisado, ele começa a subir pela árvore genealógica de environments, até atingir o seu global environment. Ou seja, o R começa a procurar pelo objeto dentro do pai do primeiro environment pesquisado, depois, no pai do pai, e assim por diante.\nExplicando ainda esse mesmo ponto, de uma outra forma: se o R não encontrar o seu objeto em um environment x, ele parte para o parent environment desse environment x, caso ele não encontre o objeto neste outro environment, então, ele parte novamente para o próximo parent environment, e assim segue, até ele chegar em seu global environment (TEAM, 2020, seç. 3.5.2 e 4.3.4).\nTerceiro, a partir do momento em que o R atinge o seu global environment, o R começa a navegar pelo seu search path (TEAM, 2020, seç. 3.5.2). Ou seja, o R começa a subir pela sequência de environments descrita pela função search(). Então ele visita primeiro o seu global environment, depois, parte para os environments dos pacotes carregados em sua sessão, depois, para o environment Autoloads e o environment do pacote base.\nQuarto, ao subir pelo seu search path, se o R atingir o empty environment (que é o pai do environment do pacote base), o processo de busca é encerrado, e o R retorna um erro, lhe avisando que o objeto não pôde ser encontrado.\nVamos para alguns exemplos práticos. Suponha que você possua a função f() apresentada abaixo salva em seu global environment. Perceba que dentro do body dessa função, temos dois objetos (x e y) que o R precisa encontrar, no momento em que executar essa função.\nQuando essa função é avaliada, o R procura primeiro dentro do environment de execução dessa função. Pois é dentro desse environment que os objetos estão sendo chamados.\nDentro desse environment de execução, o R encontra o objeto y (que é igual a 10), porém, ele não consegue encontrar o objeto x. Consequentemente, o R parte para o pai do environment de execução da função, que no exemplo abaixo se trata do global environment. Ao chegar no global environment, o R encontra o vetor x e, por isso, tal vetor é utilizado pela função f().\n\nx &lt;- c(2, 5, 6, 1)\n\nf &lt;- function(){\n  y &lt;- 10\n  return(x + y)\n}\n\nf()\n\n[1] 12 15 16 11\n\n\nAgora, vamos partir para um exemplo mais profundo. Observe o exemplo abaixo, e tente responder a seguinte pergunta: porque o resultado do comando h(3) mostrado abaixo é 13, e não 25?. Para responder a essa pergunta, vamos recapitular ou esclarecer alguns pontos a seguir.\n\ny &lt;- 15\n\nf &lt;- function() {\n  y &lt;- 10\n  g &lt;- function(x) x + y\n  return(g)\n}\n\nh &lt;- f()\nh(3)\n\n[1] 13\n\n\nPrimeiro, vamos expor o caminho de environments que você (leitor) provavelmente achou que o R iria seguir durante o cálculo de h() (painel A), e, o caminho que ele efetivamente seguiu (painel B). Tais caminhos de environments estão expostos na Figura 18.6.\n\n\n\n\n\n\n\n\nFigura 18.6: Certos parent environments podem te surpreender\n\n\n\n\n\nPelo fato da função h() ter sido criada dentro do global environment, você provavelmente pressupôs que R_GlobalEnv fosse o parent environment do environment de execução dessa função. Porém, o parent environment de h() é na verdade o environment de execução da função f().\nPois o valor do objeto h (que está salvo no global environment) é a definição da função g(). Essa função g() foi criada dentro do environment de execução da função f(). Portanto, o parent environment da função que está armazenada dentro do objeto h é o environment de execução da função f().\nTendo isso em mente, lembre-se que toda função do R possui o que chamamos de function environment. Esse é o environment no qual essa função foi criada. Para mais, o function environment é sempre o pai do environment de execução dessa função.\nEsse exemplo mostra que as conexões de todos os objetos envolvidos em uma expressão, são definidos no instante em que aquela expressão é criada. Os manuais internos da linguagem, destacam essa característica como um dos princípios fundamentais de lexical scope:\n\n\n“R adheres to a set of rules that are called lexical scope. This means the variable bindings in effect at the time the expression was created are used to provide values for any unbound symbols in the expression.” (TEAM, 2020, seç. 4.3.4).\n\n\nIsso significa que essas conexões não são calculadas pelo R, no momento em que executamos essa expressão, e, sim, no momento em que definimos ou criamos essa expressão. Em outras palavras, o parent environment da função h() foi determinado no momento em que a função g() foi criada, e não, no momento em que executamos a função h().\nConcluindo, as regras que regem o lexical scoping no R são:\n\nO R sempre inicia o seu processo de busca pelo environment no qual você requisitou pelo objeto;\nSe ele não encontra o objeto no primeiro environment pesquisado, ele começa a percorrer os parent environments, até atingir o global environment;\nAo atingir o global environment, o R percorre o search path;\nAo atingir um empty environment, a procura é interrompida, e um erro é levantado indicando que o objeto não foi encontrado;",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>*Environments* ou ambientes no R</span>"
    ]
  },
  {
    "objectID": "Capítulos/16-environments.html#criando-objetos-em-outros-environments.",
    "href": "Capítulos/16-environments.html#criando-objetos-em-outros-environments.",
    "title": "18  Environments ou ambientes no R",
    "section": "18.8 Criando objetos em outros environments.",
    "text": "18.8 Criando objetos em outros environments.\nQuando utilizamos o operador de assignment &lt;- para criar um objeto, este objeto é sempre criado dentro do environment no qual você executou tal operador. Veja o exemplo abaixo.\nRepare que dois objetos numéricos (x e y) estão sendo criados. Contudo, esses dois objetos estão sendo criados em environments diferentes. Mais especificamente, o objeto x é criado dentro do meu global environment, enquanto o objeto y é criado dentro do environment de execução da função f().\n\nx &lt;- 10\n\nf &lt;- function(){\n  y &lt;- 100\n}\n\nPortanto, você pode utilizar o body de uma função, para criar objetos em environments diferentes de seu global environments. Além disso, você já viu que a função rlang::env() te permite fornecer novos objetos para serem armazenados dentro do novo environment criado pela função. No exemplo abaixo, estou criando dois objetos (nome e ano) dentro do environment env1.\n\nenv1 &lt;- rlang::env(nome = \"Pedro\", ano = 2022)\n\nComo uma outra alternativa, você pode também utilizar a função assign() quando desejar ser mais específico quanto ao environment em que o objeto deve ser criado. Em resumo, essa função executa o mesmo trabalho do operador de assignment (&lt;-), todavia, essa função nos oferece o argumento envir, no qual podemos definir o environment no qual o objeto será criado.\nComo exemplo, estou criando abaixo dois environments separados, env1 e env2. Repare que env1 é o parent environment de env2. A princípio, esses dois environments estão vazios.\n\nenv1 &lt;- rlang::env()\nenv2 &lt;- rlang::env(env1)\n\nSe eu desejasse criar um objeto dentro do environment env2, eu poderia utilizar a função assign() como exposto abaixo. Perceba que nesse exemplo, estou criando um objeto chamado x que contém o valor 10.\n\nassign(\"x\", 10, envir = env2)\n\nDepois de executar a função, podemos acessar o objeto x com o operador $, ou ainda, com a função get() que vimos em seções anteriores.\n\nenv2$x\n\n[1] 10\n\nget(\"x\", envir = env2)\n\n[1] 10\n\n\nPara além dessas opções, você pode utilizar o operador de super-assignment (&lt;&lt;-) para redefinir um objeto presente no parent environment do environment atual. Como exemplo, vamos estudar as funções f() e g() abaixo.\nPerceba que a função g() é criada dentro da função f(), logo, o parent environment da função g() é o environment de execução da função f(). Repare também que, dentro da função f() é criado um objeto chamado y, contendo inicialmente o valor 20.\nEntretanto, a partir do momento em que a função g() é executada dentro da função f(), o valor do objeto y se torna igual a 1. Isso ocorre, pelo fato da função g() executar dentro dela, uma expressão de super-assignment, mais especificamente, a expressão y &lt;&lt;- 1.\n\nf &lt;- function(){\n  y &lt;- 20\n  ### Primeiro print()\n  print(y)\n  g &lt;- function(){\n    y &lt;&lt;- 1\n  }\n  \n  g()\n  ### Segundo print()\n  print(y)\n}\n\n\nf()\n\n[1] 20\n[1] 1\n\n\nEm mais detalhes, quando utilizamos o operador &lt;&lt;-, ao invés do R criar o objeto dentro do environment onde a expressão foi executada, ele inicia uma busca dentro do parent environment, atrás de um objeto que possua o mesmo nome do objeto contido nessa expressão.\nOu seja, ao executar a expressão y &lt;&lt;- 1, o R começou a procurar dentro do parent environment de g() (que no exemplo acima, é o environment de execução de f()), por um objeto chamado y. Ao encontrar o objeto y que guarda o valor de 20, o R redefine o seu valor para 1.\nPortanto, em uma operação de super-assignment (&lt;&lt;-), o R procura pelo objeto envolvido na operação dentro do parent environment. Caso o R encontre esse objeto, ele vai redefinir o seu valor. Entretanto, se o R não encontrar esse objeto dentro do parent environment, então, ele vai criar (ou redefinir) esse objeto dentro de seu global environment.\nPor exemplo, observe as funções f() e g() abaixo. O parent environment de g() continua sendo o environment de execução de f(). Porém, perceba que dessa vez, não existe um objeto y sendo definido dentro de f(). Para mais, repare que antes de eu executar a função f(), não existe nenhum objeto y salvo em meu global environment.\nEm contrapartida, no instante em que eu executo a função f(), um novo objeto y contendo o valor 1 surge em meu global environment. Perceba que eu utilizo a função get() em conjunto com globalenv() para demonstrar que tal objeto foi encontrado dentro de meu global environment, e não em algum outro environment.\n\n### Perceba que ainda não existe nenhum\n### objeto chamado `y` em meu global environment\nprint(y)\n\n## Error in print(y) : object 'y' not found\n\nf &lt;- function(){\n  g &lt;- function(){\n    y &lt;&lt;- 1\n  }\n  \n  g()\n}\n\n\nf()\n\n### Agora, como num passe de mágica\n### surge um objeto chamado `y` em\n### meu global environment\nget(\"y\", envir = globalenv())\n\n[1] 1\n\n\nPortanto, dessa vez, o R não conseguiu encontrar um objeto chamado y dentro do environment de f() e, por isso, ele acabou criando este objeto y dentro de meu global environment.\n\n\n\n\nCHAMBERS, J. M. Extending R. Boca Raton, FL: CRC Press, 2016.\n\n\nTEAM, R. C. R Language Definition. Version 4.0.3 ed. [s.l.] R Foundation, 2020.\n\n\nWICKHAM, H. Advanced R. 2. ed. Boca Raton, Florida: CRC Press, 2015.",
    "crumbs": [
      "Funções e Loops: construindo os seus próprios programas e automatizando tarefas",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>*Environments* ou ambientes no R</span>"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html",
    "href": "Capítulos/exercises.html",
    "title": "Exercícios",
    "section": "",
    "text": "Capítulo 1 - Noções Básicas do R\nQuestão 1.1. Tente calcular algumas operações básicas:\n1.1.A) Qual é a soma entre 32397 e 55405?\n1.1.B) Calcule a soma total do conjunto de valores dispostos no vetor conj abaixo.\nconj &lt;- c(290, 34, 512, 54, 89, 10)\n1.1.C) Considerando que, \\(y = 3x^3 - 12x^2 + \\frac{1}{15}x+ 25\\), calcule o valor de \\(y\\) quando \\(x\\) é igual a 5.\nQuestão 1.2. Em cada item abaixo, temos uma mensagem de erro específica que supostamente apareceu em seu console. Tente explicar como ou porque essas mensagens podem aparecer em seu console. Em outras palavras, tente explicar o que essas mensagens significam, e qual foi o fato ocorrido que gerou esses erros:\n1.2.A) Erro: objeto 'logica' não encontrado.\n1.2.B) Error in bind_rows() : não foi possível encontrar a função \"bind_rows\"\n1.2.C) Error in library(dplyr) : there is no package called ‘dplyr’\nQuestão 1.3. As próximas questões vão implicitamente esperar que você utilize algumas dessas funções: sum(), mean(), abs() e sd(). Claro que, o R te oferece a liberdade de escrever as suas próprias funções, ou de desenhar o seu próprio caminho até as soluções dessas questões. Portanto, não se preocupe se você encontrar uma solução para as questões abaixo, que não incluem o uso dessas funções específicas.\n1.3.A) Considerando que a variável \\(X\\) segue uma distribuição normal, como você normalizaria (isto é, calcular o índice \\(Z\\) da distribuição) os valores presentes no vetor vec abaixo, que contém uma amostra de valores da variável \\(X\\).\nvec &lt;- c(0.5, 1.2, 2.5, 1.3, 2.2, 3.7)\n1.3.B) Utilizando novamente a variável vec, calcule o seu desvio médio.\nvec &lt;- c(0.5, 1.2, 2.5, 1.3, 2.2, 3.7)",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-2---fundamentos-do-r",
    "href": "Capítulos/exercises.html#capítulo-2---fundamentos-do-r",
    "title": "Exercícios",
    "section": "Capítulo 2 - Fundamentos do R",
    "text": "Capítulo 2 - Fundamentos do R\nQuestão 2.1. Em cada item desta questão, temos um simples print() de um objeto qualquer. Com base apenas nessa primeira imagem do objeto, tente identificar a estrutura (vetor, matriz, lista, data.frame) na qual esse objeto se encontra:\n2.1.A) Objeto 1:\n\n\n[[1]]\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n\n\n2.1.B) Objeto 2:\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n2.1.C) Objeto 3:\n\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,] \"MG\" \"MG\" \"DF\" \"SP\" \"MG\"\n[2,] \"MS\" \"DF\" \"DF\" \"SP\" \"DF\"\n[3,] \"DF\" \"DF\" \"MG\" \"SP\" \"MG\"\n[4,] \"MG\" \"SP\" \"MG\" \"SP\" \"MG\"\n[5,] \"SP\" \"SP\" \"MG\" \"DF\" \"MG\"\n\n\n2.1.D) Objeto 4:\n\n\n   id valor\n1   1 -0.29\n2   2 -0.30\n3   3 -0.41\n4   4  0.25\n5   5 -0.89\n6   6  0.44\n7   7 -1.24\n8   8 -0.22\n9   9  0.38\n10 10  0.13\n\n\n2.1.E) Objeto 5:\n\n\n$estado\n[1] \"MG\"\n\n$cidade\n[1] \"Belo Horizonte\"\n\n$n_municipios\n[1] 853\n\n$regiao\n[1] \"Sudeste\"\n\n\n2.1.F) Objeto 6:\n\n\n [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n\n\nQuestão 2.2. Em cada item abaixo, você deve criar um teste lógico que seja capaz de testar as condições postas no enunciado. Em alguns itens, será fornecido o código necessário para que você crie certos objetos (como v_seq, v_rep, lst, etc.), pois os testes lógicos se baseiam nesses objetos, ou devem ser aplicados diretamente sobre esses objetos. Portanto, lembre-se de copiar o código fornecido pela questão, colar em seu console, e apertar Enter para recriar esses objetos em sua sessão do R.\n2.2.A) Crie um teste lógico que seja capaz de identificar quais dos cinco objetos abaixo, são um vetor atômico.\n\n      v_seq &lt;- 10:25\n      v_rep &lt;- rep(\"abc\", times = 30)\n      lst &lt;- list(1:10)\n      mt &lt;- matrix(1:20, nrow = 4, ncol = 5)\n      dt &lt;- data.frame(15, \"A\", 1:10)\n\n2.2.B) Imagine que você receba em sua sessão do R, o objeto lst abaixo. Tente criar um teste lógico que possa confirmar se esse objeto é uma lista. Pelo código abaixo, você já sabe que este objeto é sim uma lista. Entretanto, nem sempre você terá acesso fácil ao código que criou certo objeto, ou, nem sempre você consegue prever que tipos de objetos serão criados a partir dos comandos escritos por outras pessoas. Por isso, quando você não conhece o input que você vai receber, é sempre importante se basear em teste lógicos que possam lhe assegurar que os seus objetos estão na estrutura desejada.\n\n      lst &lt;- list(\n        estado = \"MG\",\n        cidade = \"Belo Horizonte\",\n        n_municipios = 853,\n        regiao = \"Sudeste\"\n      )\n\n2.2.C) Utilizando a mesma lista lst do exercício acima, crie um teste lógico capaz de identificar se essa lista possui um item chamado “estado”. Primeiro, aplique o seu teste lógico sobre lst, e confira se o resultado do teste é TRUE. Em seguida, aplique esse mesmo teste lógico sobre a lista lst_sem_estado abaixo, e veja se o resultado do teste é de fato FALSE.\n\n      lst_sem_estado &lt;- list(\n        regiao = \"Sudeste\",\n        n_municipios = 853\n      )\n\n2.2.D) Suponha que você possua a tabela tab abaixo. Crie um teste lógico que possa identificar se a coluna total é do tipo double.\n\n      tab &lt;- data.frame(\n        unidade = c(\"Centro\", \"Gameleira\", \"Santa Efigênia\", \"Centro\",\n                    \"Barro Preto\", \"Centro\", \"Gameleira\", \"Centro\",\n                    \"Barro Preto\", \"Santa Efigênia\"),\n        mes = c(1, 1, 1, 2, 2, 3, 3, 4, 4, 4),\n        vendas = c(1502, 1430, 1100, 1200, 1443, 1621, 1854, 2200,\n                  1129, 1872),\n        total = c(5362.14, 5105.1, 3927, 4284, 5151.51, 5786.97, \n                  6618.78, 7854, 4030.53, 6683.04)\n      )\n\n2.2.E) Utilizando a mesma tabela tab acima, crie um teste lógico que possa identificar se a tabela possui exatamente 10 linhas, E, se essa tabela possui uma coluna chamada “vendas”, E, se a 3° coluna da tabela é do tipo character. Perceba no enunciado desta questão, os E’s separando cada condição a ser testada. Esses E’s estão indicando que essas condições são dependentes, ou, em outras palavras, elas precisam ser satisfeitas ao mesmo tempo.\n2.2.F) Se eu te der um número qualquer, referente a um ano específico (por exemplo, 2005 ou 1997), crie um teste lógico capaz de atestar se esse ano fornecido é um ano bissexto. Um ano bissexto é definido pelas seguintes condições: 1) a cada 4 anos, temos um ano bissexto; 2) a cada 100 anos, nós não devemos ter um ano bissexto; 3) a cada 400 anos temos um ano bissexto. Um detalhe: as últimas regras são mais importantes do que as primeiras, ou seja, a regra 3 prevalece sobre as regras 1 e 2, da mesma forma que a regra 2, prevalece sobre a regra 1. Caso essas definições não estejam muito claras, elas basicamente significam o seguinte: 1) o ano deve ser múltiplo de 4; 2) o ano não deve ser múltiplo de 100 a não ser que ele seja múltiplo de 400; 3) se o ano é múltiplo de 400, ele é obrigatoriamente um ano bissexto.\nQuestão 2.3. Em cada item abaixo, fornecemos um vetor formado pela função c(). Perceba que em cada um desses vetores, valores de diferentes tipos são misturados. Como definimos na seção Coerção no R, quando dados de diferentes tipos são colocados dentro de um vetor atômico, o R automaticamente realiza um processo de coerção, ao converter todos esses dados para um único tipo. O seu objetivo nessa questão é simplesmente adivinhar o tipo (double, integer, logical, ou character) de dado, para o qual esses dados serão convertidos. Caso esteja na dúvida, basta copiar e colar o código em seu console que você terá uma visão do resultado.\n2.3.A)\n\n      c(1.2, 2.4, \"3.1\", 1.9)\n\n2.3.B)\n\n      integers &lt;- 1:3\n      doubles &lt;- c(2.23, 9.87, 3.2)\n      \n      c(integers, doubles)\n\n2.3.C)\n\n      c(1.56, 3L, 1L, 5L,  2.32, 9.87)\n\n2.3.D)\n\n      c(TRUE, 1.5, FALSE)\n\n2.3.E)\n\n      c(\"p\", \"b\", \"c\", TRUE, 2L, 4.318)\n\nQuestão 2.4. Os próximos exercícios serão voltados para subsetting. Ao longo desses exercícios, estaremos utilizando o data.frame flights, que provêm do pacote nycflights13. Por isso, lembre-se que para ter acesso a essa tabela, é necessário que você chame por esse pacote em sua sessão, com o comando library(). Caso você não tenha o pacote instalado em sua máquina, execute o comando install.packages() mostrado abaixo.\n\n      ### Caso você não possua o pacote nycflights13\n      ### instalado, execute o comando:\n\n      ### install.packages(\"nycflights13\")\n\n      library(nycflights13)\n\n      ### Após o comando library() você\n      ### terá acesso à tabela flights\n      flights\n\n2.4.A) Encontre todas as linhas da tabela flights em que carrier seja igual a \"B6\", e que month seja igual a 5.\n2.4.B) Todos os voos descritos na tabela flights, correspondem a voos que ocorreram no aeroporto de Nova York, ao longo do ano de 2013. A coluna dep_delay apresenta o tempo de atraso (em minutos) no momento de partida do aeroporto, e a coluna arr_delay apresenta o tempo de atraso (em minutos) no momento de chegada ao aeroporto. Tendo isso em mente, no ano de 2013, quantos voos obtiveram um tempo de atraso total acima do tempo médio de atraso?\n2.4.C) Selecione as linhas da tabela flights que se encaixam em pelo menos uma dessas duas condições: 1) possuem um arr_delay abaixo de 2 minutos, e que o aeroporto de destino (dest) seja \"BOS\"; 2) cujo horário de partida programado (sched_dep_time) seja de 6:00 (ou 600), e que o mês de ocorrência do voô seja igual a 1.",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-4---importando-e-exportando-dados-com-readr-readxl-e-haven",
    "href": "Capítulos/exercises.html#capítulo-4---importando-e-exportando-dados-com-readr-readxl-e-haven",
    "title": "Exercícios",
    "section": "Capítulo 4 - Importando e exportando dados com readr, readxl e haven",
    "text": "Capítulo 4 - Importando e exportando dados com readr, readxl e haven\n\nLembre-se que, um arquivo de texto, nada mais é do que um arquivo simples contendo um conjunto de textos. Esses textos são organizados em linhas (onde cada linha representa uma observação diferente), e em cada linha desse arquivo, esses textos são separados em diferentes colunas, através de algum caractere especial, como vírgulas (,), ou pontos e vírgulas (;).\n\nQuestão 4.1. Como descrevemos ao longo desse capítulo, arquivos de texto são talvez o principal formato de arquivo utilizado hoje para o compartilhamento de dados. Por isso, os próximos exercícios buscam reforçar os conhecimentos a respeito desses arquivos.\n4.1.A) Considerando o arquivo de texto contido no objeto t abaixo, qual é o caractere especial que define as colunas desse arquivo? Dado que você tenha identificado esse caractere especial, quais comandos você utilizaria para ler esse arquivo?\n\nt &lt;- \"\nID~Valor/Grupo~Unidade\n1~2,5488/Marketing~Kg\n2~4,0101/Análise~Kg\n3~1097/Vendas~g\n4~12,76/Logísitica~Kg\"\n\n4.1.B) Perceba abaixo, que os objetos pac1 e pac2 são praticamente iguais. Perceba também, que estamos utilizando os mesmos comandos de importação para ambos os objetos. Porém, os resultados gerados pela função são diferentes em cada objeto. Tente identificar o que está causando essa diferença. Dado que você tenha identificado a fonte de tal diferença, como você ajustaria os comandos aplicados sobre cada objeto, de forma que os seus resultados sejam exatamente iguais?\n\npac1 &lt;- \"Setor;Produção;Receita;Gasto em P&D\nProdutos alimentícios;10828,37;199907,55;3358,36\nBebidas;759,53;28093,21;\nProdutos do fumo;69,99;8863,5;121,35\nProdutos têxteis;4153,97;25804,16;746,83\nProdutos de madeira;5088,78;15320,69;279,54\nCelulose e outras pastas;26,95;4245,19;216,7\nRefino de petróleo;75,48;114316,31;1550,73\nProdutos químicos;3179,52;133582,8;2914,09\nProdutos farmacêuticos;621,82;24972,07;1038,73\"\n\n\npac2 &lt;- \"Setor;Produção;Receita;Gasto em P&D\nProdutos alimentícios;10.828,37;199907,55;3358,36\nBebidas;759,53;28093,21;x\nProdutos do fumo;69,99;8863,5;121,35\nProdutos têxteis;4.153,97;25804,16;746,83\nProdutos de madeira;5.088,78;15320,69;279,54\nCelulose e outras pastas;26,95;4245,19;216,7\nRefino de petróleo;75,48;114316,31;1550,73\nProdutos químicos;3.179,52;133582,8;2914,09\nProdutos farmacêuticos;621,82;24972,07;1038,73\"\n\nreadr::read_delim(pac1, delim = \";\")\n\n## Rows: 9 Columns: 4                     \n## -- Column specification ----------------------------------------\n## Delimiter: \";\"\n## chr (1): Setor\n## \n## i Use `spec()` to retrieve the full column specification for this data.\n## i Specify the column types or set `show_col_types = FALSE` to quiet \n## this message.\n## # A tibble: 9 x 4\n##   Setor                      `Produ\\xe7\\xe3o`  Receita `Gasto em P&D`\n##   &lt;chr&gt;                                 &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n## 1 \"Produtos aliment\\xedcios\"          1082837 19990755         335836\n## 2 \"Bebidas\"                             75953  2809321             NA\n## 3 \"Produtos do fumo\"                     6999    88635          12135\n## 4 \"Produtos t\\xeaxteis\"                415397  2580416          74683\n## 5 \"Produtos de madeira\"                508878  1532069          27954\n## 6 \"Celulose e outras pastas\"             2695   424519           2167\n## 7 \"Refino de petr\\xf3leo\"                7548 11431631         155073\n## 8 \"Produtos qu\\xedmicos\"               317952  1335828         291409\n## 9 \"Produtos farmac\\xeauticos\"           62182  2497207         103873\n\nreadr::read_delim(pac2, delim = \";\")\n\n## Rows: 9 Columns: 4                                           \n## -- Column specification -----------------------------------------\n## Delimiter: \";\"\n## chr (2): Setor, Gasto em P&D\n## \n## i Use `spec()` to retrieve the full column specification for this data.\n## i Specify the column types or set `show_col_types = FALSE` to quiet \n## this message.\n## # A tibble: 9 x 4\n##   Setor                      `Produ\\xe7\\xe3o`  Receita `Gasto em P&D`\n##   &lt;chr&gt;                                &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         \n## 1 \"Produtos aliment\\xedcios\"            10.8  19990755 3358,36       \n## 2 \"Bebidas\"                          75953     2809321 x             \n## 3 \"Produtos do fumo\"                  6999       88635 121,35        \n## 4 \"Produtos t\\xeaxteis\"                  4.15  2580416 746,83        \n## 5 \"Produtos de madeira\"                  5.09  1532069 279,54        \n## 6 \"Celulose e outras pastas\"          2695      424519 216,7         \n## 7 \"Refino de petr\\xf3leo\"             7548    11431631 1550,73       \n## 8 \"Produtos qu\\xedmicos\"                 3.18  1335828 2914,09       \n## 9 \"Produtos farmac\\xeauticos\"        62182     2497207 1038,73  \n4.1.C) Considerando que você tenha chamado com sucesso pelo pacote readr, com o comando library(), você será capaz de executar os comandos mostrados abaixo sem problemas. Tais comandos buscam importar para o R, um arquivo chamado challenge.csv (a função readr_example() nos traz a localização desse arquivo challenge.csv em seu computador). Porém, perceba pelo resultado abaixo, que erros de importação ocorreram em 1000 linhas do arquivo.\n\nimport &lt;- read_csv(readr_example(\"challenge.csv\"))\n\n## -- Column specification ---------------------------------------\n## cols(\n##   x = col_double(),\n##   y = col_logical()\n## )\n\n## Warning: 1000 parsing failures.\n##  row col           expected     actual                     file\n## 1001   y 1/0/T/F/TRUE/FALSE 2015-01-16 'C:/Users/Pedro/Documen~\n## 1002   y 1/0/T/F/TRUE/FALSE 2018-05-18 'C:/Users/Pedro/Documen~\n## 1003   y 1/0/T/F/TRUE/FALSE 2015-09-05 'C:/Users/Pedro/Documen~\n## 1004   y 1/0/T/F/TRUE/FALSE 2012-11-28 'C:/Users/Pedro/Documen~\n## 1005   y 1/0/T/F/TRUE/FALSE 2020-01-13 'C:/Users/Pedro/Documen~\n## .... ... .................. .......... ........................\n## See problems(...) for more details.\nAo navegar por todo o conteúdo desse arquivo challenge.csv, você pode perceber que os dados contidos nesse arquivo foram incorretamente interpretados pela função read_csv(). Com isso, o seu trabalho será descobrir o que deu errado nesse processo, e ajustar os comandos de importação desse arquivo para que esse erro não ocorra.\nComo uma dica, abra o arquivo readr_example(\"challenge.csv\") e veja o seu conteúdo com cuidado. Com os comandos abaixo, você pode navegar por esse arquivo em uma janela de seu próprio RStudio. Portanto, tente descobrir o que está acontecendo de errado, e crie um comando que possa corrigir esse problema de importação.\n\nfile.edit(readr_example(\"challenge.csv\"))\n\n4.1.D) Considerando o objeto t abaixo, como você faria para importar corretamente esse arquivo? Vale ressaltar, que temos uma coluna contendo datas dentro do objeto t, e, até o momento, nós ainda não discutimos como o R interpreta ou lida com esse tipo de variável. Tal discussão é feita no capítulo 12 (Introdução à variáveis de tempo com lubridate). Portanto, não se preocupe caso você não consiga importar especificamente essa coluna da maneira correta. De qualquer maneira, ao final desse livro, nós fornecemos todo o código necessário para interpretar corretamente essa coluna.\n\nt &lt;- \"Data_execução*Unidades*Valor_compra\n20/01/2020*21*R$ 3049,50\n23/01/2020*502*R$ 1289,03\n25/01/2020*90*R$ 678,00\n02/02/2020*123*R$ 5401\n05/02/2020*45*R$ 1450,10\n07/02/2020*67*R$ 2320,97\n09/02/2020*187*R$ 6231,76\"\n\nQuestão 4.2. Copie e cole o endereço URL abaixo em seu navegador de preferência. Com esse link, uma planilha em Excel será baixada. Nessa planilha, temos alguns dados referentes aos municípios de Minas Gerais, ou, mais especificamente, a como esses municípios se encaixam no critério de Produção de Alimentos no âmbito da lei estadual 18.030/2009. Tente criar um comando que possa importar corretamente os dados dessa planilha para o R.\nhttps://github.com/pedropark99/Curso-R/blob/master/Dados/emater_icms_solidario.xlsx?raw=true",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-5---transformando-dados-com-dplyr",
    "href": "Capítulos/exercises.html#capítulo-5---transformando-dados-com-dplyr",
    "title": "Exercícios",
    "section": "Capítulo 5 - Transformando dados com dplyr",
    "text": "Capítulo 5 - Transformando dados com dplyr\nUma excelente forma de exercitar os conhecimentos adquiridos nesse capítulo é simplesmente brincar com bases de dados diferentes! Simplesmente, brinque! Tente encontrar fatos curiosos sobre cada base de dados. Faça perguntas (quantas pessoas se encaixam nessa categoria? Quantas mensagens foram enviadas durante esse dia? Qual é o custo médio de um curso de Medicina nos EUA?) e tente respondê-las com as funções que você descobriu nesse capítulo.\nPor isso, a maioria dos exercícios a seguir são exercícios práticos, que pedem por uma informação específica a respeito dos dados contidos em uma determinada tabela (isto é, um data.frame). Para chegar a essa informação, você pode utilizar as funções do pacote dplyr. O código necessário para ter acesso a cada uma dessas tabelas será fornecido em cada questão.\nO projeto TidyTuesday é um ótimo lugar para encontrarmos diferentes bases de dados. Pois todas essas bases estão hospedadas na pasta do projeto no GitHub, e grande parte delas estão guardadas em arquivos de texto (.txt, .csv, .fwf, etc.), os quais podemos ler e importar diretamente da página do GitHub para o R, sem a necessidade de baixar arquivos manualmente. Em resumo, o Tidy Tuesday é um projeto onde os integrantes disponibilizam toda semana, uma base de dados diferente. Qualquer pessoa pode submeter uma base de dados para o projeto, incluindo ou não, artigos e materiais que possam instruir os usuários sobre como analisar e compreender os dados contidos nessa base.\nQuestão 5.1. Antes de partirmos para as questões práticas, vamos exercitar o seu conhecimento sobre cada função mostrada nesse capítulo. Em cada item abaixo, eu forneço um conjunto de comandos. Cada conjunto inclui funções do pacote dplyr (como filter(), mutate(), group_by(), etc.) e uma tabela específica logo no início dessa cadeia de comandos, além do operador pipe (%&gt;%) conectando cada uma das funções aplicadas. Seu trabalho é ler esse conjunto de comandos, e descrever mentalmente (ou escrever em algum papel) o que cada uma das funções aplicadas estão fazendo nessa cadeia. Em outras palavras, seu objetivo é descrever o papel que cada função desempenha nessa cadeia de comandos.\n5.1.A) Descreva os comandos abaixo:\n\nlibrary(tidyverse)\nstarwars %&gt;% \n  count(sex, eye_color) %&gt;% \n  filter(sex == \"male\", eye_color == \"red\")\n\n5.1.B) Descreva os comandos abaixo:\n\nlibrary(tidyverse)\nvec &lt;- c(\"species\", \"homeworld\", \"films\", \"vehicles\", \"starships\")\n\nstarwars %&gt;% \n  select(-all_of(vec)) %&gt;% \n  group_by(sex) %&gt;% \n  summarise(peso_medio = mean(mass, na.rm = TRUE))\n\n5.1.C) Descreva os comandos abaixo:\n\nmpg %&gt;% \n  mutate(\n    pais_origem = case_when(\n      manufacturer %in% c(\"audi\", \"volkswagen\") ~ \"Alemanha\",\n      manufacturer %in% c(\"nissan\", \"honda\",\n                          \"subaru\", \"toyota\") ~ \"Japão\",\n      manufacturer == \"hyundai\" ~ \"Coréia do Sul\",\n      manufacturer == \"land rover\" ~ \"Inglaterra\",\n      manufacturer %in% c(\"dodge\", \"jeep\", \n                          \"chevrolet\", \"ford\",\n                          \"lincoln\", \"pontiac\",\n                          \"mercury\") ~ \"EUA\"\n    )\n  ) %&gt;% \n  count(pais_origem) %&gt;% \n  mutate(\n    prop = ( n * 100 ) / sum(n)\n  )\n\nQuestão 5.2. Vamos começar pela base tuition_income.csv, referente a semana 11 do TidyTuesday em 2020. Com os comandos abaixo, você pode rapidamente importar essa base de dados para o seu R. Os dados contidos nessa base, descrevem um conjunto de universidades dos Estados Unidos durante o período de 2010 a 2018, e oferecendo informações como: nome da faculdade/universidade (name); estado em que ela se encontra (state); preço ou custo total (em dólares) exigido pela graduação na instituição (total_price); ano ao qual os valores se referem (year); fica localizada dentro do campus ou fora dele? (campus); custo total líquido (custo total menos bolsas de auxílio e prêmios) pago pela graduação na instituição (net_cost).\n\nlibrary(tidyverse)\n\ngithub &lt;- \"https://raw.githubusercontent.com/rfordatascience/\"\narquivo &lt;- \"tidytuesday/master/data/2020/2020-03-10/tuition_income.csv\"\n\ndados &lt;- read_csv(paste0(github, arquivo))\n\n5.2.A) Com esses dados em mão, tente descobrir as 10 universidades que sofreram os maiores aumentos de preços durante o período descrito na base.\n5.2.B) Dado que você descubra a universidade que sofreu o maior aumento de preço dentre as 10 universidades descritas no item anterior, procure pelos dados dessa universidade ao longo da base. Com esses dados, discuta o momento em que houve a variação. Não tem resposta certa ou errada, apenas encontre os dados dessa universidade na base, e dê sua opinião sobre tamanha variação no preço dessa universidade.\nQuestão 5.3. Caso você tenha chamado pelo pacote dplyr com sucesso em sua sessão, através do comando library(), você tem acesso à tabela starwars, que é utilizada nessa questão. Tendo a tabela starwars em mãos, da coluna 1 até a coluna 11, descubra qual a coluna do tipo character que possui o maior número de valores únicos (ou o maior número de “grupos”) ao longo da base.\n\nlibrary(tidyverse)\nstarwars\n\n# A tibble: 87 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n 2 C-3PO       167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n 3 R2-D2        96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n 4 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 5 Leia Or…    150    49 brown      light      brown           19   fema… femin…\n 6 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 7 Beru Wh…    165    75 brown      light      blue            47   fema… femin…\n 8 R5-D4        97    32 &lt;NA&gt;       white, red red             NA   none  mascu…\n 9 Biggs D…    183    84 black      light      brown           24   male  mascu…\n10 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…\n# ℹ 77 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\nQuestão 4.4. Vamos agora, voltar rapidamente para a base de dados transf que visitamos ao longo deste capítulo. Lembre-se que você pode importar essa base diretamente para o seu R, ao copiar e colar os comandos abaixo.\n\nlibrary(tidyverse)\n\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo &lt;- \"transf_reform.csv\"\n\ntransf &lt;- read_csv2(paste0(github, pasta, arquivo))\n\n4.4.A) Qual é a receita média que o atendente Eduardo realiza com transferências destinadas à Alemanha?\n4.4.B) Qual é o país de destino com o qual a atendente Ana mais trabalha?\n4.4.C) Descubra quais foram as últimas transferências executadas por cada um dos 8 atendentes presentes em transf. Lembre-se que a coluna Data fornece o ponto do tempo em que a transferência foi executada.",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-6---introdução-a-base-de-dados-relacionais-com-dplyr",
    "href": "Capítulos/exercises.html#capítulo-6---introdução-a-base-de-dados-relacionais-com-dplyr",
    "title": "Exercícios",
    "section": "Capítulo 6 - Introdução a base de dados relacionais com dplyr",
    "text": "Capítulo 6 - Introdução a base de dados relacionais com dplyr\nO primeiro exercício desse capítulo, envolve duas tabelas publicadas na semana 11 do projeto Tidy Tuesday em 2020. Mais especificamente, as tabelas tuition_cost e salary_potential. A tabela tuition_cost descreve os custos de um curso de graduação em diferentes universidades dos EUA. Em contrapartida, a tabela salary_potential fornece uma estimativa do salário pontencial que um diploma de graduação de diversas universidades dos EUA pode fornecer a um profissional.\nNo Brasil, as faculdades privadas geralmente cobram por uma mensalidade fixa que abrange todos os custos mínimos. Já algumas universidades privadas, tendem a usar um sistema mais complexo, onde uma mensalidade base é cobrada, além de taxas por aulas práticas (para cobrir gastos com o uso de equipamentos) e taxas por matéria matriculada. Em outras palavras, um aluno de uma universidade privada brasileira que se matricula, por exemplo, em 4 matérias num dado semestre, geralmente paga um valor mensal que segue a estrutura: mensalidade base + taxa por aula prática (se houver alguma aula prática) + (4 \\(\\times\\) taxa por matrícula).\nPor outro lado, as universidades americanas possuem um sistema mais complexo de cobrança. Primeiro, a maior parte dos estudantes americanos optam por morar e se alimentar nos alojamentos da universidade, ao invés de se manterem na casa dos pais. A universidade cobra uma taxa específica para esses estudantes, que busca pagar justamente os custos deste alojamento e de sua alimentação. Tal custo é geralmente denominado de room and board fees. Segundo, universidades americanas cobram principalmente pelo seu “ensino” (e alguns outros serviços) e, por isso, a maior parte de seus preços envolvem o que chamamos de “tuition fees” (ou “taxa de ensino”). Terceiro, os valores divulgados pelas universidades são geralmente anuais, logo, se o tuition fees (ou room and board fees) de uma universidade qualquer é de $25 mil, isso significa que um curso de 4 anos nessa universidade custaria em torno de $100 mil.\nPortanto, as universidades americanas cobram, em geral, dois tipos de custos diferentes (room and board fees e tuition fees) e, esses custos são em sua maioria, anuais. Grande parte dos alunos acabam pagando ambos desses custos, logo, esses custos somados representam, para grande parte da população, o custo total por ano de uma universidade nos EUA.\nPara mais, as universidades americanas também cobram taxas de ensino (tuition fees) diferentes de acordo com o estado em que o aluno reside. Ou seja, uma universidade que está sediada no estado do Texas vai cobrar uma taxa mais barata para os alunos que moram no estado do Texas. Porém, os alunos que são originalmente de outros estados, e estão vindo para essa universidade vão pagar taxas maiores.\nQuestão 6.1. Suponha que você esteja interessado em realizar um curso de graduação em alguma das universidades descritas na tabela tuition_cost. Como você provavelmente não mora nos Estados Unidos, considere os custos referentes a alunos out of state em seus cálculos. Vale também ressaltar que os salários estimados na tabela salary_potential, assim como os custos na tabela tuition_cost, são anuais. Com base nas estimativas de salário presentes na tabela salary_potential e, com base nos custos descritos na tabela tuition_cost, tente calcular (para cada universidade) o tempo de trabalho necessário (após a graduação) para pagar pelo investimento que você aplicou no curso de graduação.\n\nlibrary(tidyverse)\n\ngithub &lt;- \"https://raw.githubusercontent.com/rfordatascience/\"\npasta &lt;- \"tidytuesday/master/data/2020/2020-03-10/\"\ncost &lt;- \"tuition_cost.csv\"\nsalary &lt;- \"salary_potential.csv\"\n\ntuition_cost &lt;- read_csv(paste0(github, pasta, cost))\nsalary_potential &lt;- read_csv(paste0(github, pasta, salary))\n\nQuestão 6.2. Todos os itens abaixo envolvem as tabelas consumidores e vendedores, alguns itens serão teóricos, outros, vão lhe requisitar o cálculo de alguma informação. Como esses cálculos envolvem as informações de ambas as tabelas, você será obrigado a aplicar um join entre elas para realizá-lo:\n\nlibrary(tidyverse)\n\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo1 &lt;- \"consumidor.csv\"\narquivo2 &lt;- \"vendedores.csv\"\n\nconsumidores &lt;- read_csv2(paste0(github, pasta, arquivo1))\nvendedores &lt;- read_csv2(paste0(github, pasta, arquivo2))\n\n6.2.A) Quais colunas representam as keys em ambas as tabelas?\n6.2.B) Na tabela consumidores, quais colunas representam uma primary key, e quais representam uma foreign key?\n6.2.C) Descubra o número de cidades nas quais cada vendedor atendeu os seus clientes.\nQuestão 6.3. Dado que você tenha importado as tabelas filmes e filmes_receita abaixo para o seu R, e, tendo em mente o que vimos nesse capítulo, explique porque o comando de join abaixo não funciona sobre essas tabelas. Dado que você encontre e explique o que está errado, como você ajustaria esse comando para que ele funcione normalmente?\n\nlibrary(tidyverse)\n\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo1 &lt;- \"filmes_dados.csv\"\narquivo2&lt;- \"filmes_receita.csv\"\n\nfilmes &lt;- read_csv2(paste0(github, pasta, arquivo1))\nfilmes_receita &lt;- read_csv2(paste0(github, pasta, arquivo2))\n\n\n### Porque esse comando de join\n### abaixo não funciona?\nfilmes %&gt;% \n  left_join(\n    filmes_receita\n  )",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-7---tidy-data-uma-abordagem-para-organizar-os-seus-dados-com-tidyr",
    "href": "Capítulos/exercises.html#capítulo-7---tidy-data-uma-abordagem-para-organizar-os-seus-dados-com-tidyr",
    "title": "Exercícios",
    "section": "Capítulo 7 - Tidy data: uma abordagem para organizar os seus dados com tidyr",
    "text": "Capítulo 7 - Tidy data: uma abordagem para organizar os seus dados com tidyr\nQuestão 7.1. Os itens desta questão vão utilizar a tabela world_bank_pop. Essa tabela advém do pacote tidyr, logo, caso você tenha chamado com sucesso por esse pacote através do comando library() você já possui acesso a essa tabela. A tabela world_bank_pop contém uma série histórica de vários dados populacionais para cada país descrito na base.\n\nworld_bank_pop\n\n# A tibble: 1,064 × 20\n   country indicator      `2000`  `2001`  `2002`  `2003`  `2004`  `2005`  `2006`\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 ABW     SP.URB.TOTL    4.16e4 4.20e+4 4.22e+4 4.23e+4 4.23e+4 4.24e+4 4.26e+4\n 2 ABW     SP.URB.GROW    1.66e0 9.56e-1 4.01e-1 1.97e-1 9.46e-2 1.94e-1 3.67e-1\n 3 ABW     SP.POP.TOTL    8.91e4 9.07e+4 9.18e+4 9.27e+4 9.35e+4 9.45e+4 9.56e+4\n 4 ABW     SP.POP.GROW    2.54e0 1.77e+0 1.19e+0 9.97e-1 9.01e-1 1.00e+0 1.18e+0\n 5 AFE     SP.URB.TOTL    1.16e8 1.20e+8 1.24e+8 1.29e+8 1.34e+8 1.39e+8 1.44e+8\n 6 AFE     SP.URB.GROW    3.60e0 3.66e+0 3.72e+0 3.71e+0 3.74e+0 3.81e+0 3.81e+0\n 7 AFE     SP.POP.TOTL    4.02e8 4.12e+8 4.23e+8 4.34e+8 4.45e+8 4.57e+8 4.70e+8\n 8 AFE     SP.POP.GROW    2.58e0 2.59e+0 2.61e+0 2.62e+0 2.64e+0 2.67e+0 2.70e+0\n 9 AFG     SP.URB.TOTL    4.31e6 4.36e+6 4.67e+6 5.06e+6 5.30e+6 5.54e+6 5.83e+6\n10 AFG     SP.URB.GROW    1.86e0 1.15e+0 6.86e+0 7.95e+0 4.59e+0 4.47e+0 5.03e+0\n# ℹ 1,054 more rows\n# ℹ 11 more variables: `2007` &lt;dbl&gt;, `2008` &lt;dbl&gt;, `2009` &lt;dbl&gt;, `2010` &lt;dbl&gt;,\n#   `2011` &lt;dbl&gt;, `2012` &lt;dbl&gt;, `2013` &lt;dbl&gt;, `2014` &lt;dbl&gt;, `2015` &lt;dbl&gt;,\n#   `2016` &lt;dbl&gt;, `2017` &lt;dbl&gt;\n\n\n7.1.A) A tabela world_bank_pop não se encontra em um formato tidy. Indique qual (ou quais) dos pressupostos que definem o formato tidy data é (ou são) violado por essa tabela e, explique o porquê disso.\n7.1.B) Repare que para além das colunas country e indicator, temos os dados populacionais espalhados ao longo de diversas colunas, onde cada coluna representa o valor dessa série histórica para um determinado ano. Utilize os conhecimentos desse capítulo para reunir essas várias colunas (que se referem a anos específicos da série) de modo que a base fique mais próxima de um formato tidy data.\n7.1.C) Filtre todas as linhas da tabela que descrevem a população total de cada país (isto é, as linhas em que o valor na coluna indicator é igual ao código \"SP.POP.TOTL\"), em seguida, tente calcular a variação da população total entre cada ano da série, para todos os países.",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-8---visualização-de-dados-com-ggplot2",
    "href": "Capítulos/exercises.html#capítulo-8---visualização-de-dados-com-ggplot2",
    "title": "Exercícios",
    "section": "Capítulo 8 - Visualização de dados com ggplot2",
    "text": "Capítulo 8 - Visualização de dados com ggplot2\nQuestão 8.1. Descubra qual o problema dos comandos abaixo, porque eles não geram um gráfico conforme esperado? Ou porque eles sequer geram algum gráfico? Vale destacar que, as tabelas mpg e diamonds estão disponíveis através do próprio pacote ggplot2. Portanto, assim que você chamar por esse pacote em sua sessão através do comando library(), você terá acesso a essas tabelas.\n8.1.A) Os comandos abaixo deveriam gerar um simples gráfico de dispersão, porém, um erro é criado. Porque esse erro ocorre? Copie e cole em seu R e veja esse erro com seus próprios olhos.\n\nggplot(data = mpg) %&gt;% \n  geom_point(\n    aes(x = displ, y = hwy)\n  )\n\n8.1.B) Os comandos abaixo deveriam gerar um gráfico de dispersão, onde os pontos seriam coloridos de acordo com os valores da coluna cut. Porém, o resultado é um gráfico de dispersão onde todos os pontos continuam pretos! O que ocorreu de errado nesses comandos?\n\nggplot(data = diamonds) +\n  geom_point(\n    aes(x = carat, y = price, fill = cut)\n  )\n\n8.1.C) Os comandos abaixo deveriam gerar um simples gráfico de barras, onde todas as barras deveriam ser coloridas pela cor azul (blue), porém, o resultado é um gráfico com barras coloridas de um vermelho salmão. Porque isso ocorre? Como podemos corrigir esses comandos para que todas as barras estejam coloridas de azul?1.\n\nggplot(diamonds) +\n  geom_bar(\n    aes(x = cut, fill = \"blue\")\n  )\n\n\n\n\n\n\n\n\nQuestão 8.2. Como exercício prático, utilize as funções do pacote ggplot para desenhar os objetos abaixo:\n8.2.A) Desenha a bandeira do movimento LGBTQ+. Como uma ajuda, nós temos abaixo um vetor contendo os códigos de cada cor presente nessa bandeira:\n\nvec_colors &lt;- c(\n  \"#a319ff\",\n  \"#1294ff\",\n  \"#19bf45\",\n  \"#ffdc14\",\n  \"#ff6a00\",\n  \"#ff1919\"\n)\n\n8.2.B) Considerando a função quadrática \\(y = x^2 + 15x + 32\\), desenhe a curva dessa função para o intervalo de 0 &lt; \\(x\\) &lt; 1000.\n8.2.C) Desenhe um conjunto de setas apontando para o texto \"Uma anotação muito importante\". Ou seja, desenhe o texto guardado no objeto anotacao abaixo em seu ggplot e, em seguida, tente desenhar um conjunto de setas apontando para essa anotação.\n\nanotacao &lt;- \"Uma anotação\\nmuito importante\"\n\nQuestão 8.3. Na média qual a qualidade de corte (cut) na tabela diamonds que gera o maior preço (price). Dito de outra forma, utilize um gráfico do ggplot para responder à seguinte pergunta: tendo a tabela diamonds em mãos, quais são os cortes descritos na coluna cut que geram os diamantes mais caros do mercado, isto é, que possuem os maiores preços na coluna price. Lembre-se que a tabela diamonds advém do próprio pacote ggplot2, logo, se você chamou por esse pacote em sua sessão com um comando library(), você já tem acesso à tabela diamonds.\n\nlibrary(ggplot2)\n\n### Ao chamar pelo pacote\n### ggplot2, você terá acesso\n### à tabela diamonds\ndiamonds\n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-9---configurando-componentes-estéticos-do-gráfico-no-ggplot2",
    "href": "Capítulos/exercises.html#capítulo-9---configurando-componentes-estéticos-do-gráfico-no-ggplot2",
    "title": "Exercícios",
    "section": "Capítulo 9 - Configurando componentes estéticos do gráfico no ggplot2",
    "text": "Capítulo 9 - Configurando componentes estéticos do gráfico no ggplot2\nQuestão 9.1. Voltando ao gráfico salvo no objeto plot_exemplo, o qual utilizamos ao longo de todo este capítulo. Seu objetivo nessa questão é criar um objeto tema que seja capaz de aproximar plot_exemplo o máximo possível do gráfico abaixo.\n\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\nplot_exemplo &lt;- ggplot(data = penguins) +\n  geom_point(\n    aes(\n      x = flipper_length_mm,\n      y = body_mass_g,\n      color = species)\n  ) +\n  labs(\n    title = \"Relação entre peso e comprimento da nadadeira \n    em diferentes\\nespécies de pinguim\",\n    x = \"Comprimento da nadadeira\",\n    y = \"Peso corporal\",\n    color = \"Espécie\"\n  )\n\n\ntema &lt;- theme(\n  # Coloque as específicações necessárias\n  # para que plot_exemplo se torne\n  # o gráfico abaixo\n)\n\nplot_exemplo + tema\n\n\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nQuestão 9.2. Em cada item abaixo, vamos utilizar novamente o gráfico salvo no objeto plot_exemplo. Esses itens vão lhe questionar sobre algum erro específico, ou, lhe requisitar.\n9.2.A) Faça a legenda do gráfico plot_exemplo desaparecer.\n9.2.B) Identifique porque o erro abaixo ocorre, e tente corrigí-lo.\n\nplot_exemplo +\n  theme(\n    text = element_text(color = \"#6E1450\"),\n    panel.grid = element_rect(fill = \"#6E1450\")\n  )\n\nErro: Only elements of the same class can be merged\nRun `rlang::last_error()` to see where the error occurred.\n9.2.C) Contorne a área do grid (isto é, a área em que as formas geométricas do gráfico são desenhadas pela função geom_*()) por uma linha de cor \"#222222\".",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-10---manipulação-e-transformação-de-strings-com-stringr",
    "href": "Capítulos/exercises.html#capítulo-10---manipulação-e-transformação-de-strings-com-stringr",
    "title": "Exercícios",
    "section": "Capítulo 10 - Manipulação e transformação de strings com stringr",
    "text": "Capítulo 10 - Manipulação e transformação de strings com stringr\nQuestão 10.1. Em cada item dessa questão, você deve criar uma expressão regular que represente a sequência de caracteres descrita no enunciado. Em seguida, você deve aplicar essa expressão regular sobre o vetor words, com o objetivo de extrair todas as palavras desse vetor que se encaixam nessa determinada expressão. O vetor words advém do pacote stringr, logo, se você conseguiu chamar por esse pacote em sua sessão através do comando library(), você já possui acesso a esse vetor.\n10.1.A) Um “b” ou “c” seguidos de um “a” e um “l”.\n10.1.B) Um caractere qualquer (exceto a letra “a”) imediatamente seguido por um “c”, que por sua vez, é seguido pelo final do string.\n10.1.C) A sequência “s-p-a-c-e” de caracteres, ou, um “e” imediatamente seguido por duas letras “s”, que por sua vez são seguidos imediatamente pelo final da linha.\n10.1.D) Crie uma expressão regular que possa encontrar todas as palavras presentes em words que contém exatos 3 caracteres. Você pode solucionar essa questão com a função str_length(). Porém, você deve utilizar uma expressão regular para encontrar essas palavras de 3 caracteres, portanto, esqueça momentaneamente que a função str_length() existe2.\nQuestão 10.2. Os itens desta questão vão trabalhar com o vetor compras. Para importar esse vetor para a sua sessão do R, copie e cole os comandos abaixo em seu console. Como você pode ver abaixo, cada elemento do vetor compras contém uma string bastante longa, tão longa que fui obrigado a utilizar a função str_trunc() para cortar parte do texto e apresentar abaixo apenas os 50 primeiros caracteres de cada string. Dentro de cada string, você possui um conjunto de dados referentes a uma compra realizada em uma loja durante o ano de 2020.\n\nlibrary(tidyverse)\n\ngithub &lt;- \"https://raw.githubusercontent.com/pedropark99/\"\npasta &lt;- \"Curso-R/master/Dados/\"\narquivo &lt;- \"compras_completo.txt\"\n\ncompras &lt;- read_lines(paste0(github, pasta, arquivo))\n\nstr_trunc(head(compras), width = 50, ellipsis = \"~\")\n\n[1] \"Márcio390.287.917-210akqzS2tk$URMcLOk5Q2356772.25~\"\n[2] \"Igor944.236.416-254tLo8&S9WtXg05fsdU2188525.212/0~\"\n[3] \"Márcio395.304.955-57pfwji9Z4Q6dZxSWZV7#7Z$J218160~\"\n[4] \"Isabela322.900.842-74K5D6b$xAnY&QJ1$XQzE2f1554399~\"\n[5] \"Álvaro475.767.740-583WWonElfbisKD1GiIVS225066.161~\"\n[6] \"Rafael031.357.966-89bOzZ7#2JBcsd!sWzaeNY1866117.7~\"\n\n\n10.2.A) Como você pôde ver acima, os dados estão misturados em cada string. Em outras palavras, a loja que coletou esses dados não se preocupou em utilizar um separador especial para separar as variáveis em diferentes colunas. Agora, eles estão todos juntos, um do lado do outro, em uma única coluna.\nEm resumo, cada string guarda as informações de 7 variáveis diferentes: nome do consumidor; CPF do consumidor; código de identificação da venda; código de identificação do produto comprado; valor pago por unidade; quantidade adquirida; horário da compra. Precisamente nessa ordem. Como um guia, temos as figuras 10.8 e 10.9 abaixo. Cada figura apresenta uma “metade” específica do primeiro string presente no vetor compras (o string é muito grande, por isso, optou-se por dividi-lo em duas figuras). Cada figura, busca descrever a estrutura seguida por cada string do vetor compras.\n\n\n\n\n\nDescrição dos 39 primeiros caracteres de cada string presente em compras\n\n\n\n\n\n\n\n\n\nDescrição dos 43 últimos caracteres de cada string presente em compras\n\n\n\n\nO seu trabalho é utilizar as ferramentas que você viu nesse capítulo, para extrair essas 7 variáveis e alocá-las em colunas separadas de um data.frame. Esse não é um exercício muito simples, mas ele também transmite certa realidade. Há diversas bases de dados e análises reais na indústria, que exigem um uso intensivo de ferramentas de extração e localização de texto, como é o caso desse exercício sobre o vetor compras.\nPara realizar essa atividade, você não precisa necessariamente utilizar apenas expressões regulares por todo o caminho. Dado a complexidade dessas strings, é interessante e, até mais simples, que você misture um pouco suas técnicas, ao trabalhar com partes (ou subsets) específicos das strings com str_length() e str_sub() e, em seguida, aplicar expressões regulares sobre as partes restantes das strings.\nCaso você opte por utilizar uma única expressão regular para resolver esse item, é fundamental que você compreenda bem como os valores de cada variável podem variar em cada string. Em outras palavras, para que você seja capaz de descrever, com precisão, cada parte da sequência de caracteres que compõe essas strings, você precisa saber, por exemplo: quais caracteres podem aparecer, na parte que apresenta o código de identificação da venda; ou ainda, quantos dígitos são permitidos no campo do valor unitário do produto? Para ter essa compreensão, leia atentamente às figuras 10.8 e 10.9.\n10.2.B) Volte ao vetor compras e extraia de cada string, apenas a parte correspondente à data e horário da compra. Com esses valores em mãos, tente capturar o dia de cada data, por último, realize uma contagem sobre esses dias, e descubra o dia do mês em que essa loja possui o maior número de vendas.\n10.2.C) Selecione os 3 primeiros dígitos do CPF do consumidor de cada string.",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-12---introdução-à-variáveis-de-tempo-com-lubridate",
    "href": "Capítulos/exercises.html#capítulo-12---introdução-à-variáveis-de-tempo-com-lubridate",
    "title": "Exercícios",
    "section": "Capítulo 12 - Introdução à variáveis de tempo com lubridate",
    "text": "Capítulo 12 - Introdução à variáveis de tempo com lubridate\nQuestão 12.1. Cada item abaixo pode lhe pedir para identificar a origem de algum erro, ou de algum resultado inesperado, ou ainda, requisitar que você trabalhe com algum objeto específico para um dado fim.\n12.1.A) Perceba abaixo, que ao transformarmos o vetor vec para o tipo Date, alguns elementos são transformados para valores NA. Porque essa transformação ocorre? Há alguma solução clara para isso?\n\nvec &lt;- c(\"2020-01-17\", \"2020-02-21\", \"2020-02-30\", \n         \"2020-04-12\", \"2020-13-19\", \"2020-09-87\")\n\n\nas.Date(vec)\n\n[1] \"2020-01-17\" \"2020-02-21\" NA           \"2020-04-12\" NA          \n[6] NA          \n\n\n12.1.B) Que comandos você utilizaria para transportar o vetor vec abaixo para o tipo Date?\n\nvec &lt;- c(\"02, 02, 2020\", \"15, 03, 2020\", \"21, 04, 2020\",\n         \"19, 09, 2020\", \"22, 06, 2020\", \"25, 12, 2020\")\n\n12.1.C) Como definimos neste capítulo, no R, dados do tipo date-time são armazenados como o número de segundos desde a meia noite de 01 de janeiro de 1970. Porém, por alguma razão inesperada, quando eu crio um objeto contendo este exato ponto no tempo, e retiro a sua classe com a função unclass(), percebo que este ponto foi armazenado como o valor 10800. Porque isso ocorre? Ele não deveria ser armazenado como zero?\n\nponto &lt;- as.POSIXct(\"1970-01-01 00:00:00\")\nunclass(ponto)\n\n[1] 10800\nattr(,\"tzone\")\n[1] \"\"\n\n\nQuestão 12.2. Como definimos anteriormente neste capítulo, diversos programas, incluindo o Excel, armazenam valores do tipo date-time como o número de dias ou de segundos, em relação a um ponto específico de origem na escala do tempo. Logo abaixo, temos a tabela dados_excel. Essa tabela nos apresenta na coluna como_numero, o número aproximado no Excel que representa os valores do tipo date-time presentes na coluna como_data. Ou seja, no Excel, o ponto \"20/02/2020 03:45:00\" é armazenada como o número decimal 43.881,15625. Considerando que, no sistema Windows, o Excel utiliza a data 30 de Dezembro de 1899 (ou \"1899-12-30\") como o seu ponto de origem, o seu trabalho nessa questão é converter os números presentes no vetor numero_no_excel para o tipo POSIXct, de modo que o resultado contenha os mesmos instantes apresentados no vetor datetime_no_excel. Dica: configure o argumento tz para o fuso horário UTC, dessa forma, você evita em sua conversão, possíveis adições/subtrações automáticas que emergem da diferença entre o fuso de seu sistema operacional e o fuso UTC.\n\ndatetime_no_excel &lt;- c(\n  \"20/02/2020 03:40:00\",\n  \"20/02/2020 03:45:00\",\n  \"20/02/2020 03:50:00\",\n  \"20/02/2020 03:55:00\",\n  \"20/02/2020 04:00:00\"\n)\n\nnumero_no_excel &lt;- c(\n  43881.1527777778,\n  43881.15625,\n  43881.159722222226,\n  43881.1632060185, \n  43881.1666666667\n)\n\ndados_excel &lt;- data.frame(\n  como_data = datetime_no_excel,\n  como_numero = numero_no_excel\n)\n\nprint(dados_excel)\n\n            como_data como_numero\n1 20/02/2020 03:40:00    43881.15\n2 20/02/2020 03:45:00    43881.16\n3 20/02/2020 03:50:00    43881.16\n4 20/02/2020 03:55:00    43881.16\n5 20/02/2020 04:00:00    43881.17",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-14---funções",
    "href": "Capítulos/exercises.html#capítulo-14---funções",
    "title": "Exercícios",
    "section": "Capítulo 14 - Funções",
    "text": "Capítulo 14 - Funções\nQuestão 14.1. Em cada item abaixo, você deve construir uma função que se encaixe nos requisitos explicitados:\n14.1.A) Construa uma função que aceite um número variável de argumentos, e que, retorne esses argumentos em uma lista.\n14.1.B) Construa uma função que receba o raio de um círculo, e que calcule a área desse círculo. Vale destacar que, o R já possui um objeto pré-definido chamado pi que contém o número pi (\\(\\pi\\)).\nQuestão 14.2. Tente construir uma função que receba uma palavra qualquer como input e, que retorne o scrabble score para essa palavra como output. O scrabble score é basicamente uma pontuação baseada nas letras que estão presentes em um uma palavra. Cada letra possui uma pontuação diferente e, você deve somar a pontuação de cada letra para chegar ao scrabble score da palavra. Em mais detalhes, as letras A, E, I, O, U, L, N, R, S e T valem 1 ponto cada uma; as letras D e G, valem 2 pontos; as letras B, C, M e P, 3 pontos; as letras F, H, V, W e Y, 4 pontos; a letra K, 5 pontos; as letras J e X, 8 pontos; as letras Q e Z, 10 pontos. Tendo as pontuações do parágrafo anterior em mente, temos que a palavra “bateria” possui um scrabble score total de 9 pontos (\\(3 + 1 + 1 + 1 + 1 + 1 + 1 = 9\\)). Por outro lado, a palavra “metallica” possui um total de 13 pontos. Vale destacar que o jogo scrabble foi inicialmente desenvolvido para o alfabeto da língua inglesa, o qual não possui acentos de nenhuma natureza. Portanto, para que você não tenha que lidar com tal complexidade, considere que sua função vai receber apenas letras sem acentos. Como um exemplo de teste, você pode aplicar a sua função sobre cada palavra contida no vetor w abaixo, e verificar se o resultado de sua função equivale aos elementos correspondentes do vetor p. Ou seja, se a sua função aplicada à terceira palavra de w, retornar um valor diferente do terceiro elemento de p, sua função não está funcionando corretamente.\n\nw &lt;- c(\"isabela\", \"caderno\", \"mouse\", \"elevador\",\n       \"solar\", \"gaveta\", \"porta\", \"eduardo\")\n\np &lt;- c(9, 10, 7, 12, 5, 10, 7, 9)",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-15---loops",
    "href": "Capítulos/exercises.html#capítulo-15---loops",
    "title": "Exercícios",
    "section": "Capítulo 15 - Loops",
    "text": "Capítulo 15 - Loops\nQuestão 15.1. Responda as questões abaixo:\n15.1.A) O que acontece se executarmos o for loop abaixo:\n\nx &lt;- vector(\"integer\")\n\nfor(i in seq_along(x)){\n  print(i)\n}\n\n15.1.B) Porque o loop abaixo é um loop infinito?\n\nx &lt;- 1\nwhile ( x &lt; 10 ) {\n  print(x)\n  x &lt;- x + 1\n  if (x %% 5 == 0) {\n    x &lt;- 1\n  }\n}\n\n15.1.C) Quantas vezes o for loop abaixo vai repetir os comandos descritos em seu body?\n\ndf &lt;- data.frame(id = 1:10)\nfor(name in letters[1:24]){\n  df[[name]] &lt;- NA\n}\n\n15.1.D) Porque o for loop abaixo está retornando numeric(0) na segunda iteração? Qual é a fonte do erro?\n\ny &lt;- vector(\"integer\")\nx &lt;- 1:10\nfor(i in 1:length(y)){\n  print(x[i] + 1)\n}\n\n[1] 2\nnumeric(0)\n\n\nQuestão 15.2. Crie um loop que seja capaz de encontra o valor máximo do vetor vec abaixo. Em outras palavras, construa um loop que consiga encontrar o mesmo resultado do comando max(vec).\n\nvec &lt;- c(\n  5.2, 6.1, 2.3, 7.4, 1.1, 3.6,\n  7.2, 8.1, 3.3, 4.5, 0.8, 5.4\n)\n\nQuestão 15.3. Ao longo deste capítulo, nós não mostramos um exemplo de um loop aninhado (nested loop), isto é, um loop que contém um outro loop dentro de si. Porém, é completamente permitido que você construa camadas e camadas de loops desta maneira. Seu objetivo neste exercício é desenvolver um loop aninhado que preencha a matriz mt abaixo. Ao final do loop, cada elemento dessa matriz deve conter o resultado da multiplicação dos índices que localizam esse elemento nessa matriz. Ou seja, o elemento da 9° linha da 10° coluna, deve conter o valor \\(9 \\times 10 = 90\\); já o elemento da 15° linha da 3° coluna, deve conter o valor \\(15 \\times 3 = 45\\); e assim por diante.\n\nmt &lt;- matrix(ncol = 30, nrow = 30)",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-16---functional-programming-com-purrr",
    "href": "Capítulos/exercises.html#capítulo-16---functional-programming-com-purrr",
    "title": "Exercícios",
    "section": "Capítulo 16 - Functional programming com purrr",
    "text": "Capítulo 16 - Functional programming com purrr\nQuestão 16.1. Os itens dessa questão foram inspirados em um exercício da obra de WICKHAM; GROLEMUND (2017). Considerando a tabela diamonds do pacote ggplot2 (lembre-se que você pode acessar essa tabela através do comando ggplot2::diamonds), utilize as funções da família map() para calcular:\n16.1.A) A média de todas as colunas numéricas.\n16.1.B) O número de valores distintos em todas as colunas não numéricas.\nQuestão 16.2. Os itens dessa questão foram retirados de um exercício da obra de WICKHAM; GROLEMUND (2017).\n16.2.A) Tente explicar com suas palavras, o que exatamente o comando abaixo está fazendo. Porque cada elemento da lista resultante contém cada vez mais elementos?\n\nmap(1:5, rnorm)\n\n[[1]]\n[1] 0.8041895\n\n[[2]]\n[1] -0.05710677  0.50360797\n\n[[3]]\n[1]  1.0857694 -0.6909538 -1.2845994\n\n[[4]]\n[1]  0.04672617 -0.23570656 -0.54288826 -0.43331032\n\n[[5]]\n[1] -0.6494716  0.7267507  1.1519118  0.9921604 -0.4295131\n\n\n16.2.B) Considerando o comando abaixo, o que exatamente ele está fazendo de diferente do comando mostrado no item anterior? Porque o resultado é diferente?\n\nmap(1:5, rnorm, n = 5)\n\n[[1]]\n[1] 2.2383041 0.7206537 2.7579031 1.5607461 0.5472160\n\n[[2]]\n[1] 1.1679567 0.8334295 0.9344094 0.4362179 3.1565370\n\n[[3]]\n[1] 3.832047 2.772671 3.266137 2.623297 5.441365\n\n[[4]]\n[1] 3.204661 3.945123 4.250141 4.618243 3.827376\n\n[[5]]\n[1] 2.776100 3.736386 5.358729 4.988955 4.059351\n\n\nQuestão 16.3. Em cada item abaixo, você deve utilizar uma das funções map para aplicar um teste lógico sobre os elementos de uma lista e, filtrar os elementos dessa lista de acordo com os resultados desse teste lógico.\n16.3.A) Considerando a lista l abaixo, utilize uma das funções map para descobrir que elementos de l possuem comprimento maior que 3.\n\nl &lt;- list(\n  c(1, 5),\n  c(5, 6, 1),\n  c(9, 8, 9, 0, 0, 1),\n  c(7, 4, 4, 2),\n  c(4, 5)\n)\n\n16.3.B) Elimine todos os elementos da lista l abaixo, que possuem pelo menos um valor NA.\n\nl &lt;- list(\n  c(1, 1, 2),\n  c(6, 7, NA, 9),\n  c(NA, NA, 1, 3, 4),\n  c(3, 3, 1, 8),\n  c(6, 6, 6)\n)",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#capítulo-18---environments-ou-ambientes-no-r",
    "href": "Capítulos/exercises.html#capítulo-18---environments-ou-ambientes-no-r",
    "title": "Exercícios",
    "section": "Capítulo 18 - Environments ou ambientes no R",
    "text": "Capítulo 18 - Environments ou ambientes no R\nQuestão 18.1. Observe o exemplo abaixo, em que eu acabo de iniciar uma nova sessão no R, e crio logo em seguida, dois novos environments (env1 e env2). Através dos resultados de parent.env() abaixo, sabemos que o global environment é o pai de env1, enquanto env1 é o pai de env2. Portanto, os itens desta questão focam na relação entre esses três environments (env1, env2 e o global environment). Agora, suponha que eu crie dois objetos (obj e i) dentro de env1, e, um objeto (i) dentro de env2.\n\n### Acabei de iniciar um nova sessão no R\nenv1 &lt;- rlang::env()\nenv2 &lt;- rlang::env(env1)\n\nenv1\n\n&lt;environment: 0x5fcbb2033ec0&gt;\n\nenv2\n\n&lt;environment: 0x5fcbb1f19bc0&gt;\n\nparent.env(env1)\n\n&lt;environment: R_GlobalEnv&gt;\n\nparent.env(env2)\n\n&lt;environment: 0x5fcbb2033ec0&gt;\n\nenv1$obj &lt;- c(10, 20)\nenv1$i &lt;- 1\n\nenv2$i &lt;- 2\n\n18.1.A) Abaixo, estou utilizando a função eval() para executar a expressão obj[i] &lt;&lt;- obj[i] + 1 dentro do environment env1. O que vai acontecer nesse caso? Em que environment será salvo o resultado dessa expressão?\n\neval(quote(obj &lt;&lt;- obj[i] + 1), envir = env1)\n\n18.1.B) Abaixo, estou utilizando novamente a função eval() para executar a expressão obj[i] &lt;&lt;- obj[i] + 1 dentro de um environment específico. Porém, dessa vez, estou executando essa expressão dentro do environment env2. O que vai acontecer nesse caso? O resultado da expressão será salvo em um environment diferente do item anterior? Lembre-se, é muito importante começar com uma sessão limpa do R, e recriar os environments env1 e env2 para testar o comando abaixo.\n\neval(quote(obj &lt;&lt;- obj[i] + 1), envir = env2)\n\nQuestão 18.2. Observe os exemplos em cada item abaixo, e tente prever qual será o resultado de cada comando print().\n18.2.A)\n\nx &lt;- 1\nf &lt;- function(x){\n  x &lt;- 15\n  print(x + 1)\n}\n\n### Qual será o resultado do comando print()\n### executado por f() ?\nf()\n\n18.2.B)\n\n### Iniciei uma nova sessão no R\nobj &lt;- c(1, 2)\n\nenv1 &lt;- rlang::env()\nenv2 &lt;- rlang::env(env1)\nenv3 &lt;- rlang::env(env2)\n\nenv1$obj &lt;- c(10, 20)\nenv3$obj &lt;- c(100, 200)\n\neval(quote(obj &lt;&lt;- obj + 1), envir = env2)\n\n### Qual é o resultado do print() abaixo ?\nprint(get(\"obj\", envir = env1))\n\n\n\n\n\nWICKHAM, H.; GROLEMUND, G. R for Data Science. Sebastopol, CA: O’Reilly Media, Inc., 2017.",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/exercises.html#footnotes",
    "href": "Capítulos/exercises.html#footnotes",
    "title": "Exercícios",
    "section": "",
    "text": "Esse item foi inspirado em um exercício 7 de WICKHAM; GROLEMUND (2017) (p. 12)↩︎\nEste exercício foi diretamente extraído da obra de WICKHAM; GROLEMUND (2017) (p. 203)↩︎",
    "crumbs": [
      "Apêndices",
      "Exercícios"
    ]
  },
  {
    "objectID": "Capítulos/references.html",
    "href": "Capítulos/references.html",
    "title": "Referências bibliográficas",
    "section": "",
    "text": "ADLER, J. R in a Nutshell. Sebastopol, CA: O’Reilly,\n2010.\n\n\nBRAGA, D.; ASSUNCAO, G.; HIDALGO, L. PNADcIBGE:\nDownloading, Reading and Analysing PNADC Microdata. [s.l.]\nCRAN R Package, 2020.\n\n\nCHAMBERS, J. M. Software for Data Analysis: Programming with\nR. New York, NY: Springer, 2008.\n\n\nCHAMBERS, J. M. Extending R. Boca Raton, FL: CRC Press,\n2016.\n\n\nCHANG, W. R Graphics\nCookbook. Sebastopol, CA: O’Reilly Media, Inc., 2012.\n\n\nCHASE, W. Custom fonts and plot quality with ggplot on\nWindows, 2019. Disponível em: &lt;https://www.williamrchase.com/post/custom-fonts-and-plot-quality-with-ggplot-on-windows/&gt;\n\n\nFRIEDL, J. E. F. Mastering Regular Expressions. 3. ed.\nSebastopol, CA: O’Reilly Media, Inc., 2006.\n\n\nGILLESPIE, C.; LOVELACE, R. Efficient R\nProgramming. Sebastopol, CA: O’Reilly Media, Inc., 2017.\n\n\nGROLEMUND, G. Hands-On Programming\nwith R. Sebastopol, CA: O’Reilly Media, Inc., 2014.\n\n\nGROTHENDIECK, G.; PETZOLDT, T. Date and Time Classes in R. R\nNews, v. 4, n. 1, p. 29–31, 2004.\n\n\nHARALAMBOUS, Y. Fonts & Encodings. Sebastopol, CA:\nO’Reilly Media, Inc., 2007.\n\n\nHUGHES, J. F. et al. Computer Graphics: Principles and\nPractice. 3. ed. [s.l.] Addison-Wesley, 2014.\n\n\nIBGE. Pesquisa\nNacional por Amostra de Domicílios Contínua: Notas\nTécnicas. Rio de Janeiro: Instituto Brasileiro de Geografia\ne Estatística, 2019.\n\n\nIHAKA, R.; GENTLEMAN, R. R: A Language for Data Analysis and Graphics.\nJournal of Computational and Graphical Statistics, v.\n5, n. 3, p. 299–314, 1996.\n\n\nLONG, J. D.; TEETOR, P. R\nCookbook. 2nd. ed. Sebastopol, CA: O’Reilly Media, Inc.,\n2019.\n\n\nMCDONNELL, R. M.; OLIVEIRA, E.; GIANNOTTI, R. cepR:\nBusca CEPs Brasileiros. [s.l.] CRAN R Package, 2020.\n\n\nMURRELL, P. R Graphics. 1. ed. Boca Raton, FL: Chapman\n& Hall - CRC Press, 2006.\n\n\nNIELD, T. Getting Started with SQL: A Hands-on Approach for\nBeginners. 1. ed. Sepastopol, CA: O’Reilly Media, 2016.\n\n\nPEDERSEN, T. L. Updates to ragg and systemfonts, 2020.\nDisponível em: &lt;https://www.tidyverse.org/blog/2020/05/updates-to-ragg-and-systemfonts/&gt;\n\n\nPENG, R. D. R Programming for\nData Science. [s.l.] Leanpub, 2015.\n\n\nPEREIRA, R. H. et al. geobr:\nLoads Shapefiles of Official Spatial Data Sets of Brazil.\n[s.l.] IPEA - Instituto de Pesquisa Econômica Aplicada; CRAN R Package,\n2020.\n\n\nPETRUZALEK, D. read.dbc:\nRead Data Stored in DBC (Compressed DBF) Files. [s.l.] CRAN\nR Package, 2016.\n\n\nRIPLEY, B. D.; HORNIK, K. Date-Time Classes. R News, v.\n1, n. 2, p. 8–11, 2001.\n\n\nSIQUEIRA, R. P. sidrar:\nAn Interface to IBGE’s SIDRA API. [s.l.] CRAN R Package,\n2020.\n\n\nTEAM, R. C. R\nLanguage Definition. Version 4.0.3 ed. [s.l.] R Foundation,\n2020b.\n\n\nTEAM, R. C. An\nIntroduction to R: A Programming Environment for Data Analysis and\nGraphics. Version 4.0.3 ed. [s.l.] R Foundation, 2020a.\n\n\nWICKHAM, H. Tidy Data.\nThe Journal of Statistical Software, v. 59, 2014.\n\n\nWICKHAM, H. Advanced\nR. 2. ed. Boca Raton, Florida: CRC Press, 2015a.\n\n\nWICKHAM, H. R\nPackages. Sebastopol, CA: O’Reilly Media, Inc., 2015b.\n\n\nWICKHAM, H. ggplot2: Elegant\nGraphics for Data Analysis. 2. ed. [s.l.] Springer\nInternational Publishing, 2016.\n\n\nWICKHAM, H. et al. Welcome\nto the Tidyverse. Journal of Open Source Software,\nv. 4, n. 43, p. 1686, 2019.\n\n\nWICKHAM, H.; GROLEMUND, G. R\nfor Data Science. Sebastopol, CA: O’Reilly Media, Inc.,\n2017.\n\n\nWILKINSON, L. The Grammar of\nGraphics. 2. ed. Verlag, NY: Springer, 2005.",
    "crumbs": [
      "Apêndices",
      "Referências bibliográficas"
    ]
  }
]